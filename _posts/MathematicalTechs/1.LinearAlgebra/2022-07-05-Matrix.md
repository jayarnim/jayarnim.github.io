---
order: 2
title: Matrix
date: 2022-07-05
categories: [MATHEMATICAL TECHS, 1.linear algebra]
tags: [Mathematics]
math: true
description: >-
  Based on the lecture “Mathematics for Artificial Intelligence (2022-1)” by Prof. Yeo Jin Chung, Dept. of AI, Big Data & Management, College of Business Administration, Kookmin Univ.
image:
  path: /_post_refer_img/MathematicalTechs/1.LinearAlgebra/Thumbnail.png
---

## Matrix
-----

- **행렬(Matrix)**:

    $$\begin{aligned}
    \mathbf{X}
    &=\begin{bmatrix}
    x_{1,1}&x_{1,2}&\cdots&x_{1,P}\\
    x_{2,1}&x_{2,2}&\cdots&x_{2,P}\\
    \vdots&\vdots&\ddots&\vdots\\
    x_{N,1}&x_{N,2}&\cdots&x_{N,P}
    \end{bmatrix}
    \end{aligned}$$

    - 행(row)과 열(column)로 구분된 직사각 모양의 배열

        $$
        \mathbf{X}
        = [x_{i,j}] \in \mathbb{R}^{N \times P}, \quad
        \begin{aligned}
        i&=1,2,\cdots,N\\
        j&=1,2,\cdots,P
        \end{aligned}
        $$

    - 벡터들의 집합:

        $$\begin{aligned}
        \mathbf{X}
        &=\begin{bmatrix}
        \mathbf{x}_{1}&\mathbf{x}_{2}&\cdots & \mathbf{x}_{P}
        \end{bmatrix},\quad \forall \mathbf{x} \in \mathbb{R}^{N}
        \end{aligned}$$

- **계수(Rank)** : 임의의 행렬을 구성하는 벡터 중 선형 독립인 벡터의 갯수

    $$\begin{aligned}
    \mathrm{rank}(\mathbf{X}) \le \min{(N,P)}, \quad \mathbf{X} \in \mathbb{R}^{N \times P}
    \end{aligned}$$

    - **Full-Rank**: 어떤 행렬에 대하여 그 계수가 될 수 있는 가장 큰 값
    - 정방행렬 $$\mathbf{X} \in \mathbb{R}^{N \times N}$$ 의 계수가 `Full-Rank` 인 경우, 그 구성 벡터 $$\mathbf{x}_{1},\mathbf{x}_{2},\cdots,\mathbf{x}_{N}$$ 는 모두 선형 독립임
    - 정방행렬 $$\mathbf{X} \in \mathbb{R}^{N \times N}$$ 의 계수가 `Full-Rank` 인 경우, 그 구성 벡터들의 집합 $$S=\{\mathbf{x}_{1},\mathbf{x}_{2},\cdots,\mathbf{x}_{N}\}$$ 에 대하여 $$\mathrm{span}(S)=\mathbb{R}^{N}$$ 임
    - 정방행렬 $$\mathbf{X}$$ 의 계수가 `Full-Rank` 인 경우, 그 역행렬 $$\mathbf{X}^{-1}$$ 이 존재함
    - 정방행렬 $$\mathbf{X} \in \mathbb{R}^{N \times N}$$ 의 계수가 `Full-Rank` 인 경우, 그 행렬식 $$\mathrm{det}(\mathbf{X}) \ne 0$$ 임

## Special Matrices
-----

- **정방행렬(Square Matrix)**: 행과 열의 갯수가 동일한 행렬

    $$\begin{aligned}
    \mathbf{X}
    \in \mathbb{R}^{N \times N}
    \end{aligned}$$

- **영행렬(Zero-Matrix)**: 원소가 모두 $0$ 인 행렬
 
    $$\begin{aligned}
    \mathbf{0}
    &=\begin{bmatrix}
    0&0&0\\
    0&0&0\\
    0&0&0
    \end{bmatrix}
    \end{aligned}$$

- **항등행렬(Identify Matrix)**: 대각항 원소는 모두 $1$ 이고, 비대각항 원소는 모두 $0$ 인 정방행렬로서, 각 차원에 대하여 그 단위 벡터들의 모임

    $$\begin{aligned}
    \mathbf{I}_{N}
    &=\begin{bmatrix}
    1&0&\cdots&0\\
    0&1&\cdots&0\\
    \vdots&\vdots&\ddots&\vdots\\
    0&0&\cdots&1
    \end{bmatrix}
    =\begin{bmatrix}
    \mathbf{e}_{1}& \mathbf{e}_{2}& \cdots& \mathbf{e}_{N}
    \end{bmatrix}
    \end{aligned}$$

- **대각행렬(Diagonal Matrix)**: 대각항을 제외한 모든 원소가 $0$ 인 정방행렬

    $$\begin{aligned}
    \mathrm{diag}(1, 2, 3)
    &=\begin{bmatrix}
    1&0&0\\
    0&2&0\\
    0&0&3
    \end{bmatrix}
    \end{aligned}$$

- **삼각행렬(Triangular Matrix)**: 대각항을 기준으로 그 아래 혹은 위에 위치한 원소가 모두 0인 정방행렬

    $$\begin{aligned}
    \begin{bmatrix}
    1&4&5\\
    0&2&6\\
    0&0&3
    \end{bmatrix},
    \quad
    \begin{bmatrix}
    1&0&0\\
    4&2&0\\
    5&6&3
    \end{bmatrix}
    \end{aligned}$$

- **대칭행렬(Symmetric Matrix)**: 그 전치행렬이 자기 자신이 되는 정방행렬

    $$\begin{aligned}
    \mathbf{X}^{T}
    &=\mathbf{X}
    \end{aligned}$$

- **직교행렬(Orthogonal Matrix)**: 모든 행벡터 혹은 열벡터가 직교정규벡터로 구성된 행렬

    $$\begin{aligned}
    \mathbf{x}_{1}\perp\cdots\perp\mathbf{x}_{n},
    \quad
    \mathbf{x}_{i} = \mathbf{X}_{:,i}
    \end{aligned}$$

## Matrix Operation
-----

- **전치(Transpose)**: 행렬의 전치는 그 행과 열의 위치를 바꾸는 연산으로 정의함

    $$\begin{aligned}
    [x_{i,j}]^{T}
    &= [x_{j,i}]
    \end{aligned}$$

    - $\alpha^T=\alpha$
    - $(\mathbf{A}+\mathbf{B})^{T}=\mathbf{A}^{T}+\mathbf{B}^{T}$
    - $(\mathbf{AB})^{T}=\mathbf{B}^{T}\mathbf{A}^{T}$

- **덧셈과 뺄셈**: 크기가 $N \times P$ 로 동일한 두 행렬의 덧셈과 뺄셈을 대응 원소의 합과 차로 정의함

    $$\begin{aligned}
    \mathbf{X}+\mathbf{Y}
    &= [x_{i,j} + y_{i,j}]
    \end{aligned}$$

    - $\mathbf{X} \pm \mathbf{0} = \mathbf{X}$

- **스칼라-행렬 곱셈**: 스칼라와 행렬의 곱셈을 행렬의 모든 원소에 대한 스칼라 곱으로 정의함

    $$\begin{aligned}
    \alpha \cdot \mathbf{X}
    &= [\alpha \times x_{i,j}]
    \end{aligned}$$

- **행렬 곱셈**: 적합성 조건(Conformability Condition)을 만족하는 행렬 $$\mathbf{X} \in \mathbb{R}^{M \times P}, \mathbf{Y} \in \mathbb{R}^{P \times N}$$ 을 곱한 결과 $$\mathbf{XY} \in \mathbb{R}^{M \times N}$$ 는 전항의 $$i=1,2,\cdots,M$$ 번째 행벡터와 후항의 $$j=1,2,\cdots,N$$ 번째 열벡터 간 내적의 집합임

    $$\begin{aligned}
    \mathbf{X}^{T}
    &=\begin{bmatrix}\mathbf{x}_{1}&\mathbf{x}_{2}&\cdots&\mathbf{x}_{M}\end{bmatrix},\quad \mathbf{x}_{i} \in \mathbb{R}^{P}\\
    \mathbf{Y}
    &=\begin{bmatrix}\mathbf{y}_{1}&\mathbf{y}_{2}&\cdots&\mathbf{y}_{N}\end{bmatrix},\quad \mathbf{y}_{j} \in \mathbb{R}^{P}\\
    \mathbf{XY}
    &=\begin{bmatrix}
    \left<\mathbf{x}_{1},\mathbf{y}_{1}\right> & \left<\mathbf{x}_{1},\mathbf{y}_{2}\right> & \cdots & \left<\mathbf{x}_{1},\mathbf{y}_{N}\right>\\
    \left<\mathbf{x}_{2},\mathbf{y}_{1}\right> & \left<\mathbf{x}_{2},\mathbf{y}_{2}\right> & \cdots & \left<\mathbf{x}_{2},\mathbf{y}_{N}\right>\\
    \vdots & \vdots & \ddots & \vdots\\
    \left<\mathbf{x}_{M},\mathbf{y}_{1}\right> & \left<\mathbf{x}_{M},\mathbf{y}_{2}\right> & \cdots & \left<\mathbf{x}_{M},\mathbf{y}_{N}\right>\\
    \end{bmatrix}
    \end{aligned}$$

    - $\mathbf{XY} \ne \mathbf{YX}$
    - $\mathbf{X}\mathbf{I} = \mathbf{X}$

## Inverse Matrix
-----

- **역행렬(Inverse Matrix)**: 정방행렬 $\mathbf{X},\mathbf{Y} \in \mathbb{R}^{N \times N}$ 에 대하여 다음을 만족하는 경우, 양자는 서로 역행렬 관계에 있음

    $$\begin{aligned}
    \mathbf{X}\mathbf{Y}
    =\mathbf{Y}\mathbf{X}
    =\mathbf{I}
    \end{aligned}$$

- **가역성(Inverible)**: 그 역을 계산할 수 있는 성질

    $$\begin{aligned}
    \exists \mathbf{X}^{-1} \quad \text{such that} \quad \mathrm{rank}(\mathbf{X}_{N \times N}) = N
    \end{aligned}$$

    - **정칙행렬(Non-Singular Matrix)**: 가역성을 가지는 행렬
    - **특이행렬(Singular Matrix)**: 가역성을 갖지 않는 행렬

- 연산 규칙:
    - $\mathbf{I}^{-1}=\mathbf{I}$
    - $(\alpha\mathbf{X})^{-1}=\alpha^{-1}\mathbf{X}^{-1}$
    - $(\mathbf{X}^{T})^{-1}=(\mathbf{X}^{-1})^{T}$
    - $(\mathbf{XY})^{-1}=\mathbf{Y}^{-1}\mathbf{X}^{-1}$
    - $\mathrm{diag}(a_{i})^{-1}=\mathrm{diag}(1/a_{i})$
    - $$\mathbf{x}_{1}\perp\cdots\perp\mathbf{x}_{n} \Rightarrow \mathbf{X}^{-1}=\mathbf{X}^{T}$$ $$\quad$$
    - $\mathbf{X}^{T}=\mathbf{X} \Rightarrow (\mathbf{X}^{-1})^{T}=\mathbf{X}^{-1}$
---
order: 5
title: Posterior Estimation (2) Variational Inference
date: 2024-07-19
categories: [Data Mining Techs, Bayesian Modeling]
tags: [Bayesian, Objective Function, Variational Inference]
math: true
image:
    path: /_post_refer_img/BayesianModeling/Thumbnail.jpeg
---

## Information Theory
-----

- **정보이론(Information Theory)** : 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함

### Information Gain

- **Shannon's Information Theory Principles**
    - 자주 발생하지 않는 사건(Unlikely Event)일수록 높은 정보량을 가짐(Informative)
        - 해가 동쪽에서 뜨는 사건은 사람들이 확신하고 있는 사건이므로 정보량이 낮은 반면, 해가 서쪽에서 뜨는 사건은 자연 법칙을 거스르는 극히 드문 사건이므로 정보량이 높음

    - 독립사건은 추가적인 정보량을 가짐(Addictive Information)
        - 동전을 두 번 던져서 앞면이 두 번 나오는 사건은 동전을 한 번 던져서 앞면이 나오는 사건보다 정보량이 두 배임

- **자기정보(Self-Information)** : 확률변수 $X \sim P$ 에 대하여, 사건 $X=x$ 가 발생했을 때의 정보량

    $$\begin{aligned}
    I(X=x)
    &= \log{\frac{1}{P(X=x)}}\\
    &=-\log{P(X=x)}
    \end{aligned}$$

- **엔트로피(Entropy)** : 자기정보의 기대값으로서, 주어진 확률분포에서 발생 가능한 사건들의 평균적인 정보량

    $$\begin{aligned}
    H(P)
    &= \mathbb{E}_{X \sim P}\left[I(X)\right]\\
    &= \mathbb{E}_{X \sim P}\left[-\log{P(X)}\right]\\
    &= -\mathbb{E}_{X \sim P}\left[\log{P(X)}\right]\\
    &= -\sum_{x}{\log{P(x)} \cdot P(x)}
    \end{aligned}$$

    - 사건의 분포가 결정적일수록(Deterministic) 엔트로피가 감소함
    - 사건의 분포가 균등할수록(Uniform) 엔트로피가 증가함

### Information Discrepancy

- **교차 엔트로피(Cross Entropy)** : 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 가 $P$ 에 대하여 제공하는 **정보의 불확실성을** 측정하는 지표

    $$\begin{aligned}
    H(P,Q)
    &= \mathbb{E}_{X \sim P}\left[-\log{Q(X)}\right]\\
    &= - \sum_{x}{\log{Q(x)} \cdot P(x)}
    \end{aligned}$$

- **쿨백 라이블러 발산(Kullback-Leibler Divergence)** : 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 를 $P$ 의 **근사 분포로 사용할 때의 비효율성을** 측정하는 지표로서, $P$ 에서 샘플링된 $X$ 에 대하여, $P$ 가 제공하는 평균적인 정보량과 $Q$ 가 제공하는 평균적인 정보량의 차이

    $$\begin{aligned}
    D_{KL}(P \parallel Q)
    &= \mathbb{E}_{X \sim P}\left[-\log{P(X)}\right] - \mathbb{E}_{X \sim P}\left[-\log{Q(X)}\right]\\
    &= \mathbb{E}_{X \sim P}\left[-\log{\frac{Q(X)}{P(X)}}\right]\\
    &= \mathbb{E}_{X \sim P}\left[\log{\frac{P(X)}{Q(X)}}\right]\\
    &= \sum_{x}{\log{\frac{P(x)}{Q(x)}} \cdot P(x)}
    \end{aligned}$$

- **교차 엔트로피와 쿨백 라이블러 발산의 관계**

    $$\begin{aligned}
    D_{KL}(P \parallel Q)
    &= \sum_{x}{\log{\frac{P(x)}{Q(x)}} \cdot P(x)}\\
    &= -\sum_{x}{\log{\frac{Q(x)}{P(x)}} \cdot P(x)}\\
    &= -\sum_{x}{\left[\log{Q(x)}-\log{P(x)}\right] \cdot P(x)}\\
    &= \left[-\sum_{x}{\log{Q(x)} \cdot P(x)}\right] -\left[-\sum_{x}{\log{P(x)} \cdot P(x)}\right]\\
    &= H(P,Q) - H(P)
    \end{aligned}$$

## Variational Inference
-----

### Variational Inference

- **변분 추론(Variational Inference)** : 정보 이론을 활용하여 제안 분포 $W \sim Q$ 를 목표 분포 $W \mid \mathcal{D} \sim P$ 에 근사하는 모수 방법론(Parametric Method)

    $$\begin{aligned}
    \hat{\theta}
    &= \text{arg}\min_{\theta}{D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]}
    \end{aligned}$$

    - 두 분포 간 쿨백 라이블러 발산을 직접 계산하기에 어려움이 있으므로 증거 하한(`E`vidence `L`ower `B` `o`und; ELBO)을 최대화함으로써 목표 분포에 근사하도록 함

        $$\begin{aligned}
        \hat{\theta} &= \text{arg}\max_{\theta}{\text{ELBO}}
        \end{aligned}$$

- **이상** : 목표 분포 $W \mid \mathcal{D} \sim P$ 를 잘 설명하는 제안 분포 $W \sim Q$ 를 탐색함

    $$\begin{aligned}
    D_{KL}\big[P(W \mid \mathcal{D}) \parallel Q(W)\big]
    &= \mathbb{E}_{W \mid \mathcal{D} \sim P}\left[\log{\frac{P(W \mid \mathcal{D})}{Q(W)}}\right]
    \end{aligned}$$

- **대안** : 목표 분포 $W \mid \mathcal{D} \sim P$ 로 잘 설명될 수 있는 제안 분포 $W \sim Q$ 를 탐색함

    $$\begin{aligned}
    D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
    &= \mathbb{E}_{W \sim Q}\left[\log{\frac{Q(W)}{P(W \mid \mathcal{D})}}\right]
    \end{aligned}$$

### ELBO

- **사후 분포 $W \mid \mathcal{D} \sim P$ 와 그 근사 분포 $W \sim Q$ 의 차이 세분화**

    $$\begin{aligned}
    D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
    &= \mathbb{E}_{W \sim Q}\left[\log{\frac{Q(W)}{P(W \mid \mathcal{D})}}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(W \mid \mathcal{D})}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{\frac{P(\mathcal{D} \mid W) \cdot P(W)}{P(\mathcal{D})}}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \bigg(\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \mathbb{E}_{W \sim Q}\left[\log{P(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D})}\right]\bigg)\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)} - \log{P(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D})}\right]\\
    &= D_{KL}\big[Q(W) \parallel P(W)\big] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \log{P(\mathcal{D})}
    \end{aligned}$$

    - $D_{KL}\big[Q(W) \parallel P(W)\big]$ : 사후 분포의 근사 분포 $W \sim Q$ 와 사전 분포 $W \sim P$ 의 차이
    - $\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right]$ : 사후 분포의 근사 분포 $W \sim Q$ 에서 샘플링된 가중치 $W$ 에 대한 로그 우도의 기대값
    - $\log{P(\mathcal{D})}$ : 데이터 $\mathcal{D}$ 에 대한 로그 마진 우도(Marginal Liklihood)로서, $\mathcal{D}$ 가 발생할 확률

- **$\log{P(\mathcal{D})}$ 의 이해**

    - 목표 분포와 제안 분포 간 차이가 없다면:

        $$\begin{aligned}
        D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
        &= 0
        \end{aligned}$$

    - 따라서:

        $$\begin{aligned}
        D_{KL}\big[Q(W) \parallel P(W)\big] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \log{P(\mathcal{D})}
        &=0
        \end{aligned}$$

    - 증거(Evidence)를 기준으로 정리하면:

        $$\begin{aligned}
        \log{P(\mathcal{D})}
        &= \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
        \end{aligned}$$

    - 증거(Evidence)는 파라미터에 대하여 상수이므로:

        $$\begin{aligned}
        \therefore \log{P(\mathcal{D})}
        &\ge \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
        \end{aligned}$$

- **증거 하한(`E`vidence `L`ower `B` `o`und; ELBO)** : 파라미터 갱신 증거 $\log{P(\mathcal{D})}$ 의 하한값

    $$\begin{aligned}
    \text{ELBO}
    &= \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
    \end{aligned}$$

    - $$\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right]$$ : Log Likelihood Function
    - $$D_{KL}\big[Q(W) \parallel P(W)\big]$$ : KL Divergence from Approx. to Prior

## Bayes by Backprop
-----

- **BBB(`B`ayes `b`y `B`ackprop)** : 변분 추론을 사용하여 신경망의 가중치에 대한 사후 확률 분포를 근사하는 과정에서, 재매개변수화 트릭을 도입함으로써 역전파 알고리즘을 활용한 최적화 학습을 도모한 방법론

    - [Weight Uncertainty in Neural Networks(2015)](https://proceedings.mlr.press/v37/blundell15)

- **재매개변수화 트릭(Reparameterization Trick)** : 샘플링을 미분 가능한 함수로 변형하는 방법

    $$
    w \sim \mathcal{N}(\mu,\sigma^{2}) \quad \rightarrow \quad w = \mu + \sigma \cdot \epsilon
    $$

- **후방 템퍼링(Posterior Tempering)** : 데이터에 과적합되는 것을 방지하도록 우도 항목의 영향력을 할인하는 방법

    $$\begin{aligned}
    \text{ELBO}
    &= \frac{1}{T} \cdot \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
    \end{aligned}$$

## Monte Carlo Dropout
-----

- **MC Dropout(`M`onte `C`arlo Dropout)** : 드롭아웃의 확률적 성질을 변분추론 관점에서 해석하여 사후 확률 분포를 근사하는 모수 방법론으로서, 평가 과정에서도 드롭아웃을 유지하고 여러 번 샘플링한 결과값에 평균을 내어 최종 결론을 도출함

    - [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning(2016)](https://doi.org/10.48550/arXiv.1506.02142)

- **Original ELBO**

    $$\begin{aligned}
    \text{ELBO}
    = \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
    \end{aligned}$$

    - $P(W)$ : Prior Dist.
    - $Q(W)$ : Approx. Dist.
    - $$\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right]$$ : Likelihood

- **Prior Dist.** : Normality Assumption

    $$\begin{aligned}
    \mathcal{W} \sim \mathcal{N}\left(0, \sigma^{2}_{p}\mathbf{I}\right)
    \end{aligned}$$

- **Approx. Dist.**

    - Dropout is a process of applying Bernoulli sampling to weights, <br> so each weight has stochastic properties:

        $$\begin{aligned}
        \mathcal{W} \mid \mathbf{M} &\sim Q
        \end{aligned}$$

        - $\mathcal{W} = \mathbf{W} \odot \mathbf{M}$
        - $M_{i,j} \sim \text{Bernoulli}(p)$

    - According to the CLS, <br> the mean and variance of multiple samplings converge to a normal dist.

        $$\begin{aligned}
        q(\mathcal{\omega}) \approx \mathcal{N}\left(0, \sigma^{2}_{q}\mathbf{I}\right)
        \end{aligned}$$

- **KL Divergence from Approx. to Prior**

    $$\begin{aligned}
    D_{KL}(q \parallel p)
    &= \frac{1}{2}\sum_{i}\left(\frac{\sigma_{q}^{2}}{\sigma_{p}^{2}} + \frac{\sigma_{p}^{2}}{\sigma_{q}^{2}} - 1\right)
    \end{aligned}$$

    - If $\sigma_{p}^{2} \approx \sigma_{q}^{2}$:

        $$\begin{aligned}
        D_{KL}(q \parallel p)
        &= \frac{1}{2\sigma^{2}}\Vert \mathcal{W} \Vert^{2}
        \end{aligned}$$

- **Likelihood** <br> Approximated by averaging the results of multiple samplings

    $$\begin{aligned}
    \mathbb{E}_{\omega \sim q}[\log{p(\mathcal{D} \mid \omega)}]
    \approx \frac{1}{T}\sum_{t=1}^{T}{\log{p(\mathcal{D} \mid \omega_{t})}}
    \end{aligned}$$

- **Therefore:**

    $$\begin{aligned}
    \text{ELBO}
    &= \frac{1}{T}\sum_{t=1}^{T}{\log{p(\mathcal{D} \mid \omega_{t})}} - \frac{1}{2\sigma^{2}}\Vert \mathcal{W} \Vert^{2}
    \end{aligned}$$
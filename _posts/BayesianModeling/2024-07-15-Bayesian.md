---
order: 1
title: What? Bayesian
date: 2024-07-15
categories: [Statistical Techs, Bayesian Modeling]
tags: [Statistics, Bayesian, Optimization, MLE]
math: true
description: >-
    Based on the lecture “Bayesian Modeling (2024-1)” by Prof. Yeo Jin Chung, Dept. of AI, Big Data & Management, College of Business Administration, Kookmin Univ.
image:
    path: /_post_refer_img/BayesianModeling/Thumbnail.jpeg
---

## Compare Frequentist and Bayesian
-----

### 빈도주의자 vs. 베이지안

- **사건 $X$ 가 발생할 확률 $P(X)$ 의 정의**
    - **빈도주의자(Frequentist)** : 어떤 사건이 발생하는 장기적인 빈도

        $$
        P(X)
        $$

    - **베이지안(Bayesian)** : 어떤 사건이 발생할 것이라는 믿음 혹은 확신의 척도

        $$
        P(X \mid \theta)
        $$

- **모수 $\theta$ 의 이해**
    - **빈도주의자(Frequentist)** : 사건 발생 빈도를 묘사하는 상수

        $$
        \theta=\mu, \sigma^2, p, \cdots
        $$

    - **베이지안(Bayesian)** : 사건 발생에 대한 믿음의 분포를 묘사하는 확률변수

        $$
        \theta \sim F
        $$

### 표본의 크기가 충분하다면

- 빈도주의자의 결론과 베이지안의 결론은 일치함

    $$
    \lim_{n \rightarrow \infty}{P(\theta \mid X_{1},X_{2},\cdots,X_{n})} \approx \mu, \sigma^2, p, \cdots
    $$

    - 사건 발생에 대한 믿음은 **신규 관측치에 의해 끊임없이 갱신되어** 사건 발생에 대한 장기적인 빈도로 수렴함

### 표본의 크기가 충분하지 않다면

> 표본의 크기는 결코 크지 않다. 만일 N이 충분한 추정을 얻기에 부족하다면 더 많은 데이터(또는 더 많은 가정)을 확보해야 한다. 그러나 일단 N이 충분히 크다면 데이터를 나눠 더 많은 것(가령 여론조사에서 전국적으로 훌륭한 추정을 얻었다면 남과 여, 지역별, 연령대별 그룹 등으로 나눠 추정할 수 있다)을 얻을 수 있다. N은 충분하지 않다. 만약 충분하더라도 여러분은 이미 더 많은 데이터가 필요한 다음 문제에 직면하기 때문이다. (Andrew Gelman)

- **빈도주의자(Frequentist)** : 모수(미지의 상수)에 대한 신뢰구간을 확대함으로써 **모수 추정 과정 상의 불확실성을 최소화함**

    $$
    \text{CI}_{\theta}=\bar{X}\pm Z\cdot\frac{\sigma}{\sqrt{n}}
    $$

- **베이지안(Bayesian)** : 모수(확률변수)에 대한 사전확률을 도입함으로써 **모수 자체의 불확실성을 모형화함**

    $$
    P(\theta \mid X)=\frac{P(X \mid \theta)\cdot P(\theta)}{P(X)}
    $$

## Bayesian Framework
-----

### Bayes' Theorem

- **베이즈 정리(Bayes' Theorem)**

    > 사상 $A_{1},A_{2},\cdots,A_{n}$ 이 표본공간 $S$ 의 분할이고, $P(A_{i})>0,P(X)>0$ 이면 $X$ 에 대한 $A_{k}$ 의 조건부 확률은 다음과 같음

    $$\begin{aligned}
    P(A_{k} \mid X)
    &=\frac{P(A_{k} \cap X)}{P(X)}\\
    &=\frac{P(A_{k})\cdot P(X \mid A_{k})}{P(X)}\\
    &=\frac{P(A_{k})\cdot P(X \mid A_{k})}{\sum_{i=1}^{n}{P(A_{i}) \cdot P(X \mid A_{i})}} \propto P(A_{k})\cdot P(X \mid A_{k})
    \end{aligned}$$

    - $P(A_{k} \mid X)$ : 사건 $X$ 발생 조건부 $A_k$ 가 발생할 확률
    - $P(A_{k})$ : 사건 $A_{k}$ 가 발생할 확률
    - $P(X \mid A_{k})$ : 사건 $A_{k}$ 발생 조건부 $X$ 가 발생할 확률
    - $P(X)$ : 사건 $X$ 가 발생할 확률

- **확률분포함수로 표현한 베이즈 정리**

    $$
    P(\theta \mid \mathcal{D})=\frac{P(\theta) \cdot P(\mathcal{D} \mid \theta)}{P(\mathcal{D})} \propto \pi(\theta) \cdot \mathcal{L}(\theta)
    $$

    - $\theta$ : 모수
    - $\mathcal{D}$ : 관측된 데이터
    - $P(\theta \mid \mathcal{D})$ : $\theta$ 의 사후확률분포
    - $\pi(\theta)=P(\theta)$ : $\theta$ 의 사전확률분포
    - $\mathcal{L}(\theta)=P(\mathcal{D} \mid \theta)$ : $\theta$ 에 대한 $\mathcal{D}$ 의 우도함수
    - $P(\mathcal{D})$ : $\mathcal{D}$ 의 주변확률

### Component

- **사전확률분포(Prior Probability Distribution)** : 사건 발생 전, 가지고 있는 정보를 기초로 하여 설정된 초기 믿음

    $$
    \theta \sim P
    $$

- **사후확률분포(Posterior Probability Distribution)** : 사건 발생 후, 추가된 정보를 고려하여 갱신된 믿음

    $$
    \theta \mid \mathcal{D} \sim P
    $$

- **우도(Likelihood or Likelihood Function)** : 모수의 특정 값이 $\theta$ 로 주어졌을 때, 관측치 $\mathcal{D}$ 가 실현될 가능성

    $$\begin{aligned}
    \mathcal{L}(\theta)
    &=P(\mathcal{D} \mid \theta)\\
    &=\prod_{i=1}^{n}{f(X_{i} \mid \theta)}
    \end{aligned}$$

### `[example]` 동전 던지기

> 동전을 던졌을 때 앞면이 나올 확률을 $\theta$ 라고 하자. $\theta$ 에 대한 정보가 아무것도 없다고 가정하자. 즉, $\theta$ 는 0과 1 사이의 무작위수일 것이라고 믿어지고 있다. 동전을 두 번 던졌는데 두 번 다 앞면이 나왔다. 그렇다면 $\theta$ 에 대한 믿음은 어떻게 변화할까?

![01](/_post_refer_img/BayesianModeling/01-01.png){: width="100%"}

- **문제에서 주어진 정보**

    $$\begin{aligned}
    X \mid \theta &\sim \text{Bin}(n,\theta)\\
    \theta &\sim \text{Uniform}(0,1)
    \end{aligned}$$

- **목적 함수 정의**

    $$
    P(\theta \mid X)=\frac{\pi(\theta)P(X \mid \theta)}{P(X)} \propto \pi(\theta)P(X \mid \theta)
    $$

    - $\pi(\theta)$ : $\theta$ 에 대한 사전확률

        $$
        \pi(\theta)=1 \quad \because \theta \sim \text{Uniform}(0,1)
        $$

    - $P(X \mid \theta)$ : $\theta$ 에 대한 $X$ 의 우도함수 혹은 확률질량함수

        $$
        P(X \mid \theta)=\frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X} \quad \because X \mid \theta \sim \text{Bin}(n,\theta)
        $$

    - $P(X)$ : $X$ 의 주변확률로서 정규화 상수($\theta$ 에 대한 함수가 아니므로 이후 생략)

        $$\begin{aligned}
        P(X)
        &= \int_{0}^{1}{\frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X}}\text{d}\theta\\
        &= \frac{n!}{X!(n-X)!} \cdot \int_{0}^{1}{\theta^{X} \cdot (1-\theta)^{n-X}}\text{d}\theta\\
        &= \frac{n!}{X!(n-X)!} \cdot \text{B}(X+1,n-X+1)\\
        &= \frac{n!}{X!(n-X)!} \cdot \frac{\Gamma(X+1)\Gamma(n-X+1)}{\Gamma(n+2)} \quad \because (X+1),(n-X+1) \in \mathbf{R}^{+}\\
        &= \frac{n!}{X!(n-X)!} \cdot \frac{X!(n-X)!}{(n+1)!} \quad \because (X+1),(n-X+1) \in \mathbf{Z}^{+}\\
        &= \frac{1}{n+1}
        \end{aligned}$$

        - $\text{B}(\alpha,\beta)$ : 베타함수

            $$\begin{aligned}
            \text{B}(\alpha,\beta)
            &= \int_{0}^{1}{t^{\alpha-1}(1-t)^{\beta-1}}\text{d}t\\
            &= \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)} \quad \text{where}\; \alpha,\beta \in \mathbf{R}^{+}
            \end{aligned}$$

        - $\Gamma(n)$ : 감마함수

            $$\begin{aligned}
            \Gamma(n)
            &= \int_{0}^{\infty}{t^{(n-1)}e^{-t}}\text{d}t\\
            &= (n-1)! \quad \text{where}\; n \in \mathbf{Z}^{+}
            \end{aligned}$$

- **결론** : $\theta$ 의 사후확률은 베타분포 $\text{Beta}(3,1)$ 을 따름

    $$\begin{aligned}
    P(\theta \mid X)
    &\propto \pi(\theta)P(X \mid \theta)\\
    &= \frac{n!}{X!(n-X)!} \cdot \theta^{X} \cdot (1-\theta)^{n-X}\\
    \\
    \therefore P(\theta \mid X)
    &\sim \text{Beta}(X+1,n-X+1)
    \end{aligned}$$

    - $\text{Beta}(\alpha,\beta)$ : 베타분포

        $$
        f(x)
        = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{\text{B}(\alpha,\beta)}
        \sim \text{Beta}(\alpha,\beta)
        $$
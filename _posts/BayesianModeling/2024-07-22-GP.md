---
order: 8
title: Gaussian Process
date: 2024-07-22
categories: [Statistical Techs, Bayesian Modeling]
tags: [Statistics, Bayesian, Stochastic Process, Nonparametric Estimation]
math: true
description: >-
    Based on the lecture “Bayesian Modeling (2024-1)” by Prof. Yeo Jin Chung, Dept. of AI, Big Data & Management, College of Business Administration, Kookmin Univ.
image:
    path: /_post_refer_img/BayesianModeling/Thumbnail.jpeg
---

## Stochastic Process
-----

- **확률적 과정(Stochastic Process)**
    
    > 어떤 시점 혹은 위치 지표 $t$ 에 대하여 확률변수들의 집합 $$\{X_{t} \mid t \in T\}$$ 이 주어졌을 때 이를 확률적 과정이라고 한다. 즉, 확률적 과정은 시간 또는 공간을 따라 변화하는 확률변수들의 집합으로서, 특정한 시점 또는 위치에서 확률변수가 결정된다. 이때 시간 또는 공간을 따라 확률변수가 변하는 양상은 특정한 확률적 패턴을 가질 수 있다.

- **vs. Deterministic**

    - **결정론적 과정(Deterministic Process)** : 시스템의 상태가 주어지면 미래 상태가 항상 유일하게 결정되므로 동일한 초기 조건에서는 항상 동일한 경로(Trajectory)가 생성됨

        - **`EXAMPLE` Deterministic Auto-Regressive Model**

            $$\begin{aligned}
            X_{t}
            &= \beta + \sum_{i=1}^{p}{\alpha_{i} \cdot X_{t-i}}
            \end{aligned}$$

    - **확률적 과정(Stochastic Process)** : 초기 조건이 동일하더라도 매 실행(Realization)마다 다른 경로(Trajectory)가 생성될 수 있음

        - **`EXAMPLE` Auto-Regressive Model** \| Stochastic Error

            $$\begin{aligned}
            X_{t} = \beta + \sum_{i=1}^{p}{\alpha_{i} \cdot X_{t-i}} + \epsilon_{t}, \quad \epsilon_{t} \sim \mathcal{N}\left(0, \sigma^{2}\right)
            \end{aligned}$$

        - **`EXAMPLE` Auto-Regressive Model** \| Stochastic Initial Variable

            $$\begin{aligned}
            X_{t} = \beta + \sum_{i=1}^{p}{\alpha_{i} \cdot X_{t-i}}, \quad X_{0} \sim \mathcal{N}\left(\mu, \sigma^{2}\right)
            \end{aligned}$$

- **Stochastic Patterns**

    - **독립 확률 과정(Independent Stochastic Process)** : 각 포인트에서의 확률변수 $X_{t}$ 가 서로 독립인 확률 과정

        $$\begin{aligned}
        P\left(X_{t} \mid X_{t-1}, X_{t-2}, \cdots, X_{0}\right) = P\left(X_{t}\right)
        \end{aligned}$$

    - **마코프 과정(Markov Process)** : 현재 상태 $X_{t}$ 가 주어졌을 때, 미래 상태 $X_{t+1}$ 는 과거 상태들과 독립이고 오직 현재 상태에만 의존하는 과정

        $$\begin{aligned}
        P\left(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \cdots, X_{0}\right) = P\left(X_{t+1} \mid X_{t}\right)
        \end{aligned}$$

    - **정상 과정(Stationary Process)** : 시간 혹은 공간에 따라 확률적으로 변화하는 패턴이 일정한 성질을 유지하는 과정

        $$\begin{aligned}
        X_{t} = \alpha \cdot X_{t-1} + \epsilon_{t}, \quad \epsilon_{t} \sim \mathcal{N}\left(0, \sigma^{2}\right)
        \end{aligned}$$
        
        - 확률변수 $$X_{t}$$ 의 기대값이 일정함

            $$
            \text{E}\left[X_{t^{\forall}}\right]=\mu
            $$

        - 확률변수 $$X_{t}$$ 의 변동성이 일정함

            $$
            \text{Var}\left[X_{t^{\forall}}\right]=\text{E}\left[\left(X_{t^{\forall}}-\mu\right)\right]=\sigma^{2}
            $$

        - $X_{t}$ 와 $X_{t+h}$ 의 관계가 시점 $t$ 자체가 아니라 시간 차이 $h$ 에만 의존함

            $$
            \text{Cov}\left[X_{t},X_{t+h}\right]=\text{E}\left[\left(X_{t}-\mu\right)\left(X_{t+h}-\mu\right)\right]=\gamma\left(h\right)
            $$

## Non-Parametric Density Estimation
-----

### Non-Parametric Method

- **밀도(Density)** : 데이터가 특정 구간에 존재할 확률

- **모수 추정(Parametric Estimation)** : 데이터가 모수로써 정의되는 특정한 형태로 분포되었다고 가정하고, 소수의 모수를 추정함으로써 데이터 분포를 추정하는 방법

    - **`EXAMPLE` Probability Density Estimation** <br> 확률변수 $X$ 는 평균을 $\mu$, 분산을 $\sigma^{2}$ 으로 하는 가우시안 분포에 따라 분포되어 있음

        $$\begin{aligned}
        X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)
        \end{aligned}$$

    - **`EXAMPLE` Regression Analysis** <br> 한국인 남성의 키($Y$)는 몸무게($X$)와 선형 관계에 있음

        $$\begin{aligned}
        Y = \alpha \cdot X + \beta
        \end{aligned}$$

- **비모수 추정(Non-Parametric Estimation)** : 데이터가 특정한 형태로 분포되었다고 가정하지 않고, 주어진 데이터를 토대로 직접 추정하는 방법
    - Histogram Density Estimation
    - **Kernel Density Estimation**
    - k-Nearest Neighbors Density Estimation
    - Maximum Entropy Density Estimation
    - Regression-Based Density Estimation

### KDE

- **커널 밀도 추정(`K`ernel `D`ensity `E`stimation; KDE)** : 각 데이터 주변에서 작은 확률 분포(Kernel)를 만든 후, 이를 합산하여 전체 밀도를 추정하는 방법

    ![02](/_post_refer_img/BayesianModeling/08-02.png){: width="100%"}

- **확률 밀도 함수(Probability Density Function)**

    $$\begin{aligned}
    f(x)
    &= \frac{1}{h} \cdot \frac{1}{n} \cdot \sum_{i=1}^{n}{\mathcal{K}\left(\frac{x-x_{i}}{h}\right)}
    \end{aligned}$$

    - $n$ : 데이터 포인트 갯수
    - $x_{i}$ : 개별 데이터 포인트
    - $h$ : 밴드위스(Bandwidth)
    - $\mathcal{K}\left(\cdot\right)$ : 커널 함수(Kernel Function)

- **밴드위스(Bandwidth)** : 커널의 너비를 조절하는 하이퍼파라미터로서, 값이 클수록 전역적 패턴을, 작을수록 국소적 패턴을 포착함

    ![01](/_post_refer_img/BayesianModeling/08-01.png){: width="100%"}

- **커널 함수(Kernel Function)** : 특정 데이터 포인트 주변의 밀도를 조절하는 함수

    | Name | Function |
    |---|---|
    | Gaussian | $$\mathcal{K}(u) = \displaystyle\frac{1}{\sqrt{2\pi}} \exp\left(-\displaystyle\frac{u^2}{2}\right)$$ |
    | Epanechnikov | $$\begin{aligned}\mathcal{K}(u)=\begin{cases}\displaystyle\frac{3}{4}(1-u^{2}), \quad &\text{if} \quad \vert u \vert \le 1 \\0, \quad &\text{otherwise}\end{cases}\end{aligned}$$ |
    | Tophat | $$\begin{aligned}\mathcal{K}(u) = \begin{cases}\displaystyle\frac{1}{2}, \quad & \text{if} \quad \vert u \vert \le 1 \\0, \quad & \text{otherwise}\end{cases}\end{aligned}$$ |
    | Logistic | $$\mathcal{K}(u) = \displaystyle\frac{1}{e^{u} + e^{-u} + 2}$$ |
    | Silverman | $$\mathcal{K}(u) = \displaystyle\frac{1}{2} \cdot \exp\left(-\displaystyle\frac{\vert u \vert}{\sqrt{2}}\right) \cdot \cos\left(\displaystyle\frac{\vert u \vert}{\sqrt{2}}\right)$$ |
    | Laplacian | $$\mathcal{K}(u) = \displaystyle\frac{1}{2} \cdot \exp(-\vert u \vert)$$ |

## Gaussian Process
-----

- **다변량 가우시안 분포(Multi-Variate Gaussian Distribution)**

- **가우시안 프로세스(`G`aussian `P`rocess; GP)**

- **커널 함수(Kernel Function)** : 두 입력 벡터를 선형적으로 표현 가능한 고차원 공간에 매핑하고 그 유사도를 측정함

    | Name | Function |
    |---|---|
    | Linear | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \overrightarrow{\mathbf{x}}^{T}\overrightarrow{\mathbf{y}}$$ |
    | Polynomial | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \left(\overrightarrow{\mathbf{x}}^{T}\overrightarrow{\mathbf{y}} + \beta\right)^{d}$$ |
    | RBF | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \exp{\left[-\displaystyle\frac{\Vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}}\Vert^{2}}{2\sigma^{2}}\right]}$$ |
    | Sigmoid | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \text{tanh}\left(\alpha \cdot \overrightarrow{\mathbf{x}}^{T}\overrightarrow{\mathbf{y}} + \beta\right)$$ |
    | Laplacian | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \exp{\left[-\gamma \Vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}} \Vert_{1}\right]}$$ |
    | Exponential | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \exp{\left[-\gamma \Vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}} \Vert^{2}_{2}\right]}$$ |
    | Martern | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \displaystyle\frac{2^{1-\nu}}{\Gamma\left(\nu\right)} \cdot \left(\displaystyle\frac{\sqrt{2\nu} \Vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}} \Vert}{\ell}\right)^{\nu} \cdot K_{\nu}\left(\displaystyle\frac{\sqrt{2\nu} \Vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}} \Vert}{\ell}\right)$$ |
    | Periodic | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \exp\left[-2 \sin^2\left( \displaystyle\frac{\pi \vert \overrightarrow{\mathbf{x}}-\overrightarrow{\mathbf{y}} \vert}{p} \right) \Bigg/ \ell^2 \right]$$ |
    | Rational Quadratic | $$\mathcal{K}\left(\overrightarrow{\mathbf{x}},\overrightarrow{\mathbf{y}}\right) = \left( 1 + \displaystyle\frac{\vert \overrightarrow{\mathbf{x}} - \overrightarrow{\mathbf{y}}\vert^2}{2 \alpha \ell^2} \right)^{-\alpha}$$ |

    - **대칭성(Symmetry)** : $$\mathcal{K}\left(x,x^{\prime}\right)=\mathcal{K}\left(x^{\prime},x\right)$$

    - **양의 반정치성(Positive Semi-Definiteness, PSD)** : $$\sum_{i}\sum_{j}{\alpha_{i} \cdot \alpha_{j} \cdot \mathcal{K}\left(x_{i},x_{j}\right)} \ge 0$$

- **MLE(`M`aximum `L`iklihood `E`stimation)**

- **SGP(Sparse Gaussian Process)**

- **SVGP(Sparse Variational Gaussian Process)**

## Gaussian Process Application
-----

### GPR

### GPLVM
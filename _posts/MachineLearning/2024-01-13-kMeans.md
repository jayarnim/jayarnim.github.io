---
order: 13
title: k-Means
date: 2024-01-13
categories: [Machine Learning Techs, Machine Learning]
tags: [Machine Learning, Unsupervised Learning, Clustering]
math: true
description: >-
  Based on the lecture “Intro. to Machine Learning (2023-2)” by Prof. Je Hyuk Lee, Dept. of Data Science, The Grad. School, Kookmin Univ.
image:
  path: /_post_refer_img/MachineLearning/Thumbnail.jpg
---

## What? k-Means
-----

### k-Means

- **정의** : 중심점 기반 배타적 분리형 군집화 알고리즘

    ![01](/_post_refer_img/MachineLearning/13-01.png){: width="100%"}

- **목표** : 각 군집에 대하여, **관측치와 중심점(Centroid) 간 평균 거리(Means)**를 최소화함

    $$
    \min_{\overrightarrow{\mu}_{i}}{\sum_{i=1}^{k}\sum_{\overrightarrow{x}_{j} \in C_{i}}{||\overrightarrow{x}_{j}-\overrightarrow{\mu}_{i}||^2}}
    $$

### 한계점

- **초기 군집 중심에 민감함**

    ![02](/_post_refer_img/MachineLearning/13-02.png){: width="100%"}

- **이상치에 민감함**

    ![03](/_post_refer_img/MachineLearning/13-03.png){: width="100%"}

- **구형이 아닌 형태의 군집을 탐지하기 어려움**

    ![04](/_post_refer_img/MachineLearning/13-04.png){: width="100%"}

- **서로 다른 규모의 군집을 탐지하기 어려움**

    ![05](/_post_refer_img/MachineLearning/13-05.png){: width="100%"}

- **서로 다른 밀도의 군집을 탐지하기 어려움**

    ![06](/_post_refer_img/MachineLearning/13-06.png){: width="100%"}

## 중심점 탐색 과정
-----

![07](/_post_refer_img/MachineLearning/13-07.png){: width="100%"}

1. **군집 갯수를 설정함**

    $$
    X=C_{1} \cup C_{2} \cup \cdots \cup C_{k}\\
    \\ C_{i} \cap C_{j \ne i} = \emptyset
    $$

2. **$k$ 개의 초기 군집 중심 벡터 $\overrightarrow{c}$ 를 임의로 선정함**

    $$
    M=\{\overrightarrow{\mu}_{1},\overrightarrow{\mu}_{2},\cdots,\overrightarrow{\mu}_{k}\}
    $$

3. **모든 관측치 벡터 $\overrightarrow{x}$ 를 가장 가까운 거리에 위치한 중심 벡터 $\overrightarrow{\mu}$ 의 군집에 배타적으로 할당함**

    $$
    \overrightarrow{x}_{j} \rightarrow C_{i}\\
    \begin{aligned}
    \\\text{s.t.} \quad 
    & i=\text{arg} \min_{i}{||\overrightarrow{x}_{j}-\overrightarrow{\mu}_{i}||^2}\\
    &\overrightarrow{\mu}_{i} \in C_{i}
    \end{aligned}$$

4. **각 군집별 할당된 관측치 벡터들의 평균 벡터로 군집 중심 벡터를 갱신함**

    $$\begin{aligned}
    \overrightarrow{\mu}_{i}
    &=\displaystyle\frac{1}{|C_{i}|}\sum_{\overrightarrow{x}_{j}\in C_{i}}{\overrightarrow{x}_{j}}
    \end{aligned}$$

5. **③, ④의 과정을 반복하여 최적의 군집 중심 벡터 집합 $\hat{M}$ 을 탐색함**

    $$\begin{aligned}
    \hat{M}
    &= \{\overrightarrow{\mu}_{i} \big| \text{arg} \min_{\overrightarrow{\mu}_{i}}{\sum_{i=1}^{k}\sum_{\overrightarrow{x}_{j} \in C_{i}}{||\overrightarrow{x}_{j}-\overrightarrow{\mu}_{i}||^2}}\}
    \end{aligned}$$

## [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
-----

```python
from sklearn.cluster import KMeans
```

### General HyperParameter

- `random_state(default : None)`

### Model HyperParameter

- `n_cluster(default : 8)` : 군집 갯수

- `init(default : 'k-means++')` : 중심점 초기화 방법
    - `'k-means++'`
    - `'random'`
    - `callable`

- `n_init(default : 10)` : 중심점 초기화 횟수
    - `'auto'`
    - `int`

- `max_iter(default : 300)` : 학습(Means 최소화) 최대 횟수

- `tol(default : 1e-4)` : 허용 손실

### Attribute

- `labels_` : 각 관측치가 속한 군집 번호
- `cluster_centers_` : 군집별 중심점 위치
- `n_iter_` : 중심점 이동 횟수
- `inertia_` : 군집별 Means 평균으로서 수치가 낮을수록 응집도가 높다고 판단함

-----

### 이미지 출처

- https://ai-times.tistory.com/158
- https://github.com/pilsung-kang/multivariate-data-analysis/blob/master/09%20Clustering/09-2_K-Means%20Clustering.pdf
- https://github.com/lovit/python_ml_intro/blob/master/lecture_notes/10_clustering.pdf
- https://paulvanderlaken.com/2018/12/12/visualizing-the-inner-workings-of-the-k-means-clustering-algorithm/
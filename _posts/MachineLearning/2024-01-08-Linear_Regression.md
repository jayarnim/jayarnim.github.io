---
order: 8
title: Linear Regression
date: 2024-01-08
categories: [Artificial Intelligence, Machine Learning]
tags: [writing]
math: true
image:
  path: /img/MachineLearning/Thumbnail.jpg
---

# ğŸ’¡ What? Regression
-----

- **ì •ì˜** : ë°˜ì‘ë³€ìˆ˜ì™€ ê·¸ ì„¤ëª…ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì¶”ì„¸ë¥¼ ìš”ì•½í•˜ëŠ” ìˆ˜ë ´ ì‘ì—…

- **ì„¤ëª…ë³€ìˆ˜ì˜ ê°œìˆ˜ì— ë”°ë¥¸ êµ¬ë¶„**
    - **ë‹¨ìˆœ íšŒê·€ ëª¨í˜•(Simple Regression Model)** : ë°˜ì‘ë³€ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ë³€ìˆ˜ê°€ í•˜ë‚˜ì¸ ê²½ìš°(ì´í•˜ëŠ” ì„ í˜•ëª¨í˜•ì„ ê°€ì •)

        $$
        Y=\beta_0+\beta_1X+\varepsilon
        $$

    - **ë‹¤ì¤‘ íšŒê·€ ëª¨í˜•(Multiple Regression Model)** : ë°˜ì‘ë³€ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ë³€ìˆ˜ê°€ ë‘ ê°€ì§€ ì´ìƒì¸ ê²½ìš°(ì´í•˜ëŠ” ì„ í˜•ëª¨í˜•ì„ ê°€ì •)

        $$
        Y=\beta_0+\beta_1 X_1+\beta_2 X_2+\cdots+\beta_k X_k+\varepsilon
        $$

- **ì„ í˜• ê°€ì • ì—¬ë¶€ì— ë”°ë¥¸ êµ¬ë¶„**
    - **ì„ í˜• íšŒê·€ ëª¨í˜•(Linear Regression Model)** : ì„¤ëª…ë³€ìˆ˜ì™€ ë°˜ì‘ë³€ìˆ˜ ê°„ ì„ í˜•ê´€ê³„ë¥¼ ê°€ì •í•˜ëŠ” ê²½ìš°
        - `sklearn.linear_model.LinearRegression`
        - `sklearn.linear_model.SGDRegressor`

    - **ë¹„ì„ í˜• íšŒê·€ ëª¨í˜•(Non-Linear Regression Model)** : ì„¤ëª…ë³€ìˆ˜ì™€ ë°˜ì‘ë³€ìˆ˜ ê°„ ì„ í˜•ê´€ê³„ë¥¼ ê°€ì •í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        - `sklearn.svm.SVR`
        - `sklearn.tree.DecisionTreeRegressor`

# ğŸ’¡ Linear Regression
-----

### ë‹¨ìˆœ ì„ í˜• íšŒê·€ ëª¨í˜•

<p align="center"><img alt="reg" src="https://github.com/jayarnim/jayarnim/assets/116495744/08286995-d705-4e40-927b-4b96cbd202fb" width=80%></p>

- **ë‹¨ìˆœ ì„ í˜• íšŒê·€ ëª¨í˜•ì˜ ì´í•´**

    $$\begin{aligned}
    &Y=\beta_0+\beta_1X+\varepsilon\\
    &\Rightarrow y_i=\beta_0+\beta_1x_i+\varepsilon_i
    \end{aligned}$$

    - $\varepsilon$ : ì”ì°¨í•­(Residual)
        - $E[\varepsilon]=0$

    - $\beta_0$ : í¸í–¥(Bias)

    - $\beta_1$ : ê°€ì¤‘ì¹˜(Weight)

- **ìµœì†ŒììŠ¹ë²•ì— ê¸°ì´ˆí•œ íšŒê·€ê³„ìˆ˜ ìµœì ê°’ ë„ì¶œ**

    - **ìµœì†ŒììŠ¹ë²•(Least Square Method; OLS)** : íšŒê·€ê³„ìˆ˜ ìµœì ê°’ì„ **ì”ì°¨í•­ $\varepsilon_{i}$ ììŠ¹ì˜ í•©ê³„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°’**ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë°©ë²•

        $$\begin{aligned}
        \hat{\beta_{0}},\hat{\beta_{1}}
        &= \argmin_{\beta_{0},\beta_{1}}{L_{OLS}}
        \end{aligned}$$
    
    - ìµœì†ŒììŠ¹ë²•ì— ê¸°ì´ˆí•œ ì†ì‹¤ í•¨ìˆ˜ $L_{OLS}$

        $$\begin{aligned}
        L_{OLS}
        &= \sum_{i=1}^{n}{\varepsilon_{i}^2}\\
        \varepsilon_{i}
        &= y_{i}-\hat{y}_{i}\\
        &= y_{i}-(\beta_{0}+\beta_{1}\hat{x}_{i})
        \end{aligned}$$

    - ìµœì†ŒììŠ¹ë²•ì— ê¸°ì´ˆí•œ íšŒê·€ê³„ìˆ˜ $\beta_{0}$ ì˜ ìµœì ê°’ $\hat{\beta_{0}}$

        $$\begin{aligned}
        \hat{\beta_{0}}
        &= \overline{y}-\beta_{1}\overline{x}
        \end{aligned}$$

    - ìµœì†ŒììŠ¹ë²•ì— ê¸°ì´ˆí•œ íšŒê·€ê³„ìˆ˜ $\beta_{1}$ ì˜ ìµœì ê°’ $\hat{\beta_{1}}$

        $$\begin{aligned}
        \hat{\beta_{1}}
        &= \frac{\sum_{i=1}^{n}{(x_{i}-\overline{x})(y_{i}-\overline{y})}}{\sum_{i=1}^{n}{(x_{i}-\overline{x})^{2}}}\\
        &=\frac{\sigma_{xy}}{\sigma_{x}^{2}}
        \end{aligned}$$

### ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨í˜•

<p align="center"><img alt="multireg" src="https://github.com/jayarnim/jayarnim/assets/116495744/3c75c602-e85c-42aa-8050-ed054dec289f" width=80%></p>

- ê´€ì¸¡ì¹˜ $i$ ì— ëŒ€í•œ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨í˜•ì´ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•˜ì

    $$
    y_{i}=\beta_{0}+\beta_{1}x_{i,1}+\beta_{2}x_{i,2}+\cdots+\beta_{d}x_{i,d}
    $$

    - $i\in\{1,2,\cdots,n\}$ : ê´€ì¸¡ì¹˜ ë²ˆí˜¸
    - $k\in\{1,2,\cdots,d\}$ : ì„¤ëª…ë³€ìˆ˜ ë²ˆí˜¸

- $n$ ê°œì˜ ê´€ì¸¡ì¹˜ê°€ ì¡´ì¬í•œë‹¤ê³  í–ˆì„ ë•Œ ìœ„ ëª¨í˜•ì„ ì„ í˜•ëŒ€ìˆ˜ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ

    $$
    \hat{\overrightarrow{y}} = \hat{\mathbf{X}}\overrightarrow{\beta}
    $$

- ìµœì†ŒììŠ¹ë²•ì— ê¸°ì´ˆí•˜ì—¬ ë„ì¶œí•œ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ **ì •ê·œë°©ì •ì‹(Normal Equation)**ì´ë¼ê³  ì •ì˜í•¨

    $$\begin{aligned}
    \hat{\overrightarrow{\beta}}
    &= \argmin_{\overrightarrow{\beta}}{L_{OLS}}\\
    &= (\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\overrightarrow{y}
    \end{aligned}$$

# ğŸ’¡ [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
-----

```python
from sklearn.linear_model import LinearRegression
```

### General HyperParameter

- `n_jobs(default : None)` : ë³‘ë ¬ë¡œ ì‘ì—…í•  ì½”ì–´ ê°¯ìˆ˜

### Model HyperParameter

- `fit_intercept(default : True)` : ìƒìˆ˜í•­ $\beta_0$ ì„¤ì • ì—¬ë¶€

### Attribute

- `n_features_in_` : ì„¤ëª…ë³€ìˆ˜ ê°¯ìˆ˜
- `feature_names_in_` : ì„¤ëª…ë³€ìˆ˜ ì´ë¦„
- `coef_` : ì„¤ëª…ë³€ìˆ˜ë³„ ê°€ì¤‘ì¹˜
- `intercept_` : í¸í–¥

-----

#### ì´ë¯¸ì§€ ì¶œì²˜

- https://medium.com/analytics-vidhya/multiple-linear-regression-an-intuitive-approach-f874f7a6a7f9
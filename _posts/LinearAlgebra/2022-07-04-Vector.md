---
order: 1
title: Vector
date: 2022-07-04
categories: [MATHEMATICAL TECHS, Linear Algebra]
tags: [Mathematics]
math: true
description: >-
  Based on the lecture “Mathematics for Artificial Intelligence (2022-1)” by Prof. Yeo Jin Chung, Dept. of AI, Big Data & Management, College of Business Administration, Kookmin Univ.
image:
  path: /_post_refer_img/LinearAlgebra/Thumbnail.png
---

## What? Vector
-----

- **벡터(Vector)** : 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량
    - **원소(Element)** : 벡터를 구성하는 요소
    - **차원(Dimension)** : 원소의 갯수
    - **부분벡터(Sub-Vector)** : 임의의 벡터 $\overrightarrow{a}$ 에 대하여 그 부분 공간으로 구성된 벡터

        $$
        \overrightarrow{a_{r:s}}=\begin{pmatrix}a_r\\a_{r+1}\\a_{r+2}\\\vdots\\a_{s} \end{pmatrix}
        $$

- **특수한 벡터**
    - **영벡터(Zero Vector)** : 벡터 공간에서의 덧셈에 대한 항등원이 되는 벡터

        $$
        \overrightarrow{0}=\begin{pmatrix}0\\0\\\vdots\\0 \end{pmatrix}
        $$

    - **단위벡터(Unit Vector)** : 길이가 1인 벡터

        $$
        (\overrightarrow{e_{i}})_{j}=\begin{cases}1,\;if\;j=i\\0,\;if\;j \ne i\end{cases}
        $$

        $$
        \overrightarrow{e_{1}}=\begin{pmatrix}1\\0\\0\\\vdots\\0 \end{pmatrix}, 
        \overrightarrow{e_{2}}=\begin{pmatrix}0\\1\\0\\\vdots\\0 \end{pmatrix}, 
        \overrightarrow{e_{3}}=\begin{pmatrix}0\\0\\1\\\vdots\\0 \end{pmatrix}
        $$

- **벡터의 기하학적 해석**
    - 직각좌표계에 표현된 벡터 공간의 원소
        - **직각좌표계(Catesian Coordinate System)** : 좌표축과 평행한 단위벡터끼리 항상 서로 수직한 모든 좌표계
    - 좌표평면상 하나의 점
    - 좌표평면상 원점의 위치 이동
    - 좌표평면상 단위벡터의 선형 결합

        $$
        \begin{pmatrix}3\\2 \end{pmatrix} = 3 \times \overrightarrow{e_{1}} + 2 \times \overrightarrow{e_{2}}
        $$

## Vector Operation
-----

- **스칼라-벡터 곱셈**
    - 스칼라와 벡터의 곱셈은 벡터의 모든 원소에 대한 스칼라 곱으로 정의함

        $$
        \alpha \times \overrightarrow{a} = \begin{pmatrix}\alpha \times a_{1}\\\alpha \times a_{2}\\\vdots\\\alpha \times a_{n}\end{pmatrix}
        $$

    - 기하학적으로 봤을 때 이는 벡터를 스칼라 비율로 확대 혹은 축소하는 작업으로 해석할 수 있음

        ![01](/_post_refer_img/LinearAlgebra/01-01.jpg){: width="100%"}

    - 벡터에 음수를 곱하면 벡터의 방향이 원점에 대하여 반대가 됨

        ![02](/_post_refer_img/LinearAlgebra/01-02.png){: width="100%"}

- **덧셈과 뺄셈**
    - 차원이 $n$ 으로 동일한 벡터 $\overrightarrow{a}, \overrightarrow{b}$ 의 덧셈 혹은 뺄셈을 대응 원소의 합 혹은 차로 정의함

        $$
        \begin{pmatrix}a_{1}\\a_{2}\\\vdots\\a_{n}\end{pmatrix} + \begin{pmatrix}b_{1}\\b_{2}\\\vdots\\b_{n}\end{pmatrix} = \begin{pmatrix}a_{1}+b_{1}\\a_{2}+b_{2}\\\vdots\\a_{n}+b_{n} \end{pmatrix}
        $$

    - 기하학적으로 봤을 때 이는 벡터 $\overrightarrow{a}$ 를 방향 $\overrightarrow{b}$ 으로 폭 $\Vert \overrightarrow{b} \Vert$ 만큼 평행이동하는 작업으로 해석할 수 있음
        - **덧셈**

            ![03](/_post_refer_img/LinearAlgebra/01-03.jpeg){: width="100%"}

        - **뺄셈**

            ![04](/_post_refer_img/LinearAlgebra/01-04.png){: width="100%"}

## Linear Combination
-----

- **선형 결합(Linear Combination)**

    $$
    \alpha_{1}\overrightarrow{a_{1}} + \alpha_{2}\overrightarrow{a_{2}} + \cdots + \alpha_{p}\overrightarrow{a_{p}}
    $$

    - 차원이 $n$ 으로 동일한 임의의 벡터와 스칼라에 대하여, 각 항에 스칼라를 곱하거나 상호 더함으로써 일련의 항으로 구성하는 작업

- **선형 종속(Linearly Dependent)** : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현 가능한 경우
    - 좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치는 경우

        ![05](/_post_refer_img/LinearAlgebra/01-05.jpg){: width="100%"}

    - $n$ 차원 벡터 $\overrightarrow{a_{1}}, \overrightarrow{a_{2}}, \cdots, \overrightarrow{a_{p}}$ 와 스칼라 $\alpha_{1}, \alpha_{2}, \cdots, \alpha_{p}$ 에 대하여 다음을 만족하는 경우
        
        $$
        \alpha_{1}\overrightarrow{a_{1}} + \alpha_{2}\overrightarrow{a_{2}} + \cdots + \alpha_{p}\overrightarrow{a_{p}} = 0, \alpha^{\forall} \ne 0
        $$

- **선형 독립(Linearly Independent)** : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현될 수 없는 경우
    - 좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치지 않는 경우
        
        ![06](/_post_refer_img/LinearAlgebra/01-06.jpg){: width="100%"}

    - $n$ 차원 벡터 $\overrightarrow{a_{1}}, \overrightarrow{a_{2}}, \cdots, \overrightarrow{a_{p}}$ 와 스칼라 $\alpha_{1}, \alpha_{2}, \cdots , \alpha_{p}$ 에 대하여 다음을 만족하는 경우

        $$
        \alpha_{1}\overrightarrow{a_{1}} + \alpha_{2}\overrightarrow{a_{2}} + \cdots + \alpha_{p}\overrightarrow{a_{p}} = 0 \Rightarrow \alpha^{\forall} = 0
        $$

- **기저(Basis)**
    - $n$ 차원에 대하여 선형 독립인 벡터들의 집합
    - $n$ 차원 기저벡터의 최대 갯수는 $n$ 개임

- **$span$**

    $$
    \overrightarrow{x} = \alpha_{1}\overrightarrow{a_{1}} + \alpha_{2}\overrightarrow{a_{2}} + \cdots + \alpha_{n}\overrightarrow{a_{n}}
    $$

    - 주어진 벡터들의 선형 결합으로 나타낼 수 있는 벡터의 집합, 혹은 그러한 작업
    - $n$ 차원의 모든 기저벡터들을 $span$ 하면 해당 공간을 모두 나타낼 수 있음

## Inner Product and Norm
-----

- **내적(Inner Product)**

    $$\begin{aligned}
    \overrightarrow{a}\cdot\overrightarrow{b}&=<\overrightarrow{a},\overrightarrow{b}>\\
    &=\overrightarrow{a^{T}}\overrightarrow{b}\\
    &=\sum_{i}^{n}a_{i}b_{i}
    \end{aligned}$$

    - 차원이 $n$ 으로 동일한 두 벡터에 대하여 이를 대표하는 하나의 스칼라로 수렴하는 작업

- **유클리디안 노름(L-2 Norm)**

    $$
    \Vert \overrightarrow{a} \Vert=\sqrt{\overrightarrow{a}^T\cdot\overrightarrow{a}}
    $$

    - **정의** : 벡터의 규모(Magnitude) 혹은 길이(Length)
    
    - **성질**
        - $\Vert \overrightarrow{a} \Vert \ge0$
        - $\Vert \overrightarrow{a} \Vert =0\Rightarrow\overrightarrow{a}=\overrightarrow{0}$
        - $\Vert \alpha\overrightarrow{a} \Vert =\vert \alpha \vert \times \Vert \overrightarrow{a}\Vert$
        - $\Vert \overrightarrow{a}+\overrightarrow{b}\Vert\le\Vert\overrightarrow{a}\Vert+\Vert\overrightarrow{b}\Vert$

- **코사인 유사도(Cosine Similarity)** : 두 벡터의 사이각 $\theta$ 의 코사인 값을 이용하여 측정한 벡터 간 유사도

    $$
    cos\theta=\frac{\overrightarrow{a}\cdot\overrightarrow{b}}{\Vert\overrightarrow{a}\Vert\times\Vert\overrightarrow{b}\Vert}
    $$

    - $\theta$ : 임의의 벡터 $\overrightarrow{a}, \overrightarrow{b}$ 를 좌표평면상에 나타냈을 때, 두 벡터가 이루는 각도
    - $\Vert\overrightarrow{a}\Vert \cos{\theta}$ : $\overrightarrow{a}$ 를 $\overrightarrow{b}$ 에 정사영(Projection)하여 얻은 벡터의 길이

        ![07](/_post_refer_img/LinearAlgebra/01-07.png){: width="100%"}
    
    - **해석**
        - $-1\le \cos{\theta} \ge1$
        - $\cos{\theta} = -1$ : 음의 유사도를 가진다고 볼 수 있으며 기하학적으로 상반된 방향성을 가짐
        - $\cos{\theta} = 1$ : 양의 유사도를 가진다고 볼 수 있으며 기하학적으로 동일한 방향성을 가짐
        - $\cos{\theta} = 0$ : 유사하다고 볼 수 없으며 기하학적으로 직교함

- **직교정규벡터(Orthonomal Vector)** : 임의의 벡터에 대하여 해당 벡터와 직교하면서 그 노름이 1인 벡터
    - **정규벡터(Normal Vector)** : 노름이 1인 벡터
    - **상호직교(Mutually Orthonal)**
        - 수학적으로 봤을 때 내적값이 0인 관계

            $$
            \overrightarrow{a}\perp\overrightarrow{b}\Leftrightarrow\overrightarrow{a}\cdot\overrightarrow{b}=0
            $$

        - 기하학적으로 봤을 때 사잇각이 90도인 관계

            $$
            \overrightarrow{a}\perp\overrightarrow{b}\Leftrightarrow\frac{\overrightarrow{a}\cdot\overrightarrow{b}}{||\overrightarrow{a}||\times||\overrightarrow{b}||}=cos90^\circ
            $$
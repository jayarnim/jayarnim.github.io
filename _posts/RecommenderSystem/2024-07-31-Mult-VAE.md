---
order: 18
title: Mult-VAE
date: 2024-07-31
categories: [Research Interest, Recommender System]
tags: [Paper Review, Data Mining, Recommender System, Collaborative Filtering, Deep Learning, Autoencoder, Bayesian]
math: true
description: >-
    <ul type="square">
    <li><strong>Title</strong>: <a href="https://dl.acm.org/doi/abs/10.1145/3178876.3186150"><em>Variational Autoencoders for Collaborative Filtering</em></a></li>
    <li><strong>Author</strong>: <em>Liang et al.</em></li>
    <li><strong>Publisher</strong>: <em>WWW</em></li>
    <li><strong>Published</strong>: <em>2018</em></li>
    </ul>
image:
    path: /_post_refer_img/RecommenderSystem/Thumbnail.jpg
---

## Prerequisite; VAE
-----

### Concept

- 관측치 $\overrightarrow{\mathbf{x}}$ 가 파라미터 $\overrightarrow{\mathbf{z}}$ 에서 생성되었다고 가정하자. $\overrightarrow{\mathbf{x}}$ 의 우도 함수:

    $$
    \overrightarrow{\mathbf{x}} \mid \overrightarrow{\mathbf{z}} \sim \mathcal{L}\left(\Theta \right)
    $$

- 파라미터 $\overrightarrow{\mathbf{z}}$ 의 사전 확률 분포 결정:

    $$
    \overrightarrow{\mathbf{z}} \sim \mathcal{N}\left(0, \mathbf{I}_{K}\right)
    $$

- 파라미터 $\overrightarrow{\mathbf{z}}$ 의 사후 확률 분포 추정:

    $$
    p\left(\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} ; \Theta\right) \propto \mathcal{L}\left(\overrightarrow{\mathbf{x}} \mid \overrightarrow{\mathbf{z}} ; \Theta \right) \cdot \pi(\overrightarrow{\mathbf{z}})
    $$

- $\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} \sim P(\Theta)$ 의 근사 분포 $\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} \sim Q(\Phi)$ 정의:

    $$\begin{aligned}
    q\left(\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} ; \Phi\right)
    &= \mathcal{N}\left(\mu(\overrightarrow{\mathbf{x}};\Phi), \text{diag}[\sigma^2(\overrightarrow{\mathbf{x}};\Phi)]\right)\\
    &\approx \mu(\overrightarrow{\mathbf{x}};\Phi) + \sigma(\overrightarrow{\mathbf{x}};\Phi) \odot \epsilon \quad \text{for} \quad \epsilon \sim \mathcal{N}\left(0, \mathbf{I}_{K}\right)
    \end{aligned}$$

- ELBO:

    $$
    \text{ELBO}
    = \underbrace{\mathbb{E}_{\mathbf{z} \mid \mathbf{x} \sim Q(\Phi)}\Big[\log{\mathcal{L}\left(\overrightarrow{\mathbf{x}} \mid \overrightarrow{\mathbf{z}} ; \Theta \right)}\Big]}_{-\text{Reconstruction Loss}} - \beta \cdot \underbrace{D_{KL}\Big[q\left(\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} ; \Phi\right) \parallel \pi(\overrightarrow{\mathbf{z}})\Big]}_{\text{KL Divergence}}
    $$

- Optimization:

    $$
    \hat{\Theta},\hat{\Phi} \mid K, \beta
    = \text{arg}\max_{\Theta,\Phi}{\text{ELBO}}
    $$

    - $K$ : Dimension of Latent Space
    - $0 \le \beta \le 1$ : KL Annealing Param

### Architecture

![01](/_post_refer_img/RecommenderSystem/17-01.png){: width="100%"}

- **Encoder** : Posterior Probability Distribution Estimatior

    $$
    q\left(\overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}} ; \Phi\right)
    $$

- **Latent Space** : Posterior Probability Distribution

    $$
    \overrightarrow{\mathbf{z}} \mid \overrightarrow{\mathbf{x}}
    $$

- **Decoder** : Data Generator

    $$
    \mathcal{L}\left(\overrightarrow{\mathbf{x}} \mid \overrightarrow{\mathbf{z}} ; \Theta \right)
    $$

## Mult-VAE
-----

- **Mult-VAE(`Mult`inomial `V`ariational `A`uto`E`ncoder)** : 아이템 간 암묵적 경쟁 관계 및 파라미터 추정 시 정보 불확실성을 반영한 사용자 기반 협업 필터링 추천 알고리즘

- **선행 연구의 한계점**
    - **Likelihood Function** : 사용자가 여러 아이템과 상호작용하는 과정에서 아이템들이 암묵적 경쟁 관계에 놓인다는 점을 간과함
        - Gaussian Likelihood
        - Logistic Likihood

    - **Frequentist Method** : 협업 필터링 알고리즘 학습 시 직면하는 문제점인 정보 불확실성을 반영하지 아니함
        - Deterministic Parameter Estimation

- **Mult-VAE 의 해법**
    - Multinomial Likelihood Function
    - Probabilistic Parameter Estimation Using the Bayesian Method

### How to Modeling

- 사용자 벡터 $$\overrightarrow{\mathbf{x}}_{u}$$ 가 파라미터 $$\overrightarrow{\mathbf{z}}_{u}$$ 에서 생성되었다고 가정하자. $$\overrightarrow{\mathbf{x}}_{u}$$ 의 우도 함수:

    $$
    \overrightarrow{\mathbf{x}_{u}} \mid \overrightarrow{\mathbf{z}}_{u} \sim \mathcal{L}\left(\Theta \right) = \text{Multinomial}\left(N_{u},\overrightarrow{\mathbf{p}}_{u}\right)
    $$

    - $N_{u}$ : 사용자 $u$ 의 총 상호작용 횟수
    - $$\overrightarrow{\mathbf{p}}_{u}$$ : 파라미터 $$\overrightarrow{\mathbf{z}}_{u}$$ 로부터 계산된, 아이템에 대한 확률 벡터

        $$
        \overrightarrow{\mathbf{p}}_{u} = \text{softmax}\left[G(\overrightarrow{\mathbf{z}}_{u}; \Theta)\right]
        $$

        - $G(\Theta)$ : Decoder Network

- 파라미터 $\overrightarrow{\mathbf{z}}_{u}$ 의 사전 확률 분포 결정:

    $$
    \overrightarrow{\mathbf{z}}_{u} \sim \mathcal{N}\left(0, \mathbf{I}_{K}\right)
    $$

- 파라미터 $\overrightarrow{\mathbf{z}}_{u}$ 의 사후 확률 분포 추정:

    $$
    p\left(\overrightarrow{\mathbf{z}}_{u} \mid \overrightarrow{\mathbf{x}}_{u} ; \Theta\right) \propto \mathcal{L}\left(\overrightarrow{\mathbf{x}}_{u} \mid \overrightarrow{\mathbf{z}}_{u} ; \Theta \right) \cdot \pi(\overrightarrow{\mathbf{z}}_{u})
    $$

### Optimization

- $$\overrightarrow{\mathbf{z}}_{u} \mid \overrightarrow{\mathbf{x}}_{u} \sim P(\Theta)$$ 의 근사 분포 $$\overrightarrow{\mathbf{z}}_{u} \mid \overrightarrow{\mathbf{x}}_{u} \sim Q(\Phi)$$ 정의:

    $$\begin{aligned}
    q\left(\overrightarrow{\mathbf{z}}_{u} \mid \overrightarrow{\mathbf{x}}_{u} ; \Phi\right)
    &= \mathcal{N}\left(\mu(\overrightarrow{\mathbf{x}}_{u};\Phi), \text{diag}[\sigma^2(\overrightarrow{\mathbf{x}}_{u};\Phi)]\right)\\
    &\approx \mu(\overrightarrow{\mathbf{x}}_{u};\Phi) + \sigma(\overrightarrow{\mathbf{x}}_{u};\Phi) \odot \epsilon \quad \text{for} \quad \epsilon \sim \mathcal{N}\left(0, \mathbf{I}_{K}\right)
    \end{aligned}$$

- ELBO:

    $$
    \text{ELBO}
    = \underbrace{\mathbb{E}_{\mathbf{z}_{u} \mid \mathbf{x}_{u} \sim Q(\Phi)}\Big[\log{\mathcal{L}\left(\overrightarrow{\mathbf{x}}_{u} \mid \overrightarrow{\mathbf{z}}_{u} ; \Theta \right)}\Big]}_{-\text{Reconstruction Loss}} - \beta \cdot \underbrace{D_{KL}\Big[q\left(\overrightarrow{\mathbf{z}}_{u} \mid \overrightarrow{\mathbf{x}}_{u} ; \Phi\right) \parallel \pi(\overrightarrow{\mathbf{z}}_{u})\Big]}_{\text{KL Divergence}}
    $$

- Optimization:

    $$
    \hat{\Theta},\hat{\Phi} \mid K, \beta
    = \text{arg}\max_{\Theta,\Phi}{\text{ELBO}}
    $$

    - $K$ : Dimension of Latent Space
    - $0 \le \beta \le 1$ : KL Annealing Param
---
order: 19
title: CLiMF
date: 2024-09-05
categories: [AI Application, Recommender System]
tags: [Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF, Ranking Prediction, Objective Function, Listwise Learning, MRR]
math: true
description: >-
    <ul type="square">
    <li><strong>Title</strong>: <a href="https://doi.org/10.1145/2365952.2365981"><code>CLiMF: Learning to Maximize Reciprocal Rank with Collaborative Less-is-More Filtering</code></a></li>
    <li><strong>Published</strong>: <em>2012</em></li>
    <li><strong>Data Set</strong>: <code><a href="https://www.kaggle.com/datasets/masoud3/epinions-trust-network">Epinions</a></code>
    </li>
    </ul>
image:
    path: /_post_refer_img/RecommenderSystem/Thumbnail.jpg
---

## CLiMF
-----

- **CLiMF(`C`ollaborative `L`ess-`i`s-`M`ore `F`iltering)** : Probabilistc Pointwise Ranking Prediction

    > 선행 연구들은 명시적 피드백 하 선호 점수를 예측하는 것에 초점을 맞추었음. 이러한 연구 경향은 친구 추천, 팔로우 추천 등 이진 피드백이 활용되는 사례에 적합하지 않음. 순위 기반 최적화 및 Top-k 추천 품질에 관한 논의가 필요함. BPR 이 순위 기반 최적화를 시도하였으나, AUC 최적화는 Top-k 추천 품질 개선에 미흡함. 순위가 더 높이 제안될수록 더 큰 영향을 가지도록 유도하는 MRR 최적화가 필요함.

## MRR Optimization
-----

- **RR(`R`eciprocal `R`ank)** : 사용자 $u$ 에 대하여 정답 아이템이 처음 등장하는 순번의 역수

    $$\begin{aligned}
    \text{RR}
    &= \frac{1}{\text{Rank of 1st Relevent Item}}
    \end{aligned}$$

- **MRR(`M`ean `R`eciprocal `R`ank)** : 모든 사용자에 대하여 정답 아이템이 처음 등장하는 평균적인 순번

    $$\begin{aligned}
    \text{MRR}
    &= \frac{1}{\vert U \vert}\sum_{u \in U}{\text{RR}_{u}}
    \end{aligned}$$

## How to Modeling
-----

- **Smoothing Trick**

    $$\begin{aligned}
    \sigma(x)
    &= \frac{1}{1 + \exp{-x}}
    \end{aligned}$$

- **Rank** : 사용자 벡터 $$\overrightarrow{\mathbf{p}}_{u}$$ 와 아이템 벡터 $$\overrightarrow{\mathbf{q}}_{i}$$ 의 내적값이 클수록 해당 아이템이 상위에 랭크될 가능성이 높다는 뜻으로 이해할 수 있음

    $$\begin{aligned}
    \frac{1}{\text{Rank}(u,i)}
    &\approx \sigma\left[\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i}\right]
    \end{aligned}$$

    | Dot Product | Sigmoid Function |
    |---|---|
    | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} \to +\infty$$ | $$\sigma \to 1$$ |
    | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} \to 0$$ | $$\sigma \to 0.5$$ |
    | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} \to -\infty$$ | $$\sigma \to 0$$ |

- **Indicator Function** : 순위는 다른 아이템과의 상대적 위치이므로, 아이템 간 선호의 우열을 다루는 항목이 필요하며, 이때 사용자 $u$ 와 아이템 $i$ 의 내적값이 $j$ 보다 더 클 가능성이 높을수록 순위가 더 높다는 뜻으로 이해할 수 있음

    - Original(Rank Comparison):

        $$\begin{aligned}
        \mathbb{I}(\text{Rank}(u,i) < \text{Rank}(u,j))
        = \begin{cases}
        1 \quad &\text{If $i$ is Higher than $j$}\\
        0 \quad &\text{Otherwise}
        \end{cases}
        \end{aligned}$$

    - Convert(Dot Product Comparison):

        $$\begin{aligned}
        \sigma\left[\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} - \overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{j}\right]
        \end{aligned}$$

        | Dot Product | Sigmoid Function |
        |---|---|
        | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} > \overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{j}$$ | $$\sigma \to 1$$ |
        | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} = \overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{j}$$ | $$\sigma \to 0.5$$ |
        | $$\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} < \overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{j}$$ | $$\sigma \to 0$$ |

- **Objective Function**

    $$\begin{aligned}
    \mathcal{J}
    &= \sum_{u \in U} \sum_{i \in I_{u}^{+}}{\left(\ln{\sigma\left[\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i}\right]} + \sum_{j \in I \setminus I_{u}^{+}}{\ln{\sigma\left[\overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{i} - \overrightarrow{\mathbf{p}}_{u} \cdot \overrightarrow{\mathbf{q}}_{j}\right]}}\right)} - \lambda_{\Theta}\Vert \Theta \Vert^{2}
    \end{aligned}$$
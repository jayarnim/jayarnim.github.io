---
order: 21
title: FAWMF
date: 2024-08-21
categories: [Research Interest, Recommender System]
tags: [Paper Review, Data Mining, Recommender System, Collaborative Filtering, Latent Factor Model, Deep Learning, Autoencoder, Implicit Feedback, Weight Approach, Bayesian]
math: true
description: >-
    <ul type="square">
    <li><strong>Title</strong>: <a href="https://arxiv.org/abs/2003.01892"><code>Fast Adaptively Weighted Matrix Factorization for Recommendation with Implicit Feedback</code></a></li>
    <li><strong>Publisher</strong>: <em>AAAI</em></li>
    <li><strong>Published</strong>: <em>2020</em></li>
    <li><strong>Data Set</strong>:
        <ul>
        <li><code><a href="https://grouplens.org/datasets/movielens/">MovieLens</a></code></li>
        <li><code><a href="https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews">Amazon(Food)</a></code></li>
        <li><a href="https://www.cse.cuhk.edu.hk/irwin.king.new/pub/data/douban"><code>Douban</code></a></li>
        </ul>
    </li>
    </ul>
image:
    path: /_post_refer_img/RecommenderSystem/Thumbnail.jpg
---

## FAWMF
-----

- **FAWMF(`F`ast `A`daptively `W`eighted `M`atrix `F`actorization)**

## How to Modeling
-----

### Analyses of EXMF from Bayesian Framework

- 노출 여부의 사전 분포

    $$\begin{aligned}
    y_{i,j} \sim \text{Bernoulli}\left(\mu_{i,j}\right)
    \end{aligned}$$

    - $$y_{i,j} = \big\{1,0\big\} \in \mathbf{Y}_{M \times N}$$ : Exposure Variable
    - $$\mu_{i,j}$$ : Hyper-Parameter

- 노출 여부의 우도 함수

    $$\begin{aligned}
    r_{i,j} \mid y_{i,j} \sim \mathcal{N}\left(\overrightarrow{\mathbf{u}}_{i} \cdot \overrightarrow{\mathbf{v}}_{j}, \lambda^{-1}\right)
    \end{aligned}$$

    - $$r_{i,j} = \big\{1,0\big\} \in \mathbf{R}_{M \times N}$$ : Click Variable

- 노출 여부의 사후 분포

    $$\begin{aligned}
    p\left(y_{i,j} \mid r_{i,j}\right)
    \propto \mathcal{L}\left(r_{i,j} \mid y_{i,j}\right) \cdot \pi\left(y_{i,j}\right)
    \end{aligned}$$

### Approx. Dist.

- 노출 여부의 사후 분포의 근사 분포

    $$\begin{aligned}
    y_{i,j} \mid \gamma_{i,j} \sim \text{Bernoulli}\left(\gamma_{i,j}\right)
    \end{aligned}$$

- Parameter $\gamma$

    $$\begin{aligned}
    \gamma_{i,j}
    &= \mathcal{G}\left(i,j,\mathbf{R} \mid \Theta, \mathbf{w}, \mathbf{a}, \mathbf{b}\right)\\
    &= \overrightarrow{\Theta}_{i} \cdot \overrightarrow{\Phi}_{j}
    \end{aligned}$$

    - $$\overrightarrow{\Theta}_{i} \in \Theta_{M \times D}$$ : Community Membership Vector
        - Community Memebership is Probability : $$\Vert \overrightarrow{\Theta}_{i} \Vert_{L1} = 1, \theta_{i,d} \ge 0$$

    - $$\overrightarrow{\Phi}_{j} \in \Phi_{N \times D}$$ : Exposure Prob. of Item $j$ for each Communities

        $$\begin{aligned}
        \overrightarrow{\Phi}_{j} = \sigma \left(w_{j} \sum_{l \in U}{\overrightarrow{\Theta}_{l} \cdot \alpha_{l} \cdot r_{l,j}} + b_{j}\right)
        \end{aligned}$$

        - $$\sum_{l \in U}{\overrightarrow{\Theta}_{l}} \cdot \alpha_{l} \cdot r_{l,j}$$ : Exposure Contribution of Item $j$ for each Communities
            - $$\alpha_{i} \in \overrightarrow{\mathbf{a}}_{M}$$ : User Influence
        - $$w_{j} \in \overrightarrow{\mathbf{w}}_{N}$$ : Weight
        - $$b_{j} \in \overrightarrow{\mathbf{b}}_{N}$$ : Bias
        - $$\sigma$$ : Activation Function, Sigmoid

### Optimization

- ELBO

    $$\begin{aligned}
    \text{ELBO}
    &= \underbrace{\sum_{(i,j)}{\gamma_{i,j} \cdot \left(\overrightarrow{\mathbf{u}}_{i} \cdot \overrightarrow{\mathbf{v}}_{j} - r_{i,j}\right)^{2}}}_{\text{Clik under Exposure}} + \underbrace{\sum_{(i,j)}{\left(1-\gamma_{i,j}\right) \cdot \left(\epsilon - r_{i,j}\right)^{2}}}_{\text{non-Clik under non-Exposure}} - \sum_{(i,j)}{D_{KL}\Big[q\left(y_{i,j} \mid \gamma_{i,j}\right) \parallel \pi\left(y_{i,j}; \mu_{i,j}\right)\Big]}
    \end{aligned}$$

- KL Divergence by analytical representation of Bernoulli distribution

    $$\begin{aligned}
    D_{KL}\Big[q\left(y_{i,j} \mid \gamma_{i,j}\right) \parallel \pi\left(y_{i,j}; \mu_{i,j}\right)\Big]
    &= \sum_{y_{i,j}}{q\left(y_{i,j} \mid \gamma_{i,j}\right) \cdot \log{\frac{q\left(y_{i,j} \mid \gamma_{i,j}\right)}{\pi\left(y_{i,j}; \mu_{i,j}\right)}}}\\
    &= \gamma_{i,j} \cdot \log{\frac{\gamma_{i,j}}{\mu_{i,j}}} + \left(1-\gamma_{i,j}\right) \cdot \log{\frac{1-\gamma_{i,j}}{1-\mu_{i,j}}}
    \end{aligned}$$

- Optimization

    $$\begin{aligned}
    \overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}}, \overrightarrow{\mathbf{\Theta}}, \alpha, w, b \mid \mu, \epsilon, D, K
    &= \text{arg} \min{-\text{ELBO}}
    \end{aligned}$$

### fBGD

- **fBGD(`f`ast-`B`atch `G`radient `D`escent)** : 역전파 시 반복해서 계산해야 하는 일부 항목을 캐싱함으로써 학습 속도를 향상시키는 배치 경사하강법

- 반복 계산이 발생하는 요소:

    $$\begin{aligned}
    \frac{\partial \mathcal{J}}{\partial \alpha_{l}}
    &= \sum_{j \in I}{\frac{\partial \mathcal{J}}{\partial \overrightarrow{\Phi}_{j}} \cdot \frac{\partial \overrightarrow{\Phi}_{j}}{\partial \alpha_{l}}}
    \end{aligned}$$

- 목적 함수 $\mathcal{J}=-\text{ELBO}$ 를 아이템 $j$ 에 대한 커뮤니티 노출 확률 $\overrightarrow{\Phi}_{j}$ 에 대하여 미분한 결과:

    $$\begin{aligned}
    \frac{\partial \mathcal{J}}{\partial \overrightarrow{\Phi}_{j}}
    &= \sum_{i \in U}{\Big[\left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}\right)^{2} - 2r_{i,j}\left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}- \epsilon\right) - \epsilon^{2}\Big] \cdot \overrightarrow{\Theta}_{i}}\\
    &= \sum_{i \in U}{\left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}\right)^{2} \cdot \overrightarrow{\Theta}_{i}} - 2\sum_{i \in U}{r_{i,j} \cdot \overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j} \cdot \overrightarrow{\Theta}_{i}} + 2\sum_{i \in U}{r_{i,j} \cdot \epsilon \cdot \overrightarrow{\Theta}_{i}} - \epsilon^{2} \sum_{i \in U}{\overrightarrow{\Theta}_{i}}\\
    &= \sum_{i \in U}{\left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}\right)^{2} \cdot \overrightarrow{\Theta}_{i}} - \epsilon^{2} \sum_{i \in U}{\overrightarrow{\Theta}_{i}} - 2\sum_{i \in U}{r_{i,j} \cdot \left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j} - \epsilon\right)\cdot \overrightarrow{\Theta}_{i}}
    \end{aligned}$$

- 사용자-잠재요인 벡터와 아이템-잠재요인 벡터의 내적값 풀이:

    $$\begin{aligned}
    \overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}
    &= \sum_{g=1}^{K}{u_{i,g} \cdot v_{j,g}}\\
    \left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j}\right)^{2}
    &= \left(\sum_{g=1}^{K}{u_{i,g}v_{j,g}}\right) \cdot \left(\sum_{h=1}^{K}{u_{i,h}v_{j,h}}\right)\\
    &=\sum_{g=1}^{K}{\sum_{h=1}^{K}{u_{i,g}u_{i,h} \cdot v_{j,g}v_{j,h}}}\\
    \end{aligned}$$

- 캐싱:

    $$\begin{aligned}
    M_{g,h}
    &= \sum_{i \in U}{u_{i,g}u_{i,h} \cdot \overrightarrow{\Theta}_{i}}\\
    S
    &= \sum_{i \in U}{\overrightarrow{\Theta}_{i}}
    \end{aligned}$$

- 캐싱을 적용한 $\overrightarrow{\Phi}_{j}$ 에 대한 $\mathcal{J}$ 미분값:

    $$\begin{aligned}
    \frac{\partial \mathcal{J}}{\partial \overrightarrow{\Phi}_{j}}
    &= \sum_{g=1}^{K}{\sum_{h=1}^{K}{M_{g,h} \cdot v_{j,g}v_{j,h}}} - \epsilon^{2} \cdot S - 2\sum_{i \in U}{r_{i,j} \cdot \left(\overrightarrow{\mathcal{u}}_{i}^{T}\overrightarrow{\mathcal{v}}_{j} - \epsilon\right)\cdot \overrightarrow{\Theta}_{i}}
    \end{aligned}$$

- $\alpha_{l}$ 에 대한 $\overrightarrow{\Phi}_{j}$ 미분값:

    $$\begin{aligned}
    \frac{\partial \overrightarrow{\Phi}_{j}}{\partial \alpha_{l}}
    &= \overrightarrow{\Phi}_{j} \cdot \left(1-\overrightarrow{\Phi}_{j}\right) \cdot \overrightarrow{\Theta}_{i} \cdot w_{j} \cdot r_{l,j}
    \end{aligned}$$
---
order: 2
title: Bayes by Backprop
date: 2024-06-11
categories: [Machine Learning Techs, Bayesian Deep Learning]
tags: [Deep Learning, Bayesian, Variational Inference, Objective Function]
math: true
description: >-
    <ul type="square">
    <li><strong>Title</strong>: <a href="https://proceedings.mlr.press/v37/blundell15"><code>Weight Uncertainty in Neural Networks</code></a></li>
    <li><strong>Published</strong>: <em>2015</em></li>
    </ul>
image:
    path: /_post_refer_img/BayesianDeepLearning/Thumbnail.jpg
---

## Bayes by Backprop
-----

- **BBB(`B`ayes `b`y `B`ackprop)** : 신경망과 같은 복잡한 모형에서, 역전파 알고리즘을 활용한 최적화 학습을 통해 파라미터의 사후 분포를 추정하기 위해 정보 이론적 접근을 사용하는 베이지안 추론 방법론

- **SUMMARY**
    - **파라미터의 사후 확률 분포 추정 방법** : 변분 추론(Variational Inference)
    - **목적 함수** : 증거 하한(Evidence Lower Bound; ELBO)
    - **역전파 트릭** : 재매개변수화 트릭(Reparameterization Trick)
    - **과적합 방지 트릭** : 후방 템퍼링(Posterior Tempering)

## ELBO
-----

$$\begin{aligned}
\hat{\theta} &= \text{arg}\max_{\theta}{\text{ELBO}}
\end{aligned}$$

- **사후 분포 $W \mid \mathcal{D} \sim P$ 와 그 근사 분포 $W \sim Q$ 의 차이 세분화**

    $$\begin{aligned}
    D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
    &= \mathbb{E}_{W \sim Q}\left[\log{\frac{Q(W)}{P(W \mid \mathcal{D})}}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(W \mid \mathcal{D})}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{\frac{P(\mathcal{D} \mid W) \cdot P(W)}{P(\mathcal{D})}}\right]\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)}\right] - \bigg(\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \mathbb{E}_{W \sim Q}\left[\log{P(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D})}\right]\bigg)\\
    &= \mathbb{E}_{W \sim Q}\left[\log{Q(W)} - \log{P(W)}\right] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D})}\right]\\
    &= D_{KL}\big[Q(W) \parallel P(W)\big] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \log{P(\mathcal{D})}
    \end{aligned}$$

    - $D_{KL}\big[Q(W) \parallel P(W)\big]$ : 사후 분포의 근사 분포 $W \sim Q$ 와 사전 분포 $W \sim P$ 의 차이
    - $\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right]$ : 사후 분포의 근사 분포 $W \sim Q$ 에서 샘플링된 가중치 $W$ 에 대한 로그 우도의 기대값
    - $\log{P(\mathcal{D})}$ : 데이터 $\mathcal{D}$ 에 대한 로그 마진 우도(Marginal Liklihood)로서, $\mathcal{D}$ 가 발생할 확률

- **$\log{P(\mathcal{D})}$ 의 이해**

    $$\begin{aligned}
    D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
    &= D_{KL}\big[Q(W) \parallel P(W)\big] - \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] + \log{P(\mathcal{D})}\\
    \log{P(\mathcal{D})}
    &= D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big] + \bigg(\mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]\bigg)\\
    \therefore \log{P(\mathcal{D})}
    &\ge \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
    \end{aligned}$$

- **증거 하한(`E`vidence `L`ower `B` `o`und; ELBO)** : 파라미터 갱신 증거 $\log{P(\mathcal{D})}$ 의 하한값

    $$\begin{aligned}
    \text{ELBO}
    &= \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right] - D_{KL}\big[Q(W) \parallel P(W)\big]
    \end{aligned}$$

- **왜 $\log{P(\mathcal{D})}$ 가 파라미터 갱신 증거(Evidence)인가?**

    > 데이터 발생 원리는 모수에 있음. <br> 즉, 데이터가 발생한 다음 그 특징으로서 모수가 도출되는 것이 아니라, 모수가 데이터 발생 원리로서 선험적으로 존재하고, 이 원리에 근거하여 데이터가 발생함. 따라서 모수가 어떠하다고 주장했을 때, 데이터는 이 주장의 타당성을 보장하는 근거가 됨. <br> 다만, 빈도주의 철학에서 이는 하나의 값으로서 확정돼 있는 절대적인 진리인데 반해, 베이지안 철학에서는 불확실한 값임. 따라서 베이지안 방법론에서는 모수를 확률변수로 설정하여 모델링함. 구체적으로는 모수에 대한 연구자의 사전 신념(Prior)을 바탕으로 증거를 관측하며 이 신념을 갱신해 감(Posterior). <br> 실현된 데이터는 모수, 즉 데이터 발생 원리에 대하여 가지고 있었던 초기 신념(Prior)을 뒷받침하거나 갱신하는(Posterior) 근거로서 활용됨. 따라서 데이터 $\mathcal{D}$ 가 발생할 확률 $P(\mathcal{D})$ 은 갱신된 파라미터에 대한 증거(Evidence)임.

## Reparameterization Trick
-----

- **재매개변수화 트릭(Reparameterization Trick)** : 역전파 알고리즘을 활용한 최적화 학습이 가능하도록 샘플링을 미분 가능한 함수로 변형하는 방법

    $$
    W \sim Q \quad \rightarrow \quad w = g(\epsilon, \theta)
    $$

- **`EXAMPLE`** $$w \sim \mathcal{N}(\mu,\sigma^2)$$

    $$
    w \mid \mu,\sigma \sim \mathcal{N} \quad \rightarrow \quad w = \mu + \sigma \cdot \epsilon
    $$

## Posterior Tempering
-----

- **후방 템퍼링(Posterior Tempering)** : 데이터에 과적합되는 것을 방지하도록 우도 항목의 영향력을 할인하는 방법

    $$\begin{aligned}
    P(\theta \mid \mathcal{D})
    &\approx \left[P(\mathcal{D} \mid \theta)\right]^{1/T} \cdot P(\theta)
    \end{aligned}$$

- **`EXAMPLE` ELBO**

    $$\begin{aligned}
    \text{ELBO}
    &= -D_{KL}\big[Q(W) \parallel P(W \mid \mathcal{D})\big]
    + \frac{1}{T} \cdot \mathbb{E}_{W \sim Q}\left[\log{P(\mathcal{D} \mid W)}\right]
    \end{aligned}$$
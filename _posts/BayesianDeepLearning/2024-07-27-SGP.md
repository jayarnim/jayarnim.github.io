---
order: 5
title: Sparse Gaussian Process
date: 2024-07-27
categories: [Machine Learning Techs, Bayesian Deep Learning]
tags: [Deep Learning, Bayesian, Stochastic Process, Nonparametric Estimation, Gaussian Process, Variational Inference]
math: true
image:
    path: /_post_refer_img/BayesianDeepLearning/Thumbnail.jpg
---

## Gaussian Process
-----

- [GP DESC.](https://jayarnim.github.io/posts/GP/)

## SGP
-----

- **SGP(`S`parse `G`aussian `P`rocess)** : $M < N$ 개의 유도점(Inducing Points)을 도입하여 공분산 행렬을 근사하는 기법으로서, 계산량을 $\mathcal{O}(N^{3}) \to \mathcal{O}(M^{2}N)$ 으로 줄임으로써 효율성을 도모함

    ![01](/_post_refer_img/BayesianDeepLearning/05-01.png){: width="100%"}

- **Methods**
    - **Nyström Approximation `BASIC`**
        - Inducing Points Sampling
        - Matrix Factorization

    - FITC(`F`ully `I`ndependent `T`raining `C`onditional)
        - Inducing Points Sampling
        - All data Points are Independent of the Inducing Points
        - Matrix Factorization

    - SKI(`S`tructured `K`ernel `I`nterpolation)
        - Grid based Inducing Points
        - Matrix Factorization

    - **Sparse Variational Gaussian Process**
        - Inducing Points Optimization
        - Variational Inference

    - **DGP(`D`ecoupled `G`aussian `P`rocess)**
        - Separate the Inducing Points into Mean Function and Covariance Function
        - Mean Function and Covariance Function Optimization
        - Variational Inference

- **Nyström Approximation**

    $$\begin{aligned}
    \mathbf{K}_{N} \approx \mathbf{Q}_{N} = \mathbf{K}_{NM} \cdot \mathbf{K}^{-1}_{MM} \cdot \mathbf{K}_{MN}
    \end{aligned}$$

    - $$\mathbf{K}_{MM}$$ : 유도점끼리의 공분산 행렬
    - $$\mathbf{K}_{NM}$$ : 전체 데이터와 유도점 간 공분산 행렬
    - $$\mathbf{K}_{MN}$$ : $$\mathbf{K}_{NM}$$ 의 전치 행렬

- **Posterior Dist.**

    $$\begin{aligned}
    \mathcal{F}^{*} \mid X, Y, X^{*} \sim \mathcal{N}(\mu^{*}, (\sigma^{*})^{2})
    \end{aligned}$$

    - Posterior Mean:

        $$\begin{aligned}
        \mu^{*}=\mu(X^{*}) + \overrightarrow{\mathbf{q}}_{N}^{*}(\mathbf{Q}_{N}+\sigma^{2}_{N}\mathbf{I})^{-1}(Y-\mu(X))
        \end{aligned}$$

    - Posterior Var.:

        $$\begin{aligned}
        (\sigma^{*})^{2}
        =\mathcal{K}(X^{*},X^{*})-\overrightarrow{\mathbf{q}}_{N}^{*}(\mathbf{Q}_{N}+\sigma^{2}_{N}\mathbf{I})^{-1}\left(\overrightarrow{\mathbf{q}}_{N}^{*}\right)^{T}
        \end{aligned}$$

## Variational Inference based Opt.
-----

- **SVGP(`S`parse `V`ariational `G`aussian `P`rocess)**

- **DGP(`D`ecoupled `G`aussian `P`rocess)**
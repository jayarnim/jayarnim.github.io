[
  
  {
    "title": "Hidden Markov Model",
    "url": "/posts/hmm/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "stochastic process, time series, markov chain, hidden markov model, em algorithm, mle",
    "date": "2025-08-07 00:00:00 +0900",
    





    
    "snippet": "Markov Chain      The Markov Property is a property in which past information is concentrated in the current state, so that the future state is independent of the past state conditionally on the cu...",
    "content": "Markov Chain      The Markov Property is a property in which past information is concentrated in the current state, so that the future state is independent of the past state conditionally on the current state.\\[\\begin{gathered}  X(t+1)\\perp X(0),X(1),\\cdots,X(t-1)\\mid X(t)  \\end{gathered}\\]        For a random variable sequence \\(\\{X(t):t\\in T\\}\\) defined on a discrete time space \\(t\\in T\\) and a discrete state space \\(S=\\{k\\}_{k=1}^{K}\\), if this sequence is a stochastic process that satisfies the Markov Property, it is defined as a Markov Chain.\\[\\begin{gathered}  P[X(t+1)\\mid X(0),X(1),\\cdots,X(t-1),X(t)]  =P[X(t+1)\\mid X(t)]  \\end{gathered}\\]        discrete state probability is the possibility that at time $t$ the random variable $X(t)$ will take a specific state $i$.\\[\\pi_{i}(t)=P[X(t)=i]\\]        transition probability is the possibility that the future state $t+1$ will change to $j$ when the current state $t$ is realized as $i$.\\[\\begin{aligned}  \\alpha_{i,j}  =P[X(t+1)=j\\mid X(t)=i]  \\end{aligned}\\]        discrete state distribution vector \\(\\Pi(t)\\) is updated through multiplication with the transition probability matrix \\(\\mathbf{A}\\).\\[\\begin{aligned}  \\Pi(t+1)  &amp;=\\Pi(t)\\mathbf{A}  \\end{aligned}\\]        The possibility that a Markov Chain will maintain a specific state in the long run is called the Steady-State Probability.\\[\\begin{aligned}  \\Pi(t)\\xrightarrow{t\\to\\infty}\\Pi, \\quad\\Pi=\\Pi\\mathbf{A}  \\end{aligned}\\]  Hidden Markov Model      Let the observation $Y$ occur conditionally on the latent factor $X$, and let this latent factor $X$ be a Markov chain. This model is called a Hidden Markov Model.\\[\\begin{gathered}  P(X,Y)=P(Y\\mid X)P(X)  \\quad\\mathrm{for}\\quad  X(t)\\perp X(1),\\cdots,X(t-1)\\mid X(t)  \\end{gathered}\\]        Optimization of Hidden Markov Model is performed using the EM Algorithm.\\[\\Theta^{(s+1)}  =\\mathrm{arg}\\max_{\\Theta}{Q(\\Theta\\mid\\Theta^{(s)})}\\]        The parameters are the initial state probability $\\pi_{k}$, transition probability $\\alpha_{i,j}(\\forall t)$, and emission probability $\\beta_{k}(t)$.\\[\\Theta  :=\\left\\{\\pi_{k}\\in\\Pi,\\alpha_{i,j}\\in\\mathbf{A},\\beta_{k}(t)\\in\\mathbf{B}\\right\\}\\]        Specifically, the latent variables are (1) the probability that the hidden state $X(t)=k$ is present at each point and (2) the probability that the transition event occurring at each point is $i\\to j$, given the obs $Y$.\\[\\begin{aligned}  \\mu_{k}(t)  &amp;=P[X(t)=k\\mid Y(1),\\cdots,Y(T)]\\\\  \\gamma_{i,j}(t)  &amp;=P[X(t+1)=j,X(t)=i\\mid Y(1),\\cdots,Y(T)]  \\end{aligned}\\]  definition      Hidden State:\\[\\begin{aligned}  X(1),X(2),\\cdots,X(T)  \\end{aligned}\\]        Observed State:\\[\\begin{aligned}  Y(1),Y(2),\\cdots,Y(T)  \\end{aligned}\\]        Initial State:\\[\\begin{aligned}  \\pi_{i}(1):=P[X(1)=i]  \\end{aligned}\\]        The transition probability represents the possibility that the hidden state will transition from $i\\to j$.\\[\\begin{aligned}  \\alpha_{i,j}  :=P[X(t+1)=j\\mid X(t)=i]  \\end{aligned}\\]        The emission probability represents the possibility that the observed state $Y(t)$ will be realized at point $t$ when the hidden state $X(t)=j$ is realized at that point.\\[\\begin{aligned}  \\beta_{j}(t)  :=P[Y(t)\\mid X(t)=j]  \\end{aligned}\\]  forward probability      The forward probability is expressed as a joint probability as the possibility that the observed state from the beginning to point $t$ and the hidden state at point $t$ will be realized in a specific form.\\[\\begin{aligned}  \\phi_{j}(t)  :=P[\\underbrace{Y(1),\\cdots,Y(t)}_{\\text{obs}};\\underbrace{X(t)=j}_{\\text{latent factor}}]  \\end{aligned}\\]        initial expression ($t=1$):\\[\\begin{aligned}  \\phi_{j}(1)  &amp;=P[Y(1);X(1)=j]\\\\  &amp;=P[X(1)=j]\\cdot P[Y(1)\\mid X(1)=j]\\\\  &amp;=\\pi_{j}(1)\\beta_{j}(1)  \\end{aligned}\\]        factorization:\\[\\begin{aligned}  \\phi_{i}(t-1)  &amp;=P[Y(1),\\cdots,Y(t-1);X(t-1)=i]\\\\  \\alpha_{i,j}  &amp;=P[X(t)=j\\mid X(t-1)=i]\\\\  \\beta_{j}(t)  &amp;=P[Y(t)\\mid X(t)=j]  \\end{aligned}\\]        recursion ($t\\to t+1$):\\[\\begin{aligned}  \\phi_{j}(t)  &amp;=P[Y(1),\\cdots,Y(t);X(t)=j]\\\\  &amp;=\\sum_{i=1}^{K}{P[Y(1),\\cdots,Y(t);X(t)=j,X(t-1)=i]}\\\\  &amp;=\\beta_{j}(t)\\cdot \\sum_{i=1}^{K}{\\phi_{i}(t-1)\\cdot\\alpha_{i,j}}  \\end{aligned}\\]        final expression ($t=1,\\cdots,T$):\\[\\begin{aligned}  P[Y(1),\\cdots,Y(T)]  &amp;=\\sum_{j=1}^{K}{P[Y(1),\\cdots,Y(T);X(T)=j]}\\\\  &amp;=\\sum_{j=1}^{K}{\\phi_{j}(T)}  \\end{aligned}\\]  backward probability      The backward probability is expressed as a conditional probability as the possibility that the observed state will be realized in a specific form from point $t+1$ onwards when the hidden state at point $t$ is realized in a specific form.\\[\\begin{aligned}  \\psi_{j}(t)  :=P[\\underbrace{Y(t+1),\\cdots,Y(T)}_{\\text{obs}}\\mid\\underbrace{X(t)=j}_{\\text{latent factor}}]  \\end{aligned}\\]        final expression ($t=T$):\\[\\begin{aligned}  \\psi_{j}(T)  =P[X(T)=j]  =1  \\end{aligned}\\]        factorization:\\[\\begin{aligned}  \\alpha_{i,j}  &amp;=P[X(t+1)=j\\mid X(t)=i]\\\\  \\beta_{j}(t+1)  &amp;=P[Y(t+1)\\mid X(t+1)=j]\\\\  \\psi_{j}(t+1)  &amp;=P[Y(t+2),\\cdots,Y(T)\\mid X(t+1)=j]  \\end{aligned}\\]        recursion ($t+1\\to t$):\\[\\begin{aligned}  \\psi_{i}(t)  &amp;=P[Y(t+1),\\cdots,Y(T)\\mid X(t)=i]\\\\  &amp;=\\sum_{j}{P[Y(t+1),\\cdots,Y(T);X(t+1)=j\\mid X(t)=i]}\\\\  &amp;=\\sum_{j}{\\alpha_{i,j}\\cdot\\beta_{j}(t+1)\\cdot\\psi_{j}(t+1)}  \\end{aligned}\\]  latent factor posteriorstate posterior      1 point state posterior:\\[\\begin{aligned}  \\mu_{j}(t)  &amp;=P[X(t)=j\\mid Y(1),\\cdots,Y(T)]  \\end{aligned}\\]        factorization:\\[\\begin{aligned}  \\phi_{j}(t)  &amp;=P[Y(1),\\cdots,Y(t);X(t)=j]\\\\  \\psi_{j}(t)  &amp;=P[Y(t+1),\\cdots,Y(T)\\mid X(t)=j]\\\\  \\sum_{k}{\\phi_{k}(T)}  &amp;=P[Y(1),\\cdots,Y(T)]  \\end{aligned}\\]        transformation:\\[\\begin{aligned}  \\mu_{j}(t)  &amp;=P[X(t)=j\\mid Y(1),\\cdots,Y(T)]\\\\  &amp;=\\frac{P[Y(1),\\cdots,Y(T);X(t)=j]}{P[Y(1),\\cdots,Y(T)]}\\\\  &amp;=\\frac{\\phi_{j}(t)\\cdot\\psi_{j}(t)}{\\sum_{k}{\\phi_{k}(T)}}  \\end{aligned}\\]  transition event posterior      $i\\to j$ transition event posterior:\\[\\begin{aligned}  \\gamma_{i,j}(t)  &amp;=P[X(t+1)=j,X(t)=i\\mid Y(1),\\cdots,Y(T)]  \\end{aligned}\\]        factorization:\\[\\begin{aligned}  \\phi_{i}(t)  &amp;=P[Y(1),\\cdots,Y(t);X(t)=i]\\\\  \\alpha_{i,j}  &amp;=P[X(t+1)=j\\mid X(t)=i]\\\\  \\beta_{j}(t+1)  &amp;=P[Y(t+1)\\mid X(t+1)=j]\\\\  \\psi_{j}(t+1)  &amp;=P[Y(t+2),\\cdots,Y(t)]\\\\  \\sum_{k}{\\phi_{k}(T)}  &amp;=P[Y(1),\\cdots,Y(T)]  \\end{aligned}\\]        transformation:\\[\\begin{aligned}  \\gamma_{i,j}(t)  &amp;=P[X(t+1)=j,X(t)=i\\mid Y(1),\\cdots,Y(T)]\\\\  &amp;=\\frac{P[Y(1),\\cdots,Y(T);X(t+1)=j,X(t)=i]}{P[Y(1),\\cdots,Y(T)]}\\\\  &amp;=\\frac{\\phi_{i}(t)\\cdot\\alpha_{i,j}\\cdot\\beta_{j}(t+1)\\cdot\\psi_{j}(t+1)}{\\sum_{k}{\\phi_{k}(T)}}  \\end{aligned}\\]  E-M Algorithm      parameters:\\[\\Theta  :=\\left\\{\\pi_{k}\\in\\Pi,\\alpha_{i,j}\\in\\mathbf{A},\\beta_{k}(t)\\in\\mathbf{B}\\right\\}\\]        complete-data expected log-likelihood:\\[\\begin{aligned}  \\mathbb{E}_{q(X)}[\\log{P(Y,X\\mid\\theta)}]  &amp;=\\underbrace{\\mathbb{E}_{q(X)}[\\log{P(Y\\mid X,\\theta)}]}_{\\text{log emission prob.}}+\\underbrace{\\mathbb{E}_{q(X)}[\\log{P(X\\mid\\theta)}]}_{\\text{log transition prob.}}  \\end{aligned}\\]        emission prob.\\[\\begin{aligned}  \\mathbb{E}_{q(X)}[\\log{P(Y\\mid X,\\theta)}]  &amp;=\\underbrace{q(X)}_{\\text{state prob.}}\\cdot\\underbrace{\\log{P[Y(t)\\mid X(t)=k]}}_{\\text{log emission prob.}}\\\\  &amp;=\\mu_{k}(t)\\cdot\\log{\\beta_{k}(t)}  \\end{aligned}\\]        transition prob.\\[\\begin{aligned}  \\mathbb{E}_{q(X)}[\\log{P(X\\mid\\theta)}]  &amp;=\\underbrace{q(X)}_{\\text{event prob.}}\\cdot\\underbrace{\\log{P[X(t+1)=j\\mid X(t)=i]}}_{\\text{log transition prob.}}\\\\  &amp;=\\gamma_{i,j}(t)\\cdot\\log{\\alpha_{i,j}(t)}  \\end{aligned}\\]        init prob.\\[\\begin{aligned}  \\mathbb{E}_{q(X)}(\\log{P[X(1)=k]})  &amp;=\\underbrace{q(X)}_{\\text{state prob.}}\\cdot\\underbrace{\\log{P[X(1)=k]}}_{\\text{log init prob.}}\\\\  &amp;=\\mu_{k}(1)\\cdot\\log{\\pi_{k}}  \\end{aligned}\\]        Q function:\\[\\begin{aligned}  Q(\\Theta\\mid\\Theta^{(s)})  &amp;=\\sum_{t=1}^{T}\\sum_{k=1}^{K}{\\mu_{k}(t)\\cdot\\log{\\beta_{k}(t)}}\\\\  &amp;\\quad +\\sum_{t=1}^{T-1}\\sum_{i=1}^{K}\\sum_{j=1}^{K}{\\gamma_{i,j}(t)\\cdot\\log{\\alpha_{i,j}(t)}}+\\sum_{k=1}^{K}{\\mu_{k}(1)\\cdot\\log{\\pi_{k}}}  \\end{aligned}\\]        MLE parameter update:\\[\\Theta^{(s+1)}  =\\mathrm{arg}\\max_{\\Theta}{Q(\\Theta\\mid\\Theta^{(s)})}\\]  "
  },
  
  {
    "title": "GP (3) Random Fourier Features Gaussian Process",
    "url": "/posts/gp_rffgp/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "bayesian, stochastic process, time series, nonparametric estimation, gaussian process, multivariate Gaussian distribution, multivariate normal distribution, fourier analysis, numerical data analysis",
    "date": "2025-08-06 00:00:00 +0900",
    





    
    "snippet": "Random Fourier Feature Gaussian Process      Random Fourier Feature Gaussian Process is a technique for approximating an infinite-dimensional function space based on kernel functions to a finite-di...",
    "content": "Random Fourier Feature Gaussian Process      Random Fourier Feature Gaussian Process is a technique for approximating an infinite-dimensional function space based on kernel functions to a finite-dimensional function space based on real sinusoids.        nonparametric function:\\[f(x)=\\sum_{i=1}^{\\infty}{\\beta_{i}k(x,x_{i})}\\]        nonparametric function space:\\[\\mathcal{F}  =\\mathrm{span}\\left\\{k(\\cdot,x_{1}),k(\\cdot,x_{2}),\\cdots\\right\\}\\]        Random Fourier Feature:\\[\\sum_{i=1}^{\\infty}{\\beta_{i}k(x,x_{i})}  \\approx \\sum_{m=1}^{M}{\\gamma_{m}\\psi_{m}(x)}\\]        infinite dimensional function space is approximated by finite-dimensional space that take a finite number of real sinusoids as basis functions:\\[\\mathcal{F}  \\approx\\mathrm{span}\\left\\{\\psi_{1}(\\cdot),\\psi_{2}(\\cdot),\\cdots,\\psi_{M}(\\cdot)\\right\\}\\]  how to approximation      by Bochner’s theorem, a shift-invariant and positive-definite kernel function can be expressed as an infinite-dimensional inner product of continuous complex sinusoids.\\[\\begin{aligned}  k(x,x^{\\prime})  &amp;=\\int_{\\mathbb{R}^{d}}{\\phi(x)\\phi^{*}(x)p(\\omega)\\mathrm{d}\\omega}\\\\  \\phi(x)  &amp;=\\exp{i\\omega x},\\quad\\omega\\in\\mathbb{R}  \\end{aligned}\\]        Random Fourier Feature is a technique for approximating the infinite-dimensional inner product of continuous complex sinusoids to the finite-dimensional inner product of discrete real sinusoids.\\[\\begin{aligned}  \\int_{\\mathbb{R}^{d}}{\\phi(x)\\phi^{*}(x)p(\\omega)\\mathrm{d}\\omega}  &amp;\\approx\\sqrt{\\frac{2}{M}}\\sum_{m=1}^{M}{\\psi_{m}(x)\\psi_{m}^{*}(x)}\\\\  \\psi_{m}(x)  &amp;=\\cos{\\omega_{m}x+b_{m}},\\quad\\begin{cases}  \\omega_{m}\\sim p(\\omega)\\\\  b_{m}\\sim\\mathrm{Uniform}(0,2\\pi]  \\end{cases}  \\end{aligned}\\]        when substituted into the kernel function, which is basis function of a nonparametric function space, the nonparametric function can be expressed as a linear combination of discrete real number sinusoids.\\[\\begin{aligned}  f(x)  &amp;=\\sum_{i=1}^{\\infty}{\\beta_{i}k(x,x_{i})}\\\\  &amp;\\approx\\sum_{i=1}^{\\infty}{\\beta_{i}}\\left(\\sqrt{\\frac{2}{M}}\\sum_{m=1}^{M}{\\psi_{m}(x)\\psi_{m}(x_{i})}\\right)\\\\  &amp;=\\sum_{m=1}^{M}{\\underbrace{\\sqrt{\\frac{2}{M}}\\left(\\sum_{i=1}^{\\infty}{\\beta_{i}\\psi_{m}(x_{i})}\\right)}_{=:\\gamma_{m}}\\psi_{m}(x)}\\\\  &amp;=\\sum_{m=1}^{M}{\\gamma_{m}\\psi_{m}(x)}  \\end{aligned}\\]        therefore, the infinite dimensional function space based on the kernel function $\\phi(x)=k(\\cdot,x)$ defined for all input values $\\forall x$ is approximated by the finite dimensional function space based on the discrete real sinusoid $\\psi_{m}(x)=\\cos{\\omega_{m}x+b_{m}}$.\\[\\mathcal{F}  \\approx\\mathrm{span}\\left\\{\\psi_{1}(\\cdot),\\psi_{2}(\\cdot),\\cdots,\\psi_{M}(\\cdot)\\right\\}\\]  bayes rule      The basis \\(\\psi_{m}(x):=\\cos{\\omega_{m}x+b_{m}}\\) is deterministic after Monte Carlo approximation. Therefore, the probability of the random variable \\(f(x):=\\sum_{m=1}^{M}{\\gamma_{m}\\psi_{m}(x)}\\) is entirely based on the coefficient \\(\\gamma_{m}\\).\\[\\gamma_{m}:=\\sqrt{\\frac{2}{M}}\\sum_{i=1}^{\\infty}{\\beta_{i}\\psi_{m}(x_{i})}\\]        proxy variable of $f(x)$:          The distribution of the function value vector \\(\\mathbf{f}_{X}:=\\{f(x_{i})\\}_{i=1}^{N}\\) for the input set \\(\\{x_{i}\\}_{i=1}^{N}\\) can be expressed as a distribution that pushes forward the distribution \\(p(\\gamma)\\) of \\(\\gamma\\) through a linear transformation \\(T_{X}:=\\Psi_{X}\\).    \\[\\begin{gathered}  \\mathbf{f}_{X}=\\Psi_{X}^{T}\\gamma=T_{X}(\\gamma)\\quad\\Rightarrow\\quad p(\\mathbf{f}_{X})=(T_{X})_{\\#}p(\\gamma)  \\end{gathered}\\]          \\(\\mathbb{E}\\left[\\mathbf{f}_{X}\\right]=T_{X}\\mathbb{E}\\left[\\gamma\\right]\\) \\(\\quad\\)      \\(\\mathrm{Cov}\\left[\\mathbf{f}_{X}\\right]=T_{X}^{T}\\mathbb{E}\\left[\\gamma\\right]T_{X}\\) \\(\\quad\\)            prior:\\[\\begin{aligned}  p(\\gamma)=\\mathcal{N}(\\mu_{\\gamma},\\Sigma_{\\gamma})  \\end{aligned}\\]        likelihood:\\[\\begin{gathered}  y_{i}  =\\sum_{m=1}^{M}{\\gamma_{m}\\psi(x)}+\\epsilon_{i},\\quad\\epsilon\\sim\\mathcal{N}(0,\\sigma^{2})\\\\  \\therefore p(y\\mid\\gamma)  =\\mathcal{N}(\\Psi_{X}^{T}\\gamma,\\sigma^{2}\\mathbf{I})  \\end{gathered}\\]        posterior:\\[\\begin{aligned}  p(\\gamma\\mid y)  &amp;\\propto p(y\\mid\\gamma)p(\\gamma)\\\\  &amp;\\propto \\exp\\left[-\\frac{1}{2\\sigma^{2}}\\Vert y-\\Psi_{X}^{T}\\gamma\\Vert^{2}-\\frac{1}{2}\\Vert\\gamma\\Vert^{2}\\right]\\\\  &amp;\\propto \\mathcal{N}(\\mu_{\\gamma}^{\\prime},\\Sigma_{\\gamma}^{\\prime})  \\end{aligned}\\]          $\\mu_{\\gamma}^{\\prime}=(1/\\sigma^{2})\\Sigma_{\\gamma}\\Psi_{X}^{T}y$      $\\Sigma_{\\gamma}^{\\prime}=\\left[(1/\\sigma^{2})\\Psi_{X}^{T}\\Psi_{X}+\\mathbf{I}\\right]^{-1}$            posterior predictive:\\[\\begin{aligned}  \\mathbf{f}_{*}  &amp;=\\Psi_{*}^{T}\\gamma\\\\  \\therefore p(\\mathbf{f}_{*}\\mid y)  &amp;=\\int{p(\\mathbf{f}_{*}\\mid\\gamma)p(\\gamma\\mid y)\\mathrm{d}\\gamma}\\\\  &amp;=\\mathcal{N}(\\Psi_{*}^{T}\\mu_{\\gamma}^{\\prime},\\Psi_{*}^{T}\\Sigma_{\\gamma}^{\\prime}\\Psi_{*})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Fourier Analysis",
    "url": "/posts/fourier/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "bayesian, stochastic process, time series, nonparametric estimation, gaussian process, multivariate Gaussian distribution, multivariate normal distribution, fourier analysis, numerical data analysis",
    "date": "2025-08-05 00:00:00 +0900",
    





    
    "snippet": "Euler’s formula      Euler’s formula is a formula that shows that the Taylor series of a complex exponential function can be expressed as a trigonometric function.\\[\\begin{aligned}  \\exp{i\\theta}  ...",
    "content": "Euler’s formula      Euler’s formula is a formula that shows that the Taylor series of a complex exponential function can be expressed as a trigonometric function.\\[\\begin{aligned}  \\exp{i\\theta}  &amp;=\\sum_{n=0}^{\\infty}{\\frac{(i\\theta)^{n}}{n!}}\\\\  &amp;=\\sum_{k=0}^{\\infty}{\\frac{(i\\theta)^{2k}}{(2k)!}}+\\sum_{k=0}^{\\infty}{\\frac{(i\\theta)^{2k+1}}{(2k+1)!}}\\\\  &amp;=\\sum_{k=0}^{\\infty}{\\frac{(-1)^{k}\\theta^{2k}}{(2k)!}}+\\sum_{k=0}^{\\infty}{\\frac{\\left(i(-1)^{k}\\theta\\right)^{2k+1}}{(2k+1)!}}\\\\  &amp;=\\cos{\\theta}+i\\sin{\\theta}  \\end{aligned}\\]        complex plane is a coordinate plane that expresses complex numbers \\(Z=x+i \\cdot y\\) as vectors on the vector space \\(\\mathbb{R}^{2}:=\\mathrm{span}\\left\\{\\mathbf{e}_{X},\\mathbf{e}_{Y}\\right\\}\\), which consists of the real axis basis \\(\\mathbf{e}_{X}=\\begin{bmatrix}1\\\\0\\end{bmatrix}\\) and the imaginary axis basis \\(\\mathbf{e}_{Y}=\\begin{bmatrix}0\\\\1\\end{bmatrix}\\).\\[\\mathbf{v}_{Z}:=\\mathbf{e}_{X}x+\\mathbf{e}_{Y}y \\in \\mathbb{R}^{2}\\]        rotation transformation is a linear transformation that rotates a vector on a coordinate plane counterclockwise by $\\theta$ around the $X$ axis.\\[R:=\\begin{bmatrix}  \\cos{\\theta}&amp;-\\sin{\\theta}\\\\  \\sin{\\theta}&amp;\\cos{\\theta}  \\end{bmatrix}\\]        Therefore, Euler’s formula suggests that the complex exponential function $\\exp{i\\theta}$ rotates the complex number $Z$ by $\\theta$ in the complex plane counterclockwise around the real axis.\\[\\begin{aligned}  R\\left(\\mathbf{e}_{X};\\theta\\right)  &amp;=1\\cdot\\begin{bmatrix}\\cos{\\theta}\\\\\\sin{\\theta}\\end{bmatrix} + 0\\cdot\\begin{bmatrix}-\\sin{\\theta}\\\\\\cos{\\theta}\\end{bmatrix}\\\\  &amp;\\leftrightarrow \\cos{\\theta}+i\\sin{\\theta}  \\end{aligned}\\]  Fourier series      Fourier series is a technique for mapping a periodic signal $X_{T}(t)$, whose pattern repeats with a period of $T$ defined in the time domain, to a frequency domain composed of discrete sinusoid $\\phi_{k}(t)$ by approximating it as a linear combination of discrete sinusoid.\\[X_{T}(t)\\approx\\sum_{k=-\\infty}^{\\infty}{a_{k}\\phi_{k}(t)}\\]        sinusoid is a unit vector that rotates at a unique speed in the complex plane, and corresponds to the basis vector of a vector space.\\[\\begin{aligned}  \\phi_{k}(t)  :=\\exp{i\\omega_{k}t}  =\\cos{\\omega_{k}t}+i\\sin{\\omega_{k}t}  \\end{aligned}\\]    frequency is the unique rotational speed of a sinusoid, which corresponds to the direction of the basis vector in vector space.          $\\nu_{0}=1/T$(Hz): The number of vibrations per second as the fundamental frequency      $\\omega_{0}=\\nu_{0}\\cdot 2\\pi$(rad/s): Angular velocity in revolutions per second as the fundamental angular frequency      $\\nu_{k}=k\\cdot\\nu_{0},\\omega_{k}=k\\cdot\\omega_{0}$: Integer multiple of the fundamental frequency as the harmonic            Sinusoids that share a period $T$ are orthogonal to each other.\\[\\begin{aligned}  \\langle\\phi_{m}(t),\\phi_{n}(t)\\rangle  &amp;=\\begin{cases}  T\\quad &amp;(m = n)\\\\  0\\quad &amp;(m \\ne n)  \\end{cases}  \\end{aligned}\\]        Fourier coefficients represent the average amplitude of a sinusoids per unit time, i.e., the frequency components. In vector space, they correspond to the magnitude (coordinate value) of the result of an evaluation operation in the basis direction.\\[\\begin{aligned}  \\delta_{n}\\left[X_{T}(t)\\right]  &amp;=\\langle X_{T}(t),\\phi_{n}(t)\\rangle\\\\  &amp;\\approx \\left\\langle \\sum_{k=-\\infty}^{\\infty}{a_{k}\\phi_{k}(t)},\\phi_{n}(t) \\right\\rangle\\\\  &amp;=\\sum_{k=-\\infty}^{\\infty}{a_{k}\\left\\langle\\phi_{k}(t),\\phi_{n}(t)\\right\\rangle}\\\\  &amp;=a_{n}T + \\sum_{k \\ne n}{a_{k} \\cdot 0}\\\\  &amp;=a_{n}T  \\end{aligned}\\]  Fourier transformFourier transform      Fourier series maps a periodic signal into frequency components in a countable infinite-dimensional space consisting of discrete basis.\\[\\begin{aligned}  X_{T}(t) \\mapsto \\left\\{a_{k}\\mid k\\in\\mathbb{Z}\\right\\} \\in \\mathrm{span}\\left\\{\\phi_{k}(t)=\\exp{ik\\omega_{0}t}\\mid k\\in\\mathbb{Z}\\right\\}  \\end{aligned}\\]        Non-periodic signal can be viewed as a periodic signal with $T\\to\\infty$, which results in the generalization of the discrete harmonic ${k\\omega_{0}\\mid k\\in\\mathbb{Z}}$ into the continuous harmonic $\\omega \\in \\mathbb{R}$.\\[T \\to \\infty \\Leftrightarrow \\Delta\\omega\\to 0 \\quad (\\because\\omega_{0}=2\\pi/T)\\]        $a_{k}T$, total amplitude per period of a discrete sinusoids, generalizes to the $\\mathcal{X}(\\omega)$, amplitude of a continuous sinusoids, as the period diverges to infinity ($T\\to\\infty$) and the fundamental converges to $0$ ($\\Delta\\omega\\to 0$).\\[\\begin{aligned}  \\mathcal{X}(\\omega)  &amp;= \\lim_{\\Delta\\omega\\to 0}{a_{k}T}\\\\  &amp;= \\lim_{\\Delta\\omega\\to 0}{\\left\\langle X_{T}(t),\\phi_{k}(t)\\right\\rangle}\\\\  &amp;= \\left\\langle \\lim_{\\Delta\\omega\\to 0}{X_{T}(t)},\\lim_{\\Delta\\omega\\to 0}{\\phi_{k}(t)}\\right\\rangle\\\\  &amp;= \\left\\langle X(t),\\phi(t)\\right\\rangle  \\end{aligned}\\]        In short, the Fourier transform is a generalization of the Fourier series, which maps a non-periodic signal into a spectrum on a non-countable infinite-dimensional space consisting of a continuous basis.\\[\\begin{aligned}  X(t) \\mapsto \\mathcal{X}(\\omega) \\in \\mathrm{span}\\left\\{\\phi(t;\\omega)=\\exp{i \\omega t}\\mid\\omega\\in\\mathbb{R}\\right\\}  \\end{aligned}\\]  Inverse Fourier transform      Inverse Fourier transform is an operation that reduces the spectrum $\\mathcal{X}(\\omega)$ to an aperiodic signal $X(t)$, and is performed as an inner product with the dual basis.\\[\\langle\\cdot,\\phi^{*}(t)\\rangle_{\\omega}: \\mathcal{X}(\\omega) \\mapsto X(t)\\]        The dual basis of an orthonormal basis is simplified to a basis whose inner product with the original basis is $1$.\\[\\langle\\phi_{k}(t),\\phi_{k}^{*}(t)\\rangle=1\\]        $m=n$:\\[\\begin{aligned}  \\langle\\phi_{m}(t),\\phi_{n}(t)\\rangle  &amp;=\\int_{t \\in T}{\\exp{i(m-n)\\omega_{0}t}\\mathrm{d}t}\\\\  &amp;=\\int_{t \\in T}{1\\mathrm{d}t}\\\\  &amp;=T  \\end{aligned}\\]        $m \\ne n$:\\[\\begin{aligned}  \\langle\\phi_{m}(t),\\phi_{n}(t)\\rangle  &amp;=\\int_{t \\in T}{\\exp{i(m-n)\\omega_{0}t}\\mathrm{d}t}\\\\  &amp;=\\frac{1}{i(m-n)\\omega_{0}}\\left(\\exp{i(m-n)\\omega_{0}T}-1\\right)\\\\  &amp;=0\\\\  \\because\\exp{i(m-n)\\omega_{0}T}  &amp;=\\underbrace{\\cos{(m-n)2\\pi}}_{=1}+i\\underbrace{\\sin{(m-n)2\\pi}}_{=0}  \\end{aligned}\\]        Therefore, the dual basis of a discrete basis is defined as follows:\\[\\phi_{k}^{*}(t)=\\frac{1}{T}\\exp{-ik\\omega_{0}t}\\]        When extending the dual basis of a discrete basis to a continuous domain, the normalization constant is replaced by $1/T \\to 1/2\\pi$.\\[\\begin{aligned}  \\frac{1}{T}\\sum_{k}{(\\cdot)}  =\\frac{1}{2\\pi}\\sum_{k}{(\\cdot)\\Delta\\omega}  \\xrightarrow{\\Delta\\omega\\to 0}  \\frac{1}{2\\pi}\\int{(\\cdot)\\mathrm{d}\\omega}  \\end{aligned}\\]        Therefore, the dual basis of a continuous basis is defined as follows:\\[\\phi^{*}(t)=\\frac{1}{2\\pi}\\exp{-i\\omega t}\\]  Random Fourier FeatureRandom Fourier Feature      Bochner’s theorem states that a shift-invariant, continuous, and positive definite kernel function can be expressed as a Fourier transform whose spectrum is a probability function of continuous frequency $\\omega$.\\[\\begin{aligned}  k(x-x^{\\prime})  &amp;=\\int_{\\mathbb{R}^{d}}{\\phi(x-x^{\\prime})p(\\omega)\\mathrm{d}\\omega}\\\\  &amp;=\\int_{\\mathbb{R}^{d}}{\\phi(x)\\phi^{*}(x^{\\prime})p(\\omega)\\mathrm{d}\\omega}\\\\  &amp;=\\left\\langle\\Phi(x),\\Phi(x^{\\prime})\\right\\rangle_{p(\\omega)}  \\end{aligned}\\]        This indicates that the kernel function can be expressed as an infinite-dimensional inner product of continuous sinusoids.\\[\\begin{aligned}  \\Phi(x)  =\\begin{bmatrix}\\exp{i\\omega_{1}x}\\cdot \\sqrt{p(\\omega_{1})}\\\\\\exp{i\\omega_{2}x}\\cdot \\sqrt{p(\\omega_{2})}\\\\\\vdots\\\\\\exp{i\\omega_{\\infty}x}\\cdot \\sqrt{p(\\omega_{\\infty})}\\end{bmatrix},  \\quad \\Phi^{*}(x^{\\prime})  =\\begin{bmatrix}\\exp{-i\\omega_{1}x^{\\prime}}\\cdot \\sqrt{p(\\omega_{1})}\\\\\\exp{-i\\omega_{2}x^{\\prime}}\\cdot \\sqrt{p(\\omega_{2})}\\\\\\vdots\\\\\\exp{-i\\omega_{\\infty}x^{\\prime}}\\cdot \\sqrt{p(\\omega_{\\infty})}\\end{bmatrix}  \\end{aligned}\\]        Random Fourier Features is a technique that replaces the infinite-dimensional complex inner product with a finite-dimensional real inner product through Monte Carlo approximation in the Fourier transform of a kernel function.\\[\\begin{aligned}  \\int_{\\mathbb{R}^{d}}{\\phi(x)\\phi^{*}(x^{\\prime})p(\\omega)\\mathrm{d}\\omega}  &amp;\\approx \\frac{1}{\\sqrt{M}}\\sum_{m=1}^{M}{\\psi_{m}(x)\\psi^{*}_{m}(x^{\\prime})}, \\quad \\omega_{m} \\sim p(\\omega)  \\end{aligned}\\]        Continuous sinusoid of infinite dimension $\\phi(x)$ is approximated by a discrete sinusoid of finite dimension $\\psi_{m}(x)$ with frequency $\\omega_{m}$ sampled from the spectral density $p(\\omega)$.\\[\\begin{gathered}  \\phi(x)=\\exp{i\\omega x}\\cdot\\sqrt{p(\\omega)}, \\quad \\omega \\in \\mathbb{R}\\\\  \\Downarrow\\\\  \\psi_{m}(x)=\\frac{1}{\\sqrt{M}}\\exp{i\\omega_{m}x}, \\quad \\omega_{m} \\sim p(\\omega)  \\end{gathered}\\]        Accordingly, the infinite-dimensional inner product of continuous sinusoids, $\\phi(x)$, is approximated by the finite-dimensional inner product of discrete sinusoids, $\\psi(x)$.\\[\\begin{aligned}  \\Psi_{M}(x)  =\\frac{1}{\\sqrt{M}}\\begin{bmatrix}\\exp{i\\omega_{1}x}\\\\\\exp{i\\omega_{2}x}\\\\\\vdots\\\\\\exp{i\\omega_{M}x}\\end{bmatrix},  \\quad \\Psi^{*}_{M}(x^{\\prime})  =\\frac{1}{\\sqrt{M}}\\begin{bmatrix}\\exp{-i\\omega_{1}x}\\\\\\exp{-i\\omega_{2}x}\\\\\\vdots\\\\\\exp{-i\\omega_{M}x}\\end{bmatrix}  \\end{aligned}\\]  sinusoids simplification      The integral of a sinusoid $\\phi(x)$ on a symmetric interval can be simplified as follows:\\[\\begin{aligned}  \\int_{-\\infty}^{\\infty}{\\phi(x)\\mathrm{d}\\omega}  &amp;=\\int_{-\\infty}^{\\infty}{\\cos{\\omega x}\\mathrm{d}\\omega} + \\underbrace{\\int_{-\\infty}^{\\infty}{i\\sin{\\omega x}\\mathrm{d}\\omega}}_{=0}\\\\  &amp;= \\int_{-\\infty}^{\\infty}{\\cos{\\omega x}\\mathrm{d}\\omega}  \\quad \\because \\begin{cases}\\cos{-x}=\\cos{x}\\\\\\sin{-x}=-\\sin{x}\\end{cases}  \\end{aligned}\\]        Trigonometric Identity:\\[2\\cos{A}\\cos{B}=\\cos{(A-B)}+\\cos{(A+B)}\\]        Application:\\[\\begin{aligned}  2\\cos(\\omega_{m} x + b_{m})\\cos(\\omega_{m} x^{\\prime} + b_{m})  &amp;=\\cos(\\omega_{m}(x-x^{\\prime}))+\\cos(\\omega_{m}(x+x^{\\prime})+2b_{m})  \\end{aligned}\\]        Since the expected value of the cosine function in the interval $[0,2\\pi)$ is $0$:\\[\\begin{aligned}  2\\mathbb{E}_{b}\\left[\\cos(\\omega x + b)\\cos(\\omega x^{\\prime} + b)\\right]  &amp;=\\mathbb{E}_{b}\\left[\\cos(\\omega(x-x^{\\prime}))\\right]+\\mathbb{E}_{b}\\left[\\cos(\\omega(x+x^{\\prime})+2b)\\right]\\\\  &amp;=\\cos(\\omega(x-x^{\\prime})) \\quad \\mathrm{s.t.} \\quad b_{m}\\sim\\mathrm{Uniform}(0,2\\pi]  \\end{aligned}\\]        Finally, the continuous complex sinusoid $\\phi(x)$ of infinite dimension can be simplified into the discrete real sinusoid $\\psi_{m}(x)$ of finite dimension.\\[\\begin{aligned}  \\psi_{m}(x)  &amp;=\\sqrt{\\frac{2}{M}}\\cos(\\omega_{m}x+b_{m}), \\quad \\mathrm{for} \\quad \\begin{cases}\\omega_{m} &amp;\\sim p(\\omega)\\\\b_{m}&amp;\\sim\\mathrm{Uniform}(0,2\\pi]\\end{cases}  \\end{aligned}\\]        Accordingly, the infinite-dimensional complex inner product of continuous sinusoids is simplified to the finite-dimensional real inner product of discrete sinusoids.\\[\\begin{aligned}  \\Psi_{M}(x)  &amp;=\\sqrt{\\frac{2}{M}}\\begin{bmatrix}\\cos{(\\omega_{1}x+b_{1})}\\\\\\cos{(\\omega_{2}x+b_{2})}\\\\\\vdots\\\\\\cos{(\\omega_{M}x+b_{M})}\\end{bmatrix}, \\quad \\mathrm{for} \\quad \\begin{cases}\\omega_{m} &amp;\\sim p(\\omega)\\\\b_{m}&amp;\\sim\\mathrm{Uniform}(0,2\\pi]\\end{cases}  \\end{aligned}\\]  "
  },
  
  {
    "title": "GP (2) Sparse Gaussian Process",
    "url": "/posts/gp_sgp/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "bayesian, stochastic process, time series, nonparametric estimation, gaussian process, multivariate Gaussian distribution, multivariate normal distribution, numerical data analysis",
    "date": "2025-08-04 00:00:00 +0900",
    





    
    "snippet": "sparse gaussian process  sparse gaussian process is a technique that achieves the following two advantages by introducing $M$ inducing points that can represent all $N\\to\\infty$ observations:      ...",
    "content": "sparse gaussian process  sparse gaussian process is a technique that achieves the following two advantages by introducing $M$ inducing points that can represent all $N\\to\\infty$ observations:          infinite-dimensional function space is projected onto a low-dimensional induction point space, thereby ensuring computational efficiency.      uncertainty is restricted to the low-dimensional interior, thereby ensuring inference stability.            nonparametric function:\\[f(X)=\\sum_{i=1}^{\\infty}{\\beta_{i}k(X,X_{i})}\\]        nonparametric function space $f \\in \\mathcal{F}$ is infinite-dimensional function space consisting of an infinite number of basis functions:\\[\\mathcal{F}  =\\mathrm{span}\\left\\{k(\\cdot,X_{1}),k(\\cdot,X_{2}),\\cdots\\right\\}\\]        inducing point approximation:\\[\\sum_{i=1}^{\\infty}{\\beta_{i}k(X,X_{i})}  \\approx\\sum_{i=1}^{M}\\gamma_{i}k(X,Z_{i})\\]        infinite dimensional function spaces are approximated by finite-dimensional spaces that take a finite number of inducing points as basis functions:\\[\\mathcal{F}\\approx\\mathrm{span}\\left\\{k(\\cdot,Z_{1}),k(\\cdot,Z_{2}),\\cdots,k(\\cdot,Z_{M})\\right\\}\\]  idea      representativeness of information: statistical assumption that the correlation structure between samples occurs only through the representative value, and accordingly, conditional independence is established between samples with respect to the representative value.\\[\\begin{gathered}  f_{i} \\leftrightarrow f_{j}\\\\  \\Downarrow\\\\  f_{i} \\leftarrow u \\rightarrow f_{j}  \\end{gathered}\\]        conditional independence: when information C is conditionally given between two pieces of information A and B, the information between A and B is independent, or, C “breaks” or “absorbs” the dependence between A and B.\\[\\begin{gathered}  f_{i} \\perp f_{j}\\mid u\\\\  \\Updownarrow\\\\  \\mathrm{Cov}(f_{i},f_{j}\\mid u)  =\\underbrace{\\Sigma_{XX}-\\overbrace{\\Sigma_{XZ}\\Sigma_{ZZ}^{-1}\\Sigma_{ZX}}^{\\text{low-rank approx.}}}_{\\text{residual covariance}}\\approx 0\\\\  \\Updownarrow\\\\  p(f_{i},f_{j}\\mid u)=p(f_{i}\\mid u)p(f_{j}\\mid u)  \\end{gathered}\\]  low-rank functional approximation      inducing obs $u$, which represent full obs $f$:\\[u=f(Z) \\sim \\mathcal{N}(M(Z),K_{ZZ})\\]        to compress the function space into the induction point space:\\[\\begin{aligned}  p(f) \\to p(f \\mid u)  \\end{aligned}\\]        joint prob. dist. application:\\[\\begin{bmatrix}f\\\\u\\end{bmatrix}\\sim\\mathcal{N}\\left(\\begin{bmatrix}M(X)\\\\M(Z)\\end{bmatrix},\\begin{bmatrix}K_{ZZ}&amp;K_{ZX}\\\\K_{XZ}&amp;K_{XX}\\end{bmatrix}\\right)\\]        $f$ can be expressed as a linear combination of $u$:\\[\\mathbb{E}\\left[f \\mid u\\right] = M(X)+K_{XZ}K_{ZZ}^{-1}(u-M(Z))\\]        to convert the function value perspective $f$ to the function perspective $f(\\cdot)$:\\[\\begin{aligned}  \\mathbb{E}\\left[f(\\cdot)\\mid f(Z)\\right]  &amp;= m(\\cdot) + \\sum_{i=1}^{M}{\\gamma_{i}k(\\cdot,Z_{i})}\\\\  &amp;\\approx \\sum_{i=1}^{M}{\\gamma_{i}k(\\cdot,Z_{i})}\\\\  \\gamma_{i}  &amp;= \\sum_{j=1}^{M}{(K_{ZZ}^{-1})_{i,j}\\left(u_{j}-m(Z_{j})\\right)}  \\end{aligned}\\]        therefore infinite dimensional space consisting of a kernel function $\\phi(\\cdot)=k(\\cdot,X)$ for all input values $\\forall X$ as a basis can be approximated by a finite dimensional space consisting of a kernel function $\\psi(\\cdot)=k(\\cdot,Z)$ for the induction points $u=f(Z)$ as a basis.\\[\\mathcal{F}\\approx\\mathrm{span}\\left\\{k(\\cdot,Z_{1}),k(\\cdot,Z_{2}),\\cdots,k(\\cdot,Z_{M})\\right\\}\\]        under conditional independence, uncertainty outside the inducing point space is eliminated:\\[\\mathrm{Cov}\\left[f \\mid u\\right]  = K_{XX}-K_{XZ}K_{ZZ}^{-1}K_{ZX}  \\approx 0\\]  low-rank kernel approximation      original bayes rule:\\[\\underbrace{p(f\\mid y)}_{\\text{posterior}} \\propto \\underbrace{p(y\\mid f)}_{\\text{likelihood}}\\cdot \\underbrace{p(f)}_{\\text{prior}}\\]        updated bayes rule:\\[\\underbrace{p(f, u\\mid y)}_{\\text{posterior}} \\propto \\underbrace{p(y\\mid f)}_{\\text{likelihood}}\\cdot \\underbrace{p(f \\mid u)p(u)}_{\\text{joint prior}}\\]        plate diagram:\\[u \\rightarrow f, \\quad f \\rightarrow y, \\quad u \\nrightarrow y\\]        marginal likelihood:\\[\\begin{aligned}  p(y \\mid u)  &amp;= \\int{\\underbrace{p(y \\mid f)}_{\\text{likelihood}}\\underbrace{p(f \\mid u)}_{\\text{conditional prior}}\\mathrm{d}f}  \\end{aligned}\\]        posterior of inducing obs $u$ can be expressed through the obs $y$:\\[\\begin{aligned}  p(u \\mid y)  &amp;\\propto \\underbrace{p(y \\mid u)}_{\\text{marginal likelihood}} \\cdot \\underbrace{p(u)}_{\\text{prior}}  \\end{aligned}\\]        joint prob. dist. application:\\[\\begin{aligned}  \\begin{bmatrix}u\\\\y\\end{bmatrix}  &amp;\\sim\\mathcal{N}\\left(\\begin{bmatrix}M(Z)\\\\ M(X)\\end{bmatrix},\\begin{bmatrix}K_{ZZ}&amp;K_{ZX}\\\\K_{XZ}&amp;K_{XX}+\\sigma_{N}^{2}\\mathbf{I}\\end{bmatrix}\\right)  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  p(u \\mid y)  &amp;= \\mathcal{N}(M(Z)+K_{ZX}(K_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}(y-m(X)),K_{ZZ}-K_{ZX}(K_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}K_{XZ})  \\end{aligned}\\]        replace components by taking advantage of the property of conditional independence:\\[K_{XX} \\approx \\underbrace{K_{XZ}K_{ZZ}^{-1}K_{ZX}}_{=:Q_{XX}}\\]        woodbury identity:\\[(Q_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}  =\\frac{1}{\\sigma^{2}}\\mathbf{I}-\\frac{1}{\\sigma^{4}}K_{XZ}\\underbrace{\\left(K_{ZZ}+\\frac{1}{\\sigma^{2}}K_{ZX}K_{XZ}\\right)^{-1}}_{M \\times M}K_{ZX}\\]        computational cost reduced:\\[\\begin{aligned}  \\mathrm{Cost}\\left[(K_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}\\right]  &amp;= \\mathcal{O}(N^{3})\\\\  \\mathrm{Cost}\\left[(Q_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}\\right]  &amp;= \\mathcal{O}(N^{2}M)  \\end{aligned}\\]  "
  },
  
  {
    "title": "GP (1) Gaussian Process",
    "url": "/posts/gp_gp/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "bayesian, stochastic process, time series, nonparametric estimation, gaussian process, multivariate Gaussian distribution, multivariate normal distribution, numerical data analysis",
    "date": "2025-08-03 00:00:00 +0900",
    





    
    "snippet": "gaussian process      gaussian process is a nonparametric stochastic process that uses the mean and covariance structure of function values as prior information to infer the function distribution, ...",
    "content": "gaussian process      gaussian process is a nonparametric stochastic process that uses the mean and covariance structure of function values as prior information to infer the function distribution, assuming that the function values defined for an arbitrary input set jointly follow a multivariate normal distribution.        function definition:\\[y_{i}=f(X_{i})+\\epsilon_{i}, \\quad \\epsilon_{i} \\sim \\mathcal{N}(0,\\sigma_{N}^{2})\\]        function value vector:\\[\\begin{aligned}  \\mathbf{f}  =\\begin{bmatrix}  f(X_{1}) &amp; f(X_{2}) &amp; \\cdots &amp; f(X_{N})  \\end{bmatrix}^{T}  \\end{aligned}\\]        multivariate normal distribution assumption:\\[\\mathbf{f}\\sim\\mathcal{N}(M(X),K_{XX})\\]        function $f(\\cdot)$ is assumed to follow a gaussian process with mean function $m(\\cdot)$ and covariance function $k(\\cdot, \\cdot^{\\prime})$:\\[f(\\cdot)\\sim\\mathcal{GP}(m(\\cdot),k(\\cdot,\\cdot^{\\prime}))\\]  Mercer’s theorem      Mercer’s theorem states that a symmetric, positive definite kernel function can be expressed as the inner product of the functions forming the basis of RKHS.\\[\\begin{aligned}  k(x,x^{\\prime})  &amp;=\\sum_{i=1}^{\\infty}{\\lambda_{i}\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  &amp;=\\langle\\phi(x),\\phi(x^{\\prime})\\rangle_{\\mathcal{H}}  \\end{aligned}\\]        Covariance is the expectation of the inner product of centered vectors.\\[\\begin{aligned}  \\mathrm{Cov}\\left[A,B\\right]  &amp;=\\mathbb{E}\\left[(A-\\mu_{A})(B-\\mu_{B})\\right]  \\end{aligned}\\]        In a function space, a function is represented as a linear combination of basis functions.\\[\\begin{aligned}  f(x)  &amp;=\\sum_{i=1}^{\\infty}{\\beta_{i}\\phi_{i}(x)} \\quad \\begin{cases}\\text{$\\beta_{i}$ is stochastic}\\\\\\text{$\\phi_{i}$ is deterministic}\\end{cases}  \\end{aligned}\\]        Therefore, the covariance of the function values is derived as follows:\\[\\begin{aligned}  \\mathrm{Cov}\\left[f(x),f(x^{\\prime})\\right]  &amp;=\\mathbb{E}\\left([f(x)-m(x)][f(x^{\\prime})-m(x^{\\prime})]\\right)\\\\  &amp;=\\sum_{i=1}^{\\infty}\\sum_{j=1}^{\\infty}{\\mathbb{E}\\left[(\\beta_{i}-\\mu_{i})(\\beta_{j}-\\mu_{j})\\right]\\phi_{i}(x)\\phi_{j}(x^{\\prime})}\\\\  &amp;=\\sum_{i=1}^{\\infty}{\\lambda_{i}\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  \\\\  \\because\\mathbb{E}\\left[(\\beta_{i}-\\mu_{i})(\\beta_{j}-\\mu_{j})\\right]  &amp;=\\mathrm{Cov}\\left[\\beta_{i},\\beta_{j}\\right]\\\\  &amp;=\\begin{cases}\\mathrm{Var}\\left[\\beta_{i}\\right]\\quad &amp;i=j\\\\  0 \\quad &amp;i \\ne j\\end{cases} \\quad\\mathrm{s.t.}\\quad \\beta_{i}\\perp\\beta_{j}  \\end{aligned}\\]        By Mercer’s theorem, the covariance function becomes a kernel function.\\[\\begin{aligned}  k(x,x^{\\prime})  =\\sum_{i=1}^{\\infty}{\\lambda_{i}\\phi_{i}(x)\\phi_{i}(x^{\\prime})}  =\\mathrm{Cov}\\left[f(x),f(x^{\\prime})\\right]  \\end{aligned}\\]  bayes rule      prior represents a probabilistic assumption about the central tendency $m(\\cdot)$ and dispersion $k(\\cdot,\\cdot^{\\prime})$ of the function values:\\[\\begin{aligned}  p(f)  &amp;=\\mathcal{N}(M(X),K_{XX})  \\end{aligned}\\]        likelihood:\\[\\begin{aligned}  p(y \\mid f)  &amp;=\\mathcal{N}(f,\\sigma_{N}^{2}\\mathbf{I})  \\end{aligned}\\]        evidence:\\[\\begin{aligned}  p(y)  &amp;=\\int{p(y \\mid f)p(f)\\mathrm{d}f}\\\\  &amp;=\\mathcal{N}(M(X),K_{XX}+\\sigma_{N}^{2}\\mathbf{I})  \\end{aligned}\\]        posterior represents the updated probabilistic assumption about the mean and covariance structure of the function after conditioning on the observations:\\[\\begin{aligned}  p(f \\mid y)  &amp;=\\frac{p(y \\mid f)p(f)}{p(y)}\\\\  &amp;= \\mathcal{N}(M^{\\prime}(X),K^{\\prime}_{XX})  \\end{aligned}\\]  joint prob. dist. application      joint prob. dist. of multivariate normal dist.:\\[\\begin{bmatrix}X_{A}\\\\X_{B}\\end{bmatrix}  \\sim  \\mathcal{N}\\left(\\begin{bmatrix}\\mu_{A}\\\\ \\mu_{B}\\end{bmatrix},\\begin{bmatrix}\\Sigma_{AA}&amp;\\Sigma_{AB}\\\\ \\Sigma_{BA}&amp;\\Sigma_{BB}\\end{bmatrix}\\right)\\]        analytical representation of conditional dist.:\\[p(X_{A}\\mid X_{B})=\\mathcal{N}(\\mu_{A}+\\Sigma_{AB}\\Sigma_{BB}^{-1}\\cdot(X_{B}-\\mu_{B}),\\Sigma_{AA}-\\Sigma_{AB}\\Sigma_{BB}^{-1}\\Sigma_{BA})\\]        application to posterior inference (what is used conditionally is $y$, because what can be observed is $y$, not $\\mathbf{f}$):\\[\\begin{bmatrix}u\\\\y\\end{bmatrix}  \\sim  \\mathcal{N}\\left(\\begin{bmatrix}M(Z)\\\\ M(X)\\end{bmatrix},\\begin{bmatrix}K_{ZZ}&amp;K_{ZX}\\\\ K_{XZ}&amp;K_{XX} + \\sigma_{N}^{2}\\mathbf{I}\\end{bmatrix}\\right)  ,\\quad u=f(Z)\\]        therefore:\\[p(u \\mid y)  =\\mathcal{N}(M^{\\prime}(Z),K^{\\prime}_{ZZ})\\]        posterior mean function:\\[m^{\\prime}(Z)  =M(Z) + K_{ZX}\\cdot(K_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}\\cdot(y-M(X))\\]        posterior cov. function:\\[k^{\\prime}(Z,Z^{\\prime})  =K_{ZZ}-K_{ZX}\\cdot(K_{XX}+\\sigma_{N}^{2}\\mathbf{I})^{-1}K_{XZ}\\]  predictive dist.prior predictive dist. (unobs)      plate diagram:\\[f \\rightarrow \\cancel{y}, \\quad f_{*} \\rightarrow y_{*}, \\quad f_{*} \\leftrightarrow f\\]        prior:\\[\\begin{aligned}  p(f_{*})  &amp;= \\int{p(f_{*}\\mid f)p(f)\\mathrm{d}f}\\\\  &amp;=\\mathcal{N}(M(X_{*}),K_{**})  \\end{aligned}\\]        prior predictive dist.:\\[\\begin{aligned}  p(y_{*})  &amp;= \\int{p(y_{*}\\mid f_{*})p(f_{*})\\mathrm{d}f_{*}}\\\\  &amp;= \\mathcal{N}(M(X_{*}),K_{**}+\\sigma_{N}^{2}\\mathbf{I})  \\end{aligned}\\]  posterior predictive dist. (obs)      plate diagram:\\[f \\rightarrow y, \\quad f_{*} \\rightarrow y_{*}, \\quad f_{*} \\leftrightarrow f\\]        conditional prior:\\[\\begin{aligned}  p(f_{*} \\mid y)  &amp;= \\int{p(f_{*}\\mid f)p(f \\mid y)\\mathrm{d}f}\\\\  &amp;= \\mathcal{N}(M^{\\prime}(X_{*}),K^{\\prime}_{**})  \\end{aligned}\\]        posterior predictive dist.:\\[\\begin{aligned}  p(y_{*} \\mid y)  &amp;= \\int{p(y_{*}\\mid f_{*})p(f_{*} \\mid y)\\mathrm{d}f_{*}}\\\\  &amp;= \\mathcal{N}(M^{\\prime}(X_{*}),K^{\\prime}_{**} + \\sigma_{N}^{2}\\mathbf{I})  \\end{aligned}\\]  "
  },
  
  {
    "title": "RKHS",
    "url": "/posts/rkhs/",
    "categories": "5.BAYES, 4.stochastic process",
    "tags": "bayesian, stochastic process, time series, nonparametric estimation, gaussian process, multivariate Gaussian distribution, multivariate normal distribution, numerical data analysis",
    "date": "2025-08-02 00:00:00 +0900",
    





    
    "snippet": "evaluation operator      (in the space where the inner product is defined) the evaluation operation is the inverse operation of the inner product, which recovers the intrinsic properties of an obje...",
    "content": "evaluation operator      (in the space where the inner product is defined) the evaluation operation is the inverse operation of the inner product, which recovers the intrinsic properties of an object from a distorted representation mapped to a basis direction of a specific space. this is performed by taking the inner product with the dual basis of the mapped basis.\\[\\delta(\\cdot):=\\langle\\cdot,\\psi\\rangle\\]  vector      vector is a spatial object that has a direction and a magnitude in that direction, and has directionality as its essential property.\\[\\begin{aligned}  \\mathbf{v}  &amp;=\\underbrace{\\begin{bmatrix}\\phi_{1}&amp;\\phi_{2}&amp;\\phi_{3}\\end{bmatrix}}_{\\text{basis}} \\underbrace{\\begin{bmatrix}\\beta_{1}\\\\\\beta_{2}\\\\\\beta_{3}\\end{bmatrix}}_{\\text{coefficient}}\\\\  &amp;= \\beta_{1}\\phi_{1}+\\beta_{2}\\phi_{2}+\\beta_{3}\\phi_{3}  \\end{aligned}\\]        vector space $(V,\\langle\\cdot,\\cdot\\rangle)$ can be spaned by basis:\\[\\begin{aligned}  \\mathbf{v} \\in V  &amp;=\\mathrm{span}\\left\\{\\phi_{1},\\phi_{2},\\phi_{3}\\right\\}  \\end{aligned}\\]        vector evaluation is an operation based on the direction, that derives the magnitude in a given direction that is not dependent on the coordinate system.\\[\\delta_{i}[v]:=\\langle v, \\psi_{i} \\rangle = \\beta_{i}\\]  function      function is a mapping object that corresponds one value of the codomain $y$ to each point of the domain $X$, and has correspondence as its essential property.\\[\\begin{aligned}  f(X)  &amp;=\\underbrace{\\begin{bmatrix}\\phi_{1}(X)&amp;\\phi_{2}(X)&amp;\\phi_{3}(X)\\end{bmatrix}}_{\\text{basis}} \\underbrace{\\begin{bmatrix}\\beta_{1}\\\\\\beta_{2}\\\\\\beta_{3}\\end{bmatrix}}_{\\text{coefficient}}\\\\  &amp;= \\beta_{1}\\phi_{1}(X)+\\beta_{2}\\phi_{2}(X)+\\beta_{3}\\phi_{3}(X)  \\end{aligned}\\]        function space $(\\mathcal{F},\\langle\\cdot,\\cdot\\rangle)$ can be spaned by basis:\\[f(\\cdot) \\in \\mathcal{F}=\\mathrm{span}\\left\\{\\phi_{1}(X),\\phi_{2}(X),\\phi_{3}(X)\\right\\}\\]        function evaluation is an operation based on the input value, that derives an output value for the corresponding input value that is not dependent on the expansion of the function by the basis.\\[\\delta_{X_{i}}[f(\\cdot)]:=\\langle f(\\cdot), \\psi(X_{i}) \\rangle = f(X_{i})\\]  dual space      original space consisting of $N$ bases has a dual space consisting of $N$ dual basis.\\[\\begin{aligned}  \\mathcal{S}  &amp;=\\mathrm{span}\\left\\{\\phi_{1},\\phi_{2},\\cdots,\\phi_{N}\\right\\}\\\\  \\mathcal{S}^{*}  &amp;=\\mathrm{span}\\left\\{\\psi_{1},\\psi_{2},\\cdots,\\psi_{N}\\right\\}  \\end{aligned}\\]        dual basis is defined via inverse of the Gram matrix of original basis.\\[\\begin{aligned}  \\psi_{j}:=\\sum_{k=1}^{N}\\left(G^{-1}\\right)_{k,j}\\phi_{k}, \\quad G:=\\left\\{\\langle\\phi_{i},\\phi_{j}\\rangle\\right\\}_{(i,j)}  \\end{aligned}\\]        original basis and the dual basis react only to each other.\\[\\begin{aligned}  \\langle\\phi_{i},\\psi_{j}\\rangle  &amp;= \\left\\langle\\phi_{i},\\sum_{k=1}^{N}{\\left(G^{-1}\\right)_{k,j}\\phi_{k}}\\right\\rangle\\\\  &amp;= \\sum_{k=1}^{N}{\\left(G^{-1}\\right)_{k,j}\\langle\\phi_{i},\\phi_{k}\\rangle}\\\\  &amp;= \\sum_{k=1}^{N}{\\left(G^{-1}\\right)_{k,j}G_{i,k}}\\\\  &amp;= \\delta_{i,j}  \\end{aligned}\\]        dual basis is expressed as a linear combination of the original basis, which means that the original basis can span the dual space.\\[\\mathcal{F}^{*} \\subseteq \\mathrm{span}\\left\\{\\phi_{1},\\phi_{2},\\cdots,\\phi_{N}\\right\\} \\quad \\because \\psi_{j}:=\\sum_{k=1}^{N}{G_{k,j}\\phi_{k}}\\]        If the Gram matrix is invertible, the original basis can also be expressed as a linear combination of the dual basis. This also means that the dual basis can span the original space.\\[\\mathcal{F} \\subseteq \\mathrm{span}\\left\\{\\psi_{1},\\psi_{2},\\cdots,\\psi_{N}\\right\\} \\quad \\because \\phi_{j}:=\\sum_{k=1}^{N}{G_{k,j}\\psi_{k}}\\]        Since the original basis and the dual basis can be completely restored as linear combinations of each other, they span the same linear space.\\[\\begin{gathered}  \\mathcal{S} \\subseteq \\mathcal{S}^{*} \\quad \\mathrm{and} \\quad \\mathcal{S}^{*} \\subseteq \\mathcal{S}\\\\  \\Downarrow\\\\  \\mathcal{S}=\\mathcal{S}^{*}  \\end{gathered}\\]        therefore, the elements of the original space can be expressed as a dual basis.\\[f=\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}}=\\sum_{i=1}^{N}{\\gamma_{i}\\psi_{i}}\\]  RKHS      parametric function is a function whose number and shape of basis are fixed (e.g. polynomial regression):\\[\\begin{aligned}  f(X)  &amp;=\\beta_{1}+\\beta_{2}X+\\beta_{3}X^{2}\\\\  &amp;=\\sum_{i=1}^{3}{\\beta_{i}\\phi_{i}(X)} \\quad \\mathrm{for} \\quad \\begin{cases}\\phi_{1}(X)=1\\\\\\phi_{2}(X)=X\\\\\\phi_{3}(X)=X^{2}\\end{cases}  \\end{aligned}\\]        parameteric function space $f \\in \\mathcal{F}$ is a finite-dimensional linear subspace consisting of a finite number of basis functions \\(\\{\\phi_{i}\\}_{i=1}^{N}\\):\\[\\mathcal{F}=\\mathrm{span}\\left\\{\\phi_{1}(X),\\phi_{2}(X),\\cdots,\\phi_{N}(X)\\right\\}\\]        nonparametric function is a function whose number and shape of basis are unfixed:\\[f(X)=\\sum_{i=1}^{\\infty}{\\beta_{i}\\phi_{i}(X)}\\]        nonparametric function space $f \\in \\mathcal{F}$ is infinite-dimensional function space consisting of an infinite number of basis functions \\(\\{\\phi_{i}\\}_{i=1}^{\\infty}\\):\\[\\mathcal{F}  =\\mathrm{span}\\left\\{\\phi_{1}(X),\\phi_{2}(X),\\cdots\\right\\}\\]        RKHS is a nonparametric function space that takes the dual basis as a reproducible kernel function:\\[\\psi(X):=k(\\cdot,X)\\]        therefore, function @ RKHS can be expressed through reproducible kernel function:\\[f(X)=\\sum_{i=1}^{\\infty}{\\gamma_{i}k(X,X_{i})}\\]  "
  },
  
  {
    "title": "Beta and Extension",
    "url": "/posts/beta/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, continuous random variable, proportion analysis, beta distribution, dirichlet distribution",
    "date": "2025-07-11 00:00:00 +0900",
    





    
    "snippet": "Beta      베타 분포(Beta Distribution): 성공 확률을 나타내는 분포\\[X\\sim\\mathrm{Beta}(\\alpha,\\beta),\\quad 0&lt;X&lt;1\\]          $\\alpha$: 분포의 좌측 모양을 결정하는 형상 파라미터로서 성공 데이터의 양을 나타냄      $\\beta$: 분포의 우측 모양을 결정하는 형상...",
    "content": "Beta      베타 분포(Beta Distribution): 성공 확률을 나타내는 분포\\[X\\sim\\mathrm{Beta}(\\alpha,\\beta),\\quad 0&lt;X&lt;1\\]          $\\alpha$: 분포의 좌측 모양을 결정하는 형상 파라미터로서 성공 데이터의 양을 나타냄      $\\beta$: 분포의 우측 모양을 결정하는 형상 파라미터로서 실패 데이터의 양을 나타냄            단위 물리량이 $1$ 인 어떤 사건에 대하여 성공과 실패가 각각 $\\alpha,\\beta$ 만큼 누적 관측되었다고 하자. 전체 관측 데이터의 누적 물리량($Y_{1}+Y_{2}$) 대비 성공 데이터의 누적 물리량($Y_{1}$)의 비율을 확률변수 $X$ 로 정의하였을 때, 이 확률변수는 베타 분포를 따르게 된다.\\[\\begin{gathered}  X:=\\frac{Y_{1}}{Y_{1}+Y_{2}}\\quad\\mathrm{for}\\quad\\begin{cases}Y_{1}\\sim\\mathrm{Gamma}(\\alpha,1)\\\\Y_{2}\\sim\\mathrm{Gamma}(\\beta,1)\\end{cases}\\\\  \\Downarrow\\\\  X\\sim\\mathrm{Beta}(\\alpha,\\beta)  \\end{gathered}\\]        probability density function:\\[p(x\\mid\\alpha,\\beta)  =\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\]        beta function:\\[B(\\alpha,\\beta)  =\\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\\]        $k$-th moment:\\[\\begin{aligned}  \\mathbb{E}\\left[X^{k}\\right]  &amp;=\\int_{0}^{1}{x^{k}p(x)\\mathrm{d}x}\\\\  &amp;=\\int_{0}^{1}{x^{k}\\cdot\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\mathrm{d}x}\\\\  &amp;=\\frac{1}{B(\\alpha,\\beta)}\\underbrace{\\int_{0}^{1}{x^{(\\alpha+k)-1}(1-x)^{\\beta-1}\\mathrm{d}x}}_{=B(\\alpha+k,\\beta)}\\\\  &amp;=\\frac{B(\\alpha+k,\\beta)}{B(\\alpha,\\beta)}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=\\alpha/(\\alpha+\\beta)$      $\\mathbb{E}\\left[X^{2}\\right]=\\alpha(\\alpha+1)/(\\alpha+\\beta)(\\alpha+\\beta+1)$      $\\mathrm{Var}\\left[X\\right]=\\alpha\\beta/(\\alpha+\\beta)^{2}(\\alpha+\\beta+1)$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\\\  &amp;=\\exp{\\left[(\\alpha-1)\\log{x}+(\\beta-1)\\log{(1-x)}-\\log{B(\\alpha,\\beta)}\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\begin{pmatrix}\\alpha-1\\\\\\beta-1\\end{pmatrix}^{T}\\begin{pmatrix}\\log{x}\\\\\\log{(1-x)}\\end{pmatrix}-\\log{B(\\alpha,\\beta)}\\right]}  \\end{aligned}\\]          $T(x)=\\log{x},\\log{(1-x)}$      $\\eta(\\theta)=\\alpha-1,\\beta-1$      $A(\\eta)=\\log{B(\\alpha,\\beta)}$      $h(x)=1$      Dirichlet      디리클레 분포(Dirichlet Distribution): $K$ 개 범주가 주어졌을 때 각 범주의 실현 확률을 나타내는 분포\\[\\Pi\\sim\\mathrm{Dirichlet}(\\Theta),\\quad\\pi_{i}\\ge0,\\;\\sum_{k=1}^{K}{\\pi_{k}}=1\\]        단위 물리량이 $1$ 이고 결과가 $K$ 개의 범주로 실현되는 어떤 사건에 대하여 각 범주가 $\\theta_{1},\\cdots,\\theta_{K}$ 만큼 누적 관측되었다고 하자. 전체 관측 데이터의 누적 물리량($Y_{1}+\\cdots+Y_{K}$) 대비 범주 $k$ 실현 데이터의 누적 물리량($Y_{k}$)의 비율을 확률변수 $\\pi_{k}$ 로 정의하였을 때, 이 확률변수는 디리클레 분포를 따르게 된다.\\[\\begin{gathered}  \\pi_{k}:=\\frac{Y_{k}}{Y_{1}+\\cdots+Y_{K}}\\quad\\mathrm{for}\\quad Y_{k}\\sim\\mathrm{Gamma}(\\theta_{k},1)\\\\  \\Downarrow\\\\  \\Pi\\sim\\mathrm{Dirichlet}(\\Theta)  \\end{gathered}\\]        probability density function:\\[p(\\Pi\\mid\\Theta)  =\\frac{1}{B(\\Theta)}\\prod_{k=1}^{K}{\\pi_{k}^{\\theta_{k}-1}}\\]        multi-variate beta function:\\[B(\\Theta)  =\\frac{\\prod_{k=1}^{K}{\\Gamma\\left(\\theta_{k}\\right)}}{\\Gamma\\left(\\sum_{k=1}^{K}{\\theta_{k}}\\right)}\\]        $k$-th moment ($\\psi_{k}\\in\\mathbb{Z}\\setminus\\mathbb{Z}^{-}$):\\[\\begin{aligned}  \\mathbb{E}\\left[\\prod_{k=1}^{K}{\\pi_{k}^{\\psi_{k}}}\\right]  &amp;=\\int{\\prod_{k=1}^{K}{\\pi_{k}^{\\psi_{k}}}p(\\Pi)\\mathrm{d}\\Pi}\\\\  &amp;=\\int{\\prod_{k=1}^{K}{\\pi_{k}^{\\psi_{k}}}\\frac{1}{B(\\Theta)}\\prod_{k=1}^{K}{\\pi_{k}^{\\psi_{k}-1}}\\mathrm{d}\\Pi}\\\\  &amp;=\\frac{1}{B(\\Theta)}\\underbrace{\\int{\\prod_{k=1}^{K}{\\pi_{k}^{(\\theta_{k}+\\psi_{k})-1}}\\mathrm{d}\\Pi}}_{=B(\\Theta+\\Psi)}\\\\  &amp;=\\frac{B(\\Theta+\\Psi)}{B(\\Theta)}  \\end{aligned}\\]          $\\mathbb{E}\\left[\\pi_{k}\\right]=\\theta_{k}/\\sum_{i=1}^{K}{\\theta_{i}}$      $\\mathbb{E}\\left[\\pi_{i}\\pi_{j}\\right]=\\theta_{i}\\theta_{j}/\\sum_{i=1}^{K}{\\theta_{i}}\\left(\\sum_{i=1}^{K}{\\theta_{i}}+1\\right)$      $\\mathrm{Cov}\\left[\\pi_{i},\\pi_{j}\\right]=-\\theta_{i}\\theta_{j}/\\left(\\sum_{i=1}^{K}{\\theta_{i}}\\right)^{2}\\left(\\sum_{i=1}^{K}{\\theta_{i}}+1\\right)$            canonical form:\\[\\begin{aligned}  p(\\Pi)  &amp;=\\frac{1}{B(\\Theta)}\\prod_{k=1}^{K}{\\pi_{k}^{\\theta_{k}-1}}\\\\  &amp;=\\exp{\\left[\\log{\\prod_{k=1}^{K}{\\pi_{k}^{\\theta_{k}-1}}}-\\log{B(\\Theta)}\\right]}\\\\  &amp;=\\exp{\\left[\\sum_{k=1}^{K}{\\log{\\pi_{k}^{\\theta_{k}-1}}}-\\log{B(\\Theta)}\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\sum_{k=1}^{K}{(\\theta_{k}-1)\\log{\\pi_{k}}}-\\log{B(\\Theta)}\\right]}\\\\  \\end{aligned}\\]          $T(\\Pi)=\\log{\\Pi}$      $\\eta(\\theta)=\\Theta-\\mathbf{1}$      $A(\\eta)=\\log{B(\\Theta)}$      $h(\\Pi)=1$      "
  },
  
  {
    "title": "Chi-Squared and Extension",
    "url": "/posts/chi/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, continuous random variable, variance analysis, chi-squared distribution, wishart distribution",
    "date": "2025-07-10 00:00:00 +0900",
    





    
    "snippet": "Chi-Squared      카이제곱 분포(chi-squared distribution): 가우시안 확률변수 자승의 누적량에 대한 분포\\[\\begin{aligned}  X:=\\sum_{i=1}^{k}{Z_{i}^{2}}\\sim\\chi^{2}(k)\\quad\\mathrm{for}\\quad \\forall Z\\overset{\\text{i.i.d}}{\\sim...",
    "content": "Chi-Squared      카이제곱 분포(chi-squared distribution): 가우시안 확률변수 자승의 누적량에 대한 분포\\[\\begin{aligned}  X:=\\sum_{i=1}^{k}{Z_{i}^{2}}\\sim\\chi^{2}(k)\\quad\\mathrm{for}\\quad \\forall Z\\overset{\\text{i.i.d}}{\\sim}\\mathcal{N}(0,1)  \\end{aligned}\\]        The chi-square distribution can be viewed as a special form of the gamma distribution in that it deals with the cumulative amount of positive physical quantities:\\[\\begin{aligned}  \\mathrm{Gamma}\\left(\\alpha=\\frac{k}{2},\\beta=\\frac{1}{2}\\right)  &amp;=\\frac{(1/2)^{k/2}}{\\Gamma(k/2)}x^{k/2-1}\\exp{\\left[-\\frac{1}{2}x\\right]}\\\\  &amp;=\\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}\\exp{\\left[-\\frac{1}{2}x\\right]}\\\\  &amp;=\\chi^{2}(k)  \\end{aligned}\\]        probability density function:\\[\\begin{aligned}  p(x)  =\\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}\\exp{\\left[-\\frac{1}{2}x\\right]}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\int_{0}^{\\infty}{\\exp{tx}\\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}\\exp{\\left[-\\frac{1}{2}x\\right]}\\mathrm{d}x}\\\\  &amp;=\\frac{1}{2^{k/2}\\Gamma(k/2)}\\int_{0}^{\\infty}{x^{k/2-1}\\exp{\\left[-\\left(\\frac{1}{2}-t\\right)x\\right]}\\mathrm{d}x}\\\\  \\\\  \\frac{1}{\\beta^{\\alpha}}\\Gamma(\\alpha)  &amp;:=\\int_{0}^{\\infty}{x^{\\alpha-1}\\exp{-\\beta x}\\mathrm{d}x},\\quad\\alpha,\\beta&gt;0\\\\  \\\\  \\therefore M_{X}(t)  &amp;=\\frac{1}{2^{k/2}\\Gamma(k/2)}\\cdot\\frac{\\Gamma(k/2)}{(1/2-t)^{k/2}}\\\\  &amp;=\\left(\\frac{1}{1-2t}\\right)^{k/2}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=k$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=k(k+2)$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=2k$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}\\exp{\\left[-\\frac{1}{2}x\\right]}\\\\  &amp;=\\exp{\\left[-\\frac{k}{2}\\log{2}-\\log{\\Gamma\\left(\\frac{k}{2}\\right)}\\right]}\\cdot\\exp{\\left[\\left(\\frac{k}{2}-1\\right)\\log{x}\\right]}\\cdot\\exp{\\left[-\\frac{1}{2}x\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\begin{pmatrix}k/2-1\\\\-1/2\\end{pmatrix}^{T}\\begin{pmatrix}\\log{x}\\\\x\\end{pmatrix}-\\left\\{\\frac{k}{2}\\log{2}+\\log{\\Gamma\\left(\\frac{k}{2}\\right)}\\right\\}\\right]}  \\end{aligned}\\]          $T(x)=\\log{x},x$      $\\eta(\\theta)=k/2-1,-1/2$      $A(\\eta)=(k/2)\\log{2}+\\log{\\Gamma(k/2)}$      $h(x)=1$      Wishart      위샤트 분포(Wishart Distribution): 카이제곱 분포의 다변량 분포로서, 다변량 가우시안 확률변수에 대하여, 그 독립 표본들의 외적의 누적량을 나타내는 분포\\[S:=\\sum_{i=1}^{\\nu}{\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}}\\sim\\mathcal{W}_{P}(\\nu,\\Sigma)\\quad\\mathrm{for}\\quad\\mathbf{x}_{i}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathcal{N}_{P}(0,\\Sigma)\\]          $S\\in\\mathbb{R}^{P\\times P}$: 독립 표본들의 산점도 행렬로서 양정치 행렬      $\\nu$: 자유도로서 형상 파라미터      $\\Sigma\\in\\mathbb{R}^{P\\times P}$: 독립 표본들의 공분산 행렬로서 스케일 파라미터            probability density function:\\[p(S\\mid\\Sigma)  =\\frac{1}{2^{np/2}\\mathrm{det}(\\Sigma)^{n/2}\\Gamma_{P}(n/2)}\\mathrm{det}(S)^{(n-p-1)/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}\\]        moment generating function:\\[\\begin{aligned}  M_{S}(T)  &amp;=\\mathbb{E}_{p(S)}\\left[\\exp{\\mathrm{tr}\\left(TS\\right)}\\right]\\\\  &amp;=\\int_{S&gt;0}{\\exp{\\mathrm{tr}\\left(TS\\right)\\cdot\\frac{1}{2^{np/2}\\mathrm{det}(\\Sigma)^{n/2}\\Gamma_{P}(n/2)}\\mathrm{det}(S)^{(n-p-1)/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}}\\mathrm{d}S}\\\\  &amp;=\\frac{1}{2^{np/2}\\mathrm{det}(\\Sigma)^{n/2}\\Gamma_{P}(n/2)}\\int_{S&gt;0}{\\mathrm{det}(S)^{(n-p-1)/2}\\exp{\\left[\\mathrm{tr}\\left(TS\\right)-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}\\mathrm{d}S}\\\\  \\\\  \\mathrm{tr}\\left(TS\\right)-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)  &amp;=\\mathrm{tr}\\left(TS\\right)+\\mathrm{tr}\\left(-\\frac{1}{2}\\Sigma^{-1}S\\right)\\\\  &amp;=\\mathrm{tr}\\left(TS-\\frac{1}{2}\\Sigma^{-1}S\\right)\\\\  &amp;=-\\frac{1}{2}\\mathrm{tr}\\left(\\left[\\Sigma^{-1}-2T\\right]S\\right)\\\\  \\\\  \\because\\int_{S&gt;0}{p(S)\\mathrm{d}S}  &amp;=1\\\\  \\int_{S&gt;0}{\\mathrm{det}(S)^{(n-p-1)/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}\\mathrm{d}S}  &amp;=2^{np/2}\\mathrm{det}(\\Sigma)^{n/2}\\Gamma_{P}(n/2)\\\\  \\int_{S&gt;0}{\\mathrm{det}(S)^{(n-p-1)/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\left[\\Sigma^{-1}-2T\\right]S\\right)\\right]}\\mathrm{d}S}  &amp;=2^{np/2}\\mathrm{det}(\\Sigma^{-1}-2T)^{-n/2}\\Gamma_{P}(n/2)\\\\  \\\\  \\therefore M_{S}(T)  &amp;=\\frac{1}{2^{np/2}\\mathrm{det}(\\Sigma)^{n/2}\\Gamma_{P}(n/2)}\\cdot 2^{np/2}\\mathrm{det}(\\Sigma^{-1}-2T)^{-n/2}\\Gamma_{P}(n/2)\\\\  &amp;=\\mathrm{det}(\\Sigma)^{-n/2}\\mathrm{det}(\\Sigma^{-1}-2T)^{-n/2}\\\\  &amp;=\\mathrm{det}(\\Sigma)^{-n/2}\\cdot\\mathrm{det}(\\Sigma)^{n/2}\\mathrm{det}(I-2\\Sigma T)^{-n/2}\\\\  &amp;=\\mathrm{det}(I-2\\Sigma T)^{-n/2}  \\end{aligned}\\]          $\\mathbb{E}\\left[S_{i,j}\\right]=\\nabla_{T}M_{S}(T)\\vert_{T=0}=n\\cdot\\Sigma_{i,j}$      $\\mathbb{E}\\left[S_{i,j}S_{k,l}\\right]=\\nabla_{T}^{2}M_{S}(T)\\vert_{T=0}=n(\\Sigma_{i,k}\\Sigma_{j,l}+\\Sigma_{i,l}\\Sigma_{j,k})+n^{2}\\Sigma_{i,j}\\Sigma_{k,l}$      $\\mathrm{Cov}\\left[S_{i,j},S_{k,l}\\right]=\\mathbb{E}\\left[S_{i,j}S_{k,l}\\right]-\\mathbb{E}\\left[S_{i,j}\\right]\\mathbb{E}\\left[S_{k,l}\\right]=n(\\Sigma_{i,k}\\Sigma_{j,l}+\\Sigma_{i,l}\\Sigma_{j,k})$            canonical form:\\[\\begin{aligned}  p(S)  &amp;=\\frac{1}{2^{\\nu p/2}\\mathrm{det}(\\Sigma)^{\\nu/2}\\Gamma_{P}(\\nu/2)}\\mathrm{det}(S)^{(\\nu-p-1)/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}\\\\  &amp;=\\exp{\\left[-\\frac{\\nu p}{2}\\log{2}-\\frac{\\nu}{2}\\log{\\mathrm{det}(\\Sigma)}-\\log{\\Gamma_{P}\\left(\\frac{\\nu}{2}\\right)}\\right]}\\exp{\\left[\\frac{\\nu-p-1}{2}\\log{\\mathrm{det}(S)}\\right]}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\Sigma^{-1}S\\right)\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\begin{pmatrix}\\frac{\\nu-p-1}{2}\\\\-\\frac{1}{2}\\Sigma^{-1}\\end{pmatrix}^{T}\\begin{pmatrix}\\log{\\mathrm{det}(S)}\\\\S\\end{pmatrix}-\\left(\\frac{\\nu}{2}\\log{\\mathrm{det}(\\Sigma)}+\\log{\\Gamma_{P}\\left(\\frac{\\nu}{2}\\right)}+\\frac{\\nu p}{2}\\log{2}\\right)\\right]}  \\end{aligned}\\]          $T(S)=\\log{\\mathrm{det}(S)},S$      $\\eta(\\theta)=(\\nu-p-1)/2,-(1/2)\\Sigma^{-1}$      $A(\\eta)=(\\nu/2)\\log{\\mathrm{det}(\\Sigma)}+\\log{\\Gamma_{P}(\\nu/2)}+(\\nu p/2)\\log{2}$      $h(S)=1$      "
  },
  
  {
    "title": "Exponential and Extension",
    "url": "/posts/exponential/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, continuous random variable, survival analysis, exponential distribution, gamma distribution",
    "date": "2025-07-09 00:00:00 +0900",
    





    
    "snippet": "Exponential      지수 분포(Exponential Distribution): 포아송 과정에서 두 사건 사이 대기시간을 나타내는 분포\\[\\begin{aligned}  X\\sim\\mathrm{Exp}(\\lambda),\\quad X\\ge0  \\end{aligned}\\]          $\\lambda&gt;0$: 단위시간당 평균 사건 발생률로서...",
    "content": "Exponential      지수 분포(Exponential Distribution): 포아송 과정에서 두 사건 사이 대기시간을 나타내는 분포\\[\\begin{aligned}  X\\sim\\mathrm{Exp}(\\lambda),\\quad X\\ge0  \\end{aligned}\\]          $\\lambda&gt;0$: 단위시간당 평균 사건 발생률로서 스케일 파라미터의 역수            probability density function:\\[\\begin{aligned}  p(x\\mid\\lambda)  &amp;=\\lambda\\exp{-\\lambda x}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\int_{0}^{\\infty}{\\exp{tx}\\cdot\\lambda\\exp{-\\lambda x}\\mathrm{d}x}\\\\  &amp;=\\lambda\\int_{0}^{\\infty}{\\exp{-(\\lambda-t)x}\\mathrm{d}x}\\\\  &amp;=\\frac{\\lambda}{1-t},\\quad \\lambda&gt;t  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=1/\\lambda$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=2/\\lambda^{2}$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=1/\\lambda^{2}$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\lambda\\exp{\\left[-\\lambda x\\right]}\\\\  &amp;=\\exp{\\left[\\log\\lambda\\right]}\\cdot\\exp{\\left[-\\lambda x\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[-\\lambda x-\\left(-\\log{\\lambda}\\right)\\right]}  \\end{aligned}\\]          $T(x)=x$      $\\eta(\\theta)=-\\lambda$      $A(\\eta)=-\\log{\\lambda}$      $h(x)=1$      Gamma      감마 분포(Gamma Distribution): 지수 분포의 사건 발생 횟수를 일반화한 분포로서, 양의 누적 물리량을 나타내는 분포\\[\\begin{gathered}  T_{k}=X_{1}+\\cdots+X_{k}\\quad\\mathrm{for}\\quad X_{i}\\overset{\\text{i.i.d}}{\\sim}\\mathrm{Exp}(\\lambda)\\\\  \\Downarrow\\\\  T_{k}\\sim\\mathrm{Gamma}(\\alpha=k,\\beta=\\lambda),\\quad T_{k}&gt;0  \\end{gathered}\\]          $\\alpha&gt;0$: 사건 누적 횟수로서 형상 파라미터      $\\beta&gt;0$: 사건 단위당 평균 물리량으로서 스케일 파라미터의 역수            probability density function:\\[p(x\\mid\\alpha,\\beta)  =\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp{-\\beta x}\\]        gamma function:\\[\\begin{aligned}  \\Gamma(\\alpha)  &amp;=\\int_{0}^{\\infty}{x^{\\alpha-1}\\exp{-x}\\mathrm{d}x},\\quad \\alpha&gt;0\\\\  &amp;=(\\alpha-1)!\\quad\\mathrm{s.t.}\\quad\\alpha\\in\\mathbb{Z}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\int_{0}^{\\infty}{\\exp{tx}\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp{-\\beta x}\\mathrm{d}x}\\\\  &amp;=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\int_{0}^{\\infty}{x^{\\alpha-1}\\exp{-(\\beta-t) x}\\mathrm{d}x},\\quad t&lt;\\beta\\\\  \\\\  u  &amp;:=(\\beta-t)x\\\\  \\mathrm{d}x  &amp;:=\\frac{1}{\\beta-t}\\mathrm{d}u\\\\  \\\\  \\therefore M_{X}(t)  &amp;=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\int_{0}^{\\infty}{\\left(\\frac{u}{\\beta-t}\\right)^{\\alpha-1}\\exp{-u}\\frac{1}{\\beta-t}\\mathrm{d}u}\\\\  &amp;=\\left(\\frac{\\beta}{\\beta-t}\\right)^{\\alpha}\\frac{1}{\\Gamma(\\alpha)}\\underbrace{\\int_{0}^{\\infty}{u^{\\alpha-1}\\exp{-u}\\mathrm{d}u}}_{=:\\Gamma(\\alpha)}\\\\  &amp;=\\left(\\frac{\\beta}{\\beta-t}\\right)^{\\alpha}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=\\alpha/\\beta$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=\\alpha(\\alpha+1)/\\beta^{2}$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\alpha/\\beta^{2}$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp{-\\beta x}\\\\  &amp;=\\exp{\\left[(\\alpha-1)\\log{x}-\\beta x+\\alpha\\log{\\beta}-\\log{\\Gamma(\\alpha)}\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\begin{pmatrix}\\alpha-1\\\\-\\beta\\end{pmatrix}^{T}\\begin{pmatrix}\\log{x}\\\\x\\end{pmatrix}-(\\log{\\Gamma(\\alpha})-\\alpha\\log{\\beta})\\right]}  \\end{aligned}\\]          $T(x)=\\log{x},x$      $\\eta(\\theta)=\\alpha-1,-\\beta$      $A(\\eta)=\\log{\\Gamma(\\alpha)}-\\alpha\\log{\\beta}$      $h(x)=1$      "
  },
  
  {
    "title": "Categorical and Extension",
    "url": "/posts/categorical/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, discrete random variable, categorical data analysis, categorical distribution, multinomial distribution",
    "date": "2025-07-08 00:00:00 +0900",
    





    
    "snippet": "Categorical      카테고리 분포(Categorical Distribution): 베르누이 분포의 실현 가능한 범주를 일반화한 분포로서, $K$ 개 범주 중 하나가 실현되는 단일 시행에서 특정 범주의 실현 여부를 나타내는 분포\\[X\\sim\\mathrm{Categorical}(\\Pi)\\]                  \\(X\\): 단일 시행에...",
    "content": "Categorical      카테고리 분포(Categorical Distribution): 베르누이 분포의 실현 가능한 범주를 일반화한 분포로서, $K$ 개 범주 중 하나가 실현되는 단일 시행에서 특정 범주의 실현 여부를 나타내는 분포\\[X\\sim\\mathrm{Categorical}(\\Pi)\\]                  \\(X\\): 단일 시행에서 발생할 수 있는 결과를 \\(K\\) 차원 단위 기저 집합 \\(\\{\\mathbf{e}_{1},\\cdots,\\mathbf{e}_{K}\\}\\) 으로 표현하였을 때 그 중 하나를 실현값으로 가지는 벡터 확률변수\\[X\\in\\left\\{\\mathbf{e}_{1},\\cdots,\\mathbf{e}_{K}\\right\\} \\subset \\mathbb{R}^{K}\\quad\\mathrm{for}\\quad\\mathbf{e}_{k}=\\{\\delta_{i,k}\\}_{i=1}^{K}\\]                    $\\Pi$: 단일 시행에서 각 범주가 실현될 가능성을 나타내는 확률 파라미터\\[\\Pi=\\begin{pmatrix}\\pi_{1}&amp;\\cdots&amp;\\pi_{K}\\end{pmatrix}^{T}\\quad\\mathrm{for}\\quad\\pi_{k}:=P(X=\\mathbf{e}_{k})\\]                  probability mass function:\\[\\begin{aligned}  p(X=\\mathbf{e}_{k}\\mid\\Pi)  =\\prod_{k=1}^{K}{\\pi_{k}^{x_{k}}}  \\quad\\mathrm{for}\\quad  \\begin{cases}\\mathbf{x}=\\begin{pmatrix}x_{1}&amp;\\cdots&amp;x_{K}\\end{pmatrix}^{T}\\in\\{0,1\\}^{K}\\\\  \\sum_{k=1}^{K}{x_{k}}=1  \\end{cases}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(\\mathbf{t})  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{\\mathbf{t}^{T}X}\\right]\\\\  &amp;=\\sum_{X}{\\exp{\\mathbf{t}^{T}X}\\cdot p(x)}\\\\  &amp;=\\sum_{k=1}^{K}{\\exp{\\mathbf{t}^{T}\\mathbf{e}_{k}}\\cdot P(X=\\mathbf{e}_{k})}\\\\  &amp;=\\sum_{k=1}^{K}{\\exp{t_{k}}\\cdot\\pi_{k}}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=\\nabla_{t}M_{X}(t)\\vert_{t=0}=\\Pi$      $\\mathbb{E}\\left[XX^{T}\\right]=\\nabla_{t}^{2}M_{X}(t)\\vert_{t=0}=\\mathrm{diag}(\\Pi)$      $\\mathrm{Cov}\\left[X,X^{\\prime}\\right]=\\mathbb{E}\\left[XX^{T}\\right]-\\mathbb{E}\\left[X\\right]\\mathbb{E}\\left[X\\right]^{T}=\\mathrm{diag}(\\Pi)-\\Pi\\Pi^{T}$            canonical form:\\[\\begin{aligned}  p(\\mathbf{x})  &amp;=\\prod_{k=1}^{K}{\\pi_{k}^{x_{k}}}\\\\  &amp;=\\exp{\\left[\\sum_{k=1}^{K}{x_{k}\\log{\\pi_{k}}}\\right]}\\\\  \\\\  \\sum_{k=1}^{K}{x_{k}\\log{\\pi_{k}}}  &amp;=\\sum_{k=1}^{K-1}{x_{k}\\log{\\pi_{k}}}+x_{K}\\log{\\pi_{K}}\\\\  &amp;=\\sum_{k=1}^{K-1}{x_{k}\\log{\\pi_{k}}}+\\left(1-\\sum_{k=1}^{K-1}{x_{k}}\\right)\\log{\\pi_{K}}\\\\  &amp;=\\sum_{k=1}^{K-1}{x_{k}\\left(\\log{\\pi_{k}}-\\log{\\pi_{K}}\\right)}+\\log{\\pi_{K}}\\\\  &amp;=\\sum_{k=1}^{K-1}{x_{k}\\cdot\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}+\\log{\\pi_{K}}\\\\  \\\\  \\therefore p(\\mathbf{x})  &amp;=\\exp{\\left[\\sum_{k=1}^{K-1}{x_{k}\\cdot\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}+\\log{\\pi_{K}}\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[\\sum_{k=1}^{K-1}{x_{k}\\cdot\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}-\\log{\\frac{1}{\\pi_{K}}}\\right]}  \\end{aligned}\\]          $T(\\mathbf{x})=x_{k}$      $\\eta(\\theta)=\\log{(\\pi_{k}/\\pi_{K})}$      $A(\\eta)=\\log{(1/\\pi_{K})}$      $h(\\mathbf{x})=1$      conjugate prior      categorical model:\\[X\\mid\\Pi\\sim\\mathrm{Categorical}(\\Pi)\\]        canonical form:\\[p(x\\mid\\Pi)  =1\\cdot\\exp{\\left[\\sum_{k=1}^{K-1}{x_{k}\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}-\\log{\\frac{1}{\\pi_{K}}}\\right]}\\]          $T(x)=x_{k}$      $\\eta(\\theta)=\\log{(\\pi_{k}/\\pi_{K})}$      $A(\\eta)=\\log{(1/\\pi_{k})}$      $h(x)=1$            prior of $\\eta$:\\[\\begin{aligned}  p(\\eta)  &amp;\\propto\\exp{\\left[\\alpha\\cdot\\eta(\\theta)-\\beta\\cdot A(\\eta)\\right]}\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\sum_{k=1}^{K-1}{\\eta_{k}}-\\beta\\cdot \\log{\\left(1+\\sum_{k=1}^{K-1}{\\exp{\\eta_{k}}}\\right)}\\right]}  \\end{aligned}\\]        change of variables $\\eta\\to\\pi$:\\[\\begin{aligned}  p_{\\Pi}(\\Pi)\\mathrm{\\partial}\\Pi  &amp;=p_{\\mathrm{H}}(\\mathrm{H})\\mathrm{\\partial}\\mathrm{H}\\\\  \\therefore p_{\\Pi}(\\Pi)  &amp;=p_{\\mathrm{H}}\\left(\\sum_{k=1}^{K-1}{\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}\\right)\\left\\vert\\frac{\\mathrm{\\partial}\\mathrm{H}}{\\mathrm{\\partial}\\Pi}\\right\\vert\\\\  &amp;\\propto\\exp{\\left[\\alpha\\cdot\\sum_{k=1}^{K-1}{\\eta_{k}}-\\beta\\cdot \\log{\\left(1+\\sum_{k=1}^{K-1}{\\exp{\\eta_{k}}}\\right)}\\right]}\\cdot\\left\\vert\\frac{\\mathrm{\\partial}\\mathrm{H}}{\\mathrm{\\partial}\\Pi}\\right\\vert\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\sum_{k=1}^{K-1}{\\log{\\pi_{k}}}-\\alpha(K-1)\\log{\\pi_{K}}+\\beta\\log{\\pi_{K}}\\right]}\\cdot\\frac{1}{\\prod_{k=1}^{K}{\\pi_{k}}}\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\sum_{k=1}^{K-1}{\\log{\\pi_{k}}}\\right]}\\exp{\\left[\\beta\\log{\\pi_{K}}-\\alpha(K-1)\\log{\\pi_{K}}\\right]}\\cdot\\frac{1}{\\prod_{k=1}^{K}{\\pi_{k}}}\\\\  &amp;=\\left(\\prod_{k=1}^{K-1}{\\pi_{k}^{\\alpha}}\\right)\\cdot\\pi_{K}^{\\beta-\\alpha(K-1)}\\cdot\\frac{1}{\\prod_{k=1}^{K}{\\pi_{k}}}\\\\  &amp;=\\left(\\prod_{k=1}^{K-1}{\\pi_{k}^{\\alpha-1}}\\right)\\cdot\\pi_{K}^{\\beta-\\alpha(K-1)-1}\\\\  &amp;=\\prod_{k=1}^{K}{\\pi_{k}^{\\alpha_{k}-1}}  \\quad\\mathrm{for}\\quad\\alpha_{k}  =\\begin{cases}  \\alpha,\\quad &amp;k\\ne K\\\\  \\beta-\\alpha(K-1),\\quad &amp;k=K\\\\  \\end{cases}\\\\  &amp;\\approx\\mathrm{Dirichlet}(\\mathbf{a})  \\end{aligned}\\]        Therefore, the realization probability of the Categorical distribution $\\Pi$ follows a Dirichlet distribution.\\[\\Pi\\sim\\mathrm{Dirichlet}(\\mathbf{a})\\]  Multinomial      다항 분포(Multinomial Distribution): 카테고리 분포의 시행 횟수를 일반화한 분포로서, $K$ 개 범주 중 하나가 실현되는 시행을 $n$ 번 반복했을 때, 각 범주가 실현될 조합을 나타내는 분포\\[\\begin{gathered}  X:=\\sum_{i=1}^{n}{Z_{i}}\\quad\\mathrm{for}\\quad Z_{i}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathrm{Categorical}(\\Pi)\\\\  \\Downarrow\\\\  X\\sim\\mathrm{Multinomial}(n,\\Pi)  \\end{gathered}\\]        probability mass function:\\[p(X=\\mathbf{x}\\mid\\Pi)  =\\frac{n!}{x_{1}!\\cdots x_{K}!}\\prod_{k=1}^{K}{\\pi_{k}^{x_{k}}}  \\quad\\mathrm{for}\\quad  \\begin{cases}\\mathbf{x}=\\begin{pmatrix}x_{1}&amp;\\cdots&amp;x_{K}\\end{pmatrix}^{T}\\\\  \\sum_{k=1}^{K}{x_{k}}=n  \\end{cases}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(\\mathbf{t})  &amp;=\\mathbb{E}_{p(\\mathbf{x})}\\left[\\exp{\\mathbf{t}^{T}X}\\right]\\\\  &amp;=\\mathbb{E}_{p(\\mathbf{z})}\\left[\\exp{\\left(\\mathbf{t}^{T}\\sum_{i=1}^{n}{Z_{i}}\\right)}\\right]\\\\  &amp;=\\mathbb{E}_{p(\\mathbf{z})}\\left[\\exp{\\left(\\sum_{i=1}^{n}{\\mathbf{t}^{T}Z_{i}}\\right)}\\right]\\\\  &amp;=\\mathbb{E}_{p(\\mathbf{z})}\\left[\\prod_{i=1}^{n}{\\exp{\\mathbf{t}^{T}Z_{i}}}\\right]\\\\  &amp;=\\prod_{i=1}^{n}{\\mathbb{E}_{p(\\mathbf{z})}\\left[\\exp{\\mathbf{t}^{T}Z_{i}}\\right]}\\quad(\\because Z_{i}\\perp Z_{j})\\\\  &amp;=\\left(\\mathbb{E}_{p(\\mathbf{z})}\\left[\\exp{\\mathbf{t}^{T}Z}\\right]\\right)^{n}\\\\  &amp;=\\left(\\sum_{k=1}^{K}{\\exp{t_{k}}\\cdot\\pi_{k}}\\right)^{n}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=\\nabla_{t}M_{X}(t)\\vert_{t=0}=n\\cdot\\Pi$      $\\mathbb{E}\\left[XX^{T}\\right]=\\nabla_{t}^{2}M_{X}(t)\\vert_{t=0}=n\\cdot\\mathrm{diag}(\\Pi)$      $\\mathrm{Cov}\\left[X,X^{\\prime}\\right]=\\mathbb{E}\\left[XX^{T}\\right]-\\mathbb{E}\\left[X\\right]\\mathbb{E}\\left[X\\right]^{T}=n\\left(\\mathrm{diag}(\\Pi)-\\Pi\\Pi^{T}\\right)$            canonical form:\\[\\begin{aligned}  p(\\mathbf{x})  &amp;=\\frac{n!}{x_{1}!\\cdots x_{K}!}\\prod_{k=1}^{K}{\\pi_{k}^{x_{k}}}\\\\  &amp;=\\frac{n!}{x_{1}!\\cdots x_{K}!}\\exp{\\left[\\sum_{k=1}^{K}{x_{k}\\log{\\pi_{k}}}\\right]}\\\\  &amp;=\\frac{n!}{x_{1}!\\cdots x_{K}!}\\cdot\\exp{\\left[\\sum_{k=1}^{K-1}{x_{k}\\cdot\\log{\\frac{\\pi_{k}}{\\pi_{K}}}}-n\\cdot\\log{\\frac{1}{\\pi_{K}}}\\right]}  \\end{aligned}\\]          $T(\\mathbf{x})=x_{k}$      $\\eta(\\theta)=\\log{(\\pi_{k}/\\pi_{K})}$      $A(\\eta)=n\\cdot\\log{(1/\\pi_{K})}$      $h(\\mathbf{x})=n!/x_{1}!\\cdots x_{K}!$      "
  },
  
  {
    "title": "Bernoulli and Extension",
    "url": "/posts/bernoulli/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, discrete random variable, categorical data analysis, bernoulli distribution, binomial distribution",
    "date": "2025-07-07 00:00:00 +0900",
    





    
    "snippet": "Bernoulli      베르누이 분포(Bernoulli Distribution): $p$ 의 확률로 성공 여부가 결정되는 단일 시행(베르누이 시행)에서 성공 여부를 나타내는 분포\\[X\\sim\\mathrm{Bernoulli}(\\pi),\\quad X\\in\\{0,1\\}\\]          $0&lt;\\pi&lt;1$: 성공 가능성으로서 확률 파라미터  ...",
    "content": "Bernoulli      베르누이 분포(Bernoulli Distribution): $p$ 의 확률로 성공 여부가 결정되는 단일 시행(베르누이 시행)에서 성공 여부를 나타내는 분포\\[X\\sim\\mathrm{Bernoulli}(\\pi),\\quad X\\in\\{0,1\\}\\]          $0&lt;\\pi&lt;1$: 성공 가능성으로서 확률 파라미터            probability mass function:\\[p(X=k\\mid \\pi)  =\\pi^{k}(1-\\pi)^{1-k}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\pi\\cdot\\exp{[t-1]}+(1-\\pi)\\cdot\\exp{[t-0]}\\\\  &amp;=\\pi\\cdot\\exp{t}+(1-\\pi)  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=\\pi$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=\\pi$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\pi(1-\\pi)$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\pi^{x}(1-\\pi)^{1-x}\\\\  &amp;=\\exp{\\left[x\\log{\\pi}+(1-\\pi)\\log{(1-\\pi)}\\right]}\\\\  &amp;=1\\cdot\\exp{\\left[x\\cdot\\log{\\frac{\\pi}{1-\\pi}}+\\log{(1-\\pi)}\\right]}  \\end{aligned}\\]          $T(x)=x$      $\\eta(\\theta)=\\log{\\left[\\pi/(1-\\pi)\\right]}$      $A(\\eta)=-\\log{(1-\\pi)}$      $h(x)=1$      conjugate prior      bernoulli model:\\[X\\mid\\pi\\sim\\mathrm{Bernoulli}(\\pi)\\]        canonical form:\\[p(x\\mid\\pi)  =1\\cdot\\exp{\\left[x\\cdot\\log{\\frac{\\pi}{1-\\pi}}+\\log{(1-\\pi)}\\right]}\\]          $T(x)=x$      $\\eta(\\theta)=\\log{\\left[\\pi/(1-\\pi)\\right]}$      $A(\\eta)=-\\log{(1-\\pi)}$      $h(x)=1$            prior of $\\eta$:\\[\\begin{aligned}  p(\\pi)  &amp;\\propto\\exp{\\left[\\alpha\\cdot\\eta(\\theta)-\\beta\\cdot A(\\eta)\\right]}\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\eta-\\beta\\cdot\\log{\\left(1+\\exp{\\eta}\\right)}\\right]}\\\\  &amp;=\\exp{\\alpha\\eta}\\cdot\\left(1+\\exp{\\eta}\\right)^{-\\beta}  \\end{aligned}\\]        change of variables $\\eta\\to\\pi$:\\[\\begin{aligned}  p_{\\pi}(\\pi)\\mathrm{d}\\pi  &amp;=p_{\\eta}(\\eta)\\mathrm{d}\\eta\\\\  \\therefore p_{\\pi}(\\pi)  &amp;=p_{\\eta}\\left(\\log{\\frac{\\pi}{1-\\pi}}\\right)\\left\\vert\\frac{\\mathrm{d}\\eta}{\\mathrm{d}\\pi}\\right\\vert\\\\  &amp;\\propto\\exp{\\left[\\alpha\\cdot\\log{\\frac{\\pi}{1-\\pi}}\\right]}\\left(1+\\exp{\\left[\\log{\\frac{\\pi}{1-\\pi}}\\right]}\\right)^{-\\beta}\\cdot\\frac{1}{\\pi(1-\\pi)}\\\\  &amp;=\\pi^{\\alpha}(1-\\pi)^{-\\alpha}\\cdot(1-\\pi)^{\\beta}\\cdot\\pi^{-1}(1-\\pi)^{-1}\\\\  &amp;=\\pi^{\\alpha-1}(1-\\pi)^{(\\beta-\\alpha)-1}\\\\  &amp;=\\mathrm{Beta}(\\alpha,\\beta-\\alpha)  \\end{aligned}\\]        Therefore, the success probability of the Bernoulli distribution $\\pi$ follows a Beta distribution. Here, each parameter of the Beta distribution represents (1) Amount of Success Data and (2) Amount of Failure Data.\\[\\pi\\sim\\mathrm{Beta}(\\alpha,\\beta)\\]  Binomial      이항 분포(Binomial Distribution): 베르누이 분포의 실행 횟수를 일반화한 분포로서, $n$ 번의 베르누이 시행에서 성공 횟수를 나타내는 분포\\[\\begin{gathered}  X:=\\sum_{i=1}^{n}{Z_{i}},\\quad Z_{i}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathrm{Bernoulli}(\\pi)\\\\  \\Downarrow\\\\  X\\sim\\mathrm{Binomial}(n,\\pi)  \\end{gathered}\\]          $n$: 베르누이 시행 횟수      $0&lt;\\pi&lt;1$: 성공 가능성으로서 확률 파라미터            probability mass function:\\[p(X=k\\mid \\pi)  =\\begin{pmatrix}n\\\\x\\end{pmatrix}\\pi^{k}(1-\\pi)^{n-k}\\]        조합(Combination):\\[_{n}C_{k}  :=\\begin{pmatrix}n\\\\ k\\end{pmatrix}  =\\frac{n!}{k!(n-k)!}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{\\left(t\\cdot\\sum_{i=1}^{n}{Z_{i}}\\right)}\\right]\\\\  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{\\sum_{i=1}^{n}{tZ_{i}}}\\right]\\\\  &amp;=\\mathbb{E}_{p(x)}\\left[\\prod_{i=1}^{n}{\\exp{tZ_{i}}}\\right]\\\\  &amp;=\\prod_{i=1}^{n}{\\mathbb{E}_{p(x)}\\left[\\exp{tZ_{i}}\\right]}\\quad(\\because Z_{i}\\perp Z_{j})\\\\  &amp;=\\left[\\pi\\cdot\\exp{t}+(1-\\pi)\\right]^{n}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=\\pi$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=n\\pi+n(n-1)\\pi^{2}$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=n\\pi(1-\\pi)$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\begin{pmatrix}n\\\\x\\end{pmatrix}\\pi^{x}(1-\\pi)^{n-x}\\\\  &amp;=\\begin{pmatrix}n\\\\x\\end{pmatrix}\\exp{\\left[x\\cdot\\log{\\pi}+(n-x)\\cdot\\log{(1-\\pi)}\\right]}\\\\  &amp;=\\begin{pmatrix}n\\\\x\\end{pmatrix}\\cdot\\exp{\\left[x\\cdot\\log{\\frac{\\pi}{1-\\pi}}+n\\cdot\\log{(1-\\pi)}\\right]}  \\end{aligned}\\]          $T(x)=x$      $\\eta(\\theta)=\\log{\\left[\\pi/(1-\\pi)\\right]}$      $A(\\eta)=-n\\cdot\\log{(1-\\pi)}$      $h(x)=\\begin{pmatrix}n\\ x\\end{pmatrix}$      "
  },
  
  {
    "title": "Poisson",
    "url": "/posts/poisson/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, discrete random variable, count data analysis, poisson distribution",
    "date": "2025-07-06 00:00:00 +0900",
    





    
    "snippet": "definition      포아송 분포(Poisson Distribution): 단위 시간 혹은 영역 내에서 발생하는 사건 수를 나타내는 분포\\[X\\sim\\mathrm{Poisson}(\\lambda),\\quad X\\in\\mathbb{Z}\\setminus\\mathbb{Z}^{-}\\]          $\\lambda&gt;0$: 단위 시간 당 평균 발생...",
    "content": "definition      포아송 분포(Poisson Distribution): 단위 시간 혹은 영역 내에서 발생하는 사건 수를 나타내는 분포\\[X\\sim\\mathrm{Poisson}(\\lambda),\\quad X\\in\\mathbb{Z}\\setminus\\mathbb{Z}^{-}\\]          $\\lambda&gt;0$: 단위 시간 당 평균 발생 횟수로서 스케일 파라미터의 역수            probability mass function:\\[\\begin{aligned}  p(x\\mid\\lambda)  &amp;=\\frac{\\lambda^{x}\\exp{-\\lambda}}{x!}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\sum_{x=0}^{\\infty}{\\exp{tx}\\cdot\\frac{\\lambda^{x}\\exp{-\\lambda}}{x!}}\\\\  &amp;=\\exp{-\\lambda}\\sum_{x=0}^{\\infty}{\\frac{\\left(\\lambda\\exp{t}\\right)^{x}}{x!}}\\\\  \\\\  \\because\\exp{x}  &amp;=\\sum_{k=0}^{\\infty}{\\frac{x^{k}}{k!}}\\\\  \\sum_{x=0}^{\\infty}{\\frac{\\left(\\lambda\\exp{t}\\right)^{x}}{x!}}  &amp;=\\exp{\\left[\\lambda\\cdot\\exp{t}\\right]}\\\\  \\\\  \\therefore  M_{X}(t)  &amp;=\\exp{-\\lambda}\\cdot\\exp{\\left[\\lambda\\cdot\\exp{t}\\right]}\\\\  &amp;=\\exp{\\left[\\lambda\\left(\\exp{t}-1\\right)\\right]}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=\\lambda$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=\\lambda+\\lambda^{2}$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\lambda$            canonical form:\\[\\begin{aligned}  p(x)  &amp;=\\frac{\\lambda^{x}\\exp{-\\lambda}}{x!}\\\\  &amp;=\\frac{1}{x!}\\exp{\\left[x\\log{\\lambda}-\\lambda\\right]}  \\end{aligned}\\]          $T(x)=x$      $\\eta(\\theta)=\\log{\\lambda}$      $A(\\eta)=\\lambda$      $h(x)=1/x!$      conjugate prior      poisson model:\\[X\\mid\\lambda\\sim\\mathrm{Poisson}(\\lambda)\\]        canonical form:\\[\\begin{aligned}  p(x\\mid\\lambda)  &amp;=\\frac{\\lambda^{x}\\exp{-\\lambda}}{x!}\\\\  &amp;=\\frac{1}{x!}\\exp{\\left[x\\log{\\lambda}-\\lambda\\right]}  \\end{aligned}\\]          $T(x)=x$      $\\eta(\\theta)=\\log{\\lambda}$      $A(\\eta)=\\lambda$      $h(x)=1/x!$            prior of $\\eta$:\\[\\begin{aligned}  p(\\eta)  &amp;\\propto\\exp{\\left[\\alpha\\cdot\\eta(\\theta)-\\beta\\cdot A(\\eta)\\right]}\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\log{\\lambda}-\\beta\\cdot \\lambda\\right]}\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\eta-\\beta\\cdot\\exp{\\eta}\\right]}  \\end{aligned}\\]        change of variables $\\eta\\to\\log{\\lambda}$:\\[\\begin{aligned}  p_{\\lambda}(\\lambda)\\mathrm{d}\\lambda  &amp;=p_{\\eta}(\\eta)\\mathrm{d}\\eta\\\\  \\therefore p_{\\lambda}(\\lambda)  &amp;=p_{\\eta}(\\log{\\lambda})\\left\\vert\\frac{\\mathrm{d}\\eta}{\\mathrm{d}\\lambda}\\right\\vert\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\log{\\lambda}-\\beta\\cdot\\lambda\\right]}\\cdot\\frac{1}{\\lambda}\\\\  &amp;=\\lambda^{\\alpha-1}\\exp{-\\beta\\lambda}\\\\  &amp;\\approx\\mathrm{Gamma}(\\alpha,\\beta)  \\end{aligned}\\]        Therefore, rate parameter of poisson $\\lambda$, average occurrence rate per unit time, follow gamma distribution. accordingly, $\\alpha$ represents the number of events occurring, and $\\beta$ represents the waiting time per event.\\[\\lambda\\sim\\mathrm{Gamma}(\\alpha,\\beta)\\]  "
  },
  
  {
    "title": "Multi-Variate Gaussian",
    "url": "/posts/mvn/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, continuous random variable, numerical data analysis, multivariate gaussian distribution, multivariate normal distribution",
    "date": "2025-07-05 00:00:00 +0900",
    





    
    "snippet": "definition      다변량 가우시안 분포(Multi-Variate Normal Distribution): 유한 차원의 상관된 가우시안 확률변수 벡터에 대하여 정의되는 가우시안 분포\\[\\begin{aligned}  \\mathbf{x} \\sim \\mathcal{N}_{P}\\left(\\mu, \\Sigma\\right)  \\end{aligned}\\] ...",
    "content": "definition      다변량 가우시안 분포(Multi-Variate Normal Distribution): 유한 차원의 상관된 가우시안 확률변수 벡터에 대하여 정의되는 가우시안 분포\\[\\begin{aligned}  \\mathbf{x} \\sim \\mathcal{N}_{P}\\left(\\mu, \\Sigma\\right)  \\end{aligned}\\]                  \\(\\mathbf{x}\\) : multi-variable vector\\[\\mathbf{x}  =\\begin{bmatrix}  x_{1}&amp;x_{2}&amp;\\cdots&amp;x_{p}  \\end{bmatrix}^{T}\\]                    each elements \\(x_{i}\\in\\mathbf{x}\\) are random variables that follow individual Gaussian dist.\\[x_{i}\\sim\\mathcal{N}\\left(\\mu_{i}, \\sigma_{i}^{2}\\right),  \\quad x_{i} \\cancel{\\perp} x_{j}\\]                    \\(\\mu\\): mean vector\\[\\mu  =\\begin{bmatrix}  \\mu_{1}&amp;\\mu_{2}&amp;\\cdots&amp;\\mu_{p}  \\end{bmatrix}^{T}\\]                    \\(\\Sigma\\): covariance matrix\\[\\Sigma  =\\begin{bmatrix}  \\sigma_{1}^{2} &amp; \\sigma_{1,2} &amp; \\cdots &amp; \\sigma_{1,p}\\\\ \\sigma_{2,1} &amp; \\sigma_{2}^{2} &amp; \\cdots &amp; \\sigma_{2,p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\Sigma_{p,1} &amp; \\sigma_{p,2} &amp; \\cdots &amp; \\sigma_{p}^{2}  \\end{bmatrix}\\]                  probability density function:\\[\\begin{aligned}  p(\\mathbf{x}\\mid\\mu,\\Sigma)  &amp;= \\frac{1}{(2\\pi)^{p/2}\\mathrm{det}(\\Sigma)^{1/2}} \\exp{\\left[-\\frac{1}{2}\\underbrace{(\\mathbf{x}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{x}-\\mu)}_{\\text{Mahalanobis Distance}}\\right]}  \\end{aligned}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(\\mathbf{t})  &amp;=\\mathbb{E}_{p(\\mathbf{x})}\\left[\\exp{t^{T}X}\\right]\\\\  &amp;=\\int_{-\\infty}^{\\infty}{\\exp{\\mathbf{t}^{T}\\mathbf{x}}\\cdot p(\\mathbf{x})\\mathrm{d}\\mathbf{x}}\\\\  &amp;=\\frac{1}{(2\\pi)^{p/2}\\mathrm{det}(\\Sigma)^{1/2}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[\\mathbf{t}^{T}\\mathbf{x}-\\frac{1}{2}\\left(\\mathbf{x}-\\mu\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\mu\\right)\\right]}\\mathrm{d}\\mathbf{x}}\\\\  \\\\  \\mathbf{t}^{T}\\mathbf{x}-\\frac{1}{2}\\left(\\mathbf{x}-\\mu\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\mu\\right)  &amp;=-\\frac{1}{2}\\left(\\mathbf{x}-\\left[\\mu+\\Sigma t\\right]\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\left[\\mu+\\Sigma t\\right]\\right)+\\mathbf{t}^{T}\\mu+\\frac{1}{2}\\mathbf{t}^{T}\\Sigma\\mathbf{t}\\\\  &amp;=-\\frac{1}{2}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)+\\mathbf{t}^{T}\\mu+\\frac{1}{2}\\mathbf{t}^{T}\\Sigma\\mathbf{t}\\\\  \\\\  \\therefore M_{X}(\\mathbf{t})  &amp;=\\frac{1}{(2\\pi)^{p/2}\\mathrm{det}(\\Sigma)^{1/2}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[\\mathbf{t}^{T}\\mu+\\frac{1}{2}\\mathbf{t}^{T}\\Sigma\\mathbf{t}\\right]}\\cdot\\exp{\\left[-\\frac{1}{2}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)\\right]}\\mathrm{d}\\mathbf{x}}\\\\  &amp;=\\exp{\\left[\\mathbf{t}^{T}\\mu+\\frac{1}{2}\\mathbf{t}^{T}\\Sigma\\mathbf{t}\\right]}\\cdot\\underbrace{\\frac{1}{(2\\pi)^{p/2}\\mathrm{det}(\\Sigma)^{1/2}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[-\\frac{1}{2}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)^{T}\\Sigma^{-1}\\left(\\mathbf{x}-\\mu^{\\prime}\\right)\\right]}\\mathrm{d}\\mathbf{x}}}_{=1}\\\\  &amp;=\\exp{\\left[\\mathbf{t}^{T}\\mu+\\frac{1}{2}\\mathbf{t}^{T}\\Sigma\\mathbf{t}\\right]}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=\\nabla_{t}M_{X}(t)\\vert_{t=0}=\\mu$      $\\mathbb{E}\\left[XX^{T}\\right]=\\nabla_{t}^{2}M_{X}(t)\\vert_{t=0}=\\mu^{T}\\mu+\\Sigma$      $\\mathrm{Cov}\\left[X,X^{\\prime}\\right]=\\mathbb{E}\\left[XX^{T}\\right]-\\mathbb{E}\\left[X\\right]\\mathbb{E}\\left[X\\right]^{T}=\\Sigma$            canonical form:\\[\\begin{aligned}  p(\\mathbf{x})  &amp;=\\frac{\\mathrm{det}(\\Lambda)^{1/2}}{(2\\pi)^{p/2}}\\exp{\\left[-\\frac{1}{2}(\\mathbf{x}-\\mu)^{T}\\Lambda(\\mathbf{x}-\\mu)\\right]}\\\\  \\\\  -\\frac{1}{2}(\\mathbf{x}-\\mu)^{T}\\Lambda(\\mathbf{x}-\\mu)  &amp;=-\\frac{1}{2}\\mathbf{x}^{T}\\Lambda\\mathbf{x}+\\mu^{T}\\Lambda\\mathbf{x}-\\frac{1}{2}\\mu^{T}\\Lambda\\mu\\\\  \\\\  \\mathbf{x}^{T}\\Lambda\\mathbf{x}  &amp;=\\mathrm{tr}\\left(\\mathbf{x}^{T}\\Lambda\\mathbf{x}\\right)\\\\  &amp;=\\mathrm{tr}\\left(\\Lambda\\mathbf{x}\\mathbf{x}^{T}\\right)\\\\  &amp;=\\left\\langle\\Lambda,\\mathbf{x}\\mathbf{x}^{T}\\right\\rangle_{F}\\\\  \\\\  \\therefore -\\frac{1}{2}(\\mathbf{x}-\\mu)^{T}\\Lambda(\\mathbf{x}-\\mu)  &amp;=-\\frac{1}{2}\\left\\langle\\Lambda,\\mathbf{x}\\mathbf{x}^{T}\\right\\rangle_{F}+\\mu^{T}\\Lambda\\mathbf{x}-\\frac{1}{2}\\mu^{T}\\Lambda\\mu\\\\  \\\\  \\therefore p(\\mathbf{x})  &amp;=\\exp{\\left[-\\frac{p}{2}\\log{2\\pi}+\\frac{1}{2}\\log{\\mathrm{det}(\\Lambda)}-\\frac{1}{2}\\left\\langle\\Lambda,\\mathbf{x}\\mathbf{x}^{T}\\right\\rangle_{F}+\\mu^{T}\\Lambda\\mathbf{x}-\\frac{1}{2}\\mu^{T}\\Lambda\\mu\\right]}\\\\  &amp;=\\frac{1}{(2\\pi)^{p/2}}\\exp{\\left(\\begin{bmatrix}-(1/2)\\Lambda\\\\\\mu^{T}\\Lambda\\end{bmatrix}^{T}\\begin{bmatrix}\\mathbf{x}\\mathbf{x}^{T}\\\\\\mathbf{x}\\end{bmatrix}-\\frac{1}{2}\\left[\\mu^{T}\\Lambda\\mu+\\log{\\mathrm{det}(\\Lambda)}\\right]\\right)}  \\end{aligned}\\]          $T(\\mathbf{x})=\\mathbf{x}\\mathbf{x}^{T},\\mathbf{x}$      $\\eta(\\theta)=-(1/2)\\Lambda,\\mu^{T}\\Lambda$      $A(\\eta)=-(1/2)[\\mu^{T}\\Lambda\\mu+\\log{\\mathrm{det}(\\Lambda)}]$      $h(\\mathbf{x})=1/(2\\pi)^{p/2}$      conjugate prior      multi-variate gaussian model:\\[\\mathbf{x}_{i}\\mid\\Lambda\\overset{\\mathrm{i.i.d}}{\\sim}\\mathcal{N}(0,\\Lambda^{-1}),\\quad i=1,\\cdots,n\\]        canonical form:\\[\\begin{aligned}  p(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{n}\\mid\\Lambda)  &amp;=\\prod_{i=1}^{n}{p(\\mathbf{x}_{i}\\mid\\Lambda)}\\quad(\\because \\mathbf{x}_{i}\\perp \\mathbf{x}_{j})\\\\  &amp;=\\prod_{i=1}^{n}{(2\\pi)^{-p/2}\\mathrm{det}(\\Lambda)^{1/2}\\exp{\\left[-\\frac{1}{2}\\mathbf{x}_{i}^{T}\\Lambda\\mathbf{x}_{i}\\right]}}\\\\  &amp;=(2\\pi)^{-np/2}\\mathrm{det}(\\Lambda)^{n/2}\\exp{\\left[-\\frac{1}{2}\\sum_{i=1}^{n}{\\mathbf{x}_{i}^{T}\\Lambda\\mathbf{x}_{i}}\\right]}\\\\  \\\\  \\sum_{i=1}^{n}{\\mathbf{x}_{i}^{T}\\Lambda\\mathbf{x}_{i}}  &amp;=\\sum_{i=1}^{n}{\\mathrm{tr}\\left(\\Lambda\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\right)}\\\\  &amp;=\\mathrm{tr}\\left(\\Lambda\\sum_{i=1}^{n}{\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}}\\right)\\\\  &amp;=\\mathrm{tr}(\\Lambda S)\\quad\\mathrm{for}\\quad S:=\\sum_{i=1}^{n}{\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}}\\\\  \\\\  \\mathrm{tr}(\\Lambda S)  &amp;=\\sum_{i=1}^{p}{(\\Lambda S)_{i,i}}\\\\  &amp;=\\sum_{i=1}^{p}\\sum_{j=1}^{p}{\\Lambda_{i,j}S_{j,i}}\\\\  &amp;=\\sum_{i=1}^{p}\\sum_{j=1}^{p}{\\Lambda_{i,j}S_{i,j}}\\quad(\\because S=S^{T})\\\\  &amp;=\\langle\\Lambda,S\\rangle_{F}\\\\  \\\\  \\therefore p(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{n}\\mid\\Lambda)  &amp;= (2\\pi)^{-np/2}\\mathrm{det}(\\Lambda)^{n/2}\\exp{\\left[-\\frac{1}{2}\\langle\\Lambda,S\\rangle_{F}\\right]}\\\\  &amp;= (2\\pi)^{-np/2}\\exp{\\left(-\\frac{1}{2}\\langle\\Lambda,S\\rangle_{F}-\\left[-\\frac{n}{2}\\log{\\mathrm{det}(\\Lambda)}\\right]\\right)}  \\end{aligned}\\]          $T(x)=S$      $\\eta(\\theta)=-(1/2)\\Lambda$      $A(\\eta)=-(n/2)\\log{\\mathrm{det}(\\Lambda)}$      $h(x)=(2\\pi)^{-np/2}$            prior of $\\eta$:\\[\\begin{aligned}  p(\\eta)  &amp;\\propto\\exp{\\left[\\left\\langle\\chi,\\eta(\\theta)\\right\\rangle_{F}-\\nu\\cdot A(\\eta)\\right]}\\quad\\mathrm{for}\\quad\\chi^{T}=\\chi\\\\  &amp;=\\exp{\\left(\\chi\\cdot\\eta-\\nu\\cdot\\left[-\\frac{1}{2}\\log{\\mathrm{det}(-2\\eta)}\\right]\\right)}  \\end{aligned}\\]        change of variables $\\eta\\to\\Lambda$:\\[\\begin{aligned}  p_{\\Lambda}(\\Lambda)\\mathrm{d}\\Lambda  &amp;=p_{\\eta}(\\eta)\\mathrm{d}\\eta\\\\  \\therefore p_{\\Lambda}(\\Lambda)  &amp;=p_{\\eta}(\\eta)\\left\\vert\\frac{\\mathrm{d}\\eta}{\\mathrm{d}\\Lambda}\\right\\vert\\\\  &amp;\\propto\\exp{\\left(\\chi\\cdot\\left[-\\frac{1}{2}\\Lambda\\right]-\\nu\\cdot\\left[-\\frac{1}{2}\\log{\\mathrm{det}(\\Lambda)}\\right]\\right)}\\cdot\\left\\vert-\\frac{1}{2}\\right\\vert^{p(p+1)/2}\\\\  &amp;\\propto\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\chi^{T}\\Lambda\\right)+\\frac{\\nu}{2}\\log{\\mathrm{det}(\\Lambda)}\\right]}\\\\  &amp;=\\mathrm{det}(\\Lambda)^{\\nu/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\chi^{T}\\Lambda\\right)\\right]}\\\\  &amp;=\\mathrm{det}(\\Lambda)^{\\nu/2}\\exp{\\left[-\\frac{1}{2}\\mathrm{tr}\\left(\\chi\\Lambda\\right)\\right]}\\quad(\\because\\chi^{T}=\\chi)\\\\  &amp;\\approx \\mathcal{W}_{P}\\left(\\nu+p+1,\\chi^{-1}\\right)  \\end{aligned}\\]        Therefore, the precision of the Multi-Variate Gaussian distribution $\\Sigma^{-1}$, the reciprocal of the covariance, follows a Wishart distribution. Here, each parameter of the wishart distribution represents (1) degrees of freedom and (2) the precision scale.\\[\\Sigma^{-1}\\sim\\mathcal{W}_{P}(\\nu,V)\\]  conditional probability      마할라노비스 거리(Mahalanobis Distance): 상관관계가 존재하는 다변량 데이터에서, 하나의 데이터 포인트가 특정 분포 혹은 군집에서 얼마나 떨어져 있는지를 측정하는 개념으로서, 단순 좌표 상의 거리뿐만 아니라 데이터 분포(분산-공분산 구조)까지 반영하여 측정된 거리\\[\\begin{aligned}  D_{M}(x)  &amp;= \\sqrt{(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu)}  \\end{aligned}\\]          $\\sqrt{(x-\\mu)^{T}(x-\\mu)}$ : 데이터 포인트와 특정 분포 중심점 간 편차로서 유클리드 거리      $\\Sigma$ : 특정 분포의 공분산 행렬로서 데이터의 분산과 변수 간 상관관계를 포함하며, 이를 반영하여 방향성과 크기에 따라 거리를 조정함            multi-variate gaussian dist.:\\[\\begin{aligned}  \\mathbf{Z}  =\\begin{bmatrix}Z_{1} \\\\ Z_{2}\\end{bmatrix}  \\sim \\mathcal{N}\\left(\\begin{bmatrix}\\mu_{1} \\\\ \\mu_{2}\\end{bmatrix}, \\begin{bmatrix}\\Sigma_{11} &amp; \\Sigma_{12}\\\\ \\Sigma_{21} &amp; \\Sigma_{22}\\end{bmatrix}\\right)  \\end{aligned}\\]        probability density function:\\[\\begin{aligned}  p(\\mathbf{Z})  &amp;= \\frac{1}{(2\\pi)^{n/2}\\mathrm{det}(\\Sigma)^{1/2}} \\exp{\\left[-\\frac{1}{2}\\underbrace{(\\mathbf{Z}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mu)}_{\\text{Mahalanobis Distance}}\\right]}  \\end{aligned}\\]        inv-covariance matrix:\\[\\begin{aligned}  \\Sigma^{-1}  &amp;= \\begin{bmatrix}  \\Sigma_{11}^{-1}+\\Sigma_{11}^{-1}\\Sigma_{12} \\cdot \\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1} \\cdot \\Sigma_{12}\\Sigma_{11}^{-1} &amp; -\\Sigma_{11}^{-1}\\Sigma_{12}\\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1}\\\\  -\\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1}\\Sigma_{21}\\Sigma_{11}^{-1} &amp; \\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1}  \\end{bmatrix}  \\end{aligned}\\]        exponent formula expansion:\\[\\begin{aligned}  (\\mathbf{Z}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mu)  &amp;= \\underbrace{(Z_{1}-\\mu_{1})^{T}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})}_{\\text{Mahalanobis Distance of } Z_{1}}\\\\  &amp;\\quad + \\underbrace{\\left[Z_{2}-\\left\\{\\mu_{2}+\\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\right\\}\\right]^{T}\\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1}\\left[Z_{2}-\\left\\{\\mu_{2}+\\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\right\\}\\right]}_{\\text{Conditional Mahalanobis Distance of }Z_{2} \\mid Z_{1}}  \\end{aligned}\\]        components of the conditional Mahalanobis distance can be interpreted in terms of expectation and covariance:\\[\\begin{aligned}  \\mathbb{E}\\left[Z_{2} \\mid Z_{1}\\right]  &amp;= \\mu_{2} + \\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\\\  \\mathrm{Cov}\\left[Z_{2} \\mid Z_{1}\\right]  &amp;= \\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Gaussian",
    "url": "/posts/gaussian/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, continuous random variable, numerical data analysis, gaussian distribution, normal distribution, student’s t-distribution",
    "date": "2025-07-04 00:00:00 +0900",
    





    
    "snippet": "definition      가우시안 분포(Gaussian Distribution): 독립적인 무작위 충격들이 누적되어 나타나는 연속 실수값을 나타내는 분포\\[X\\sim\\mathcal{N}(\\mu,\\sigma^{2})\\]          $\\mu$: 평균 위치로서 위치 파라미터      $\\sigma^{2}$: 분산으로서 스케일 파라미터        ...",
    "content": "definition      가우시안 분포(Gaussian Distribution): 독립적인 무작위 충격들이 누적되어 나타나는 연속 실수값을 나타내는 분포\\[X\\sim\\mathcal{N}(\\mu,\\sigma^{2})\\]          $\\mu$: 평균 위치로서 위치 파라미터      $\\sigma^{2}$: 분산으로서 스케일 파라미터            probability density function:\\[p(x\\mid\\mu,\\sigma^{2})  =\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}\\]        moment generating function:\\[\\begin{aligned}  M_{X}(t)  &amp;=\\mathbb{E}_{p(x)}\\left[\\exp{tX}\\right]\\\\  &amp;=\\int_{-\\infty}^{\\infty}{\\exp{tx}\\cdot\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}\\mathrm{d}x}\\\\  &amp;=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[tx-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}\\mathrm{d}x}\\\\  \\\\  tx-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}  &amp;=-\\frac{1}{2\\sigma^{2}}x^{2}+\\left(\\frac{\\mu}{\\sigma^{2}}+t\\right)x-\\frac{\\mu^{2}}{2\\sigma^{2}}\\\\  &amp;=-\\frac{\\left[x-(\\mu+\\sigma^{2}+t)\\right]^{2}}{2\\sigma^{2}}+\\mu t+\\frac{\\sigma^{2}t^{2}}{2}\\\\  &amp;=-\\frac{\\left(x-\\mu^{\\prime}\\right)^{2}}{2\\sigma^{2}}+\\mu t+\\frac{\\sigma^{2}t^{2}}{2}\\\\  \\\\  \\therefore M_{X}(t)  &amp;=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[\\mu t+\\frac{\\sigma^{2}t^{2}}{2}\\right]}\\cdot\\exp{\\left[-\\frac{(x-\\mu^{\\prime})^{2}}{2\\sigma^{2}}\\right]}\\mathrm{d}x}\\\\  &amp;=\\exp{\\left[\\mu t+\\frac{\\sigma^{2}t^{2}}{2}\\right]}\\cdot\\underbrace{\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\int_{-\\infty}^{\\infty}{\\exp{\\left[-\\frac{(x-\\mu^{\\prime})^{2}}{2\\sigma^{2}}\\right]}\\mathrm{d}x}}_{=1}\\\\  &amp;=\\exp{\\left[\\mu t+\\frac{\\sigma^{2}t^{2}}{2}\\right]}  \\end{aligned}\\]          $\\mathbb{E}\\left[X\\right]=(\\mathrm{d}/\\mathrm{d}t)M_{X}(t)\\vert_{t=0}=\\mu$      $\\mathbb{E}\\left[X^{2}\\right]=(\\mathrm{d}^{2}/\\mathrm{d}t^{2})M_{X}(t)\\vert_{t=0}=\\mu^{2}+\\sigma^{2}$      $\\mathrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\sigma^{2}$            canonical form ($\\tau=1/\\sigma^{2}$):\\[\\begin{aligned}  p(x)  &amp;=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}\\\\  &amp;=\\sqrt{\\frac{\\tau}{2\\pi}}\\exp{\\left[-\\frac{\\tau}{2}(x-\\mu)^{2}\\right]}\\\\  &amp;=\\frac{1}{\\sqrt{2\\pi}}\\exp{\\left[\\begin{pmatrix}-(1/2)\\tau\\\\\\mu\\tau\\end{pmatrix}^{T}\\begin{pmatrix}x^{2}\\\\x\\end{pmatrix}-\\frac{1}{2}(\\mu^{2}\\tau-\\log{\\tau})\\right]}  \\end{aligned}\\]          $T(x)=x^{2},x$      $\\eta(\\theta)=-(1/2)\\tau,\\mu\\tau$      $A(\\eta)=(1/2)(\\mu^{2}\\tau-\\log{\\tau})$      $h(x)=1/\\sqrt{2\\pi}$      conjugate prior      gaussian model:\\[X\\mid\\tau\\sim\\mathcal{N}(0,\\tau^{-1})\\]        canonical form:\\[\\begin{aligned}  p(x\\mid\\tau)  &amp;=\\sqrt{\\frac{\\tau}{2\\pi}}\\exp{\\left[-\\frac{\\tau}{2}x^{2}\\right]}\\\\  &amp;=\\frac{1}{\\sqrt{2\\pi}}\\exp{\\left[-\\frac{1}{2}\\tau x^{2}-\\left(-\\frac{1}{2}\\log{\\tau}\\right)\\right]}  \\end{aligned}\\]          $T(x)=x^{2}$      $\\eta(\\theta)=-(1/2)\\tau$      $A(\\eta)=-(1/2)\\log{\\tau}$      $h(x)=1/\\sqrt{2\\pi}$            prior of $\\eta$:\\[\\begin{aligned}  p(\\eta)  &amp;\\propto \\exp\\left[\\alpha\\cdot\\eta(\\theta)-\\beta\\cdot A(\\eta)\\right]\\\\  &amp;=\\exp{\\left[\\alpha\\cdot\\eta-\\beta\\cdot\\left(-\\frac{1}{2}\\log{[-2\\eta]}\\right)\\right]}\\\\  &amp;=(-2\\eta)^{\\beta/2}\\cdot\\exp{\\alpha\\eta}  \\end{aligned}\\]        change of variables $\\eta\\to\\tau$:\\[\\begin{aligned}  p_{\\tau}(\\tau)\\mathrm{d}\\tau  &amp;=p_{\\eta}(\\eta)\\mathrm{d}\\eta\\\\  \\therefore p_{\\tau}(\\tau)  &amp;=p_{\\eta}\\left(-\\frac{1}{2}\\tau\\right)\\left\\vert\\frac{\\mathrm{d}\\eta}{\\mathrm{d}\\tau}\\right\\vert\\\\  &amp;=(\\tau)^{\\beta/2}\\cdot\\exp{\\left[-\\frac{\\alpha}{2}\\tau\\right]}\\cdot\\frac{1}{2}\\\\  &amp;=\\frac{1}{2}\\tau^{(\\beta/2 + 1)-1}\\exp{\\left[-\\frac{\\alpha}{2}\\tau\\right]}\\\\  &amp;\\approx\\mathrm{Gamma}\\left(\\frac{\\beta}{2}+1,\\frac{\\alpha}{2}\\right)  \\end{aligned}\\]        Therefore, the precision of the Gaussian distribution $1/\\sigma^{2}$, the reciprocal of the variance, follows a gamma distribution. Here, each parameter of the gamma distribution represents (1) the number of virtual samples and (2) the precision scale.\\[1/\\sigma^{2}\\sim\\mathrm{Gamma}(\\alpha,\\beta)\\]  sample variance distribution      gaussian model:\\[\\begin{aligned}  X\\sim\\mathcal{N}\\left(\\mu,\\sigma^{2}\\right),\\quad\\text{$\\mu$ is known}  \\end{aligned}\\]        jeffreys prior of $\\sigma^{2}$:\\[\\begin{aligned}  p\\left(\\sigma^{2}\\right)\\propto \\frac{1}{\\sigma^{2}}  \\end{aligned}\\]        likelihood of $\\sigma^{2}$:\\[\\begin{aligned}  p\\left(x_{1},\\cdots,x_{k}\\mid\\sigma^{2}\\right)  &amp;=\\prod_{i=1}^{k}{p(x_{i}\\mid\\sigma^{2})}\\quad(\\because x_{i}\\perp x_{j})\\\\  &amp;=\\prod_{i=1}^{k}{\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x_{i}-\\mu)^{2}}{2\\sigma^{2}}\\right]}}\\\\  &amp;=\\prod_{i=1}^{k}{\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}}\\cdot\\prod_{i=1}^{k}{\\exp{\\left[-\\frac{(x_{i}-\\mu)^{2}}{2\\sigma^{2}}\\right]}}\\\\  \\\\  \\prod_{i=1}^{k}{\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}}  &amp;=\\left(2\\pi\\sigma^{2}\\right)^{-k/2}\\\\  &amp;=(2\\pi)^{-k/2}\\cdot(\\sigma^{2})^{-k/2}\\\\  \\prod_{i=1}^{k}{\\exp{\\left[-\\frac{(x_{i}-\\mu)^{2}}{2\\sigma^{2}}\\right]}}  &amp;=\\exp{\\left[\\sum_{i=1}^{k}{-\\frac{(x_{i}-\\mu)^{2}}{2\\sigma^{2}}}\\right]}\\\\  &amp;=\\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{k}{(x_{i}-\\mu)^{2}}\\right]}\\\\  &amp;=\\exp{\\left[-\\frac{1}{2}\\cdot\\frac{\\nu S^{2}}{\\sigma^{2}}\\right]}\\\\  \\\\  \\therefore p\\left(x_{1},\\cdots,x_{k}\\mid\\sigma^{2}\\right)  &amp;=(2\\pi)^{-k/2}\\cdot(\\sigma^{2})^{-k/2}\\cdot\\exp{\\left[-\\frac{\\nu}{2\\sigma^{2}}\\cdot S^{2}\\right]}\\\\  &amp;\\propto\\left(\\sigma^{2}\\right)^{-k/2}\\cdot\\exp{\\left[-\\frac{1}{2}\\cdot\\frac{\\nu S^{2}}{\\sigma^{2}}\\right]}  \\end{aligned}\\]        posterior of $\\sigma^{2}$:\\[\\begin{aligned}  p\\left(\\sigma^{2}\\mid x_{1},\\cdots,x_{k}\\right)  &amp;\\propto p\\left(x_{1},\\cdots,x_{k}\\mid\\sigma^{2}\\right)p\\left(\\sigma^{2}\\right)\\\\  &amp;\\propto\\left(\\sigma^{2}\\right)^{-k/2}\\cdot\\exp{\\left[-\\frac{1}{2}\\cdot\\frac{\\nu S^{2}}{\\sigma^{2}}\\right]}\\cdot\\frac{1}{\\sigma^{2}}  \\end{aligned}\\]        change of variables:\\[\\begin{gathered}  z:=\\frac{\\nu S^{2}}{\\sigma^{2}}  \\end{gathered}\\]        posterior of $z$:\\[\\begin{aligned}  \\quad p_{z}(z)\\mathrm{d}z  &amp;=p_{\\sigma^{2}}\\left(\\sigma^{2}\\right)\\mathrm{d}\\sigma^{2}\\\\  \\therefore p_{z}(z\\mid x_{1},\\cdots,x_{k})  &amp;\\propto p_{\\sigma^{2}}\\left(\\frac{\\nu S^{2}}{z}\\right)\\cdot\\frac{\\nu S^{2}}{z^{2}}\\\\  &amp;\\propto(\\nu S^{2}/z)^{-k/2}\\cdot\\exp{\\left[-\\frac{\\nu S^{2}}{2\\nu S^{2}/z}\\right]}\\cdot\\frac{1}{\\nu S^{2}/z}\\cdot\\frac{\\nu S^{2}}{z^{2}}\\\\  &amp;=\\left(\\nu S^{2}\\right)^{-k/2}\\cdot z^{k/2-1}\\cdot\\exp{\\left[-\\frac{1}{2}z\\right]}\\\\  &amp;\\approx z^{k/2-1}\\cdot\\exp{\\left[-\\frac{1}{2}z\\right]}\\\\  &amp;\\approx \\chi^{2}(k)  \\end{aligned}\\]        therefore, sample variance of gaussian distribution, $S^{2}$, follows a chi-square distribution.\\[\\begin{aligned}  z=\\frac{\\nu S^{2}}{\\sigma^{2}}=\\sum_{i=1}^{k}{\\left(\\frac{x_{i}-\\mu}{\\sigma}\\right)^{2}}  \\sim\\chi^{2}(k)  \\end{aligned}\\]  student’s t      gaussian random variable:\\[X_{i}\\sim\\mathcal{N}(\\mu,\\sigma^{2})\\]        standardization:\\[Z=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}\\sim\\mathcal{N}(0,1)\\]        If the population variance $\\sigma^{2}$ is unknown, the sample variance $S^{2}$ can be used:\\[S^{2}=\\frac{1}{\\nu}\\sum_{i=1}^{n}{\\left(X_{i}-\\overline{X}\\right)^{2}}\\]        chi-squared dist.:\\[\\begin{aligned}  U\\sim\\chi^{2}(\\nu)  \\end{aligned}\\]        chi-squared variable can be represented by $S^{2}$:\\[\\begin{aligned}  U  &amp;=\\sum_{i=1}^{n}{\\left(\\frac{X_{i}-\\overline{X}}{\\sigma}\\right)^{2}}\\\\  &amp;=\\frac{1}{\\sigma^{2}}\\cdot\\nu S^{2}  \\end{aligned}\\]        as a result, when the population variance is unknown, the test statistic can be replaced by the ratio of the chi-square random variable to the standard normal random variable:\\[\\begin{aligned}  \\frac{\\overline{X}-\\mu}{S/\\sqrt{n}}  &amp;=\\underbrace{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}_{=:Z}\\cdot\\frac{\\sigma}{S}\\\\  &amp;=Z\\cdot\\frac{1}{\\sqrt{S^{2}/\\sigma^{2}}}\\\\  &amp;=\\frac{Z}{\\sqrt{U/\\nu}}\\quad\\left(\\because\\frac{S^{2}}{\\sigma^{2}}=\\frac{U}{\\nu}\\right)  \\end{aligned}\\]        the ratio of the chi-square random variable to the standard normal random variable is defined as the Student’s t random variable:\\[T=\\frac{Z}{\\sqrt{U/\\nu}}\\sim t(\\nu),\\quad Z \\perp U\\]  "
  },
  
  {
    "title": "Exponential Family",
    "url": "/posts/exp_family/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, probability distribution, measure, parameter, exponential family, conjugate",
    "date": "2025-07-03 00:00:00 +0900",
    





    
    "snippet": "parameter  파라미터(Parameter): 특정 구조로 가정된 분포 모형의 구체적 형태를 조정하는 변수                  위치 파라미터(Location Parameter): 분포의 중심 위치를 조정하는 파라미터\\[X\\mapsto X+\\theta\\]                    척도 파라미터(Scale Parameter): 분포...",
    "content": "parameter  파라미터(Parameter): 특정 구조로 가정된 분포 모형의 구체적 형태를 조정하는 변수                  위치 파라미터(Location Parameter): 분포의 중심 위치를 조정하는 파라미터\\[X\\mapsto X+\\theta\\]                    척도 파라미터(Scale Parameter): 분포의 폭을 조정하는 파라미터\\[X\\mapsto \\theta\\cdot X\\]                    형상 파라미터(Shape Parameter): 왜도, 첨도 등 분포의 모양을 조정하는 파라미터\\[X\\mapsto g(X;\\theta)\\]              Parameteric Distribution Families          location family      scale family      shape family      location-scale family      location-scale-shape family      mixture family      exponential family      conjugate family      non-exponential family      exponential family      지수족(Exponential Family): 확률 분포 함수를 지수 함수로 변환하였을 때, 충분통계량 $T(x)$ 과 자연매개변수 $\\eta(\\theta)$ 가 선형 결합으로 표현되고, 정규화 항 $A(\\eta)$ 과 기저 측도 $h(x)$ 가 분리된 하나의 구조로 표현될 수 있는 확률분포들의 모임\\[\\begin{aligned}  P_{X}(B)  &amp;=\\int_{x\\in B}{f(x)\\mathrm{d}\\mu(x)}\\\\  &amp;=\\int_{x\\in B}{\\exp{\\left[\\eta(\\theta)^{T}T(x)-A(\\eta)\\right]}\\mathrm{d}\\nu(x)}  \\end{aligned}\\]        정규 형식(canonical form):\\[f(x\\mid\\theta)  =h(x)\\exp{\\left[\\eta(\\theta)^{T}T(x)-A(\\eta)\\right]}\\]          $f(x\\mid\\theta)$: probability distribution function      $T(x)$: sufficient statistics      $\\eta(\\theta)$: natural parameter      $h(x)$: base measure            충분통계량(Sufficient Statistics): 관측 데이터 $x\\in X$ 로부터 모수 $\\theta$ 추정에 필요한 정보를 충분히 요약하는(정보 손실 없이 요약하는) 함수\\[f(\\theta\\mid x)=f(\\theta\\mid T(x))\\]        자연매개변수(Natural Parameter): 확률분포의 로그 우도 $\\log{p(x)}$ 가 충분통계량 $T(x)$ 에 대하여 선형 형식으로 표현되도록 만드는 파라미터 변환, 혹은 그 표현\\[\\eta=g(\\theta)\\]        기저 측도(Base Measure): 파라미터 $\\theta$ 에 대하여 독립인 항\\[\\mathrm{d}\\nu(x):=h(x)\\mathrm{d}\\mu(x)\\]                  common representation of measures in exponential normal form:\\[\\begin{aligned}  \\int_{x\\in X}{f(x)\\underbrace{\\mathrm{d}\\mu(x)}_{\\text{refer. measure}}}  &amp;=\\int_{x\\in X}{\\exp{\\left[\\eta(\\theta)^{T}T(x)-A(\\eta)\\right]}\\underbrace{h(x)\\mathrm{d}\\mu(x)}_{\\text{base measure}}}  \\end{aligned}\\]                    support set (domain) of the probability measure:\\[\\begin{gathered}  f(x)&gt;0\\Leftrightarrow h(x)&gt;0\\quad(\\because\\exp{(\\cdot)}&gt;0)\\\\  \\therefore\\mathrm{supp}(f):=\\{x\\mid h(x)&gt;0\\}  \\end{gathered}\\]                  정규화 항(Normalizer): 충분통계량과 자연매개변수의 선형 결합이 확률 분포의 요건을 갖출 수 있도록($P(\\Omega)=1$) 정규화하는 항\\[\\begin{aligned}  \\exp{A(\\eta)}  &amp;=\\int_{x\\in X}{\\exp{\\left[\\eta(\\theta)^{T}T(x)\\right]}\\mathrm{d}\\nu(x)}  \\end{aligned}\\]                  parameter space:\\[\\begin{gathered}  \\frac{\\eta(\\theta)^{T}T(x)}{A(\\theta)}=1\\\\  \\therefore\\Theta:=\\left\\{\\theta\\mid A(\\theta)&lt;\\infty\\right\\}  \\end{gathered}\\]                    moment generating structure:\\[\\begin{aligned}  \\exp{A(\\eta)}  &amp;=\\mathbb{E}_{\\nu}\\left[\\exp{\\eta(\\theta)^{T}T(X)}\\right]\\\\  &amp;=\\sum_{k=0}^{\\infty}{\\frac{\\eta^{k}(\\theta)}{k!}\\mathbb{E}_{\\nu}\\left[T^{k}(X)\\right]}\\\\  \\\\  \\therefore\\nabla_{\\eta}^{k}A(\\eta)  &amp;=\\mathbb{E}_{\\nu}\\left[T^{k}(X)\\right]  \\end{aligned}\\]            bayes rule      prior:\\[p(\\eta)\\propto\\exp{\\left[\\alpha\\eta(\\theta)-\\beta A(\\eta)\\right]}\\]        likelihood:\\[\\begin{aligned}  p(x_{1},\\cdots,x_{n}\\mid\\eta)  &amp;=\\prod_{i=1}^{n}{h(x_{i})\\exp{\\left[\\eta(\\theta)^{T}T(x_{i})-A(\\eta)\\right]}}\\quad(\\because x_{i}\\perp x_{j})\\\\  &amp;=\\prod_{i=1}^{n}{h(x_{i})}\\cdot\\exp{\\left[\\eta(\\theta)\\sum_{i=1}^{n}{T(x_{i})}-nA(\\eta)\\right]}  \\end{aligned}\\]        posterior:\\[\\begin{aligned}  p(\\eta\\mid x_{1},\\cdots,x_{n})  &amp;\\propto p(x_{1},\\cdots,x_{n}\\mid\\eta)\\cdot p(\\eta)\\\\  &amp;\\propto \\prod_{i=1}^{n}{h(x_{i})}\\cdot\\exp{\\left[\\eta(\\theta)\\sum_{i=1}^{n}{T(x_{i})}-nA(\\eta)\\right]}\\cdot\\exp{\\left[\\alpha\\eta(\\theta)-\\beta A(\\eta)\\right]}\\\\  &amp;=\\prod_{i=1}^{n}{h(x_{i})}\\cdot\\exp{\\left[\\left(\\alpha+\\sum_{i=1}^{n}{T(x_{i})}\\right)\\eta(\\theta)-(\\beta+n)A(\\eta)\\right]}\\\\  \\\\  \\alpha^{\\prime}  &amp;:=\\alpha+\\sum_{i=1}^{n}{T(x_{i})}\\\\  \\beta^{\\prime}  &amp;:=\\beta+n\\\\  \\\\  \\therefore p(\\eta\\mid x_{1},\\cdots,x_{n})  &amp;\\propto \\prod_{i=1}^{n}{h(x_{i})}\\cdot\\exp{\\left[\\alpha^{\\prime}\\eta(\\theta)-\\beta^{\\prime}A(\\eta)\\right]}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Probability Distribution",
    "url": "/posts/prob_dist/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, random variable, distribution, measure, moment",
    "date": "2025-07-02 00:00:00 +0900",
    





    
    "snippet": "measure space      가측 공간(Measureable Space): 어떠한 크기를 측정할 수 있는 집합이 정의된 공간\\[(\\Omega,\\mathcal{F})\\]          $\\Omega$: 기저 집합      $\\mathcal{F}$: 기저 집합의 시그마 대수로서 어떠한 크기를 측정할 수 있는 부분집합들의 모임             ...",
    "content": "measure space      가측 공간(Measureable Space): 어떠한 크기를 측정할 수 있는 집합이 정의된 공간\\[(\\Omega,\\mathcal{F})\\]          $\\Omega$: 기저 집합      $\\mathcal{F}$: 기저 집합의 시그마 대수로서 어떠한 크기를 측정할 수 있는 부분집합들의 모임                  $A\\subseteq\\Omega\\in\\mathcal{F}$          $A\\in\\mathcal{F}\\Rightarrow A^{C}\\in\\mathcal{F}$          $A_{1},A_{2},\\cdots\\in\\mathcal{F}\\Rightarrow\\bigcup_{i}{A_{i}}\\in\\mathcal{F}$                          보렐 공간(Borel Space): 가측 공간의 특수한 경우로서 기저 집합을 실수 공간으로 가지는 공간\\[(\\mathbb{R},\\mathcal{B})\\quad\\mathrm{for}\\quad\\mathcal{B}(\\mathbb{R}):=\\sigma\\left(\\left\\{(-\\infty,x]\\mid x\\in\\mathbb{R}\\right\\}\\right)\\]        측도 공간(Measure Space): 가측 공간 $(\\Omega,\\mathcal{F})$ 에 대하여 측도 함수 $\\mu$ 가 정의된 공간\\[(\\Omega,\\mathcal{F},\\mu)\\]  probability distribution      확률 공간(Probability Space): 표본 공간 위에 정의된 가측 공간에 대하여 확률의 크기를 부여하는 측도 함수 $P$ 가 정의된 공간\\[\\begin{aligned}  (\\Omega,\\mathcal{F},P)  \\end{aligned}\\]                  $\\Omega$: 표본 공간(Sample Space)으로서 무작위 실험으로 발생 가능한 결과들의 집합 (ex. 동전을 두 번 던지는 실험 결과)\\[\\Omega=\\{HH,TT,HT,TH\\}\\]                    $\\mathcal{F}$: 사건(Event)으로서 표본 공간의 시그마 대수 (ex. 앞면이 한 번 이상 나오는 사건)\\[\\{HH,HT,TH\\}\\subset\\sigma(\\Omega)\\]                    $P$: 확률 측도(Probability Measure)로서 사건에 확률을 부여하는 측도\\[P:\\mathcal{F}\\to[0,1]\\quad\\mathrm{s.t.}\\quad P(\\Omega)=1\\]                  확률 변수(Random Variable): 표본 공간 위에 정의된 가측 공간을 보렐 공간으로 사상하는 함수\\[X:(\\Omega,\\mathcal{F})\\to(\\mathbb{R},\\mathcal{B})\\]        확률 분포(Probability Distribution): 확률 공간 $(\\Omega,\\mathcal{F},P)$ 위에 정의된 확률 변수 $X$ 가 유도하는 푸시포워드 측도(push-forward measure)\\[\\begin{gathered}  P_{X}=P\\circ X^{-1}:\\mathcal{B}\\to[0,1]  \\end{gathered}\\]        푸시포워드 확률 공간(Push-forward Probability Space): 확률 변수 $X$ 에 의하여 유도된 새로운 확률 공간\\[(\\Omega,\\mathcal{F},P)\\xrightarrow{X}(\\mathbb{R},\\mathcal{B},P_{X})\\]  functions      Integral representation of probability distribution:\\[P_{X}(B)=\\int_{x\\in B}{f(x)\\mathrm{d}\\mu(x)}\\]    기준 측도(Reference Measure): 보렐 공간 $(\\mathbb{R},\\mathcal{B})$ 의 원소들에 대하여 그 기본 단위를 제공하는 측도                  연속 확률 분포(Continuous Distribtution): 르베그 측도(Lebesgue Measure)\\[\\begin{gathered}  \\mu(x):=x,\\quad\\mathrm{d}\\mu(x)=\\mathrm{d}x\\\\  \\Downarrow\\\\  P_{X}(B)=\\int_{x\\in B}{f(x)\\mathrm{d}x}  \\end{gathered}\\]                    이산 확률 분포(Discrete Distribution): 카운팅 측도(Counting Measure)\\[\\begin{gathered}  \\mu(x):=\\#x,\\quad\\mathrm{d}\\mu(x)=1\\\\  \\Downarrow\\\\  P_{X}(B)=\\sum_{x\\in B}{f(x)}  \\end{gathered}\\]                  누적 분포 함수(Cumulative Distribution Function): 확률 변수 $X$ 가 특정 값 $t$ 이하일 확률을 나타내는 함수\\[F(t):=P_{X}(X\\le t)=\\int_{x\\le t}{f(x)\\mathrm{d}\\mu(x)}\\]        확률 분포 함수(Probability Distribution Function): 확률 변수가 특정 값을 가질 확률을 나타내는 함수로서, 기저 단위당 확률의 크기를 부여하는 함수\\[f(x):=\\frac{\\mathrm{d}F}{\\mathrm{d}\\mu}(x)\\]  moment      적률(moment): 확률 분포의 모양을 수치로 요약하는 값                  비중심 적률:\\[\\mathbb{E}\\left[X^{k}\\right]  :=\\int{x^{k}\\mathrm{d}P_{X}(x)}  =\\int{x^{k}f(x)\\mathrm{d}\\mu(x)}\\]                    중심 적률:\\[\\mathbb{E}\\left[\\left(X-\\mathbb{E}[X]\\right)^{k}\\right]  :=\\int{(x-\\mu)^{k}\\mathrm{d}P_{X}(x)}  =\\int{(x-\\mu)^{k}f(x)\\mathrm{d}\\mu(x)}\\]                  기대값(Expected Value): 1차 비중심 적률로서 분포의 위치를 나타냄\\[\\mathbb{E}\\left[X\\right]  =\\int{xf(x)\\mathrm{d}\\mu(x)}\\]          $\\mathbb{E}[\\alpha]=\\alpha$      $\\mathbb{E}[\\alpha X]=\\alpha\\mathbb{E}[X]$      $\\mathbb{E}[\\alpha X \\pm \\beta Y]=\\alpha\\mathbb{E}[X]\\pm\\beta\\mathbb{E}[Y]$      $\\mathbb{E}[XY]=\\mathbb{E}[X]\\mathbb{E}[Y]\\quad(\\mathrm{s.t.}\\;X\\perp Y)$            분산(Variance): 2차 중심 적률로서 분포의 폭을 나타냄\\[\\mathrm{Var}\\left[X\\right]  =\\mathbb{E}\\left[\\left(X-\\mu\\right)^{2}\\right]  =\\int{(x-\\mu)^{2}f(x)\\mathrm{d}\\mu(x)}\\]          $\\mathrm{Var}[\\alpha]=0$      $\\mathrm{Var}[\\alpha X]=\\alpha^{2}\\mathrm{Var}[X]$      $\\mathrm{Var}[\\alpha+X]=\\mathrm{Var}[X]$      $\\mathrm{Var}[\\alpha X\\pm\\beta Y]=\\alpha^{2}\\mathrm{Var}[X]+\\beta^{2}\\mathrm{Var}[Y]\\pm2\\alpha\\beta\\mathrm{Cov}[X,Y]$            왜도(Skewness): 표준화된 3차 중심 적률로서 분포의 좌우 비대칭성을 나타냄\\[\\mathrm{Skew}\\left[X\\right]  =\\frac{1}{\\sigma^{3}}\\cdot\\mathbb{E}\\left[\\left(X-\\mu\\right)^{3}\\right]  =\\frac{1}{\\sigma^{3}}\\int{\\left(x-\\mu\\right)^{3}f(x)\\mathrm{d}\\mu(x)}\\]        첨도(Kurtosis): 표준화된 4차 중심 적률로서 분포 중심의 뾰족한 정도나 꼬리의 두터운 정도 등을 나타냄\\[\\mathrm{Kurt}\\left[X\\right]  =\\frac{1}{\\sigma^{4}}\\cdot\\mathbb{E}\\left[\\left(X-\\mu\\right)^{4}\\right]  =\\frac{1}{\\sigma^{4}}\\int{\\left(x-\\mu\\right)^{4}f(x)\\mathrm{d}\\mu(x)}\\]  MGF      적률 생성 함수(Moment Generating Function): 확률 측도 \\(P_{X}\\) 의 라플라스 변환으로서, \\(P_{X}\\) 의 표현 공간을 확률 도메인(probability domain) \\((\\mathbb{R},\\mathcal{B})\\) 에서 라플라스 도메인(laplace domain) \\(\\{t\\in\\mathbb{R}\\mid\\mathbb{E}[\\exp{tX}]&lt;\\infty\\}\\) 으로 사상하는 함수\\[\\begin{aligned}  M_{X}(t)  =\\mathbb{E}\\left[\\exp{tX}\\right]  =\\int{\\exp{tx}\\cdot f(x)\\mathrm{d}\\mu(x)}  \\end{aligned}\\]        Taylor Series of the moment generating function:\\[\\begin{aligned}  \\exp{tX}  &amp;\\approx\\sum_{k=0}^{\\infty}{\\frac{(tX)^{k}}{k!}}\\\\  \\\\  \\therefore M_{X}(t)  &amp;=\\mathbb{E}\\left[\\exp{tX}\\right]\\\\  &amp;\\approx\\mathbb{E}\\left[\\sum_{k=0}^{\\infty}{\\frac{(tX)^{k}}{k!}}\\right]\\\\  &amp;=\\sum_{k=0}^{\\infty}{\\frac{t^{k}}{k!}\\mathbb{E}\\left[X^{k}\\right]}  \\end{aligned}\\]        $k$-th order derivatives:\\[\\begin{aligned}  \\frac{\\mathrm{d}^{k}}{\\mathrm{d}t^{k}}M_{X}(t)  &amp;=\\sum_{n=k}^{\\infty}{\\frac{t^{n-k}}{(n-k)!}\\mathbb{E}\\left[X^{n}\\right]}  \\end{aligned}\\]        the $k$-th derivative evaluated at $t=0$ is $k$-th moment:\\[\\begin{aligned}  \\frac{\\mathrm{d}^{k}}{\\mathrm{d}t^{k}}M_{X}(t)\\vert_{t=0}  &amp;=\\sum_{n=k}^{\\infty}{\\frac{0^{n-k}}{(n-k)!}\\mathbb{E}\\left[X^{n}\\right]}\\\\  &amp;=\\frac{0^{k-k}}{(k-k)!}\\mathbb{E}\\left[X^{k}\\right]+\\underbrace{\\frac{0^{k+1-k}}{(k+1-k)!}\\mathbb{E}\\left[X^{k+1}\\right]+\\frac{0^{k+2-k}}{(k+2-k)!}\\mathbb{E}\\left[X^{k+2}\\right]+\\cdots}_{=0}\\\\  &amp;=\\mathbb{E}\\left[X^{k}\\right]  \\end{aligned}\\]  "
  },
  
  {
    "title": "Uncertainty and Probability",
    "url": "/posts/probability/",
    "categories": "2.STATISTICAL TECHS, 1.probability",
    "tags": "statistics, uncertainty, probability, distribution",
    "date": "2025-07-01 00:00:00 +0900",
    





    
    "snippet": "uncertainty  불확실성(Uncertainty): 어떠한 사건의 결과에 대하여 사전에 확신할 수 없는 상태          우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성        인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생...",
    "content": "uncertainty  불확실성(Uncertainty): 어떠한 사건의 결과에 대하여 사전에 확신할 수 없는 상태          우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성        인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생하는 불확실성          정보 불완전성(Data Uncertainty): 관측 데이터가 불완전하거나(Incomplete), 불충분하거나(Insufficient), 왜곡된(Distorted) 상황      파라미터 불확실성(Parameter Uncertainty): 주어진 모형 안에서 최적 파라미터를 유일하게 식별할 수 없는 문제      구조적 불확실성(Structural Uncertainty): 데이터 생성 메커니즘을 기술하는 함수 구조를 확신할 수 없어 특정 모형을 가정할 수 없는 문제      표현의 불확실성(Latent Representation Uncertainty): 잠재공간의 비식별성으로 인해 치역(관측값)만으로 정의역(잠재요인)을 유일하게 결정하여 표현할 수 없는 문제        존재론적 불확실성(Ontic Uncertainty): 모형이 모사하고자 하는 실제 메커니즘이 본질적으로 불확실하여 정보가 증가하더라도 제거될 수 없는 불확실성probability  확률실험(Random Experiment) : 사건의 불확실성을 가진 프로세스                  표본공간(Sample Space) : 확률실험에서 발생 가능한 모든 결과의 집합 (e.g. 동전 던지기)\\[\\Omega=\\{H,T\\}\\]                    사건(Event) : 표본공간의 부분집합으로서 발생 가능한 결과의 일부 (e.g. 동전을 한 번 던졌을 때 앞면이 나오는 사건)\\[A=\\{H\\}\\in\\mathcal{F}\\]                    확률(Probability): 사건의 불확실성을 정량화하기 위한 도구로서, 표본공간 $\\Omega$ 위에 정의된 시그마대수 $\\mathcal{F}:=\\sigma(\\Omega)$ 에 대하여 그 원소 $A$, 즉 사건이 발생할 상대적 가능성\\[P(A)\\quad\\text{s.t.}\\quad 0 \\le P(A) \\le 1\\]              확률의 고전적 접근법 : 확률실험의 대칭성(Symmetric Nature)을 이용하여 각 결과가 발생할 가능성을 논리적으로 추론하는 방법          어떤 확률실험이 발생 가능성이 동일한(Equally Likely) $n$ 개의 결과를 가질 때, 단순 사건이 발생할 확률은 $1/n$ 임      $n$ 개의 결과 중 $n_A$ 개 결과를 취하는 복합 사건이 발생할 확률은 $n_{A}/n$ 임        확률의 경험적 접근법 : 반복 실험 결과를 근거로 확률을 부여하는 방법으로서 빈도적 접근법          어떤 확률실험을 $n$ 번 반복했을 때, 어떤 결과가 $k \\le n$ 번 발생했다면 그 결과가 발생할 확률은 $k/n$ 임      실험 횟수가 매우 크고, 모든 실험이 동일한 환경에서 이루어졌을 때 정당성을 가짐        확률의 주관적 접근법 : 고전적 접근법, 경험적 접근법에 의해 확률을 부여하는 것이 불가능한 경우 개인적인 판단에 의해 확률을 부여하는 방법axioms and laws  확률의 공리(Axioms of Probability):                  비음성 공리(non-negativity):\\[P(A) \\ge 0\\]                    정규화 공리(normalization):\\[P(\\Omega)=1\\]                    가산성 공리(countable additivity / σ-additivity):\\[A_i \\cap A_j=\\emptyset\\Rightarrow P\\left(\\bigcup_{i=1}^{n}{A_{i}}\\right)=\\sum_{i=1}^{n}{A_{i}}\\]              확률 법칙(Laws of Probability):                  여집합 법칙(complement rule):\\[P(A^{C})=1-P(A)\\]                    단조성 법칙(monotonicity):\\[A\\subseteq B\\Rightarrow P(A)\\le P(B)\\]                    차집합 법칙:\\[P(B\\setminus A)=P(B)-P(A\\cap B)\\]                    포함-배제 법칙(inclusion–exclusion):\\[P(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\]                    유한 가법성 법칙(finite additivity):\\[A\\cap B=\\emptyset\\Rightarrow P(A\\cup B)=P(A)+P(B)\\]                    증가열의 연속성 법칙(continuity of increasing sequence):\\[A_{1}\\subseteq A_{2}\\subseteq\\cdots,\\quad\\bigcup_{n=1}^{\\infty}{A_{n}}=A\\Rightarrow\\lim_{n\\to\\infty}{P(A_{n})}=P(A)\\]                    감소열의 연속성 법칙(continuity of decreasing sequence):\\[A_{1}\\supseteq A_{2}\\supseteq\\cdots,\\quad\\bigcap_{n=1}^{\\infty}{A_{n}}=A\\Rightarrow\\lim_{n\\to\\infty}{P(A_{n})}=P(A)\\]                    전체 확률 법칙(total probability):\\[P(A)=\\sum_{i}{P(A\\mid B_{i})P(B_{i})}\\]                    베이즈 법칙(bayes):\\[P(A\\mid B)=\\frac{P(B\\mid A)P(A)}{P(B)}\\]            statistical independence      결합 확률(Joint Probability): 확률 변수 $A, B$ 에 대하여 그 실현값 $A_i \\in A$ 와 $B_j \\in B$ 가 동시에 발생할 확률\\[P(A_i \\cap B_j)\\]        결합확률표: 상호배타적이고(\\(X_{i}\\cap X_{j}=\\emptyset\\)) 집단전체적인(\\(\\bigcup_{i}{X_{i}}=\\Omega\\)) 사건들에 대한 확률 변수 \\(A,B\\) 에 대하여 사건 \\(A_{i},B_{j}\\) 가 동시에 발생할 결합 확률을 요약한 표                                       $B_1$          $B_2$          $\\cdots$          $B_m$          $\\sum_{j=1}^{m}P(A_i \\cap B_j)$                                      $A_1$          $P(A_1 \\cap B_1)$          $P(A_1 \\cap B_2)$          $\\cdots$          $P(A_1 \\cap B_m)$          $P(A_1)$                          $A_2$          $P(A_2 \\cap B_1)$          $P(A_2 \\cap B_2)$          $\\cdots$          $P(A_2 \\cap B_m)$          $P(A_2)$                          $\\vdots$          $\\vdots$          $\\vdots$          $\\ddots$          $\\vdots$          $\\vdots$                          $A_n$          $P(A_n \\cap B_1)$          $P(A_n \\cap B_2)$          $\\cdots$          $P(A_n \\cap B_m)$          $P(A_n)$                          $\\sum_{i=1}^{n}P(A_i \\cap B_j)$          $P(B_1)$          $P(B_2)$          $\\cdots$          $P(B_m)$          $1$                          조건부 확률(Conditional Probability): 사건 $B$ 가 발생했을 때 사건 $A$ 가 발생할 확률\\[P(A\\mid B)=\\frac{P(A\\cap B)}{P(B)}\\]        통계적 독립성(Statistical Independence): 한 사건의 발생 여부가 다른 사건이 발생할 가능성에 아무런 영향을 끼치지 못하는 경우 혹은 한 사건에 관한 정보가 다른 사건에 관한 정보를 추가적으로 제공하지 못하는 경우\\[P(A\\mid B)=P(A)\\Rightarrow A\\perp B\\]  "
  },
  
  {
    "title": "Bayesian Attention Modules",
    "url": "/posts/bam/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, deep Learning, attention mechanism, latent factor, variational inference",
    "date": "2024-09-19 00:00:00 +0900",
    





    
    "snippet": "Bayesian Attention Modules  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty...",
    "content": "Bayesian Attention Modules  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생하는 불확실성                  정보 불완전성(Data Uncertainty): 관측 데이터가 불완전하거나(Incomplete), 불충분하거나(Insufficient), 왜곡된(Distorted) 상황          파라미터 불확실성(Parameter Uncertainty): 주어진 모형 안에서 최적 파라미터를 유일하게 식별할 수 없는 문제          구조적 불확실성(Structural Uncertainty): 데이터 생성 메커니즘을 기술하는 함수 구조를 확신할 수 없어 특정 모형을 가정할 수 없는 문제          표현의 불확실성(Latent Representation Uncertainty): 잠재공간의 비식별성으로 인해 치역(관측값)만으로 정의역(잠재요인)을 유일하게 결정하여 표현할 수 없는 문제                    존재론적 불확실성(Ontic Uncertainty): 모형이 모사하고자 하는 실제 메커니즘이 본질적으로 불확실하여 정보가 증가하더라도 제거될 수 없는 불확실성            문제 의식: 요청 정보와 참조 정보 간 대응 관계는 관측값만으로는 드러나지 않는 잠재 구조로서, 표현의 불확실성을 내포함    Bayesian Attention Modules: 어텐션 스코어에 실증적 베이지안 프레임워크를 적용하여 요청 정보와 참조 정보 간 관계 대응의 불확실성을 반영하는 방법론          어텐션 스코어를 확정적인 값을 취하는 상수가 아니라 확률 분포를 따르는 확률변수로 가정함      요청 정보와 참조 정보 간 유사도 함수 값의 지수변환을 어텐션 스코어의 기대값으로 간주함      참조 정보에 대한 개별 요청 정보의 집중도를 사전 정보(해당 참조 정보에 대한 요청 정보 전반의 집중도)로 규제함      Notation  $y$: response variable  $q,k,v,\\cdots \\in X$: explanatory variables  $q,k,v$: query, key, value  $S$: random variable of attention score  $s$: sample of attention score  $\\Omega$: random variable of attention weight  $\\omega$: sample of attention weight  $P_{\\theta}(\\cdot)$: posterior dist.  $Q_{\\phi}(\\cdot)$: approx. dist.  $\\Pi_{\\eta}(\\cdot)$: prior dist.  $\\mathcal{L}(\\cdot)$: likelihood  $\\mathbf{h}$: linear transformation vector  $\\mathbf{W}$: linear transformation matrix  $\\mathbf{b}$: bias vectorHow to Modeling      attention score distribution must be defined over non-negative random variables          if Approx. is Weibull Dist., Prior must be Gamma Dist.                  Weibull: $S \\sim \\mathrm{Weibull}(k,\\lambda)$ ($k$ is hyper-parameter)          Gamma: $S \\sim \\mathrm{Gamma}(\\alpha,\\beta)$ ($\\beta$ is hyper-parameter)                    if Approx. is Lognormal Dist., Prior must be Lognormal Dist.                  Lognormal: $S \\sim \\mathrm{Lognormal}(\\mu,\\sigma^{2})$ ($\\sigma$ is hyper-parameter)                          function values of the attention scores are used to compute the parameters of the Approx. dist. $Q_{\\phi}(S)$\\[\\begin{aligned}  \\mathbb{E}\\left[S_{i,j}\\right]=\\exp{\\psi_{i,j}} \\quad \\mathrm{for} \\quad \\psi_{i,j}=f(q_{i},k_{j})  \\end{aligned}\\]          Weibull: $\\lambda=\\exp{\\psi} / \\Gamma(1+1/k)$      Lognormal: $\\mu=\\psi - \\sigma^{2}/2$            Prior $\\Pi_{\\eta}(S)$ is contextual dist. based on keys\\[\\begin{aligned}  \\mathbb{E}\\left[S_{j}\\right]=\\exp{\\psi_{j}} \\quad \\mathrm{for} \\quad \\psi_{j}=\\mathrm{softmax}\\left[\\mathbf{h}^{T}(\\mathbf{W}k_{j}+\\mathbf{b})\\right]  \\end{aligned}\\]          Gamma: $\\alpha=\\exp{\\psi}\\cdot\\beta$      Lognormal: $\\mu=\\psi - \\sigma^{2}/2$            attention weights are derived through L1-normalization, rather than softmax, in order to reflect uncertainty\\[\\begin{aligned}  \\omega_{i}  &amp;= \\frac{s_{i}}{\\sum_{l \\ne i}{s_{l}}}  \\end{aligned}\\]        bayesian framework\\[\\begin{aligned}  P_{\\theta}(S \\mid y,X)  = \\frac{\\mathcal{L}(y \\mid S, X)\\Pi(S)}{P(y \\mid X)}  \\end{aligned}\\]          posterior: $P_{\\Theta}(S \\mid y,X)$      likelihood: $\\mathcal{L}(y \\mid S, X)$      prior: $\\Pi_{\\eta}(S)$            variational inference\\[\\begin{aligned}  \\mathrm{ELBO}  = \\mathbb{E}_{S \\sim Q_{\\phi}}\\left[\\log{\\mathcal{L}(y \\mid X)}\\right]-\\mathrm{KL}\\left[Q_{\\phi}(S) \\parallel \\Pi_{\\eta}(S)\\right]  \\end{aligned}\\]          approx: $Q_{\\phi}(S) \\approx P_{\\theta}(S \\mid y,X)$      "
  },
  
  {
    "title": "CLiMF",
    "url": "/posts/climf/",
    "categories": "6.RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, implicit feedback, occf, byaesian, ranking prediction, objective function, listwise learning, mrr",
    "date": "2024-09-05 00:00:00 +0900",
    





    
    "snippet": "CLiMF      CLiMF(Collaborative Less-is-More Filtering) : Probabilistc Pointwise Ranking Prediction          선행 연구들은 명시적 피드백 하 선호 점수를 예측하는 것에 초점을 맞추었음. 이러한 연구 경향은 친구 추천, 팔로우 추천 등 이진 피드백이 활용되는 사례에 적합...",
    "content": "CLiMF      CLiMF(Collaborative Less-is-More Filtering) : Probabilistc Pointwise Ranking Prediction          선행 연구들은 명시적 피드백 하 선호 점수를 예측하는 것에 초점을 맞추었음. 이러한 연구 경향은 친구 추천, 팔로우 추천 등 이진 피드백이 활용되는 사례에 적합하지 않음. 순위 기반 최적화 및 Top-k 추천 품질에 관한 논의가 필요함. BPR 이 순위 기반 최적화를 시도하였으나, AUC 최적화는 Top-k 추천 품질 개선에 미흡함. 순위가 더 높이 제안될수록 더 큰 영향을 가지도록 유도하는 MRR 최적화가 필요함.      MRR Optimization      RR(Reciprocal Rank) : 사용자 $u$ 에 대하여 정답 아이템이 처음 등장하는 순번의 역수\\[\\begin{aligned}  \\text{RR}  &amp;= \\frac{1}{\\text{Rank of 1st Relevent Item}}  \\end{aligned}\\]        MRR(Mean Reciprocal Rank) : 모든 사용자에 대하여 정답 아이템이 처음 등장하는 평균적인 순번\\[\\begin{aligned}  \\text{MRR}  &amp;= \\frac{1}{\\vert U \\vert}\\sum_{u \\in U}{\\text{RR}_{u}}  \\end{aligned}\\]  How to Modeling      Smoothing Trick\\[\\begin{aligned}  \\sigma(x)  &amp;= \\frac{1}{1 + \\exp{-x}}  \\end{aligned}\\]        Rank : 사용자 벡터 \\(\\overrightarrow{\\mathbf{p}}_{u}\\) 와 아이템 벡터 \\(\\overrightarrow{\\mathbf{q}}_{i}\\) 의 내적값이 클수록 해당 아이템이 상위에 랭크될 가능성이 높다는 뜻으로 이해할 수 있음\\[\\begin{aligned}  \\frac{1}{\\text{Rank}(u,i)}  &amp;\\approx \\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right]  \\end{aligned}\\]                            Dot Product          Sigmoid Function                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to +\\infty\\)          \\(\\sigma \\to 1\\)                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to 0\\)          \\(\\sigma \\to 0.5\\)                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to -\\infty\\)          \\(\\sigma \\to 0\\)                          Indicator Function : 순위는 다른 아이템과의 상대적 위치이므로, 아이템 간 선호의 우열을 다루는 항목이 필요하며, 이때 사용자 $u$ 와 아이템 $i$ 의 내적값이 $j$ 보다 더 클 가능성이 높을수록 순위가 더 높다는 뜻으로 이해할 수 있음                  Original(Rank Comparison):\\[\\begin{aligned}  \\mathbb{I}(\\text{Rank}(u,i) &lt; \\text{Rank}(u,j))  = \\begin{cases}  1 \\quad &amp;\\text{If $i$ is Higher than $j$}\\\\  0 \\quad &amp;\\text{Otherwise}  \\end{cases}  \\end{aligned}\\]                    Convert(Dot Product Comparison):\\[\\begin{aligned}  \\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\right]  \\end{aligned}\\]                                            Dot Product              Sigmoid Function                                                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} &gt; \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 1\\)                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} = \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 0.5\\)                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} &lt; \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 0\\)                                                Objective Function\\[\\begin{aligned}  \\mathcal{J}  &amp;= \\sum_{u \\in U} \\sum_{i \\in I_{u}^{+}}{\\left(\\ln{\\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right]} + \\sum_{j \\in I \\setminus I_{u}^{+}}{\\ln{\\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\right]}}\\right)} - \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}  \\end{aligned}\\]  "
  },
  
  {
    "title": "BPR",
    "url": "/posts/bpr/",
    "categories": "6.RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, implicit feedback, occf, byaesian, ranking prediction, objective function, pairwise learning, auc",
    "date": "2024-08-28 00:00:00 +0900",
    





    
    "snippet": "BPR      BPR(Bayesian Personalized Ranking) : Probabilistc Pairwise Ranking Prediction          선행 연구들은 대체로 평점 예측에 집중하는 경향을 보였으며, 이는 명시적 피드백 환경에 적합함. 하지만 실제에서는 주로 암묵적 피드백이 사용되며, 때문에 개별 아이템의 평점을 정확히...",
    "content": "BPR      BPR(Bayesian Personalized Ranking) : Probabilistc Pairwise Ranking Prediction          선행 연구들은 대체로 평점 예측에 집중하는 경향을 보였으며, 이는 명시적 피드백 환경에 적합함. 하지만 실제에서는 주로 암묵적 피드백이 사용되며, 때문에 개별 아이템의 평점을 정확히 맞추는 것보다는 중요한 상호작용 정보과 중요하지 않은 상호작용 정보 간 차등을 두는 (아이템 간 선호 순위를 맞추는) 목적 함수가 요구됨.      AUC Optimization      ROC(Receiver Operating Characteristic) is the set of $(x, y)$ pairs for all threshold $t$ values:\\[\\begin{aligned}  \\text{ROC}  &amp;=\\left\\{(x,y) \\mid t \\in [0,1]\\right\\}  \\end{aligned}\\]                  $x$ is FPR(False Positive Rate):\\[\\begin{aligned}  x  &amp;=f(t)\\\\  &amp;=p\\left(\\hat{z} &gt; t\\mid z=\\text{NEG}\\right)  \\end{aligned}\\]                    $y$ is TPR(True Positive Rate):\\[\\begin{aligned}  y  &amp;=g(t)\\\\  &amp;=p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right)  \\end{aligned}\\]                  AUC(Area Under the Curve) is the area under the ROC curve:\\[\\begin{aligned}  \\text{AUC}  &amp;=\\int_{0}^{1}{g \\circ f^{-1}\\left(x\\right)\\text{d}x}  \\end{aligned}\\]        Convert to Probability                  $f(t), g(t)$ is related to CDF(Cumulative Distribution Function):\\[\\begin{aligned}  f(t)  &amp;= p\\left(\\hat{z} &gt; t\\mid z=\\text{NEG}\\right)\\\\  &amp;= 1 - \\underbrace{p\\left(\\hat{z} \\le t\\mid z=\\text{NEG}\\right)}_{\\text{CDF}}\\\\  \\\\  g(t)  &amp;= p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right)\\\\  &amp;= 1 - \\underbrace{p\\left(\\hat{z} \\le t\\mid z=\\text{POS}\\right)}_{\\text{CDF}}  \\end{aligned}\\]                    Change of Variables:\\[\\begin{aligned}  \\frac{\\text{d}x}{\\text{d}t}  &amp;= \\frac{\\text{d}f(t)}{\\text{d}t}\\\\  &amp;= -\\underbrace{p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)}_{\\text{PDF}}\\\\  \\\\  \\therefore \\text{d}x  &amp;= -p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t  \\end{aligned}\\]                    Therefore:\\[\\begin{aligned}  \\text{AUC}  &amp;=\\int_{x=0}^{x=1}{g \\circ f^{-1}\\left(x\\right)\\text{d}x}\\\\  &amp;= \\int_{t=1}^{t=0}{g(t) \\frac{\\text{d}f(t)}{\\text{d}t} \\text{d}t}\\\\  &amp;= -\\int_{t=0}^{t=1}{g(t) \\frac{\\text{d}f(t)}{\\text{d}t} \\text{d}t}\\\\  &amp;= \\int_{t=0}^{t=1}{p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right) p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t}\\\\  &amp;= \\int_{t=0}^{t=1}\\int_{\\tau&gt;t}{p\\left(\\hat{z} = \\tau\\mid z=\\text{POS}\\right) p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t}\\\\  &amp;= p(\\hat{z}_{\\text{POS}} &gt; \\hat{z}_{\\text{NEG}})  \\end{aligned}\\]            Data Set  학습 데이터 : 개별 사용자 $u$ 의 선호체계 $&gt;_{u}$                  비교 가능성(Totality)\\[\\forall i,j \\in I:\\quad i \\ne j \\quad \\Rightarrow \\quad \\left(i &gt;_{u} j\\right) \\vee \\left(j &gt;_{u} i\\right)\\]                    반대칭성(Anti-Symmetry)\\[\\forall i,j \\in I:\\quad \\left(i &gt;_{u} j\\right) \\wedge \\left(j &gt;_{u} i\\right) \\quad \\Rightarrow \\quad i = j\\]                    이행성(Transitivity)\\[\\forall i,j,k \\in I:\\quad \\left(i &gt;_{u} j\\right) \\wedge \\left(j &gt;_{u} k\\right) \\quad \\Rightarrow \\quad \\left(i &gt;_{u} k\\right)\\]                  Pair-wise Preference Data Set\\[\\Omega  = \\Big\\{(u,i,j) \\mid i \\in I_{u} \\wedge j \\in I \\setminus I_{u}\\Big\\}\\]          $I$ : 아이템 집합      $I_{u} \\subset I$ : 사용자 $u$ 가 상호작용한 아이템 집합      $i \\in I_{u}$ : 사용자 $u$ 가 상호작용한 아이템      $j \\in I \\setminus I_{u}$ : 사용자 $u$ 가 상호작용하지 아니한 아이템            Single Data Point Definition\\[x_{u,i,j}:=r_{u,i} - r_{u,j}\\]  How to ModelingPosterior Estimation\\[\\underbrace{\\ln{P(\\Theta \\mid \\mathcal{D})}}_{\\begin{array}{c} \\text{Objective Function} \\\\ \\text{(Log Posterior)} \\end{array}} \\propto \\underbrace{\\ln{P(\\mathcal{D} \\mid \\Theta)}}_{\\text{Log Likelihood}} + \\underbrace{\\ln{P(\\Theta)}}_{\\text{Log Prior}}\\]      Log Likelihood                  Likelihood of Single Data Point\\[\\begin{aligned}  P(i &gt;_{u} j \\mid \\Theta)  &amp;= \\sigma\\left(\\hat{x}_{u,i,j}\\right)  \\end{aligned}\\]                    Likelihood of Data Set\\[\\begin{aligned}  P(\\mathcal{D} \\mid \\Theta)  &amp;= \\prod_{(u,i,j)\\in\\Omega}{P(i &gt;_{u} j \\mid \\Theta)}\\\\  &amp;= \\prod_{(u,i,j)\\in\\Omega}{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}  \\end{aligned}\\]                    Log Likelihood\\[\\begin{aligned}  \\ln{P(\\mathcal{D} \\mid \\Theta)}  &amp;= \\ln{\\prod_{(u,i,j)\\in\\Omega}{P(i &gt;_{u} j \\mid \\Theta)}}\\\\  &amp;= \\sum_{(u,i,j)\\in\\Omega}{\\ln{P(i &gt;_{u} j \\mid \\Theta)}}\\\\  &amp;= \\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}}  \\end{aligned}\\]                  Prior Determination; $\\Theta \\sim \\mathcal{N}\\left(0, \\lambda_{\\Theta}^{-1}\\mathbf{I}\\right)$\\[\\begin{aligned}  P\\left(\\Theta\\right)  &amp;= \\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}} \\cdot \\exp \\left[-\\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\right]\\\\  \\\\  \\ln{P\\left(\\Theta\\right)}  &amp;= \\ln{\\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}} \\cdot \\exp \\left[-\\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\right]}\\\\  &amp;= \\ln{\\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}}} - \\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\\\  &amp;\\propto -\\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}  \\end{aligned}\\]        Posterior Estimation\\[\\begin{aligned}  P(\\Theta \\mid \\mathcal{D})  &amp;\\propto P(\\mathcal{D} \\mid \\Theta) \\cdot P(\\Theta)\\\\  \\\\  \\ln{P(\\Theta \\mid \\mathcal{D})}  &amp;\\propto \\ln{P(\\mathcal{D} \\mid \\Theta)} + \\ln{P(\\Theta)}\\\\  &amp;\\propto \\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} -\\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}  \\end{aligned}\\]  Optimization      Objective Function\\[\\text{BPR-OPT} = \\ln{P(\\Theta \\mid \\mathcal{D})}\\]        Optimization\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max_{\\Theta}{\\ln{P(\\Theta \\mid \\mathcal{D})}}\\\\  &amp;= \\text{arg} \\max_{\\Theta}{\\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} - \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}\\\\  &amp;= \\text{arg} \\min_{\\Theta}{\\sum_{(u,i,j)\\in\\Omega}{-\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} + \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}  \\end{aligned}\\]          $\\hat{\\Theta}$ is MAP(Maximum a Posteriori) Estimator      "
  },
  
  {
    "title": "GPT",
    "url": "/posts/gpt/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, generative model, gpt, attention mechanism",
    "date": "2024-08-23 00:00:00 +0900",
    





    
    "snippet": "GPT      지피티(Generative Pre-trained Transformer; GPT) : 트랜스포머의 디코더 아키텍처를 기반으로 하여 다양한 텍스트 데이터로 사전 훈련된 자기회귀모형(Auto-Regressive Model)                  자기회귀모형(Auto-Regressive Model; AR) : 이전 출력값들을 참고하여...",
    "content": "GPT      지피티(Generative Pre-trained Transformer; GPT) : 트랜스포머의 디코더 아키텍처를 기반으로 하여 다양한 텍스트 데이터로 사전 훈련된 자기회귀모형(Auto-Regressive Model)                  자기회귀모형(Auto-Regressive Model; AR) : 이전 출력값들을 참고하여 다음 출력값을 예측하는 모형\\[\\begin{aligned}  X_{t}  &amp;= \\beta + \\sum_{i=1}^{p}{\\alpha_{i} \\cdot X_{t-i}} + \\epsilon_{t}  \\end{aligned}\\]                  \\(X_{t}\\) : 현재 시점 출력값          \\(X_{t-i}\\) : 이전 시점 출력값          \\(\\alpha_{i}\\) : 각 시점에 대한 가중치          \\(\\beta\\) : 편향          \\(\\epsilon_{t}\\) : 노이즈                          vs. BERT                                           BERT          GPT                                      Type          Masked Language Model          Auto-Regressive Model                          Task          Natural Language Understanding          Natural Language Generation                          Object          Predict Masked Word          Predict Next Word                          Direction          Bidirectional          Unidirectional                          Transformer          Encoder          Decoder                          Version                                           GPT-1          GPT-2          GPT-3                                      Year          2018          2019          2020                          Embedding Dimension          768          1,024          12,288                          Decoder Layers          12          48          96                          Attention Heads          12          16          96                          Total Parameters          117M          1.5B~15B          175B                          Traning Data          BooksCorpus          OpenWebText          Common Crawl  WebText2  Wikipedia  BooksCorpus                    Word Representation      Unique(or Max) Number of Vector                            VECTOR          GPT-1          GPT-2          GPT-3                                      Unique Tokens          40,000          50,257          50,257                          Max Seq          512          1,024          2,048                      Tokenization Method : BPE(Byte-Pair Encoding)                  단어를 문자(Byte) 단위로 쪼갠 후 가장 많이 등장하는 문자 쌍(Pair)을 병합하는 과정을 반복하여 최종 내부 단어(Sub-Word) 단위 토큰을 생성함                    Split a Word into Bytes                                            Word              Bytes                                                          low              [l, o, w]                                      lower              [l, o, w, e, r]                                      newest              [n, e, w, e, s, t]                                      widest              [w, i, d, e, s, t]                                                  Merge Pairs                                            Pair              Count              Merge                                                          (l, o)              2              lo                                      (o, w)              2              ow                                      (e, s)              2              es                                      (s, t)              2              st                                      $\\vdots$              $\\vdots$              $\\vdots$                                                  Result                                            Word              Sub-Word Tokens                                                          low              [lo, w]                                      lower              [lo, w, er]                                      newest              [ne, w, est]                                      widest              [wi, d, est]                                                Embedding\\[\\begin{aligned}  \\mathbf{x}_{i}  &amp;= \\\\mathbf{x}^{(i)}_{\\text{TOKEN}} + \\mathbf{x}^{(i)}_{\\text{POS}}  \\end{aligned}\\]                  \\(\\mathbf{x}^{(i)}_{\\text{TOKEN}}\\) : Token Embedding                    \\(\\mathbf{x}^{(i)}_{\\text{POS}}\\) : Position Embedding, Not Fixed But Learnable            Single Layer\\[\\begin{aligned}\\mathcal{X}^{(0)}&amp;=\\text{Embeddings}\\left(\\text{Tokens}\\right)\\\\\\mathcal{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right) + \\mathcal{X}^{(k)}\\Big]\\\\\\mathcal{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathcal{H}^{(k)}\\right) + \\mathcal{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathcal{X}$ is Input Data of Single Layer, $\\mathcal{Y}$ is Output Data of Single Layer          \\(\\mathcal{X}^{(k+1)}=\\mathcal{Y}^{(k)}\\) : Input Data of $k+1$ Decoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathcal{X}^{(0)}\\) is Sum of Token Embedding &amp; Position Embedding Vector      Output Data of Final Layer \\(\\mathcal{Z}=\\mathcal{Y}^{(K)}\\) is Output of Decoder Module            \\(\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right)\\) : Multi-Head Masked Self Attention          $\\mathcal{M}$ : Causal Mask(Upper-triangular mask)            \\(\\text{FFN}\\left(\\mathcal{H}^{(k)}\\right)\\) : Feed-Forward Networks\\[\\begin{aligned}  \\text{FFN}\\left(\\mathcal{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathcal{H}^{(k)} + \\mathbf{b}^{(k)}_{1}\\right]\\right) + \\mathbf{b}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Sourse  https://wikidocs.net/184363"
  },
  
  {
    "title": "BERT",
    "url": "/posts/bert/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, language model, bert, attention mechanism",
    "date": "2024-08-22 00:00:00 +0900",
    





    
    "snippet": "BERT      버트(Bidirectional Encoder Representations from Transformers; BERT) : 트랜스포머의 인코더 아키텍처를 기반으로 하여 위키피디아(25억 단어), BooksCorpus(8억 단어) 등 레이블 없는 텍스트 데이터로 사전 훈련된 대형 언어 모형(Pre-trained Large Language...",
    "content": "BERT      버트(Bidirectional Encoder Representations from Transformers; BERT) : 트랜스포머의 인코더 아키텍처를 기반으로 하여 위키피디아(25억 단어), BooksCorpus(8억 단어) 등 레이블 없는 텍스트 데이터로 사전 훈련된 대형 언어 모형(Pre-trained Large Language Model)            Version Comparison                                       BASE          LARGE                                      Embedding Dimension          768          1024                          Encoder Layers          12          24                          Attention Heads          12          16                          Total Parameter          110M          340M                    Word Representation      Unique(or Max) Number of Vector                            VECTOR          NUM                                      Unique Tokens          30,522                          Max Seq          512                          Max Sentence          2                          Each observation can contain up to two sequences          CLS my dog is cute SEP he likes play ##ing SEP              CLS : 입력 정보를 종합하여 대표하는 벡터      SEP : 문장 구분자        Tokenization Method : Word-Piece Encoding          단어 사전에 존재하는 단어들로 쪼개고, 이때 내부 단어(Sub-Word)는 앞에 ## 을 표기하여 온전한 단어가 아님을 나타냄      Here is the sentence I want embeddings for.      [here, is, the, sentence, i, want, em, ##bed, ##ding, ##s, for, .]            Embedding    \\[\\begin{aligned}  \\mathbf{x}_{i}  &amp;= \\mathbf{x}^{(i)}_{\\text{TOKEN}} + \\mathbf{x}^{(i)}_{\\text{POS}} + \\mathbf{x}^{(i)}_{\\text{SEG}}  \\end{aligned}\\]                  \\(\\mathbf{x}^{(i)}_{\\text{TOKEN}}\\) : Token Embedding                    \\(\\\\mathbf{x}^{(i)}_{\\text{POS}}\\) : Position Embedding, Not Fixed But Learnable                    \\(\\mathbf{x}^{(i)}_{\\text{SEG}}\\) : Segment Embedding                                            Token              Segment Embedding                                                          CLS              First Sequence Vector                                      Tokens @ First Sequence              First Sequence Vector                                      SEP              First Sequence Vector                                      Tokens @ Second Sequence              Second Sequence Vector                                      SEP              Second Sequence Vector                                          Single Layer\\[\\begin{aligned}\\mathbf{X}^{(0)}&amp;=\\text{Embeddings}\\left(\\text{Tokens}\\right)\\\\\\mathbf{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right) + \\mathbf{X}^{(k)}\\Big]\\\\\\mathbf{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right) + \\mathbf{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathbf{X}$ is Input Data of Single Layer, $\\mathbf{Y}$ is Output Data of Single Layer          \\(\\mathbf{X}^{(k+1)}=\\mathbf{Y}^{(k)}\\) : Input Data of $k+1$ Encoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathbf{X}^{(0)}\\) is Sum of Token Embedding &amp; Position Embedding &amp; Segment Embedding Vector      Output Data of Final Layer \\(\\mathbf{Z}=\\mathbf{Y}^{(K)}\\) is Output of BERT Module            \\(\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right)\\) : Multi-Head Self Attention        \\(\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)\\) : Feed-Forward Networks\\[\\begin{aligned}  \\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathbf{H}^{(k)} + \\mathbf{b}^{(k)}_{1}\\right]\\right) + \\\\mathbf{b}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Pre-Training for Transfer Learning      MLM(Masked Language Model) : 입력 문장에서 일부는 MASK 로 가리고, 일부는 다른 단어로 무작위 변경한 후(10%), 원래 단어를 예측하도록 양방향 학습함으로써 일반화된 언어 패턴을 학습하고 문맥을 이해하는 능력을 강화함                      Bidirection : 트랜스포머 디코더가 단방향 예측($t-1$ 시점까지 정보를 기반으로 $t$ 시점을 예측)을 수행했던 것과 달리, 버트는 양방향 예측(이전 시점과 이후 시점의 정보를 종합하여 $t$ 시점을 예측)을 수행하므로, 문맥 벡터 생성 시 미래 순번 정보를 모두 마스킹 처리하지 않음                    How to Process Target                                            역할              처리 방법              비중                                                          CONTEXT              변경하지 않음              85%                                      PREDICTION              MASK              12%                                      PREDICTION              무작위 변경              1.5%                                      PREDICTION              변경하지 않음              1.5%                                                NSP(Next Sentence Prediction) : CLS 토큰을 기반으로 두 문장이 연속된 문장인지 아닌지 예측하도록 학습함으로써 문장 간 관계를 학습함      Sourse  https://pub.towardsai.net/demystifying-bert-efe9ac3c1c74  https://www.sbert.net/examples/unsupervised_learning/MLM/README.html  https://wikidocs.net/115055"
  },
  
  {
    "title": "Transformer",
    "url": "/posts/transformer/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, machine translation, transformer, attention mechanism",
    "date": "2024-08-21 00:00:00 +0900",
    





    
    "snippet": "Attention is all you need      트랜스포머(Transformer) : 시계열 데이터를 순차 입력 받는 RNN 계열 레이어를 배제하고 어텐션 메커니즘을 전적으로 활용하여 시계열 데이터의 병렬 처리를 도모하는 기계 번역 아키텍처        TOTAL ARCHITECTURE : SEQ2SEQ 의 ENCODER-DECODER 구조를 ...",
    "content": "Attention is all you need      트랜스포머(Transformer) : 시계열 데이터를 순차 입력 받는 RNN 계열 레이어를 배제하고 어텐션 메커니즘을 전적으로 활용하여 시계열 데이터의 병렬 처리를 도모하는 기계 번역 아키텍처        TOTAL ARCHITECTURE : SEQ2SEQ 의 ENCODER-DECODER 구조를 따름              ENCODER : Natural Language Understanding &amp; Feature Extraction      DECODER : Natural Language Generation            Transformer Application              BERT(Bidirectional Encoder Representations from Transformers) : LLM, Transformer Encoder Application      GPT(Generative Pre-Training) : GM, Transformer Decoder Application      Core Techs      Token Embedding : 입력 문장 내 단어들 각각의 정보를 표현하는 벡터를 생성함        Positional Encoding : 입력 문장 내 단어들의 위치 정보를 표현하는 벡터를 생성함        Multi-Head Self Attention @ Encoder : 인코더에서 입력 문장 내 단어들 간 관계를 학습하여 각 단어가 문장에서 어떤 역할을 하는지를 반영하는 문맥 벡터를 생성함        Multi-Head Masked Self Attention @ Decoder : 디코더에서 출력 문장 내 단어들 간 관계를 학습하여 각 단어의 문맥 벡터를 생성하되, 이전 순번까지의 단어만 참고하도록 마스킹하여 다음 순번에 관한 정보가 유출되는 것을 방지함        Multi-Head Cross Attention @ Decoder : 출력 문장의 각 단어가 인코더의 출력들과 맺는 관계를 학습하여 출력 문장 생성 시 개별 순번마다 입력 문장에서 어떤 부분이 중요한지 반영하는 문맥 벡터를 생성함  Positional EncodingCondition  주기성(Periodicity) : 벡터는 단어 간 상대적 위치를 표현할 수 있어야 함          단어의 절대적 위치가 아니라 단어 간 상대적 위치에 따른 관계 패턴이 문장의 의미를 결정함      어텐션 메커니즘은 각 단어가 서로를 참조하는 방식으로 정보를 처리함      주기성을 띠는 함수가 관계 패턴을 결정짓는 상대적 위치를 표현하기에 효율적임        연속성(Continuity) : 벡터는 연속적인 값을 가져야 함          임의의 두 단어 순번 간 거리가 일정하다면, 벡터 간 거리도 일정해야 함      임의의 두 단어 순번 간 위치가 비슷하다면, 벡터 값도 유사해야 함      불연속적인 값이 존재하면 모형이 상대적 위치에 따른 관계 패턴을 학습하기 어려움        일반화(Generalization) : 벡터는 특정 모형 구조나 훈련 데이터에 종속되지 않고, 모든 상황에서 일정한 방식으로 사용할 수 있어야 함          벡터는 모형 설계 방식과 상관없이 일정한 방식으로 위치 정보를 제공해야 함      벡터는 시퀀스 길이에 상관없이 일정한 정보 해상도를 가져야 함        단어 임베딩과의 균형(Balance with Word Embedding) : 벡터의 원소값은 단어의 의미 정보와 위치 정보가 균형을 이룰 수 있는 범위 내에 존재해야 함          원소값이 너무 크면 단어의 의미가 왜곡될 수 있음      원소값이 너무 작으면 위치 정보가 무시될 수 있음      Positional Encoding\\[\\begin{aligned}\\mathbf{e}_{\\text{POS}}&amp;=\\begin{pmatrix}\\sin{\\frac{POS}{10000^{0}}} \\\\\\cos{\\frac{POS}{10000^{0}}} \\\\\\sin{\\frac{POS}{10000^{2/8}}} \\\\\\cos{\\frac{POS}{10000^{2/8}}} \\\\\\sin{\\frac{POS}{10000^{4/8}}} \\\\\\cos{\\frac{POS}{10000^{4/8}}} \\\\\\sin{\\frac{POS}{10000^{6/8}}} \\\\\\cos{\\frac{POS}{10000^{6/8}}}\\end{pmatrix},\\quad \\text{where} \\quad d=8\\end{aligned}\\]      FUNCTION    \\[\\begin{aligned}  PE(POS,2i)&amp;=\\sin{\\frac{POS}{10000^{2i/d}}}\\\\  PE(POS,2i+1)&amp;=\\cos{\\frac{POS}{10000^{2i/d}}}  \\end{aligned}\\]          $POS$ : 문장 내 단어 순번      $d$ : 단어 임베딩 벡터 차원      $i=0,1,\\cdots,\\displaystyle\\frac{d}{2}-1$ : 포지셔널 인코딩 벡터의 차원 인덱스            PERIODICITY    \\[\\begin{aligned}  \\begin{pmatrix}\\sin{\\frac{POS+K}{10000^{2i/d}}} \\\\ \\cos{\\frac{POS+K}{10000^{2i/d}}}\\end{pmatrix}  = \\begin{pmatrix}\\cos{\\frac{K}{10000^{2i/d}}} &amp; \\sin{\\frac{K}{10000^{2i/d}}} \\\\ -\\sin{\\frac{K}{10000^{2i/d}}} &amp; \\cos{\\frac{K}{10000^{2i/d}}}\\end{pmatrix}  \\cdot \\begin{pmatrix}\\sin{\\frac{POS}{10000^{2i/d}}} \\\\ \\cos{\\frac{POS}{10000^{2i/d}}}\\end{pmatrix}  \\end{aligned}\\]          \\(\\displaystyle\\begin{pmatrix}\\cos{\\frac{K}{10000^{2i/d}}} &amp; \\sin{\\frac{K}{10000^{2i/d}}} \\\\ -\\sin{\\frac{K}{10000^{2i/d}}} &amp; \\cos{\\frac{K}{10000^{2i/d}}}\\end{pmatrix}\\) : $2 \\times 2$ Rotation Matrix      즉, 임베딩 차원 $d=2$ 일 때, 위치가 $K$ 만큼 이동하게 되면 벡터 공간 상에서 특정한 크기 \\(\\displaystyle\\frac{K}{10000^{2i/d}}\\) 만큼의 회전 변환이 이루어짐      요컨대 포지셔널 인코딩 벡터는 위치 간 관계(혹은 위치의 변화)를 부드러운(연속적인) 회전 변환 형태로 표현함      Single LayersEncoder Layer\\[\\begin{aligned}\\mathbf{X}^{(0)}&amp;=\\text{Token-Embedding}\\left(\\text{Tokens}\\right) + \\text{Positional-Encoding}\\left(\\text{Tokens}\\right)\\\\\\mathbf{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right) + \\mathbf{X}^{(k)}\\Big]\\\\\\mathbf{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right) + \\mathbf{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathbf{X}$ is Input Data of Single Layer, $\\mathbf{Y}$ is Output Data of Single Layer          \\(\\mathbf{X}^{(k+1)}=\\mathbf{Y}^{(k)}\\) : Input Data of $k+1$ Encoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathbf{X}^{(0)}\\) is Sum of Token Embedding &amp; Positional Encoding Vector      Output Data of Final Layer \\(\\mathbf{Z}=\\mathbf{Y}^{(K)}\\) is Output of Encoder Module            \\(\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right)\\) : Multi-Head Self Attention @ Encoder        \\(\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)\\) : Feed-Forward Networks @ Encoder\\[\\begin{aligned}  \\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathbf{H}^{(k)} + \\mathbf{b}^{(k)}_{1}\\right]\\right) + \\mathbf{b}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Decoder Layer\\[\\begin{aligned}\\mathcal{X}^{(0)}&amp;=\\text{Token-Embedding}\\left(\\text{Tokens}\\right) + \\text{Positional-Encoding}\\left(\\text{Tokens}\\right)\\\\\\mathcal{H}^{(k)}_{1}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right) + \\mathcal{X}^{(k)}\\Big]\\\\\\mathcal{H}^{(k)}_{2}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{H}^{(k)}_{1},\\mathbf{Z},\\mathbf{Z}\\right) + \\mathcal{H}^{(k)}_{1}\\Big]\\\\\\mathcal{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right) + \\mathcal{H}^{(k)}_{2}\\Big]\\end{aligned}\\]  $\\mathcal{X}$ is Input Data of Single Layer, $\\mathcal{Y}$ is Output Data of Single Layer          \\(\\mathcal{X}^{(k+1)}=\\mathcal{Y}^{(k)}\\) : Input Data of $k+1$ Decoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathcal{X}^{(0)}\\) is Sum of Token Embedding &amp; Positional Encoding Vector      Output Data of Final Layer \\(\\mathcal{Z}=\\mathcal{Y}^{(K)}\\) is Output of Decoder Module            \\(\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right)\\) : Multi-Head Masked Self Attention @ Decoder          $\\mathcal{M}$ : Causal Mask(Upper-triangular mask)            \\(\\text{Multi-Head}\\left(\\mathcal{H}^{(k)}_{1},\\mathbf{Z},\\mathbf{Z}\\right)\\) : Multi-Head Cross Attention @ Decoder          \\(\\mathbf{Z}\\) : Output of Encoder Module            \\(\\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right)\\) : Feed-Forward Networks @ Decoder\\[\\begin{aligned}  \\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathcal{H}^{(k)}_{2} + \\mathbf{b}^{(k)}_{1}\\right]\\right) + \\mathbf{b}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Sourse  https://zeuskwon-ds.tistory.com/88  https://bongholee.com/transformer-yoyag-jeongri-2/  https://wikidocs.net/162096"
  },
  
  {
    "title": "Attention Mechanism",
    "url": "/posts/attn/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, machine translation, rnn, attention mechanism",
    "date": "2024-08-20 00:00:00 +0900",
    





    
    "snippet": "Attention Mechanism  어텐션 메커니즘(Attention Mechanism) : 요청 정보와 참조 정보가 주어진 상황에서, 특정 요청 정보가 입력되었을 때 해당 요청 정보와 각 참조 정보 간 매칭 점수를 토대로 참조 정보를 가중합한 문맥 정보를 생성하는 메커니즘          교차 어텐션(Cross Attention) : 입력값과 반환...",
    "content": "Attention Mechanism  어텐션 메커니즘(Attention Mechanism) : 요청 정보와 참조 정보가 주어진 상황에서, 특정 요청 정보가 입력되었을 때 해당 요청 정보와 각 참조 정보 간 매칭 점수를 토대로 참조 정보를 가중합한 문맥 정보를 생성하는 메커니즘          교차 어텐션(Cross Attention) : 입력값과 반환할 값이 다른 경우      셀프 어텐션(Self Attention) : 입력값과 반환할 값이 같은 경우            Framework    \\[\\begin{aligned}  \\text{ATTN}\\left(\\mathcal{Q},\\mathcal{K},\\mathcal{V}\\right)  = \\text{Softmax}\\left[f(\\mathcal{Q},\\mathcal{K})\\right] \\cdot \\mathcal{V}  = \\mathcal{C}  \\end{aligned}\\]          INPUT                  \\(\\mathcal{Q} \\in \\mathbb{R}^{M \\times D}\\) : 요청 정보로서 질의(Query)          \\(\\mathcal{K} \\in \\mathbb{R}^{N \\times D}\\) : 요청 정보와의 매칭 점수 계산에 동원되는 참조 정보의 인덱스로서 키(Key)          \\(\\mathcal{V} \\in \\mathbb{R}^{N \\times D_{V}}\\) : 참조 정보의 인덱스가 가리키는 실제 정보로서 값(Value)                    OUTPUT                  \\(\\mathcal{A}=f(\\mathcal{Q},\\mathcal{K}) \\in \\mathbb{R}^{M \\times N}\\) : 질의와 키 간 유사도 행렬                          \\(\\alpha_{m,n} \\in \\mathcal{A}\\) : 어텐션 점수(Attention Score)                                \\(\\mathcal{W}=\\text{Softmax}\\left[\\mathcal{A}\\right] \\in \\mathbb{R}^{M \\times N}\\) : 유사도 정규화 행렬로서 어텐션 맵(Attention Map)                          \\(\\omega \\in \\mathcal{W}\\) : 어텐션 분포(Attention Distribution)              \\(\\omega_{m,n} \\in \\omega \\in \\mathcal{W}\\) : 어텐션 가중치(Attention Weight)                                \\(\\mathcal{C}=\\mathcal{W} \\cdot \\mathcal{V} \\in \\mathbb{R}^{M \\times D_{V}}\\) : 문맥 행렬(Context Matrix)                          \\(\\sigma \\in \\mathcal{C}\\) : 문맥 벡터(Context Vector)                                                Attention Score Function                            Name          Function          Defined by                                      Dot Product          \\(f(\\mathbf{q}, \\mathbf{K}) = \\mathbf{q} \\cdot \\mathbf{K}\\)          Luong et al. (2015)                          Learnable Weighted Attention          \\(f(\\mathbf{q}, \\mathbf{K}) = \\mathbf{q}^{T} \\cdot \\mathbf{W} \\cdot \\mathbf{K}\\)          Luong et al. (2015)                          Additive Attention          \\(f(\\mathbf{q}, \\mathbf{K}) = \\mathbf{W}^{T}_{A} \\cdot \\text{tanh}\\left[\\mathbf{W}_{B} \\cdot (\\mathbf{q} \\oplus \\mathbf{K})\\right]\\)          Bahdanau et al. (2015)                          Concatenation          \\(f(\\mathbf{q}, \\mathbf{K}) = \\mathbf{W}^{T}_{A} \\cdot \\text{tanh}\\left[\\mathbf{W}_{B} \\cdot \\mathbf{q} + \\mathbf{W}_{C} \\cdot \\mathbf{K}\\right]\\)          Bahdanau et al. (2015)                          Scaled Dot Product          \\(f(\\mathbf{q}, \\mathbf{K}) = \\displaystyle\\frac{\\mathbf{q}^{T} \\cdot \\mathbf{K}}{\\sqrt{n}}\\)          Vaswani et al. (2017)                    Adaptive Weight      적응형 가중치 할당(Adaptive Weight Allocation) : 표현력을 강화하기 위하여 학습 가능한 가중치 행렬 $\\mathbf{W}$ 을 활용하여 $\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$ 를 선형 변환하고, 이를 기반으로 유사도를 계산하여 입력 간 상호작용 정보를 동적으로 학습하는 기법                            WHAT          INPUT DATA          LEARNABLE WEIGHT          TOTAL                                      \\(\\mathcal{Q}\\)          \\(\\mathbf{Q} \\in \\mathbb{R}^{M \\times D_{Q}}\\)          \\(\\mathbf{W}_{Q} \\in \\mathbb{R}^{D_{Q} \\times D}\\)          \\(\\mathbf{Q} \\cdot \\mathbf{W}_{Q} \\in \\mathbb{R}^{M \\times D}\\)                          \\(\\mathcal{K}\\)          \\(\\mathbf{K} \\in \\mathbb{R}^{N \\times D_{K}}\\)          \\(\\mathbf{W}_{K} \\in \\mathbb{R}^{D_{K} \\times D}\\)          \\(\\mathbf{K} \\cdot \\mathbf{W}_{K} \\in \\mathbb{R}^{N \\times D}\\)                          \\(\\mathcal{V}\\)          \\(\\mathbf{V} \\in \\mathbb{R}^{N \\times D_{V}}\\)          \\(\\mathbf{W}_{V} \\in \\mathbb{R}^{D_{V} \\times D}\\)          \\(\\mathbf{V} \\cdot \\mathbf{W}_{V} \\in \\mathbb{R}^{N \\times D}\\)                          WHY? NECESSITY          $\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$ 간 차원 보정이 필요한 경우                  $\\mathcal{Q}$ 와 $\\mathcal{K}$ 가 서로 다른 특징 차원을 가지고 있는 경우($D_{Q} \\ne D_{K} \\ne D_{V}$)          $\\mathcal{Q}$ 와 $\\mathcal{K}$ 가 서로 같은 특징 차원을 공유하고 있으나 상황에 따라 유사도가 중요도에 작용하는 방향(선호/비선호)이 다를 경우                    상호작용 정보를 포착함에 있어서 유사도 이상의 복잡한 관계를 조명하고자 하는 경우                  셀프 어텐션에서, 입력값과 반환할 값은 동일하나 역할($\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$)에 따라 서로 다른 정보 처리를 수행해야 하는 경우          멀티 헤드 어텐션에서, 헤드마다 상호작용 정보를 다각도로 포착하고자 하는 경우                    Variations      멀티 헤드 어텐션(Multi-Head Attention) : 입력 데이터를 여러 독립적인 적응형 가중 어텐션 메커니즘(헤드)으로 병렬 처리하여, 데이터 간 관계와 패턴을 다각도로 학습하는 기법                      하나의 헤드는 독립적인 적응형 가중 어텐션으로 이루어짐\\[\\begin{aligned}  \\text{HEAD}^{(h)}  &amp;= \\text{ATTN}^{(h)}\\left(\\mathbf{Q} \\cdot \\mathbf{W}_{\\mathcal{Q}}^{(h)}, \\mathbf{K} \\cdot \\mathbf{W}_{\\mathcal{K}}^{(h)}, \\mathbf{V} \\cdot \\mathbf{W}_{\\mathcal{V}}^{(h)}\\right)  \\end{aligned}\\]                    멀티 헤드 어텐션의 결과값은 헤드별 결과값의 벡터 결합을 선형 변환한 값임\\[\\begin{aligned}  \\text{Multi-Head}\\left(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}\\right)  &amp;= \\left[\\cdots \\oplus \\text{HEAD}^{(h)} \\oplus \\cdots \\right] \\cdot \\mathbf{W}_{\\mathcal{O}}  \\end{aligned}\\]                  셀프 어텐션(Self-Attention) : 입력값과 반환할 값이 같은 경우로서, 통상 역할($\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$)에 따라 서로 다른 정보 처리를 수행하도록 적응형 가중 어텐션과 결합되어 활용됨    \\[\\begin{aligned}  \\mathcal{Q}=\\mathbf{X} \\cdot \\mathbf{W}^{(Q)}, \\quad \\mathcal{K}=\\mathbf{X} \\cdot \\mathbf{W}^{(K)}, \\quad \\mathcal{Q}=\\mathbf{V} \\cdot \\mathbf{W}^{(V)}  \\end{aligned}\\]        마스크 행렬(Mask Matrix) : 특정 위치에 대한 가중치를 차단하거나 조정함으로써 예측해야 하는 정보가 유출되거나 불필요한 정보가 참조되는 것을 방지함    \\[\\begin{aligned}  f\\left(\\mathcal{Q}_{M \\times D}, \\mathcal{K}_{N \\times D}\\right) + \\mathbf{M}_{M \\times N}  \\end{aligned}\\]          셀프 어텐션은 입력 데이터의 모든 위치가 서로 영향을 주고받는 구조이나, 시퀀스 생성 모형은 현재 순번 데이터로만 다음 순번을 예측해야 하므로, 미래 위치에 대한 주의 점수를 $-\\infty$ 로 처리하여 모형이 해당 정보를 참조하지 못하도록 강제함      Application to SEQ2SEQ      SEQ2SEQ 적용 목적 : RNN 계열 레이어의 초기 순번 정보 유실 문제 및 기울기 소실 문제를 보완하기 위함으로서, 문맥 벡터를 최종 은닉 상태로 획일화하여 사용하지 않고, 인코더 각 순번 은닉 상태와 디코더 현재 시점 간 관련성을 고려하여, 디코더의 각 시점에 특화된 문맥 벡터를 생성함        루옹 어텐션(Luong Attention) : 디코더의 현재 시점 은닉 상태를 활용하여 문맥 벡터를 생성하고, 이를 현재 시점 은닉 상태에 적용하는 어텐션 기법                      Attention Mechanism\\[\\sigma^{(t)}  = \\text{ATTN}\\left(\\eta_{t}, \\mathbf{H}, \\mathbf{H}\\right)\\]                  \\(\\mathcal{Q} = \\eta_{t}\\) : 디코더의 $t$ 시점 은닉 상태          \\(\\mathcal{K} = \\mathcal{V} = \\mathbf{H}\\) : 인코더의 각 순번 은닉 상태 행렬          \\(\\sigma^{(t)}\\) : 디코더의 $t$ 시점 문맥 벡터(Context Vector)                            Combining information on the context vector at $t$ and the hidden state at $t$\\[\\mathbf{z}_{t}  = \\text{F}_{\\text{tanh}}\\left[\\sigma^{(t)} \\oplus \\eta_{t}\\right]\\]                  바다나우 어텐션(Bahdanau Attention) : 디코더의 이전 시점 은닉 상태를 활용하여 문맥 벡터를 생성하고, 이를 현재 시점 입력값에 적용하는 어텐션 기법                      Attention Mechanism\\[\\sigma^{(t)}  = \\text{ATTN}\\left(\\eta_{t-1}, \\mathbf{H}, \\mathbf{H}\\right)\\]                  \\(\\mathcal{Q} = \\eta_{t-1}\\) : 디코더의 $t-1$ 시점 은닉 상태          \\(\\mathcal{K} = \\mathcal{V} = \\mathbf{H}\\) : 인코더의 각 순번 은닉 상태 행렬          \\(\\sigma^{(t)}\\) : 디코더의 $t$ 시점 문맥 벡터(Context Vector)                            Combining information on the context vector at $t$ and the input vector at $t$\\[\\mathbf{z}_{t}  = \\sigma^{(t)} \\oplus \\hat{\\mathbf{y}}_{t-1}\\]            Sourse  https://www.linkedin.com/pulse/what-self-attention-impact-large-language-models-llm-nikhil-goel-srpbc  https://newsletter.theaiedge.io/p/the-multi-head-attention-mechanism  https://krypticmouse.hashnode.dev/attention-is-all-you-need  https://wikidocs.net/22893  https://wikidocs.net/73161"
  },
  
  {
    "title": "SEQ2SEQ",
    "url": "/posts/seq2seq/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, machine translation, rnn",
    "date": "2024-08-19 00:00:00 +0900",
    





    
    "snippet": "Machine Translation      기계 번역(Machine Translation) : 특정 언어로 표현된 텍스트를 다른 언어로 된 텍스트로 변환하는 과정              NLU(Natural Language Understanding) : 특정 언어로 된 텍스트를 이해하는 과정으로서, 해당 텍스트를 벡터 공간에 사상(Projection...",
    "content": "Machine Translation      기계 번역(Machine Translation) : 특정 언어로 표현된 텍스트를 다른 언어로 된 텍스트로 변환하는 과정              NLU(Natural Language Understanding) : 특정 언어로 된 텍스트를 이해하는 과정으로서, 해당 텍스트를 벡터 공간에 사상(Projection)하는 절차(Many to One)      NLG(Natural Language Generation) : 다른 언어로 된 텍스트를 생성하는 과정으로서, 사상된 벡터를 목표 언어로 변환하는 절차(Many to Many)            Brief History          RBMT(Rule-based Machine Translation) : 규칙 기반 기계 번역      SMT(Statistical Machine Translation) : 통계적 기계 번역      NMT(Neural Networks based Machine Translation) : 신경망 기반 기계 번역                  Word Embedding          End-to-End Model                    SEQ2SEQ      시퀀스 투 시퀀스(SEQ2SEQ) : RNN 계열 레이어 기반 기계 번역 알고리즘\\[\\begin{aligned}  P(y_{1}, y_{2}, \\cdots, y_{T^{\\prime}} \\mid x_{1}, x_{2}, \\cdots, x_{T})  = \\prod_{t=1}^{T^{\\prime}}{P(y_{t} \\mid z, y_{1}, y_{2}, \\cdots, y_{t-1})}  \\end{aligned}\\]        Architecture                      인코더(Encoder) : 입력 문장의 모든 단어들을 순차로 입력 받아 하나의 문맥 벡터(Context Vector)로 변환하는 모듈(NLU Process)\\[\\begin{aligned}  h_{t}, c_{t}  &amp;= \\text{LSTM}\\left[\\mathbf{x}_{t}, h_{t-1}, c_{t-1}\\right]  \\end{aligned}\\]                  \\(h_{t}\\) : $t$ 시점 은닉 상태          \\(c_{t}\\) : $t$ 시점 셀 상태          \\(\\mathbf{x}_{t}\\) : $t$ 번째 단어 임베딩 벡터          \\(\\mathbf{z}=h_{T}\\) : 마지막 시점 은닉 상태로서 문맥 벡터(Context Vector)                            디코더(Decoder) : 문맥 벡터를 참조하여 목표 언어의 단어들을 순차로 출력하는 모듈(NLG Process)\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\hat{\\mathbf{v}}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]                  \\(\\eta_{t}\\) : $t$ 시점 은닉 상태                          \\(\\eta_{0}=\\mathbf{z}\\) : 초기 은닉 상태는 문맥 벡터를 할당함                                \\(\\sigma_{t}\\) : $t$ 시점 셀 상태          \\(\\hat{\\mathbf{y}}_{t}=\\text{arg} \\max{\\text{F}_{\\text{Softmax}}\\left[\\eta_{t}\\right]}\\) : 목표 언어의 $t$ 시점에서 발생 확률이 가장 높은 단어의 임베딩 벡터                          \\(\\hat{\\mathbf{y}}_{0}\\) : 초기 입력값은 &lt;SOS&gt; 토큰을 활용함              \\(\\hat{\\mathbf{y}}_{T}\\) : 마지막 출력값은 &lt;EOS&gt; 토큰을 활용함                                                교사 강요(Teacher Forcing) : 디코더 학습 과정에서, 다음 시점의 입력으로서 이전 시점에서 생성한 출력값 대신 정답 시퀀스를 사용하는 기법                      Training Phase : 정답 시퀀스 \\(\\mathbf{y}_{t-1}\\) 를 입력값으로 사용함\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\mathbf{y}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]                    Inference Phase : 이전 시점에서 생성한 출력값 \\(\\hat{\\mathbf{y}}_{t-1}\\) 를 입력값으로 사용함\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\hat{\\mathbf{y}}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]            Metric      BLEU Score(Bi-Lingual Evaluation Understudy Score) : 기계 번역 및 자연어 생성에서 기계 번역 결과와 기준 텍스트 간의 유사성을 정량화하는 성능 평가 지표\\[\\begin{aligned}  \\text{BLEU}  &amp;= \\text{BP} \\cdot \\exp{\\left[\\sum_{n=1}^{N}{w_{n}\\cdot\\log{P_{n}}}\\right]}  \\end{aligned}\\]        $\\text{BP}$ : 길이 패널티(Brevity Penalty)로서, 생성된 문장(Hypothesis)이 참조 문장(Reference)보다 지나치게 짧을 경우 패널티를 부여함\\[\\begin{aligned}  \\text{BP}  = \\begin{cases}  1 \\quad &amp; h &gt; r\\\\  \\exp{\\left[1-\\displaystyle\\frac{r}{h}\\right]} \\quad &amp; h \\le r  \\end{cases}  \\end{aligned}\\]          $h$ : 생성된 문장(Hypothesis)의 길이      $r$ : 참조 문장(Reference)의 길이            $P_{n}$ : $n-\\text{gram}$ 정밀도로서, 생성된 문장(Hypothesis)과 참조 문장(Reference) 간 $n-\\text{gram}$ 중복 비율\\[\\begin{aligned}  P_{n}  &amp;= \\frac{\\sum_{n-\\text{gram} \\in \\text{Hypothesis}}{\\min{\\Big[\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram}), \\text{Count}_{\\text{Reference}}(n-\\text{gram})\\Big]}}}{\\sum_{n-\\text{gram} \\in \\text{Hypothesis}}{\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram})}}  \\end{aligned}\\]          Why not intersection?  생성된 문장을 기준으로(분모로) 하는 정밀도 특성 상, 참조 문장과의 교집합에 해당하는 특정 유니그램이 반복 생성되었을 때 성능이 과대평가되는 것을 방지하기 위하여 참조 문장에서 등장하는 최대 횟수까지만 매칭을 인정함              \\(\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram})\\) : 생성된 문장(Hypothesis)의 유니그램 중 특정 $n-\\text{gram}$ 등장 횟수      \\(\\text{Count}_{\\text{Reference}}(n-\\text{gram})\\) : 참조 문장(Reference)의 유니그램 중 특정 $n-\\text{gram}$ 등장 횟수            \\(\\sum_{n=1}^{N}{w_{n}\\cdot\\log{P_{n}}}\\) : $n-\\text{gram}$ 정밀도 가중 평균          통상 가중치 $w_{n}$ 은 균등하게 분배함      Sourse  https://yjjo.tistory.com/35"
  },
  
  {
    "title": "Topic Model",
    "url": "/posts/topic_model/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, topic model, matrix decomposition, latent factor, dirichlet distribution",
    "date": "2024-08-18 00:00:00 +0900",
    





    
    "snippet": "Topic Model  토픽 모형(Topic Model) : 관측 가능한 단어(Word) 및 문서(Document)로부터 말뭉치(Corpus)에 내재되어 있는(Latent) 토픽(Topic)을 탐색하는 방법          문서(Document)는 토픽(Topic)으로 어떻게 표현할 수 있을까?      단어(Word)는 토픽(Topic) 별로 어떻게...",
    "content": "Topic Model  토픽 모형(Topic Model) : 관측 가능한 단어(Word) 및 문서(Document)로부터 말뭉치(Corpus)에 내재되어 있는(Latent) 토픽(Topic)을 탐색하는 방법          문서(Document)는 토픽(Topic)으로 어떻게 표현할 수 있을까?      단어(Word)는 토픽(Topic) 별로 어떻게 등장하는가?      탐색된 Something(Topic)의 정체를 무엇이라 정의하면 좋을까?      LSA      잠재 의미 분석(Latent Semantic Analysis; LSA) : 특이값 분해(Singular Value Decomposition; SVD)를 활용하여 Document-Term Matrix 를 분해하는 방법\\[\\mathbf{A} \\approx \\mathbf{U} \\cdot \\Sigma \\cdot \\mathbf{V}^{T}\\]                            Dimension          Interpretation                                                 $n$          Number of Document                                     $d$          Number of Term                                     $k$          Number of Topic          Hyper-Parameter                            $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ : Document-Term Matrix      \\(\\mathbf{U} \\cdot \\Sigma\\) : Document-Topic Matrix                  $\\mathbf{U} \\in \\mathbb{R}^{n \\times k}$          $\\Sigma \\in \\mathbb{R}^{k \\times k}$                    $\\Sigma \\cdot \\mathbb{V}^{T}$ : Term-Topic Matrix                  $\\mathbf{V} \\in \\mathbb{R}^{d \\times k}$          $\\Sigma \\in \\mathbb{R}^{k \\times k}$                    SVD      특이값 분해(Singular Value Decomposition; SVD) : 차원의 크기가 $n \\times d$ 인 임의의 행렬 $\\mathbb{A}$ 를 세 개의 행렬의 곱으로 분해하는 방법        \\(\\mathbf{U} \\in \\mathbb{R}^{n \\times k}\\) : 직교 정규 행렬(Ortho-normal Matrix)                  열벡터 $\\mathbf{u}_{i} \\in \\mathbf{U}$ 는 행렬 $\\mathbf{A} \\cdot \\mathbf{A}^{T}$ 의 고유벡터(Eigen Vector)임\\[\\mathbf{A}\\mathbf{A}^{T} \\cdot \\mathbf{u}_{i} = \\lambda_i \\mathbf{u}_{i}\\]                    열벡터 $\\mathbf{u}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\mathbf{u}_{i} \\Vert = 1\\]                    열벡터 \\(\\mathbf{u}_{i}, \\mathbf{u}_{j}\\) 은 직교함\\[\\mathbf{u}_{i} \\perp \\mathbf{u}_{j} \\Leftrightarrow \\langle \\mathbf{u}_{i}, \\mathbf{u}_{j} \\rangle = 0\\]              $\\mathbf{V} \\in \\mathbb{R}^{d \\times k}$ : 직교 정규 행렬(Ortho-normal Matrix)                  열벡터 $\\mathbf{v}_{i} \\in \\mathbf{V}$ 는 행렬 $\\mathbf{A}^{T} \\cdot \\mathbf{A}$ 의 고유벡터(Eigen Vector)임\\[\\mathbf{A}^{T}\\mathbf{A} \\cdot \\mathbf{v}_{i} = \\lambda_{i} \\mathbf{v}_{i}\\]                    열벡터 $\\mathbf{v}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\mathbf{v}_{i} \\Vert = 1\\]                    열벡터 \\(\\mathbf{v}_{i}, \\mathbf{v}_{j}\\) 은 직교함\\[\\mathbf{v}_{i} \\perp \\mathbf{v}_{j} \\Leftrightarrow \\langle \\mathbf{v}_{i}, \\mathbf{v}_{j} \\rangle = 0\\]                  $\\Sigma \\in \\mathbb{R}^{k \\times k}$ : 대각 행렬(Diagonal Matrix)\\[\\Sigma  = \\begin{pmatrix}  \\sigma_{1} &amp; 0 &amp; \\cdots &amp; 0 \\\\  0 &amp; \\sigma_{2} &amp; \\cdots &amp; 0 \\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\  0 &amp; 0 &amp; \\cdots &amp; \\sigma_{k}  \\end{pmatrix}\\]                  대각항의 원소 $\\sigma_{i}$ 는 행렬 $\\mathbf{A} \\cdot \\mathbf{A}^{T}$ 혹은 $\\mathbf{A}^{T} \\cdot \\mathbf{A}$ 의 고유값(Eigen Value) $\\lambda_{i}$ 의 자승근임\\[\\sigma_{i} = \\sqrt{\\lambda_i}\\]            LDA      잠재 디리클레 할당(Latent Dirichlet Allocation; LDA) : 베이지안 프레임워크를 활용하여 문서에 내재된 잠재적인 토픽 구조를 탐색하는 방법\\[\\begin{aligned}  &amp;\\hat{\\theta}, \\hat{\\psi}\\\\  &amp;=\\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d \\mid z(d,n)) \\times P(\\psi_{z(d,n)} \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{\\underbrace{P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)}_{\\begin{array}{c} \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\begin{array}{c} \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}}}}  \\end{aligned}\\]          $P(\\theta_d \\mid z(d,n)) \\propto P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)$ : Posterior Probability of Document-Topic Allocation      $P(\\psi_{z(d,n)} \\mid w(d,n)) \\propto P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})$ : Posterior Probability of Topic-Word Allocation      Posterior Probability  각 문서는 여러 토픽의 혼합으로 구성되어 있고, 각 토픽은 특정 단어들의 혼합으로 구성되어 있다고 가정하자. 특정 문서를 구성하고 있는 단어들로부터, 해당 단어들을 발생시킨 토픽들의 비중을 추론할 수 있음.      문서 $d$ 에는 여러 토픽들이 담겨 있으며, 각 토픽 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} k \\mid \\theta_d &amp;\\sim \\text{Multinomial}(\\theta_{d})\\\\ \\theta_{d} &amp;\\sim \\text{Dirichlet}(\\alpha) \\end{aligned}\\]          $k \\mid \\theta_d$ : 문서 $d$ 에서 토픽 $k$ 가 발생할 확률      $\\theta_d$ : $d$ 번째 문서에서 각 토픽들이 발생할 확률            토픽 $k$ 에서는 여러 단어들이 발생할 수 있으며, 각 단어 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} w \\mid \\psi_{k} &amp;\\sim \\text{Multinomial}(\\psi_{k})\\\\ \\psi_{k} &amp;\\sim \\text{Dirichlet}(\\beta) \\end{aligned}\\]          $w \\mid \\psi_{k}$ : 토픽 $k$ 에서 단어 $w$ 가 발생할 확률      $\\psi_{k}$ : 토픽 $k$ 에서 각 단어들이 발생할 확률            따라서 단어 $w(d,n)$ 이 발생했을 때, $\\theta_d$ 및 $\\psi_{z(d,n)}$ 의 사후 확률 분포는 다음과 같음\\[\\begin{aligned} &amp;P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))\\\\ &amp;\\propto \\underbrace{P(\\theta_d \\mid z(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)} \\mid w(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}\\\\ &amp;\\propto \\left[\\underbrace{P(\\theta_d)}_{\\text{Prior}} \\cdot \\underbrace{P(z(d,n) \\mid \\theta_d)}_{\\text{Likelihood}}\\right] \\times \\left[\\underbrace{P(\\psi_{z(d,n)})}_{\\text{Prior}} \\cdot \\underbrace{P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\text{Likelihood}}\\right] \\end{aligned}\\]          $w(d,n)$ : 문서 $d$ 의 $n$ 번째 단어      $z(d,n)$ : 단어 $w(d,n)$ 에 대하여 해당 단어가 할당된 토픽      $\\theta_d$ : 문서 $d$ 의 토픽 분포      $\\psi_{z(d,n)}$ : 토픽 $z(d,n)$ 의 단어 분포      Sourse  https://intoli.com/blog/pca-and-svd/"
  },
  
  {
    "title": "Language Model",
    "url": "/posts/langauge_model/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, language model",
    "date": "2024-08-17 00:00:00 +0900",
    





    
    "snippet": "Language Model  언어 모형(Language Model) : Word Sequence(문장)에 확률을 할당하여 가장 자연스러운 문장을 탐색하는 모형Statistical Language ModelSLM      SLM(Statistical Language Model) : 조건부 확률을 활용하여 Word Sequence 발생 확률을 부여하는 모...",
    "content": "Language Model  언어 모형(Language Model) : Word Sequence(문장)에 확률을 할당하여 가장 자연스러운 문장을 탐색하는 모형Statistical Language ModelSLM      SLM(Statistical Language Model) : 조건부 확률을 활용하여 Word Sequence 발생 확률을 부여하는 모형\\[\\begin{aligned}  P(W)  &amp;= P(w_1, w_2, \\cdots, w_n)\\\\  &amp;= \\cancel{P(w_1)} \\cdot \\frac{\\cancel{P(w_1,w_2)}}{\\cancel{P(w_1)}} \\cdot \\frac{\\cancel{P(w_1, w_2, w_3)}}{\\cancel{P(w_1, w_2)}} \\cdots \\frac{P(w_1, w_2, \\cdots, w_n)}{\\cancel{P(w_1, w_2, \\cdots, w_{n-1})}}\\\\  &amp;= P(w_1) \\cdot P(w_2 \\mid w_1) \\cdot P(w_3 \\mid w_1, w_2) \\cdots P(w_n \\mid w_1, w_2, \\cdots, w_{n-1})\\\\  &amp;= \\prod_{i=1}^{n}{P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]        확률 부여 방법\\[\\begin{aligned}  P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})  &amp;= \\frac{\\text{Count}(w_1, w_2, \\cdots, w_i)}{\\text{Count}(w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]          $\\text{Count}(w_1, w_2, \\cdots, w_i)$ : 말뭉치에서 Word Sequence $(w_1, w_2, \\cdots, w_i)$ 가 등장한 횟수      n-Gram      n-Gram : $i$ 번째 단어를 예측함에 있어 $N-1$ 개의 단어만을 활용하는 방법\\[\\begin{aligned}  P(W)  &amp;= \\prod_{i=1}^{n}{P(w_{i} \\mid w_{i-(n-1)}, w_{i-(n-2)}, \\cdots, w_{i-1})}  \\end{aligned}\\]        How to Select $n$ : 통상 $n \\le 5$ 권장                            Problem          Small $n$          Large $n$                                      Sparsity Problem          $\\downarrow$          $\\uparrow$                          Long-term Dependency          $\\uparrow$          $\\downarrow$                            희소성 문제(Sparsity Problem) : 충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제      장기 의존성 문제(Long-term Dependency) : 문맥 내에서 멀리 떨어져 있는 단어들 간의 관계를 처리하는 문제      Neural Networks based Langauge Model  통계적 방법론의 한계점과 그 대안          NNLM(Neural Networks Langauge Model) : 임베딩을 활용한 희소성 문제 보완      RNNLM(Recurrent Neural Networks Langauge Model) : RNN 계열 레이어를 활용한 장기 의존성 문제 보완            How to Generate a Context Vector for $w_{t+1}$              NNLM : $t$ 번째까지 등장한 단어 벡터들의 결합(Concatenation)으로 생성      RNNLM : $t$ 번째까지 등장한 단어 벡터들을 RNN 계열 레이어에 순차 입력하여 생성      NNLM  INPUT → PROJECTION          Projection : \\(\\mathbf{w}_{i} = \\mathbf{x}_{i} \\cdot \\mathbf{W}\\)      Concatenation : \\(\\mathbf{z}_{t} = \\mathbf{w}_{t-n+1} \\oplus \\mathbf{w}_{t-n+2} \\oplus \\cdots \\oplus \\mathbf{w}_{t}\\)            PRJECTION → HIDDEN\\[\\begin{aligned}  \\mathbf{h}_{t}  &amp;= \\text{F}_{\\text{ReLU}}\\left[\\mathbf{z}_{t}\\right]  \\end{aligned}\\]        HIDDEN → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{t+1}  &amp;= \\text{F}_{\\text{Softmax}}\\left[\\mathbf{h}_{t}\\right]  \\end{aligned}\\]  RNNLM      INPUT → PROJECTION\\[\\mathbf{w}_{i}  = \\mathbf{x}_{i} \\cdot \\mathbf{W}\\]        PRJECTION → HIDDEN\\[\\begin{aligned}  h_{t}, c_{t}  &amp;= \\text{LSTM}\\left(\\mathbf{w}_{t}, h_{t-1}, c_{t-1}\\right)  \\end{aligned}\\]        HIDDEN → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{t+1}  &amp;= \\text{F}_{\\text{Softmax}}\\left[h_{t}\\right]  \\end{aligned}\\]  Metric      PPL(PerPLexity) : 언어 모형의 성능 평가 지표\\[\\begin{aligned}  PPL(W)  &amp;= P(W)^{-\\frac{1}{N}}\\\\  &amp;= P(w_1, w_2, \\cdots, w_N)^{-\\frac{1}{N}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{P(w_1, w_2, \\cdots, w_N)}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  \\end{aligned}\\]        해석 : 선택 가능한 경우의 수를 의미하는 분기 계수(Branching Factor)로서, 특정 시점마다 평균적으로 고민하는 선택지 수\\[\\begin{aligned}  PPL(W)  &amp;=10\\\\  \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  &amp;= 10\\\\  \\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}\\\\  \\underset{\\frac{1}{10}}{P(w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_2 \\mid w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_3 \\mid w_1, w_2)} \\cdots \\underset{\\frac{1}{10}}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Docs Representation",
    "url": "/posts/docs_representation/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, document representation, embedding",
    "date": "2024-08-16 00:00:00 +0900",
    





    
    "snippet": "Traditional Method      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법            DTM(Document Term Matrix) : 여러 개의 문서를 BoW 로 표현하는 방법            TF-IDF(Term Frequency-Inverse Document Frequency) : DTM 내 ...",
    "content": "Traditional Method      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법            DTM(Document Term Matrix) : 여러 개의 문서를 BoW 로 표현하는 방법            TF-IDF(Term Frequency-Inverse Document Frequency) : DTM 내 단어들에 대하여 각 단어의 중요도에 따라 가중치를 부여하여 표현하는 방법\\[\\text{TF-IDF}(d,t)=\\text{TF}(d,t) \\cdot \\text{IDF}(t)\\]                  TF(Term Frequency) : 문서 $d$ 에서 단어 $t$ 가 등장하는 횟수\\[\\text{TF}(d,t)\\]                    IDF(Inverse Document Frequency) : 단어 $t$ 가 등장하는 문서의 수에 반비례하는 수\\[\\text{IDF}(t)=\\ln{\\frac{n}{1+\\text{DF}(t)}}\\]                  $n$ : 문서의 수          $\\text{DF}(t)$ : 단어 $t$ 가 등장하는 문서의 수                    DOC2VEC      도큐먼트 투 벡터(DOC2VEC) : WORD2VEC 을 활용하여 문서의 밀집 표현을 학습하는 방법론            PV-DM(Paragraph Vector-Distributed Memory) : WORD2VEC 의 CBOW 와 유사한 학습 방법으로서, 도큐먼트 벡터와 주변 단어 벡터들이 주어졌을 때 발생 가능한 중심 단어 벡터를 추론하는 과정에서 도큐먼트 벡터 표현을 학습함\\[\\begin{aligned}  P\\left(w_{t} \\mid d, w_{t-\\omega}, \\cdots, w_{t-1}, w_{t+1}, \\cdots, w_{t+\\omega}\\right)  &amp;= \\text{Softmax}\\left(\\mathbf{d} + \\sum_{i \\in \\text{Context}}{\\mathbf{w}_{i}}\\right)  \\end{aligned}\\]        PV-DBOW(Paragraph Vector-Distributed Bag Of Words) : WORD2VEC 의 Skip-Gram 과 유사한 학습 방법으로서, 도큐먼트 벡터가 주어졌을 때 단어들의 발생 확률 분포 벡터를 추론하는 과정에서 도큐먼트 벡터 표현을 학습함\\[\\begin{aligned}  P\\left(\\cdots \\mid d\\right)  &amp;= \\text{Softmax}\\left(\\mathbf{d} \\cdot \\mathbf{W}\\right)  \\end{aligned}\\]  "
  },
  
  {
    "title": "WORD2VEC Improvements",
    "url": "/posts/word2vec_improvements/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, word representation, embedding",
    "date": "2024-08-15 00:00:00 +0900",
    





    
    "snippet": "Fast-Text      Fast-Text : 내부 단어(Sub-word)를 고려한 임베딩 학습 방법론          EAT vs. EATING              WORD2VEC 의 한계점 : 단어의 형태학적 특성을 고려하지 않으므로, 비슷한 문맥에서 사용되지 않았다면 동일한 어근에서 파생된 단어들의 의미상 유사도를 반영할 수 없음      ...",
    "content": "Fast-Text      Fast-Text : 내부 단어(Sub-word)를 고려한 임베딩 학습 방법론          EAT vs. EATING              WORD2VEC 의 한계점 : 단어의 형태학적 특성을 고려하지 않으므로, 비슷한 문맥에서 사용되지 않았다면 동일한 어근에서 파생된 단어들의 의미상 유사도를 반영할 수 없음      Fast-Text 의 해법 : 단어를 철자(Character) 단위의 n-gram 으로 간주하고, 단어 자체가 아니라 내부 단어들의 임베딩을 학습함                  통상 $3 \\le n \\le 6$ 으로 설정함                          EXAMPLE “eating”                      Character $n$-grams of eating                                            word              $n$              n-grams(sub-word)                                                          eating              3-gram              &lt;ea, eat, ati, tin, ing, ng&gt;                                      eating              4-gram              &lt;eat, eati, atin, ting, ing&gt;                                      eating              5-gram              &lt;eati, eatin, ating, ting&gt;                                      eating              6-gram              &lt;eatin, eating, ating&gt;                                      eating              Full              eating                                                  Embedding Vector of eating\\[\\begin{aligned}  \\mathbf{z}  &amp;= \\text{Embedding}\\left(\\text{eating}\\right) + \\sum_{n}{\\text{Embedding}\\left(n\\text{-grams}\\right)}  \\end{aligned}\\]            GloVe  WORD2VEC, Fast-Text 의 한계점 : 말뭉치 내 Global Context 를 활용하지 못함Co-occurrence Matrix based Method      Co-occurrence Matrix : 말뭉치에서 각 단어가 윈도우 내에 다른 단어와 함께 등장하는 횟수를 측정한 행렬                            Counts          I          like          enjoy          deep          learning          NLP          flying          .                                      I          0                                                                                                       like                     0                                                                                            enjoy                                0                                                                                 deep                                           0                                                                      learning                                                      0                                                           NLP                                                                 0                                                flying                                                                            0                                     .                                                                                       0                            $X_{i,j} \\in \\mathbf{X}_{N \\times N}$ : $i$ 번째 단어를 중심으로 했을 때 윈도우 내에 $j$ 번째 단어가 등장한 횟수            PMI(Point Mutual Information) : 단순 횟수 측정 시 발생하는 고빈도 단어에 대한 잘못된 표현을 정정하기 위하여 고안된 측정 지표로서, 단어 $x$ 와 $y$ 가 동시에 발생할 확률을, 각각이 발생할 확률로 나눈 값\\[\\begin{aligned}  PMI(A,B)  &amp;= \\log{\\frac{P(A,B)}{P(A)P(B)}}\\\\  &amp;= \\log{N} + \\log{\\text{Count}(A,B)} - \\log{\\text{Count}(A)} - \\log{\\text{Count}(B)}  \\end{aligned}\\]        PPMI(Positive Point Mutual Information) : 두 단어의 동시 발생 횟수가 $0$ 일 때 발생하는 음의 무한대로의 발산 문제를 해결한 측정 지표\\[\\begin{aligned}  PPMI(A,B)  &amp;=\\max\\left(0, PMI(A,B)\\right)  \\end{aligned}\\]        SVD 를 활용하여 고차원 문제 보완    \\[\\begin{aligned}  \\mathbf{X}_{N \\times N}  \\approx \\underbrace{\\mathbf{U}_{N \\times N} \\cdot \\Sigma_{N \\times D}}_{\\text{Vector Representation}} \\cdot \\mathbf{V}^{T}_{N \\times D}  \\end{aligned}\\]  GloVe  Co-occurrence Matrix based Method 의 한계점          단어 간 유사도가 반영된 벡터 표현을 도출하지 못함      고차원 행렬이기 때문에 SVD 등 차원 축소 기법을 추가로 활용해야 함            GloVe(Global Vectors for Word Representation) : 단어 간 전역적 통계 정보를 활용하여 단어를 임베딩하는 방법론                      중심 단어 $i$ 와 주변 단어 $j$ 간 임베딩 벡터의 내적값이 동시 발생 확률이 되도록 학습함\\[\\begin{aligned}  \\mathbf{w}_{i} \\cdot \\mathbf{v}_{j}   \\approx \\log{P(w_{j} \\mid w_{i})}  = \\log{\\frac{X_{i,j}}{\\sum_{k}{X_{i,k}}}}  \\end{aligned}\\]                  $\\mathbf{w}_{i} \\in \\mathbf{W}$ : 단어 $i$ 가 중심 단어일 때의 임베딩 벡터          $\\mathbf{v}_{j} \\in \\mathbf{V}$ : 단어 $j$ 가 주변 단어일 때의 임베딩 벡터          $P(w_{j} \\mid w_{i})$ : 중심 단어 $i$ 발생 조건부 $j$ 발생 확률          $\\log{P(w_{j} \\mid w_{i})}$ : 스케일 조정을 위하여 공동 발생 확률 자체가 아니라 공동 발생 확률의 로그값에 수렴하도록 학습함                            동시 발생 확률 $P(w_{j} \\mid w_{i})$ 대신 동시 발생 횟수 $X_{i,j}$ 를 활용함\\[\\begin{aligned}  \\mathbf{w}_{i} \\cdot \\mathbf{v}_{j}   \\approx \\log{X_{i,j}}  \\end{aligned}\\]                  내적 값과 확률 값의 직접 대응이 어렵기 때문임($\\because \\sum_{j}{P(w_{j} \\mid w_{i})}=1$)                          Loss Function\\[\\begin{aligned}  \\mathcal{L}  &amp;= \\sum_{i,j}{f(X_{i,j})\\left(\\mathbf{w}_{i} \\cdot \\mathbf{v}_{j} + (b_{i} + \\beta_{j}) - \\log{X_{i,j}}\\right)^{2}}  \\end{aligned}\\]          \\(f(X_{i,j})=\\min{\\left[1, \\left(\\displaystyle\\frac{X_{i,j}}{X_{\\text{max}}}\\right)^{3/4}\\right]}\\) : 학습 중 고빈도 단어 영향력 조정 함수      ELMo      FFNN 에 기반한 기존 방법론의 한계점 : 문장 전체의 문맥을 반영하지 못하여 동의어, 다형어에 대한 표현이 제대로 이루어지지 못함        ELMo(Embeddings from Language Model) : 방대한 텍스트 데이터로 사전 훈련된 LSTM 기반 언어 모형 BiLM 을 활용하는 단어 임베딩 방법론            BiLM(Bidirectional Language Model) : 문장 시퀀스를 순방향, 역방향으로 각각 학습하는 LSTM 기반 언어 모형            Forward Path                      Multi-Layer LSTM\\[\\begin{aligned} h^{(k)}_{t}, c^{(k)}_{t} &amp;= \\text{LSTM}^{(k)}\\left(h^{(k-1)}_{t}, h^{(k)}_{t-1}, c^{(k)}_{t-1}\\right) \\end{aligned}\\]                  $h^{(k)}_{t}$ : $k$ 번째 LSTM Layer 의 $t$ 시점 은닉 값                          첫 번째 LSTM Layer 의 $t$ 시점 입력값 \\(h^{(0)}_{t}\\) 은 $t$ 시점 단어 $w_{t}$ 의 임베딩 벡터임                                $c^{(k)}_{t}$ : $k$ 번째 LSTM Layer 의 $t$ 시점 셀 상태 값                            Output Layer\\[\\begin{aligned} \\hat{\\mathbf{y}} &amp;= \\text{F}_{\\text{Softmax}}\\left[h^{(K)}_{T}\\right] \\end{aligned}\\]                  ELMo Representation    \\[\\begin{aligned}  \\mathbf{w}_{t}  &amp;= \\sum_{k}{\\gamma^{(k)}\\left(h^{(k)}_{t} \\oplus \\eta^{(k)}_{t}\\right)}  \\end{aligned}\\]  Sourse  https://intoli.com/blog/pca-and-svd/  https://github.com/dvgodoy/dl-visuals/  https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782  https://wikidocs.net/33930"
  },
  
  {
    "title": "ExpoMF",
    "url": "/posts/expomf/",
    "categories": "6.RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, implicit feedback, occf, latent factor, em algorithm, mle",
    "date": "2024-08-14 00:00:00 +0900",
    





    
    "snippet": "Previous Research      Problems with implicit feedback          암시적 피드백 하에서는 관측된 아이템을 선호 아이템, 미관측된 아이템을 비선호 아이템으로서 추정함. 하지만 관측 행위는 선호 외에 불호와 우연성을, 미관측 행위는 비선호 외에 미노출이라는 경우의 수를 포괄하고 있음. 따라서 미관측된 아이템...",
    "content": "Previous Research      Problems with implicit feedback          암시적 피드백 하에서는 관측된 아이템을 선호 아이템, 미관측된 아이템을 비선호 아이템으로서 추정함. 하지만 관측 행위는 선호 외에 불호와 우연성을, 미관측 행위는 비선호 외에 미노출이라는 경우의 수를 포괄하고 있음. 따라서 미관측된 아이템을 단순히 비선호 아이템으로 치부하는 것은 무리가 있음.            WMF(Weighted Matrix Factorization) : Confidence Weighted Approach\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}, \\overrightarrow{\\mathbf{q}}  &amp;= \\text{arg}\\min_{\\Theta}{\\sum_{(u,i)}{c_{u,i} \\cdot \\left(r_{u,i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right)^{2} + \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}}}  \\end{aligned}\\]          \\(c_{u,i}:=1+\\alpha \\cdot r_{u,i}\\) : Confience Weight            BPR(Bayesian Personalized Ranking) : Pairwise Learning Approach\\[\\begin{aligned}  \\Theta  &amp;= \\text{arg}\\min_{\\Theta}{\\sum_{(u,i,j)}{-\\ln{\\sigma\\left(\\hat{r}_{u,i} - \\hat{r}_{u,j}\\right)} + \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}}  \\end{aligned}\\]  EXMF  EXMF(Exposure Matrix Factorization) : 미관측 아이템에 대한 사용자의 노출 여부를 명시적으로 모델링하는 방법론          WMF : 미관측 항목에 낮은 신뢰도를 부여하고 있으나, 이는 모든 미관측 항목을 단순히 하향 가중하는 직관적인 접근법임      BPR : 관측 항목과 미관측 항목 간 순위에 격차를 벌리고 있으나, 이는 미관측 원인 중 하나인 노출 여부를 명시적으로 다루는 접근법이 아님      EXMF : 사용자 노출 여부를 명시적으로 모델링함으로써 사용자가 관측하지 않은 이유를 설명하고자 함      How to Modeling      사용자 $i$ 가 아이템 $j$ 를 클릭할 가능성\\[\\begin{aligned}  p\\left(r_{i,j},y_{i,j} \\mid \\mu_{i,j}, \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)  &amp;= \\underbrace{p\\left(y_{i,j} \\mid \\mu_{i,j}\\right)}_{\\text{Exposure Prob.}} \\cdot \\overbrace{p\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)^{y_{i,j}}}^{\\text{Click Prob. under Exposure}} \\cdot \\underbrace{\\mathbf{I}\\left[r_{i,j}=0\\right]^{1-y_{i,j}}}_{\\text{non-Click Prob. under non-Exposure}}  \\end{aligned}\\]          \\(r_{i,j} = \\big\\{1,0\\big\\} \\in \\mathbf{R}_{M \\times N}\\) : 클릭 변수      \\(y_{i,j} = \\big\\{1,0\\big\\} \\in \\mathbf{Y}_{M \\times N}\\) : 노출 변수            \\(p\\left(y_{i,j} \\mid \\mu_{i,j}\\right)\\) : 사용자 $i$ 가 아이템 $j$ 에 노출될 가능성\\[\\begin{aligned}  y_{i,j} &amp;\\sim \\text{Bernoulli}\\left(\\mu_{u,i}\\right)  \\end{aligned}\\]        \\(p\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)^{y_{i,j}}\\) : 사용자 $i$ 가 아이템 $j$ 에 노출되었을 때, 아이템을 클릭할 가능성\\[\\begin{aligned}  r_{i,j} \\mid y_{i,j}=1 &amp;\\sim \\mathcal{N}\\left(\\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)  \\end{aligned}\\]        \\(\\mathbf{I}\\left[r_{i,j}=0\\right]^{1-y_{i,j}}\\) : 사용자 $i$ 가 아이템 $j$ 에 노출되지 않았을 때, 아이템을 클릭하지 않을 가능성\\[\\begin{aligned}  r_{i,j} \\mid y_{i,j}=0  &amp;\\sim \\delta_{0}\\\\  &amp;\\approx \\mathcal{N}\\left(\\epsilon, \\lambda^{-1}\\right)   \\end{aligned}\\]          $\\delta_{x=k}: p\\left(x=k\\right)=1$            Objective Function\\[\\begin{aligned}  \\mathcal{J}  &amp;= \\sum_{(i,j)}{\\log{p\\left(r_{i,j},y_{i,j} \\mid \\mu_{i,j}, \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)}}\\\\  &amp;= \\sum_{(i,j)}{\\log{\\text{Bernoulli}\\left(y_{i,j}\\mid \\mu_{i,j}\\right)} + y_{i,j} \\cdot \\log{\\mathcal{N}\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)} + (1-y_{u,i}) \\cdot \\cancel{\\log{\\mathbf{I}\\left[r_{i,j}=0\\right]}}}\\\\  &amp;= \\sum_{(i,j)}{\\log{\\text{Bernoulli}\\left(y_{i,j}\\mid \\mu_{i,j}\\right)} + y_{i,j} \\cdot \\log{\\mathcal{N}\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)}}  \\end{aligned}\\]        Maximum Likelihood Estimation\\[\\begin{aligned}  \\mu, \\overrightarrow{\\mathbf{u}}, \\overrightarrow{\\mathbf{v}}  &amp;= \\text{arg}\\max_{\\Theta}{\\mathcal{J}}  \\end{aligned}\\]  Optimizer  E-M Algorithm : 잠재 변수의 기대값을 추정하고, 이를 바탕으로 학습 파라미터를 최적화하는 방법론          E-Step(Expectation Step) : 잠재 변수의 기대값 추정      M-Step(Maximization Step) : 잠재 변수의 기대값 추정치를 바탕으로 학습 파라미터 갱신            E-Step(Expectation Step) : 사용자 $i$ 가 아이템 $j$ 에 노출되었는지 여부의 기대값 $\\mathbb{E}\\left[y_{i,j}=1\\right]$ 으로서 사용자가 특정 아이템에 노출될 가능성의 추정치\\[\\begin{aligned}  \\mathbb{E}\\left[y_{i,j}=1\\right]  &amp;= p\\left(y_{i,j}=1 \\mid r_{i,j}\\right)\\\\  &amp;= \\frac{\\overbrace{p\\left(r_{i,j} \\mid y_{i,j}=1\\right)}^{\\text{Likelihood}} \\cdot \\overbrace{p\\left(y_{i,j}=1 \\mid \\mu_{i,j}\\right)}^{\\text{Prior}}}{\\underbrace{p\\left(r_{i,j} \\mid \\mu_{i,j}\\right)}_{\\text{Posterior}}}\\\\  &amp;= \\frac{\\mu_{i,j} \\cdot \\mathcal{N}\\left(r_{u,i} \\mid \\overrightarrow{\\mathbf{p}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}, \\lambda^{-1}\\right)}{\\mu_{i,j} \\cdot \\mathcal{N}\\left(r_{u,i} \\mid \\overrightarrow{\\mathbf{p}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}, \\lambda^{-1}\\right) + \\left(1 - \\mu_{i,j}\\right)}  \\end{aligned}\\]        M-Step(Maximization Step) : User and Item-Latent Factors updated using ALS                  User-Latent Factor\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{i}  \\leftarrow \\left(\\lambda \\sum_{j}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot \\overrightarrow{\\mathbf{v}}_{j} \\otimes \\overrightarrow{\\mathbf{v}}_{j}} + \\gamma_{\\Theta}\\mathbf{I}\\right)^{-1} \\left(\\lambda \\sum_{j}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot r_{i,j} \\cdot \\overrightarrow{\\mathbf{v}}_{j}}\\right)  \\end{aligned}\\]                    Item-Latent Factor\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{j}  \\leftarrow \\left(\\lambda \\sum_{i}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot \\overrightarrow{\\mathbf{u}}_{i} \\otimes \\overrightarrow{\\mathbf{u}}_{i}} + \\gamma_{\\Theta}\\mathbf{I}\\right)^{-1} \\left(\\lambda \\sum_{i}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot r_{i,j} \\cdot \\overrightarrow{\\mathbf{u}}_{i}}\\right)  \\end{aligned}\\]            "
  },
  
  {
    "title": "Word Representation",
    "url": "/posts/word_representation/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp, word representation, embedding",
    "date": "2024-08-14 00:00:00 +0900",
    





    
    "snippet": "Representation MethodsSparse Representation      희소 표현(Sparse Representation) : 하나의 단어를 하나의 차원으로 하는 $n$ 차원 공간에 단어를 표현하는 방법    \\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &a...",
    "content": "Representation MethodsSparse Representation      희소 표현(Sparse Representation) : 하나의 단어를 하나의 차원으로 하는 $n$ 차원 공간에 단어를 표현하는 방법    \\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots \\end{pmatrix}\\\\  \\text{Puppy}&amp;=\\begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\cdots \\end{pmatrix}  \\end{aligned}\\]          Dimensionality Curse Problem in Sparse Vector      Semantic/Structural Disjointness Problem      Dense Representation      단어 임베딩(Word Embedding) : 희소 표현의 한계점을 보완한 방법으로서, 분포 가설에 근거하여 단어를 밀집된 형태로 표현하는 방법          Embedding  An embedding is a mapping of a discrete - categorical - variable to a vector of continuous numbers.  In the context of machine learning, an embedding is a low-dimensional, learned continuous vector representation of discrete variables into which you can translate high-dimensional vectors.            밀집 표현(Dense Representation) : 연구자가 설정한 $k \\le n$ 차원 공간에 단어를 표현하는 방법\\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 0.1 &amp; 0.3 &amp; -0.2 \\end{pmatrix}\\\\  \\text{Puppy}&amp;=\\begin{pmatrix} 0.1 &amp; 0.3 &amp; -0.3 \\end{pmatrix}  \\end{aligned}\\]        분산 표현(Distributed Representation) : 분포 가설에 근거하여 단어의 의미 를 다차원 공간에 표현하는 방법                  분포 가설(Distributional Hypothesis) : 비슷한 문맥에서 등장하는, 다시 말해 비슷하게 분포되어 있는 단어들은 비슷한 의미를 가짐\\[\\begin{aligned}  &amp;\\text{My dog is cute. Sometimes my dog braks at me.}\\\\  &amp;\\text{My puppy is cute. Sometimes my puppy braks at me.}  \\end{aligned}\\]            WORD2VEC  워드 투 벡터(WORD2VEC) : 단어 임베딩 학습 방법론          CBOW(Continuous Bag of Words) : 주변 단어들로부터 중심 단어를 예측하는 과정에서 단어의 벡터 표현을 학습하는 방법론      Skip-Gram : 중심 단어로부터 주변 단어들을 예측하는 과정에서 단어의 벡터 표현을 학습하는 방법론      SGNS(Skip-Gram with Negative Sampling) : Skip-Gram 에 Negative Sampling 을 적용함으로써 단어 예측 문제의 유형을 전환하는 방법론                  Skip-Gram : 중심 단어가 등장했을 때 전체 단어가 발생할 확률 분포 학습 문제          SGNS : 중심 단어가 등장했을 때 특정 주변 단어 발생 여부 판별 문제                          EXAMPLE “The fat cat sat on the mat” (Where Window Size is 2)        Annotation          $\\omega$ : Context Window Size      $i$ : Target Word      $j = 1,2,\\cdots,\\omega,\\cdots,2\\omega$ : Context Words      $N$ : Number of Words      $D$ : Embedding Size      $\\mathbf{X} \\in \\mathbb{R}^{N \\times N}$ : One-Hot Encoded Matrix      $\\mathbf{W} \\in \\mathbb{R}^{N \\times D}$ : Embedding Matrix      CBOW      INPUT → PROJECTION\\[\\begin{aligned}  \\mathbf{z}_{i}  &amp;= \\frac{1}{2 \\omega} \\sum_{j}{\\mathbf{x}_{j} \\cdot \\mathbf{W}}  \\end{aligned}\\]          \\(\\mathbf{w}_{j} = \\mathbf{x}_{j} \\cdot \\mathbf{W} \\in \\mathbb{R}^{D}\\) : Embedding Vector of Context Word \\(j\\)            PROJECTION → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{x}}_{i}  &amp;= \\text{Softmax}\\left[\\mathbf{z}_{i} \\cdot \\mathbf{W}^{T}\\right]  \\end{aligned}\\]        Optimization\\[\\begin{aligned}  \\hat{\\mathbf{W}}  &amp;= \\text{arg} \\min{\\sum_{i}{\\text{Cross-Entropy}\\left[\\mathbf{x}_{i}, \\hat{\\mathbf{x}}_{i}\\right]}}  \\end{aligned}\\]  Skip-Gram      INPUT → PROJECTION\\[\\begin{aligned}  \\mathbf{w}_{i}  &amp;=\\mathbf{x}_{i} \\cdot \\mathbf{W}  \\end{aligned}\\]        PROJECTION → OUTPUT\\[\\begin{aligned}  \\mathbf{y}_{i}  &amp;= \\text{Softmax}\\left[\\mathbf{w}_{i} \\cdot \\mathbf{W}^{T}\\right]  \\end{aligned}\\]          \\(\\mathbf{y}_{i} \\in \\mathbb{R}^{N}\\) : Context Probability Distribution Vector for Target Word $i$            Optimization\\[\\begin{aligned}  \\hat{\\mathbf{W}}  &amp;= \\text{arg} \\min{\\sum_{i,j}{\\text{Cross-Entropy}\\left[\\mathbf{x}_{j}, \\mathbf{y}_{i}\\right]}}  \\end{aligned}\\]  SGNS      이진 분류 문제로 전환하기 위한 입력과 레이블 변화            Negative Sampling                      $k$ 번째 단어가 샘플링될 확률\\[\\begin{aligned}  P\\left(w_{k} \\mid \\alpha \\right)  &amp;= \\frac{f\\left(w_{k}\\right)^{\\alpha}}{\\sum_{l=1}^{N}{f\\left(w_{l}\\right)^{\\alpha}}}  \\end{aligned}\\]                  $\\alpha=0.75$ : 샘플링 확률 조정 파라미터로서 고빈도 단어가 샘플링될 확률을 할인함          $f\\left(w_{k}\\right)$ : 통상 단어 빈도수로 설정함                          Optimization    \\[\\begin{aligned}  \\hat{\\mathbf{W}}, \\hat{\\mathbf{V}}  &amp;= \\text{arg} \\min{-\\sum_{i,j}{y_{i,j} \\log{\\sigma\\left[\\mathbf{W}_{i} \\cdot \\mathbf{V}_{j}\\right]} + \\left(1-y_{i,j}\\right) \\log{\\sigma\\left[-\\mathbf{W}_{i} \\cdot \\mathbf{V}_{j}\\right]}}}  \\end{aligned}\\]          $\\mathbf{W} \\in \\mathbb{R}^{N \\times D}$ : Target Embedding Matrix      $\\mathbf{V} \\in \\mathbb{R}^{N \\times D}$ : Target Embedding Matrix      $\\sigma\\left[\\cdot\\right]$ : Sigmoid Function            What? Final Embedding Matrix          Target Embedding Matrix $\\mathbf{W}$      Concatenation $\\mathbf{W} \\oplus \\mathbf{V}$      Mean, Plus, etc.      Sourse  https://velog.io/@growthmindset/%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9One-Hot-Encoding  https://wikidocs.net/22660  https://wikidocs.net/69141"
  },
  
  {
    "title": "Text Data Preprocessing",
    "url": "/posts/text_data_preprocessing/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp",
    "date": "2024-08-13 00:00:00 +0900",
    





    
    "snippet": "Text Analytics      텍스트 애널리틱스(Text Analytics) : 텍스트로부터 정보를 추출하는 과정          Text mining, text data mining(TDM) or text analytics is the process of deriving high-quality information from text. It in...",
    "content": "Text Analytics      텍스트 애널리틱스(Text Analytics) : 텍스트로부터 정보를 추출하는 과정          Text mining, text data mining(TDM) or text analytics is the process of deriving high-quality information from text. It involves “the discovery by computer of new, previously unknown information, by automatically extracting inofrmation from different written resources. (Wikipedia)            사례                                       규칙 기반 방법론          통계적 방법론          신경망 기반 방법론          RNN          Attention                                      단어 표현          One-Hot Encoding          -          Word2Vec          ELMo          -                          문서 표현          DTM          -          Doc2Vec          -          -                          언어 모형          -          SLM          NNLM          RNNLM          BERT                          토픽 모형          -          LSA, LDA          -          -          BERTopic                          기계 번역          RBMT          SMT          -          SEQ2SEQ          Transformer                          생성 모형          -          -          -          -          GPT                    Process      문제 정의(Problem Definition)          어떤 문제를 해결할 것인가? 이를 위해 필요한 데이터는 무엇인가?        텍스트 데이터 획득(Text Data Collection)          크롤링(Crawling)      스크래이핑(Scraping) 등        텍스트 데이터 전처리(Text Data Preprocessing) : 자연어를 특정 단위로 분할하고, 유용하지 않은 데이터를 제거하고, 동일한 의미를 가진 데이터를 획일화하는 작업          토큰화(Tokenization)      정제(Cleansing)      정규화(Normalization) 등        벡터 표현(Vector Representation) : 자연어를 컴퓨터가 이해할 수 있는 형식으로 표현하는 작업          원-핫 인코딩(One-Hot Encoding)      워드 투 벡터(Word2Vec) 등        모델링(Modeling)          Summarization      Visualization      Topic Model      Docs Classification      Docs Clustering      NLU(Natural Language Understanding)      NLG(Natural Language Generation)      Text Data Preprocessing  순서          토큰화(Tokenization)      정제(Cleansing)      정규화(Normalization)      Tokenization  자연어(Natural Language) : 사람들이 일상적으로 쓰는 언어를 인공적인 언어인 인공어와 구분하여 부르는 개념(Wikipedia)          형태상으로는 문자(Character)로, 의미상으로는 단어(Word)로 구성된 시계열 데이터(Sequence Data)      자연어를 컴퓨터가 이해할 수 있는 형식으로 변환함에 있어, 그 의미가 반영될 수 있어야 함        토큰화(Tokenization) : 주어진 말뭉치를 토큰 단위로 나누는 작업          말뭉치(Corpus) : 자연어 처리 목적으로 수집된 텍스트 데이터      토큰(Token) : 문장이나 단어 등 의미의 최소 단위        POS(Part of Speech) Tagging : (특히 동음이의어를 구분하기 위하여) 토큰에 그 앞, 뒤 문맥상 적합한 품사를 태깅하는 작업Cleansing  정제(Cleansing) : 말뭉치에서 노이즈를 제거하는 작업          등장 빈도가 적은 토큰 제거      (특히 영어에서) 길이가 짧은 토큰 제거      불용어(Stopwords) 제거      오탈자, 띄어쓰기 교정 등      Normalization      정규화(Normalization) : 다른 형태를 취하나 의미가 같은 단어들을 하나로 통합하여 동일한 표현으로 만드는 작업    표제어 추출(Lemmatization) : 대상 토큰의 품사에 알맞은 표제어를 추출하는 행위          표제어(Lemma) : 기본 사전형 단어        어간 추출(Stemming) : 단어의 변형된 형태를 제거하거나 치환하여 어간을 추출하는 행위로서, 형태학적 파싱보다는 정해진 규칙에 따라 접사를 잘라내는 작업에 가까움          형태학(Morphology) : 형태소로부터 단어가 형성되는 과정을 분석하는 학문      형태소(Morpheme) : 의미가 있는, 가장 작은 말의 단위                  어간(Stem) : 단어의 의미를 담고 있는 부분          접사(Affix) : 단어에 추가적인 의미를 부여하는 부분                    Agglutinative Language      교착어(Agglutinative Language) : 한국어 등 어간에 문법적으로 기능하는 형태소가 결합하여 문법적 기능이 부여되는 언어    자립형태소 : 자립하여 사용할 수 있는 형태소          체언(명사, 대명사, 수사)      수식언(관형사, 부사)      감탄사 등        의존형태소 : 다른 형태소와 결합하여 사용되는 형태소          어미 : 동사, 형용사의 어간에 결합하여 문법적 기능을 부여하는 형태소      조사 : 체언에 결합하여 문법적 기능을 부여하는 형태소      "
  },
  
  {
    "title": "Regular Expression",
    "url": "/posts/regular-expression/",
    "categories": "4.MODALITY, 1.netural language processing",
    "tags": "modality, nlp",
    "date": "2024-08-12 00:00:00 +0900",
    





    
    "snippet": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                   ...",
    "content": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                      .          개행 문자(\\n) 를 제외하고 공백을 포함한 모든 문자                          \\s          탭(\\t), 개행 문자(\\n)                          \\d          숫자                          \\D          \\d 의 검사 범위를 제외한 모든 문자                          \\w          알파벳 대소문자와 언더바(_)                          \\W          \\w 의 검사 범위를 제외한 모든 문자                          검사 범위 수동 지정                            패턴          설명                                      [xyz]          x, y, z 중 하나                          [^xyz]          x, y, z 를 제외한 모든 문자 중 하나                          (xyz)          xyz 매칭                          (?:xyz)          xyz 매칭                          x|yz          x 또는 yz                          검사 위치 지정                            패턴          설명                                      ^          첫 번째 줄의 시작                          $          마지막 줄의 끝                          \\b          경계 문자                          \\B          경계 문자                          (?=)          긍정형 전방 탐색                          (?!)          부정형 전방 탐색                          (?&lt;=)          긍정형 후방 탐색                          (?&lt;!)          부정형 후방 탐색                          수량 지정                            패턴          설명                                      *          $0$ 개 이상                          +          $1$ 개 이상                          ?          $0$ 또는 $1$                          {n}          $n$ 개                          {n,}          $n$ 개 이상                          {,n}          $n$ 개 이하                          {m,n}          $m$ 개 이상 $n$ 개 이하                    Python Package re      re.compile(pattern)      import re  pattern = ...  p = re.compile(pattern, option)              option                  None          re.DOTALL : 개행 문자(\\n)를 무시하고 매칭함          re.IGNORECASE : 대소문자 구분 없이 매칭함          re.MULTILINE : 문자열의 각 줄마다 매칭함                          p.match(my_str) : 문자열 처음부터 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.match(my_str)              result.group() : 매칭된 문자열을 반환함      result.start() : 매칭된 문자열의 시작 위치를 반환함      result.end() : 매칭된 문자열의 끝 위치를 반환함      result.span() : 매칭된 문자열의 (시작 위치, 끝 위치) 를 튜플로 반환함            p.search(my_str) : 문자열 전체를 탐색하여 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.search(my_str)            p.findall(my_str) : 정규표현식과 매칭되는 모든 문자열을 반환함      my_str = ...  result = p.findall(my_str)            p.finditer(my_str) : 정규표현식과 매칭되는 모든 문자열을 반복 가능한 객체(iterator)로 반환함      my_str = ...  result = p.finditer(my_str)            p.sub(re_str, my_str) : 정규표현식과 매칭되는 모든 문자열을 다른 문자열로 수정함      my_str = ...  re_str = ...  result = p.sub(re_str, my_str)      Matching Rule of PythonForward Orderpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            1efG 매칭            추가 매칭되는 문자열 없음      Excluding the Prior Matchedpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efCefGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            먼저 매칭된 문자열을 제외하고 탐색하므로 CefG 는 포함되지 않음      Greedypattern = '[a-zA-Z0-9]+ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      If Python is not Greedy            But Python is Greedy      Exploration      긍정형 전방 탐색 B(?=A) : Pattern A 의 시작점 이전 지점에서 Pattern B 를 탐색함      pattern = '[a-zA-Z0-9]+(?=efg)'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                긍정형 후방 탐색 (?&lt;=A)B : Pattern A 의 끝점 이후 지점에서 Pattern B 를 탐색함      pattern = '(?&lt;=efg)[a-zA-Z0-9]+'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                부정형 전방 탐색 B(?!A) : Pattern A 의 시작점을 제외한 지점에서 Pattern B 를 탐색함      pattern = '[a-zA-Z0-9]+(?!efg)'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                부정형 후방 탐색 (?&lt;!A)B : Pattern A 의 끝점을 제외한 지점에서 Pattern B 를 탐색함      pattern = '(?&lt;!efg)[a-zA-Z0-9]+'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)          Sourse  https://zephyrus1111.tistory.com/310"
  },
  
  {
    "title": "Variational AutoEncoder",
    "url": "/posts/vae/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, deep learning, neural networks, variational inference, unsupervised learning, latent factor, feature engineering, autoencoder, generative model, cv",
    "date": "2024-08-09 00:00:00 +0900",
    





    
    "snippet": "Variational AutoEncoder  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): ...",
    "content": "Variational AutoEncoder  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생하는 불확실성                  정보 불완전성(Data Uncertainty): 관측 데이터가 불완전하거나(Incomplete), 불충분하거나(Insufficient), 왜곡된(Distorted) 상황          파라미터 불확실성(Parameter Uncertainty): 주어진 모형 안에서 최적 파라미터를 유일하게 식별할 수 없는 문제          구조적 불확실성(Structural Uncertainty): 데이터 생성 메커니즘을 기술하는 함수 구조를 확신할 수 없어 특정 모형을 가정할 수 없는 문제          표현의 불확실성(Latent Representation Uncertainty): 잠재공간의 비식별성으로 인해 치역(관측값)만으로 정의역(잠재요인)을 유일하게 결정하여 표현할 수 없는 문제                    존재론적 불확실성(Ontic Uncertainty): 모형이 모사하고자 하는 실제 메커니즘이 본질적으로 불확실하여 정보가 증가하더라도 제거될 수 없는 불확실성            문제 의식: 확률적 경사하강법을 적용하여 표현의 불확실성을 효율적으로 수행할 수 있는 일반적인 방법론이 부재함          연속 잠재요인을 가지는 베이지안 모형에서 사후 분포는 대체로 비가해적임(Intractable). 즉, 해석적 표현이나 미분 가능한 형태의 표현을 구하기 어려움. 이를 근사하기 위한 몬테-카를로 시뮬레이션 기반 근사 방법은 역전파 학습을 적용할 수 없거나(MCMC), 분산이 매우 커서 추정이 불안정함(VI).            변분 오토인코더(Variational AutoEncoder; VAE) : 오토인코더 아키텍처의 잠재 공간을 확률변수화하여 표현의 불확실성을 모델링하되, 재매개변수화 트릭(Reparameterization Trick) 을 적용하여 잠재요인의 근사 분포(Encoder)와 우도(Decoder) 학습을 확률적 경사하강법(Stochastic Gradient Variational Bayes) 을 통해 수행하는 생성 모형(Generative Model)          Variational Inference      Reparameterization Trick      How to ModelingModified Architecture\\[\\begin{gathered}X \\xrightarrow{\\text{Encoder}} Z \\xrightarrow{\\text{Decoder}} \\hat{X}\\\\\\Downarrow\\\\X \\xrightarrow{\\text{Encoder}} Q(Z \\mid X) \\xrightarrow{\\text{Decoder}} P(X \\mid Z)\\end{gathered}\\]      encoder module, which reduces the obs $X \\in \\mathbb{R}^{N}$ to latent factor dimensions $Z \\in \\mathbb{R}^{M}(M\\ll N)$, is approx. estimator:\\[Z=F(X;\\phi)\\quad\\Longrightarrow\\quad Q\\left(Z\\mid X;\\phi\\right)\\approx P(Z\\mid X)\\]        latent space is approx. conditional on obs:\\[Z\\quad\\Longrightarrow\\quad Z\\mid X\\]        decoder module, which reconstruct obs $\\hat{X}$ from latent factor $Z$, is likelihood estimator:\\[\\hat{X}=G(Z;\\theta)\\quad\\Longrightarrow\\quad P\\left(X\\mid Z;\\theta \\right)\\]  Stochastic Gradient Variational Bayes      prior is multi-variate gaussian dist.:\\[\\begin{aligned}  Z \\sim \\mathcal{N}(0,\\sigma^{2}\\mathbf{I})\\quad\\Leftrightarrow\\quad Z_{i}\\perp Z_{j}  \\end{aligned}\\]        posterior is approximated by latent space:\\[\\begin{aligned}  P(Z \\mid X)  \\propto \\underbrace{P(X\\mid Z)}_{\\text{est. by decoder}}P(Z)  \\approx \\underbrace{Q(Z \\mid X)}_{\\text{est. by encoder}}  \\end{aligned}\\]        Reparameterization Trick is a technique that transforms the sampling process from an approximate distribution into a differentiable function:\\[\\begin{gathered}  Z_{i} \\sim \\mathcal{N}(\\mu_{i},\\sigma_{i}^{2})\\\\  \\Downarrow\\\\  Z_{i} = \\mu_{i} + \\sigma_{i} \\cdot \\epsilon_{i}, \\quad \\epsilon_{i} \\sim \\mathcal{N}(0,1)  \\end{gathered}\\]        ELBO with reparameterization trick can be applied to stochastic gradient descent:\\[\\begin{aligned}  \\mathrm{ELBO}  :=\\mathbb{E}_{Z\\sim Q}\\left[\\log{p(X\\mid Z ; \\theta)}\\right]-D_{KL}\\left[q(Z;\\phi)\\parallel p(Z)\\right]  \\end{aligned}\\]  Source  https://velog.io/@jochedda/%EB%94%A5%EB%9F%AC%EB%8B%9D-Autoencoder-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EC%A2%85%EB%A5%98"
  },
  
  {
    "title": "BNNs (2) Monte Carlo Dropout",
    "url": "/posts/mc_dropout/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, deep learning, neural networks, variational inference",
    "date": "2024-08-08 00:00:00 +0900",
    





    
    "snippet": "Monte Carlo Dropout  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불...",
    "content": "Monte Carlo Dropout  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생하는 불확실성                  정보 불완전성(Data Uncertainty): 관측 데이터가 불완전하거나(Incomplete), 불충분하거나(Insufficient), 왜곡된(Distorted) 상황          파라미터 불확실성(Parameter Uncertainty): 주어진 모형 안에서 최적 파라미터를 유일하게 식별할 수 없는 문제          구조적 불확실성(Structural Uncertainty): 데이터 생성 메커니즘을 기술하는 함수 구조를 확신할 수 없어 특정 모형을 가정할 수 없는 문제          표현의 불확실성(Latent Representation Uncertainty): 잠재공간의 비식별성으로 인해 치역(관측값)만으로 정의역(잠재요인)을 유일하게 결정하여 표현할 수 없는 문제                    존재론적 불확실성(Ontic Uncertainty): 모형이 모사하고자 하는 실제 메커니즘이 본질적으로 불확실하여 정보가 증가하더라도 제거될 수 없는 불확실성            문제 의식                  모형의 불확실성(Model Uncertainty):                  인공신경망 알고리즘은 파라미터 수가 매우 많아 과적합 문제(Overfitting) 에서 자유롭지 못함. 여기서 과적합이란, 모형의 복잡도가 데이터 셋이 제공하는 정보량보다 심화되어 발생하는 현상임. 이는 정보가 부족한 상황에서 단일 가설을 확신하여 예측하는 과신의 문제(Overconfidence) 에서 비롯함.                            계산 복잡도(Computational Cost):                  과신의 문제를 직접 다루는 베이즈 추론을 신경망에 적용하는 경우 계산 복잡도 문제에서 자유로울 수 없음. 가령 Bayes by Backprop 의 경우 파라미터마다 평균과 분산을 각각 계산해야 하므로 추론해야 하는 파라미터 수가 결정론적 신경망의 두 배가 됨.                          MC Dropout(Monte-Carlo Dropout): 드롭아웃이 적용된 인공신경망의 가우시안 프로세스의 유한 차원 근사임을 증명하여 결정론적 신경망과 동일한 비용으로 불확실성 모델링이 가능함을 확인함      1 layer nn analysis      1 layer nn:\\[\\begin{aligned}  f(x)  &amp;:=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{w_{i}\\sigma(v_{i}x)}  \\end{aligned}\\]          $v_{i}$: input -&gt; hidden weight      $\\sigma$: activation function      $w_{i}$: hidden -&gt; output weight      $N$: num of node unit            therefore 1 layer nn can be considered as an element on the function space consisting of a basis function, $\\phi_{i}(x):=\\sigma(v_{i}x)$.\\[\\begin{aligned}  f(\\cdot)\\in\\mathcal{F}:=\\mathrm{span}\\{\\phi_{1}(\\cdot),\\phi_{2}(\\cdot),\\cdots,\\phi_{N}(\\cdot)\\}  \\end{aligned}\\]        apply dropout mask $m_{i}$ to weight $w_{i}$:\\[\\begin{aligned}  \\beta_{i}  &amp;=w_{i} \\cdot m_{i} \\quad  m_{i}\\sim\\mathrm{Bernoulli}(p)\\\\  &amp;=\\begin{cases}w_{i},\\quad &amp;p\\\\0,\\quad &amp;1-p\\end{cases}  \\end{aligned}\\]        since the function value $f(x)$ is a sum of random features $\\beta_{i}\\phi_{i}(x)$, $\\beta_{i}\\phi_{i}(x)$, it becomes a random variable.\\[\\begin{aligned}  \\therefore f(x)  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)}  \\end{aligned}\\]  Lindeberg-Feller CLT      Lindeberg-Feller CLT:          합계 변수 $f:=\\sum_{i=1}^{N}{X_{i}}$ 에 대하여 (1) 개별 변수 $X_{i}$ 가 상호 독립이고($X_{i}\\perp X_{j}$), (2) 개별 변수 $X_{i}$ 의 분산이 유한하며($\\mathrm{Var}\\left[X_{i}\\right]&lt;\\infty$), (3) 합계 변수 $f$ 의 분산이 유한하다면($\\mathrm{Var}\\left[f\\right]&lt;\\infty$), 합계 변수 $f$ 의 분포는 $N\\to\\infty$ 일 때 $X_{i}$ 의 분포와 상관없이 가우시안 분포에 근사한다($f\\sim\\mathcal{N}$).            independence condition:\\[\\beta_{i}\\phi_{i}(x) \\perp \\beta_{j}\\phi_{j}(x)\\]          $v_{i}\\perp v_{j}$ (input weight)      $w_{i}\\perp w_{j}$ (output weight)      $m_{i}\\perp m_{j}$ (dropout weight)            finiteness of individual variance:\\[\\begin{aligned}  \\mathrm{Var}\\left[\\frac{1}{\\sqrt{N}}\\beta_{i}\\phi_{i}(x)\\right]  &amp;= \\frac{1}{N}\\phi_{i}^{2}(x)\\cdot w_{i}^{2}\\cdot p(1-p) &lt; \\infty  \\end{aligned}\\]        finite convergence of total variance:\\[\\begin{aligned}  \\lim_{N\\to\\infty}{\\mathrm{Var}\\left[f(x)\\right]}  &amp;=\\lim_{N\\to\\infty}{\\frac{1}{N}\\sum_{i=1}^{N}{\\phi_{i}^{2}(x)\\cdot w_{i}^{2}\\cdot p(1-p)}} &lt; \\infty  \\end{aligned}\\]        conclusion:\\[\\begin{aligned}  f(x) \\overset{N\\to\\infty}{\\sim} \\mathcal{N}  \\end{aligned}\\]  gaussian process      gaussian process:          임의의 입력 집합 $x_{1},x_{2},\\cdots,x_{N}$ 위에 정의된 함수 $f(\\cdot)$ 의 함수값 $f(x)$ 이 다변량 가우시안 분포 $\\mathcal{N}(M(X),K_{XX})$ 를 따른다고 하자. 함수 $f(\\cdot)$ 는 평균 함수 $m(\\cdot)$ 와 공분산 함수 $k(\\cdot,\\cdot)$ 으로 정의되는 함수 분포 $\\mathcal{GP}(m(\\cdot),k(\\cdot,\\cdot))$ 를 따르는 확률변수가 된다. 이때 분포 파라미터 $m(\\cdot)$, $k(\\cdot,\\cdot)$ 는 사전 정보에 의해 정의되며, 관측 데이터가 주어질 경우 베이즈 갱신 규칙에 따라 사후 분포로 갱신된다.            mean:\\[\\begin{aligned}  \\mathbb{E}\\left[f(x)\\right]  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{w_{i}p\\phi_{i}(x)}  \\end{aligned}\\]        covariance:\\[\\begin{aligned}  \\mathrm{Cov}\\left[f(x),f(x^{\\prime})\\right]  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{w_{i}^{2}p(1-p)\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  &amp;=\\sum_{i=1}^{N}{\\underbrace{\\frac{1}{N}w_{i}^{2}p(1-p)}_{=:\\lambda_{i}}\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  &amp;=k(x,x^{\\prime})\\quad\\because\\text{Mercer's theorem}  \\end{aligned}\\]        as a result, 1 layer nn $f(\\cdot)$ to which dropout is applied becomes a random variable of the function dist.\\[\\begin{aligned}  f(\\cdot)\\sim\\mathcal{GP}(m(\\cdot),k(\\cdot,\\cdot))  \\end{aligned}\\]        1 layer nn $f(\\cdot)$ becomes an element within the function space $\\mathcal{F}$:\\[\\begin{aligned}  f(\\cdot)\\in\\mathcal{F}  :=\\mathrm{span}\\left\\{\\phi_{1}(\\cdot),\\phi_{2}(\\cdot),\\cdots,\\phi_{N}(\\cdot)\\right\\}  \\end{aligned}\\]  ELBO      original ELBO:\\[\\begin{aligned}  \\mathrm{ELBO}  = \\mathbb{E}_{f \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid f)}\\right] - D_{KL}\\left[Q(f) \\parallel P(f)\\right]  \\end{aligned}\\]        proxy variable of $f(x)$:          \\(f(x)\\) 는 비선형 함수이기 때문에 확률 분포를 정의하기 어렵다. 다만, 입력 집합 \\(\\{x_{i}\\}_{i=1}^{M}\\) 에 대한 함수값 벡터 \\(\\mathbf{f}_{X}:=\\{f(x_{i})\\}_{i=1}^{M}\\) 의 분포는 \\(\\beta\\) 의 분포 \\(p(\\beta)\\) 를 선형 변환 \\(T_{X}:=1/\\sqrt{N}\\{\\phi_{j}(x_{i})\\}_{i,j=1}^{M,N}\\) 을 통해 보낸(pushforward) 분포로 표현될 수 있다. 따라서 \\(f(x)\\) 에 확률성을 부여하는 가중치 \\(\\beta\\) 를 \\(f(x)\\) 의 대리변수로서 정의한다.    \\[\\begin{aligned}  \\mathbf{f}_{X}=\\frac{1}{\\sqrt{N}}\\Phi_{X}^{T}\\beta=T_{X}(\\beta)  \\quad\\Rightarrow\\quad  p(\\mathbf{f}_{X})=(T_{X})_{\\#}p(\\beta)  \\end{aligned}\\]        approx.:\\[\\begin{aligned}  Q(\\beta)  =\\mathrm{Bernoulli}(p;W,0)  \\end{aligned}\\]        prior:\\[\\begin{aligned}  P(\\beta)  =\\mathcal{N}\\left(0, \\sigma^{2}\\mathbf{I}\\right)  \\end{aligned}\\]        KL Divergence:\\[\\begin{aligned}  D_{KL}\\left[Q\\parallel P\\right]  &amp;=p\\log{\\frac{p}{P(W)}}+(1-p)\\log{\\frac{1-p}{P(0)}}  \\end{aligned}\\]        because prior is gaussian dist.:\\[\\begin{aligned}  P(W)  &amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp{-\\frac{1}{2\\sigma^{2}}\\Vert W\\Vert^{2}}\\\\  P(0)  &amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma}  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  \\therefore D_{KL}\\left[Q\\parallel P\\right]  &amp;=\\underbrace{p\\log{p}+(1-p)\\log{(1-p)}}_{\\text{entropy}} + \\underbrace{\\frac{1}{2}\\log{2\\pi\\sigma^{2}}}_{\\text{const.}} + \\frac{p}{2\\sigma^{2}}\\Vert W\\Vert^{2}\\\\  &amp;\\approx\\frac{p}{2\\sigma^{2}}\\Vert W\\Vert^{2}  \\end{aligned}\\]        final objective function:\\[\\begin{aligned}  \\mathrm{ELBO}  = \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - \\Lambda_{W}\\Vert W\\Vert^{2}  \\end{aligned}\\]  calculation      seperation:\\[\\begin{aligned}  f(x)  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)}\\\\  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]+\\left(\\beta_{i}\\phi_{i}(x)-\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]\\right)}\\\\  &amp;=\\underbrace{\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]}}_{\\text{deterministic mean}}+\\underbrace{\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)-\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]}}_{\\text{stochastic variance}}  \\end{aligned}\\]  mean      mean of $\\beta_{i}$:\\[\\begin{aligned}  \\mathbb{E}\\left[\\beta_{i}\\right]  &amp;=\\mathbb{E}\\left[w_{i} \\cdot m_{i}\\right]\\\\  &amp;=w_{i} \\cdot \\mathbb{E}\\left[m_{i}\\right]\\\\  &amp;=w_{i}\\cdot p\\\\  \\end{aligned}\\]        mean of $\\beta_{i}\\phi_{i}(x)$:\\[\\begin{aligned}  \\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]  &amp;=\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]\\\\  &amp;=\\mathbb{E}\\left[\\beta_{i}\\right]\\cdot\\phi_{i}(x)\\quad\\because\\text{$\\phi_{i}(x)$ is deterministic}\\\\  &amp;=w_{i}p\\cdot\\phi_{i}(x)  \\end{aligned}\\]        mean of $f(x)$:\\[\\begin{aligned}  \\mathbb{E}\\left[f(x)\\right]  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]}\\\\  &amp;=\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{w_{i}p\\phi_{i}(x)}  \\end{aligned}\\]  variance      variance of $\\beta_{i}$:\\[\\begin{aligned}  \\mathbb{E}\\left[\\beta_{i}\\right]  &amp;=\\mathbb{E}\\left[w_{i} \\cdot m_{i}\\right]\\\\  &amp;=w_{i} \\cdot \\mathbb{E}\\left[m_{i}\\right]\\\\  &amp;=w_{i}\\cdot p\\\\  \\\\  \\mathbb{E}\\left[\\beta_{i}^{2}\\right]  &amp;=\\mathbb{E}\\left[w_{i}^{2} \\cdot m_{i}^{2}\\right]\\\\  &amp;=w_{i}^{2}\\cdot\\mathbb{E}\\left[m_{i}^{2}\\right]\\\\  &amp;=w_{i}^{2}\\cdot\\mathbb{E}\\left[m_{i}\\right]\\quad\\because m_{i}^{2}=m_{i}\\\\  &amp;=w_{i}^{2}\\cdot p\\\\  \\\\  \\therefore\\mathrm{Var}\\left[\\beta_{i}\\right]  &amp;=\\mathbb{E}\\left[\\beta_{i}^{2}\\right]-\\left(\\mathbb{E}\\left[\\beta_{i}\\right]\\right)^{2}\\\\  &amp;=w_{i}^{2}\\cdot p - \\left(w_{i}\\cdot p\\right)^{2}\\\\  &amp;=w_{i}^{2}\\cdot p(1-p)  \\end{aligned}\\]        variance of $\\beta_{i}\\phi_{i}(x)$:\\[\\begin{aligned}  \\mathrm{Var}\\left[\\beta_{i}\\phi_{i}(x)\\right]  &amp;=\\mathrm{Var}\\left[\\beta_{i}\\phi_{i}(x)\\right]\\\\  &amp;=\\phi_{i}^{2}(x)\\cdot\\mathrm{Var}\\left[\\beta_{i}\\right]\\quad\\because\\text{$\\phi_{i}$ is deterministic}\\\\  &amp;=\\phi_{i}^{2}(x)\\cdot w_{i}^{2}\\cdot p(1-p)  \\end{aligned}\\]        variance of $f(x)$:\\[\\begin{aligned}  \\mathrm{Var}\\left[f(x)\\right]  &amp;=\\mathrm{Var}\\left[\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)-\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]}\\right]\\quad\\because\\text{$\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]}$ is deterministic}\\\\  &amp;=\\mathrm{Var}\\left[\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)}\\right]\\quad\\because\\text{$\\mathbb{E}\\left[\\beta_{i}\\phi_{i}(x)\\right]$ is constant}\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{\\mathrm{Var}\\left[\\beta_{i}\\phi_{i}(x)\\right]}\\quad\\because\\beta_{i}\\phi_{i}(x)\\perp\\beta_{j}\\phi_{j}(x)\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{\\phi_{i}^{2}(x)\\cdot w_{i}^{2}\\cdot p(1-p)}  \\end{aligned}\\]  covariance      component $\\mathbb{E}\\left[f(x)f(x^{\\prime})\\right]$:\\[\\begin{aligned}  f(x)f(x^{\\prime})  &amp;=\\left(\\frac{1}{\\sqrt{N}}\\sum_{i=1}^{N}{\\beta_{i}\\phi_{i}(x)}\\right)\\left(\\frac{1}{\\sqrt{N}}\\sum_{j=1}^{N}{\\beta_{j}\\phi_{j}(x^{\\prime})}\\right)\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}{\\beta_{i}\\beta_{j}\\phi_{i}(x)\\phi_{j}(x^{\\prime})}\\\\  \\therefore\\mathbb{E}\\left[f(x)f(x^{\\prime})\\right]  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\beta_{j}\\right]\\phi_{i}(x)\\phi_{j}(x^{\\prime})}\\\\  &amp;=\\frac{1}{N}\\sum_{i=j}{\\mathbb{E}\\left[\\beta_{i}^{2}\\right]\\phi_{i}(x)\\phi_{i}(x^{\\prime})}+\\frac{1}{N}\\sum_{i\\ne j}{\\mathbb{E}\\left[\\beta_{i}\\right]\\mathbb{E}\\left[\\beta_{j}\\right]\\phi_{i}(x)\\phi_{j}(x^{\\prime})}\\quad\\mathrm{s.t.}\\quad\\beta_{i}\\perp\\beta_{j}  \\end{aligned}\\]        component $\\mathbb{E}\\left[f(x)\\right]\\mathbb{E}\\left[f(x^{\\prime})\\right]$:\\[\\begin{aligned}  \\mathbb{E}\\left[f(x)\\right]\\mathbb{E}\\left[f(x^{\\prime})\\right]  &amp;=\\left(\\frac{1}{\\sqrt{N}}{\\sum_{i=1}^{N}{\\mathbb{E}\\left[\\beta_{i}\\right]\\phi_{i}(x)}}\\right)\\left(  \\frac{1}{\\sqrt{N}}{\\sum_{j=1}^{N}{\\mathbb{E}\\left[\\beta_{j}\\right]\\phi_{j}(x^{\\prime})}}\\right)\\\\  &amp;=\\frac{1}{N}\\sum_{i=j}{\\mathbb{E}\\left[\\beta_{i}\\right]^{2}\\phi_{i}(x)\\phi_{i}(x^{\\prime})}+\\frac{1}{N}\\sum_{i\\ne j}{\\mathbb{E}\\left[\\beta_{i}\\right]\\mathbb{E}\\left[\\beta_{j}\\right]\\phi_{i}(x)\\phi_{j}(x^{\\prime})}  \\end{aligned}\\]        covariance of $f(x),f(x^{\\prime})$:\\[\\begin{aligned}  \\mathrm{Cov}\\left[f(x),f(x^{\\prime})\\right]  &amp;=\\mathbb{E}\\left[f(x)f(x^{\\prime})\\right]-\\mathbb{E}\\left[f(x)\\right]\\mathbb{E}\\left[f(x^{\\prime})\\right]\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{\\left(\\mathbb{E}\\left[\\beta_{i}^{2}\\right]-\\mathbb{E}\\left[\\beta_{i}\\right]^{2}\\right)\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{\\mathrm{Var}\\left[\\beta_{i}\\right]\\phi_{i}(x)\\phi_{i}(x^{\\prime})}\\\\  &amp;=\\frac{1}{N}\\sum_{i=1}^{N}{w_{i}^{2}p(1-p)\\phi_{i}(x)\\phi_{i}(x^{\\prime})}  \\end{aligned}\\]  "
  },
  
  {
    "title": "BNNs (1) Bayes by Backprop",
    "url": "/posts/bbb/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, deep learning, neural networks, variational inference",
    "date": "2024-08-07 00:00:00 +0900",
    





    
    "snippet": "Bayes by Backprop  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불완전...",
    "content": "Bayes by Backprop  불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태                  우발적 불확실성(Aleatoric Uncertainty): 관측치에 내재된 잡음 혹은 무작위성으로 인해 발생하는 불확실성            인식적 불확실성(Epistemic Uncertainty): 정보 불완전성으로 인하여 발생하는 불확실성                  정보 불완전성(Data Uncertainty): 관측 데이터가 불완전하거나(Incomplete), 불충분하거나(Insufficient), 왜곡된(Distorted) 상황          파라미터 불확실성(Parameter Uncertainty): 주어진 모형 안에서 최적 파라미터를 유일하게 식별할 수 없는 문제          구조적 불확실성(Structural Uncertainty): 데이터 생성 메커니즘을 기술하는 함수 구조를 확신할 수 없어 특정 모형을 가정할 수 없는 문제          표현의 불확실성(Latent Representation Uncertainty): 잠재공간의 비식별성으로 인해 치역(관측값)만으로 정의역(잠재요인)을 유일하게 결정하여 표현할 수 없는 문제                    존재론적 불확실성(Ontic Uncertainty): 모형이 모사하고자 하는 실제 메커니즘이 본질적으로 불확실하여 정보가 증가하더라도 제거될 수 없는 불확실성            문제 의식                  모형의 불확실성(Model Uncertainty):                  인공신경망 알고리즘은 파라미터 수가 매우 많아 과적합 문제(Overfitting) 에서 자유롭지 못함. 여기서 과적합이란, 모형의 복잡도가 데이터 셋이 제공하는 정보량보다 심화되어 발생하는 현상임. 이는 정보가 부족한 상황에서 단일 가설을 확신하여 예측하는 과신의 문제(Overconfidence) 에서 비롯함.                            사후 분포 계산의 비가용성(intractable):                  과신의 문제를 직접 다루는 베이즈 추론을 신경망에 적용하기에는 사후 분포의 계산이 비가용적임. 다시 말해, 계산 복잡도가 너무 크거나, 해석적으로(analytic) 닫힌형 표현을 얻을 수 없음. 사후 분포 근사 기법인 MCMC, VI 등은 샘플링 과정이 미분 가능하지 않기 때문에 역전파 학습 적용이 불가능함.                          BBB(Bayes by Backprop): 인공신경망의 가중치에 불확실성을 반영하여 데이터에 대한 설명력을 확보하는 동시에(Likelihood) 사전 정보(Prior)를 활용하여 모형의 복잡도를 제어함으로써(Kullback–Leibler divergence) 일반화 성능을 향상시키는 학습 방법론          Variational Inference      Factorized Gaussian      Scale Mixture Gaussian      Reparameterization Trick      How to Modeling      Factorized Gaussian is used as the approx. This allows the multivariate Gaussian distribution to be decomposed into the product of independent terms, thereby improving computational efficiency.\\[\\begin{aligned}  Q(\\mathbf{w})  &amp;=\\mathcal{N}(\\mu,\\sigma^{2}\\mathbf{I})\\\\  &amp;=\\prod_{d=1}^{D}{\\mathcal{N}(w_{d};\\mu_{d},\\rho)} \\quad \\mathrm{s.t.}\\quad w_{i} \\perp w_{j}\\\\  \\sigma_{d}  &amp;=\\log{\\left[1+\\exp{\\rho_{d}}\\right]}  \\end{aligned}\\]        By using a scale mixture Gaussian as a prior, noise parameters are removed while the valid signal is preserved, achieving both sparsity and expressiveness.\\[\\begin{aligned}  P(\\mathbf{w})  &amp;=\\pi \\cdot \\mathcal{N}(0,\\sigma_{1}^{2}) + (1-\\pi) \\cdot \\mathcal{N}(0,\\sigma_{2}^{2})  \\end{aligned}\\]        Reparameterization Trick is a technique that transforms the sampling process from an approximate distribution into a differentiable function:\\[\\begin{gathered}  w_{i} \\sim \\mathcal{N}(\\mu_{i},\\sigma_{i}^{2})\\\\  \\Downarrow\\\\  w_{i} = \\mu_{i} + \\sigma_{i} \\cdot \\epsilon_{i}, \\quad \\epsilon_{i} \\sim \\mathcal{N}(0,1)  \\end{gathered}\\]        Variational Inference:\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]  "
  },
  
  {
    "title": "Bayesian Regression (2) Subjective Prior",
    "url": "/posts/bayesian_regression_2/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, regression analysis, linear regression analysis, numerical data analysis",
    "date": "2024-08-06 00:00:00 +0900",
    





    
    "snippet": "        Bayesian Regression ModelLiklihood Function      다중선형회귀모형의 우도 함수:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{b}, \\sigma^2)  &amp;= (2\\pi\\sigma^{2})^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}...",
    "content": "        Bayesian Regression ModelLiklihood Function      다중선형회귀모형의 우도 함수:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{b}, \\sigma^2)  &amp;= (2\\pi\\sigma^{2})^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right]} \\quad (\\because \\mathbf{y} \\sim \\mathcal{N}(\\mathbf{X}\\mathbf{b}, \\sigma^{2}\\mathbf{I}))\\\\  &amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right]}  \\end{aligned}\\]  Setting Conjugate Prior\\[p(\\mathbf{b}, \\sigma^{2}) = p(\\mathbf{b} \\mid \\sigma^{2}) \\cdot p(\\sigma^{2})\\]      Conjugate Prior of $\\sigma^{2}$ is Scaled Inverse Chi-Squared Distribution\\[\\begin{gathered}  p(\\sigma^{2})  \\propto (\\sigma^{2})^{-\\nu_{0}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot \\nu_{0} s_{0}^{2}\\right]}\\\\  \\therefore \\sigma^{2} \\sim \\text{Scaled Inv-}\\chi^2(\\nu_{0}, s_{0}^{2})  \\end{gathered}\\]          $\\nu_{0}$ : 사전 자유도      $s_{0}^{2}$ : 사전 잔차 분산            Conjugate Prior of $\\beta$ given $\\sigma^{2}$ is Normal Distribution\\[\\begin{gathered}  p(\\mathbf{b} \\mid \\sigma^{2})  \\propto (\\sigma^{2})^{-(n-\\nu_{0})/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{b}-\\mu_{0})^{T}\\Lambda_{0}(\\mathbf{b}-\\mu_{0})\\right]}\\\\  \\therefore \\mathbf{b} \\mid \\sigma^{2} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2}\\Lambda_{0}^{-1})  \\end{gathered}\\]          $\\mu_{0}$ : $\\mathbf{b}$ 의 사전 평균      $\\sigma^{2}\\Lambda_{0}^{-1}$ : $\\mathbf{b}$ 의 사전 공분산 행렬      Posterior Estimation\\[\\begin{aligned}p(\\mathbf{b}, \\sigma^{2} \\mid \\mathcal{D})&amp;\\propto \\mathcal{L}(\\mathbf{b}, \\sigma^{2}) \\cdot p(\\mathbf{b}, \\sigma^{2})\\\\&amp;\\propto (\\sigma^{2})^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right]} \\times (\\sigma^{2})^{-\\nu_{n}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot \\nu_{n} s_{n}^{2}\\right]} \\times (\\sigma^{2})^{-(n-\\nu_{n})/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{b}-\\mu_{n})^{T}\\Lambda_{n}(\\mathbf{b}-\\mu_{n})\\right]}\\\\&amp;= (\\sigma^2)^{-(n+\\nu_{n})/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\left(\\nu_{n} s_{n}^{2} + (\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right)\\right]} \\times (\\sigma^{2})^{-(n-\\nu_{n})/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{b}-\\mu_{n})^{T}\\Lambda_{n}(\\mathbf{b}-\\mu_{n})\\right]}\\end{aligned}\\]      Posterior of $\\sigma^2$ is Inverse-Gamma Distribution\\[\\begin{gathered}  p(\\sigma^{2} \\mid \\mathcal{D})  \\propto (\\sigma^2)^{-(n+\\nu_{n})/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\left(\\nu_n s_{n}^{2} + (\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right)\\right]}\\\\  \\therefore \\sigma^{2} \\mid \\mathcal{D}  \\sim \\text{Inv-Gamma}\\left(\\frac{n + \\nu_{n}}{2}, \\frac{1}{2} \\left[\\nu_{n} s_{n}^{2} + (\\mathbf{y} - \\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y} - \\mathbf{X}\\mathbf{b})\\right]\\right)  \\end{gathered}\\]          $\\nu_{n}$ : 사후 자유도      $s_{n}^{2}$ : 사후 잔차 분산            Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{gathered}  p(\\mathbf{b}\\mid\\sigma^{2},\\mathcal{D})  \\propto (\\sigma^{2})^{-(n-\\nu_{n})/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot(\\mathbf{b}-\\mu_{n})^{T}\\Lambda_{n}(\\mathbf{b}-\\mu_{n})\\right]}\\\\  \\therefore \\mathbf{b}\\mid\\sigma^{2},\\mathcal{D}  \\sim \\mathcal{N}(\\mu_{n}, \\sigma^{2}\\Lambda_{n}^{-1})  \\end{gathered}\\]          $\\mu_{n}$ : $\\mathbf{b}$ 의 사후 평균      $\\sigma^{2}\\Lambda_{n}^{-1}$ : $\\mathbf{b}$ 의 사후 공분산 행렬      "
  },
  
  {
    "title": "Bayesian Regression (1) Objective Prior",
    "url": "/posts/bayesian_regression_1/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, regression analysis, linear regression analysis, numerical data analysis",
    "date": "2024-08-05 00:00:00 +0900",
    





    
    "snippet": "        Bayesian Regression ModelLiklihood Function Transformation      다중선형회귀모형의 우도 함수:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{b}, \\sigma^2)  &amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}...",
    "content": "        Bayesian Regression ModelLiklihood Function Transformation      다중선형회귀모형의 우도 함수:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{b}, \\sigma^2)  &amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right]} \\quad (\\because \\mathbf{y} \\sim \\mathcal{N}(\\mathbf{X}\\mathbf{b}, \\sigma^2\\mathbf{I}))\\\\  &amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})\\right]}  \\end{aligned}\\]        $(\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})$ 변형:\\[\\begin{aligned}  (\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})  &amp;= \\left[(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}}) + (\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})\\right]^{T}\\left[(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}}) + (\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})\\right]\\\\  &amp;= (\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}}) + (\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b}) + 2 \\cdot (\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})\\\\  \\\\  (\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})  &amp;= (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\\\  2 \\cdot (\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{X}\\hat{\\mathbf{b}}-\\mathbf{X}\\mathbf{b})  &amp;=0\\\\  \\\\  \\therefore (\\mathbf{y}-\\mathbf{X}\\mathbf{b})^{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{b})  &amp;= (\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}}) + (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\\\  \\end{aligned}\\]        우도 함수에 대입:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{b}, \\sigma^2)  &amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})\\right]} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\right]}\\\\  \\end{aligned}\\]        잔차 분산 및 자유도 정의:\\[\\begin{aligned}  s^{2}  &amp;= \\frac{1}{\\nu} \\cdot RSS\\\\  &amp;= \\frac{1}{\\nu} \\cdot (\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})^{T}(\\mathbf{y}-\\mathbf{X}\\hat{\\mathbf{b}})\\\\  \\nu  &amp;= n-k  \\end{aligned}\\]        우도 함수에 대입:\\[\\begin{aligned}  \\therefore \\mathcal{L}(\\mathbf{b}, \\sigma^{2})  &amp;\\propto (\\sigma^{2})^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot \\nu s^{2}\\right]} \\times (\\sigma^{2})^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\right]}  \\end{aligned}\\]  Prior Determination\\[\\begin{aligned}p(\\mathbf{b}, \\sigma^{2})&amp;= p(\\mathbf{b} \\mid \\sigma^{2}) \\cdot p(\\sigma^{2})\\\\&amp;= p(\\mathbf{b}) \\cdot p(\\sigma^{2}) \\quad (\\because \\text{i.i.d})\\\\&amp;= 1 \\times \\frac{1}{\\sigma^{2}}\\end{aligned}\\]      Jacobian Change of $\\sigma^2$ for Relaxing Range Constraints\\[\\begin{aligned}  \\psi  &amp;= \\log{\\sigma^{2}}\\\\  \\therefore p(\\sigma^{2})  &amp;= p(\\psi) \\cdot \\frac{1}{\\sigma^{2}}  \\end{aligned}\\]        Non-informative Prior Determination of $\\beta, \\psi$\\[\\mathbf{b}, \\psi \\sim \\text{Uniform}(0,1)\\]        Jeffreys Prior of $\\sigma^{2}$\\[\\begin{aligned}  p(\\sigma^{2})  = p(\\psi) \\cdot \\frac{1}{\\sigma^{2}}  = \\frac{1}{\\sigma^{2}}  \\end{aligned}\\]  Posterior Estimation\\[\\begin{aligned}p(\\mathbf{b}, \\sigma^{2} \\mid \\mathcal{D})&amp;\\propto \\mathcal{L}(\\mathbf{b}, \\sigma^{2}) \\cdot p(\\mathbf{b}, \\sigma^{2})\\\\\\&amp;\\propto (\\sigma^{2})^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot \\nu s^{2}\\right]} \\times (\\sigma^{2})^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}} \\cdot (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\right]} \\times \\frac{1}{\\sigma^{2}}\\\\&amp;= (\\sigma^{2})^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}}\\cdot \\nu s^{2}\\right]} \\times (\\sigma^{2})^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^{2}} \\cdot (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\right]}\\end{aligned}\\]      Marginal Posterior of $\\sigma^2$ is Inverse Chi-Squared Distribution\\[\\begin{gathered}  f(\\sigma^2 \\mid \\nu,s^2)  =(\\sigma^2)^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\  \\therefore \\sigma^2 \\mid \\mathcal{D}  \\sim \\text{Inv-}\\chi^2(\\nu,s^2)  \\end{gathered}\\]        Conditional Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{gathered}  f(\\mathbf{b} \\mid \\hat{\\mathbf{b}}, \\mathbf{V}_{\\beta})  = (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot (\\mathbf{b} - \\hat{\\mathbf{b}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\mathbf{b} - \\hat{\\mathbf{b}})\\right]}\\\\  \\therefore \\mathbf{b} \\mid \\sigma^{2}, \\mathcal{D}  \\sim \\mathcal{N}(\\hat{\\mathbf{b}}, \\sigma^2\\mathbf{V}_{\\beta})  \\end{gathered}\\]          $\\hat{\\mathbf{b}}=(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}$ : $\\mathbf{b}$ 의 최우추정량      $\\sigma^2\\mathbf{V}_{\\beta}=\\sigma^2(\\mathbf{X}^{T}\\mathbf{X})^{-1}$ : $\\mathbf{b}$ 의 공분산 행렬      "
  },
  
  {
    "title": "Naive Bayes",
    "url": "/posts/naive_bayes/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, categorical data analysis",
    "date": "2024-08-04 00:00:00 +0900",
    





    
    "snippet": "Naive Bayes      나이브 베이즈(Naive Bayes): 베이즈 정리에 기초하여 관측치의 범주를 판별하는 알고리즘            Class Conditional Independent Assumption:\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)  &amp;= P(X_{1} \\mid...",
    "content": "Naive Bayes      나이브 베이즈(Naive Bayes): 베이즈 정리에 기초하여 관측치의 범주를 판별하는 알고리즘            Class Conditional Independent Assumption:\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)  &amp;= P(X_{1} \\mid Y) \\times P(X_{2} \\mid Y) \\times \\cdots \\times P(X_{n} \\mid Y)  \\end{aligned}\\]  Decision Function      problem definition:\\[\\begin{aligned}  \\hat{Y}  &amp;= f(\\mathbf{x})\\\\  &amp;= \\text{arg} \\max_{Y}{P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          관측치 벡터 \\(\\mathbf{x}\\) 의 범주 \\(\\hat{Y}\\) 는 \\(\\mathbf{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 로 주어졌을 때, 범주 \\(Y\\) 가 \\(i=1,2,\\cdots\\) 일 확률이 최대인 \\(i\\) 임            By Bayes’ theorem:\\[\\begin{aligned}  &amp;P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          \\(P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 범주에 대한 사후 확률로서, 관측치 벡터 \\(\\mathbf{x}=(x_{1},x_{2},\\cdots,x_{n})\\) 가 주어졌을 때, 해당 관측치의 범주 \\(Y\\) 가 $i$ 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i)\\) : 관측치 범주에 대한 우도로서, 범주 \\(Y=i\\) 가 주어졌을 때, 관측치 벡터 \\(\\mathbf{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률      \\(P(Y=i)\\) : 관측치 범주에 대한 사전 확률로서, 범주 \\(Y\\) 가 \\(i\\) 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 범주에 대한 주장의 근거로서, 관측치 벡터 \\(\\mathbf{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률            Multivariate conditional probability can be converted to univariate conditional probability under class conditional independence assumption:\\[\\begin{aligned}  &amp;P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)\\\\  &amp;= P(X_{1} \\mid Y) \\times P(X_{2} \\mid Y) \\times \\cdots \\times P(X_{n} \\mid Y)  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  &amp;P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{\\sum_{j}P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=j)}\\\\  &amp;= \\frac{\\prod_{k=1}^{n}{P(X_{k}=x_{k} \\mid Y=i)} \\cdot P(Y=i)}{\\sum_{j}{\\prod_{k=1}^{n}{P(X_{k}=x_{k} \\mid Y=j)}}}  \\end{aligned}\\]  Laplace Smoothing      라플라스 평활화(Laplace Smoothing): 훈련 데이터 세트에 존재하지 않는 사례 \\(\\mathbf{x}_{k}\\) 에 대한 확률을 \\(0\\) 으로 부여하는 것을 방지하기 위한 기법\\[P(\\mathbf{x}_{k} \\mid Y)  = \\frac{\\text{Count}(\\mathbf{x}_{k},Y)+\\alpha}{\\text{Count}(Y)+2\\alpha}\\]          \\(P(\\mathbf{x}_{k} \\mid Y)\\) : 관측치 벡터 \\(\\mathbf{x}_{k}\\) 가 범주 \\(Y\\) 에 속할 조건부 확률      \\(\\text{Count}(\\mathbf{x}_{k},Y)\\) : 관측치 벡터 \\(\\mathbf{x}_{k}\\) 와 범주 \\(Y\\) 의 동시 출현 빈도      \\(\\text{Count}(Y)\\) : 범주 \\(Y\\) 의 출현 빈도      \\(\\alpha\\) : 라플라스 평활화 강도      Sourse  https://www.linkedin.com/pulse/naive-bayes-theorem-machine-learning-rohit-bele/"
  },
  
  {
    "title": "Multi Armed Bandits",
    "url": "/posts/multi_armed_bandits/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, multi armed bandits",
    "date": "2024-08-03 00:00:00 +0900",
    





    
    "snippet": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. ...",
    "content": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. 단, 슬롯 머신의 보상 확률은 알려져 있지 않다. 어떤 슬롯 머신을 고르는 것이 이득일까?            A/B Test vs. MAB                      A/B Test : 탐색 후 그 결과를 100% 활용하는 불연속적인(Discrete) 방법                  $n$ 개의 집단에 $n$ 개의 선택지를 노출하여 순수하게 새로운 가능성을 탐색(Exploration)한 후, 의사결정이 완료된 후에는 채택된 선택지를 모든 집단에 노출하여 활용함(Exploitation)                            MAB : 탐색과 활용을 동시에 수행하는 연속적인(Continuous) 방법                  고객의 피드백을 실시간으로 반영하며 각 선택지의 보상 확률을 갱신함으로써 열등한 선택지는 비교적 적게 노출하고 우월한 선택지는 비교적 많이 노출함                          Selection Issue : Exploration-Exploitation Trade-off              만약 적당히 좋은 결과를 돌려주는 슬롯 머신을 찾아냈다면, 그 결과를 유지하기 위해 그 슬롯 머신을 활용할 것인가(Exploitation) 아니면 더 좋은 결과를 얻을 수 있다는 희망으로 다른 슬롯 머신을 탐색할 것인가(Exploration)?              탐색(Exploration) : 다양한 슬롯 머신들을 선택하면서 보상이 어느 정도 도출되는지 탐색하는 과정      활용(Exploitation) : 수집된 정보를 바탕으로 보상 확률이 높은 슬롯 머신을 선택하는 과정      Selection Algorithms      Loss Function for MAB is Total Regret\\[\\begin{aligned}  \\mathcal{R}(T)  &amp;= \\sum_{t=1}^{T}{\\left[\\theta_{opt}-\\theta_{B(t)}\\right]}\\\\  &amp;= T \\cdot \\theta_{opt} - \\sum_{t=1}^{T}{\\theta_{B(t)}}  \\end{aligned}\\]          $B(t)$ : $t$ 번째 시점에서 선택한 슬롯 머신      $P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률 분포      $\\theta_{B(t)} \\sim P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률      $\\theta_{opt}$ : 최적 슬롯 머신의 보상 확률      Bayes Selection; Thompson Sampling      모든 슬롯 머신의 보상 확률에 대하여 사전 확률 분포 설정\\[\\begin{aligned} X \\mid \\theta &amp;\\sim \\text{Bin}(n,\\theta)\\\\ \\therefore \\theta &amp;\\sim \\text{Beta}(\\alpha_0,\\beta_0) \\end{aligned}\\]        보상 확률이 가장 높은 슬롯 머신 선택\\[B(t)=\\text{arg}\\max_{a}{\\theta_{a}}\\]        보상 관찰 후 해당 슬롯 머신의 사후 확률 분포 갱신\\[\\begin{aligned} \\theta_{B(t)} \\mid X &amp;\\sim \\text{Beta}(\\alpha, \\beta)\\\\ \\alpha &amp;= \\alpha_0 + X\\\\ \\beta &amp;= \\beta_0 - n + X \\end{aligned}\\]  Extra Selection Algorithms      Greedy : $t-1$ 번째 시점까지 탐색한 정보를 토대로 기대 보상이 가장 큰 슬롯 머신만을 활용하는 전략\\[\\begin{aligned}  B(t)  &amp;= \\text{arg}\\max_{a}{Q(a;t)}\\\\  &amp;= \\text{arg}\\max_{a}{\\frac{\\sum_{i=1}^{t-1}{\\tau_{i} \\cdot \\mathbb{I}\\left[B(i)=a\\right]}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}  \\end{aligned}\\]          $\\tau_{i}$ : $i$ 번째 시점에서 받은 보상      $\\mathbb{I}\\left[B(i)=a\\right]$ : Indicate Function            $\\varepsilon$-Greedy : $\\varepsilon$ 의 확률로 새로운 슬롯 머신을 탐색하는 전략\\[B(t)  = \\begin{cases}\\begin{aligned}  Q(a;t) \\quad &amp; \\text{with probability} \\; 1-\\varepsilon\\\\  \\text{random} \\quad &amp; \\text{with probability} \\; \\varepsilon  \\end{aligned}\\end{cases}\\]          $Q(a;t)$ : Exploitation Term      $\\text{random}$ : Exploration Term            UCB(Upper Confidence Bound) : 승률이 높은 슬롯 머신을 활용하면서, 승률의 불확실성이 높은 슬롯 머신을 탐색하는 전략\\[B(t)  =\\text{arg}\\max_{a}{\\left[Q(a;t) + c \\cdot \\sqrt{\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}\\right]}\\]          $Q(a;t)$ : Exploitation Term      $\\sqrt{\\displaystyle\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}$ : Exploration Term      $c$ : Exploration Constant      Source  https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/  https://link.springer.com/article/10.1007/s10489-023-04955-0?fromPaywallRec=false"
  },
  
  {
    "title": "Bayesian DiD",
    "url": "/posts/bayesian_did/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, design of experiments, did",
    "date": "2024-08-02 00:00:00 +0900",
    





    
    "snippet": "DiD      이중차분법(Difference-in-Differences; DiD): 평행 추세 가정 하에 정책 시행에 따른 인과적 효과를 반사실과의 추세 차이로써 추정하는 준실험설계법(Quasi-Experimental)        평행 추세 가정(Parallel Trends Assumption): 관측 불가능한 반사실(counterfactual),...",
    "content": "DiD      이중차분법(Difference-in-Differences; DiD): 평행 추세 가정 하에 정책 시행에 따른 인과적 효과를 반사실과의 추세 차이로써 추정하는 준실험설계법(Quasi-Experimental)        평행 추세 가정(Parallel Trends Assumption): 관측 불가능한 반사실(counterfactual), 즉 실험군이 실제로 정책이 적용되지 않은 상태를 대리하는 논리적 장치로서, 정책이 없었더라면 실험군의 추세는 통제군과 동일했을 것이라는 가정\\[\\begin{aligned}  \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0)-Y_{i,s}(0) \\mid D_{i}=1\\right]}_{\\text{experimental group}}  &amp;\\approx \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0)-Y_{i,s}(0) \\mid D_{i}=0\\right]}_{\\text{control group}}\\\\  \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0) \\mid D_{i}=1\\right]}_{\\text{counterfactual}} - \\underbrace{\\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=1\\right]}_{\\text{factual}}  &amp;\\approx \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0) \\mid D_{i}=0\\right] - \\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=0\\right]}_{\\text{control group}}\\\\  \\therefore \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0) \\mid D_{i}=1\\right]}_{\\text{counterfactual}}  &amp;\\approx \\underbrace{\\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=1\\right]}_{\\text{factual}}\\\\  &amp;\\quad + \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0) \\mid D_{i}=0\\right] - \\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=0\\right]}_{\\text{control group}}  \\end{aligned}\\]        정책의 인과적 효과(Average Treatment effect on the Treated; ATT): 정책 시행에 따른 실제 결과와 정책 미시행에 따른 반사실적 결과 간 차이\\[\\begin{aligned}  \\delta  &amp;=\\mathbb{E}\\left[Y_{i,t}(1)-Y_{i,t}(0) \\mid D_{i}=1\\right]\\\\  &amp;=\\underbrace{\\mathbb{E}\\left[Y_{i,t}(1)\\mid D_{i}=1\\right]}_{\\text{factual}} - \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0)\\mid D_{i}=1\\right]}_{\\text{counterfactual}}\\\\  &amp;\\approx \\underbrace{\\mathbb{E}\\left[Y_{i,t}(1)\\mid D_{i}=1\\right] - \\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=1\\right]}_{\\text{experimental group}}\\\\  &amp;\\quad+ \\underbrace{\\mathbb{E}\\left[Y_{i,t}(0) \\mid D_{i}=0\\right] - \\mathbb{E}\\left[Y_{i,s}(0) \\mid D_{i}=0\\right]}_{\\text{control group}}  \\end{aligned}\\]  Model      2시점 2단위 모형\\[\\begin{aligned}  Y_{i,t}(D_{i} \\times T_{t})  &amp;=\\alpha + \\beta D_{i} + \\gamma T_{t} + \\delta(D_{i} \\times T_{t}) + \\epsilon_{i,t}  \\end{aligned}\\]          $t \\in {0,1}$: 2시점(정책 시행 전과 후)      $i \\in {0,1}$: 2단위(실험군과 통제군)      $Y_{i,t}$: 단위 $i$ 의 시점 $t$ 에서 결과      $\\alpha$: 통제군의 사전 평균      $\\beta$: 실험군과 통제군 간 고정 수준 차이      $D_{i} \\in {0,1}$: 단위 $i$ 의 처리군 여부      $\\gamma$: 사전-사후 공통 추세 변화      $T_{t} \\in {0,1}$: 시점 $t$ 의 사후 여부      $\\delta$: 정책의 인과적 효과(ATT)            다시점 다단위 모형(processing time per unit is the same)\\[\\begin{aligned}  Y_{i,t}(D_{i} \\times T_{t})  &amp;=\\alpha_{i} + \\gamma_{t} + \\delta_{i}(D_{i} \\times T_{t}) + \\epsilon_{i,t}  \\end{aligned}\\]          $t=1,2,\\cdots,K$: 다시점      $i=1,2,\\cdots,N$: 다단위      $Y_{i,t}$: 단위 $i$ 의 시점 $t$ 에서 결과      $\\alpha_{i}$: 단위 $i$ 의 고정 효과      $\\gamma_{t}$: 시점 $t$ 의 고정 효과      $D_{i} \\in {0,1}$: 단위 $i$ 의 처리군 여부      $T_{t} \\in {0,1}$: 시점 $t$ 의 사후 여부      $\\delta_{i}$: 단위 $i$ 에 대하여 정책의 인과적 효과(ATT)      Bayesian Methodflat bayesian      frequentist ols:\\[Y_{i,t}  =\\alpha_{i}+\\gamma_{t}+\\delta_{i}(D_{i} \\times T_{t})+\\epsilon_{i,t}\\]        bayesian likelihood:\\[\\begin{aligned}  Y_{i,t} \\mid \\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma  &amp;\\sim \\mathcal{N}(\\mu_{i,t},\\sigma^{2})\\\\  \\mu_{i,t}  &amp;= \\alpha_{i} + \\gamma_{t} + \\delta_{i}(D_{i} \\times T_{t})  \\end{aligned}\\]        prior of parameters:\\[\\begin{aligned}  \\alpha_{i} &amp;\\overset{\\mathrm{i.i.d}}{\\sim} \\mathcal{N}(0,10^{2}) \\quad i=1,\\cdots,N\\\\  \\gamma_{t} &amp;\\overset{\\mathrm{i.i.d}}{\\sim} \\mathcal{N}(0,10^{2}) \\quad t=1,\\cdots,T\\\\  \\delta_{i} &amp;\\overset{\\mathrm{i.i.d}}{\\sim} \\mathcal{N}(0,10^{2}) \\quad i=1,\\cdots,N\\\\  \\sigma &amp;\\sim \\mathrm{Half-cauchy}(2)  \\end{aligned}\\]        posterior estimation:\\[\\begin{aligned}  \\underbrace{p(\\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma \\mid Y_{i,t})}_{\\text{posterior}}   &amp;\\propto \\underbrace{p(Y_{i,t} \\mid \\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma)}_{\\text{likelihood}}\\\\  &amp;\\quad\\times\\underbrace{p(\\alpha_{i})p(\\gamma_{t})p(\\delta_{i})p(\\sigma)}_{\\text{prior}} \\quad \\mathrm{s.t.} \\quad \\alpha_{i}\\perp\\gamma_{t}\\perp\\delta_{i}\\perp\\sigma  \\end{aligned}\\]        refer. cauchy distribution                  $X \\sim \\mathrm{Cauchy}(x_{0},\\gamma)$:\\[f(x) = \\frac{1}{\\pi \\gamma \\left[1 + \\left(\\frac{x - x_{0}}{\\gamma}\\right)^{2} \\right]}\\]                    $X \\sim \\mathrm{Half-Cauchy}(\\gamma)$: absolute value distribution of cauchy\\[f(x) = \\frac{2}{\\pi \\gamma \\left[1 + \\left(x/\\gamma\\right)^{2} \\right]}, \\quad x&gt;0\\]            hierarchical bayesian      level 1:\\[Y_{i,t} \\mid \\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma \\sim \\mathcal{N}(\\mu_{i,t},\\sigma^{2})\\]        level 2:\\[\\begin{aligned}  \\alpha_{i} \\mid \\mu_{\\alpha},\\tau_{\\alpha} &amp;\\sim \\mathcal{N}(\\mu_{\\alpha},\\tau_{\\alpha}^{2}) \\quad i=1,\\cdots,N\\\\  \\gamma_{t} \\mid \\mu_{\\gamma},\\tau_{\\gamma} &amp;\\sim \\mathcal{N}(\\mu_{\\gamma},\\tau_{\\gamma}^{2}) \\quad t=1,\\cdots,T\\\\  \\delta_{i} \\mid \\mu_{\\delta},\\tau_{\\delta} &amp;\\sim \\mathcal{N}(\\mu_{\\delta},\\tau_{\\delta}^{2}) \\quad i=1,\\cdots,N  \\end{aligned}\\]        level 3:\\[\\begin{aligned}  \\mu_{\\alpha} &amp;\\sim \\mathcal{N}(0,10^{2}), \\quad \\tau_{\\alpha} \\sim \\mathrm{Half-cauchy}(2)\\\\  \\mu_{\\gamma} &amp;\\sim \\mathcal{N}(0,10^{2}), \\quad \\tau_{\\gamma} \\sim \\mathrm{Half-cauchy}(2)\\\\  \\mu_{\\delta} &amp;\\sim \\mathcal{N}(0,10^{2}), \\quad \\tau_{\\delta} \\sim \\mathrm{Half-cauchy}(2)  \\end{aligned}\\]        posterior estimation:\\[\\begin{aligned}  \\underbrace{p(\\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma \\mid Y_{i,t})}_{\\text{posterior}}   &amp;\\propto \\underbrace{p(Y_{i,t} \\mid \\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma)}_{\\text{likelihood}}\\\\  &amp;\\quad\\times \\underbrace{p(\\alpha_{i} \\mid \\mu_{\\alpha},\\tau_{\\alpha})p(\\mu_{\\alpha})p(\\tau_{\\alpha})}_{\\propto p(\\mu_{\\alpha},\\tau_{\\alpha} \\mid \\alpha_{i})} \\quad &amp;\\mathrm{s.t.} \\quad \\mu_{\\alpha} \\perp \\tau_{\\alpha}\\\\  &amp;\\quad\\times \\underbrace{p(\\gamma_{t} \\mid \\mu_{\\gamma},\\tau_{\\gamma})p(\\mu_{\\gamma})p(\\tau_{\\gamma})}_{\\propto p(\\mu_{\\gamma},\\tau_{\\gamma} \\mid \\gamma_{t})} \\quad &amp;\\mathrm{s.t.} \\quad \\mu_{\\gamma} \\perp \\tau_{\\gamma}\\\\  &amp;\\quad\\times \\underbrace{p(\\delta_{i} \\mid \\mu_{\\delta},\\tau_{\\delta})p(\\mu_{\\delta})p(\\tau_{\\delta})}_{\\propto p(\\mu_{\\delta},\\tau_{\\delta} \\mid \\delta_{i})} \\quad &amp;\\mathrm{s.t.} \\quad \\mu_{\\delta} \\perp \\tau_{\\delta}\\\\  &amp;\\quad\\times p(\\sigma)  \\end{aligned}\\]  uncertainty in treatment assignment      policy exposure uncertainty:\\[\\begin{aligned}  D_{i} \\mid \\pi_{i} &amp;\\sim \\mathrm{Bernoulli}(\\pi_{i})\\\\  \\pi_{i} &amp;\\overset{\\mathrm{i.i.d}}{\\sim} \\mathrm{Beta}(1,1)  \\end{aligned}\\]        parallel trends assumption:\\[\\begin{gathered}  \\mathbb{E}\\left[Y_{i,t}(0)-Y_{i,s}(0) \\mid \\pi_{i}\\right]  = \\mathbb{E}\\left[Y_{i,t}(0)-Y_{i,s}(0)\\right]\\\\  \\Updownarrow\\\\  (Y_{i,t}(0)-Y_{i,s}(0))  \\perp D_{i} \\mid \\pi_{i}  \\end{gathered}\\]        posterior estimation:\\[\\begin{aligned}  &amp;p(\\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma,\\pi_{i} \\mid Y_{i,t}, D_{i})\\\\  &amp;\\propto \\underbrace{p(Y_{i,t} \\mid \\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma) \\cdot p(\\alpha_{i})p(\\gamma_{t})p(\\delta_{i})p(\\sigma)}_{\\propto p(\\alpha_{i},\\gamma_{t},\\delta_{i},\\sigma \\mid Y_{i,t})}\\\\  &amp;\\quad\\times \\underbrace{p(D_{i}\\mid\\pi_{i})\\cdot p(\\pi_{i})}_{\\propto p(\\pi_{i}\\mid D_{i})}  \\end{aligned}\\]        In frequentist inference, the expected causal effect is defined as follows:\\[\\mathbb{E}\\left[\\delta_{i}(D_{i} \\times T_{t})\\right]  =\\begin{cases}  \\delta_{i}T_{t} \\quad &amp;\\mathrm{if}\\quad D_{i}=1 \\\\  0 \\quad &amp;\\mathrm{otherwise}  \\end{cases}\\]        In Bayesian inference, the expected causal effect is given by:\\[\\mathbb{E}\\left[\\delta_{i}(D_{i} \\times T_{t})\\right]  =\\pi_{i}\\delta_{i}T_{t}\\]  "
  },
  
  {
    "title": "Bayesian A/B Test",
    "url": "/posts/bayesian_ab_test/",
    "categories": "5.BAYES, 3.bayes applications",
    "tags": "bayesian, design of experiments, a/b test",
    "date": "2024-08-01 00:00:00 +0900",
    





    
    "snippet": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 ...",
    "content": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 기록하였다. $A,B$ 전환율 간에 유의한 차이가 있다고 볼 수 있는가? (단, \\(\\sigma^2_{A}=\\sigma^2_{B}\\) 임이 알려져 있다고 가정한다.)            디자인      방문자 수      전환 수                  A      1,300      120              B      1,275      125      Frequentist A/B Test  Point Estimator          Interest Parameter : $\\pi_A-\\pi_B$      Point Estimator : $p_A-p_B$        Hypothesis          $H_{0}:\\quad p_A-p_B = D_{0}$      $H_{1}:\\quad p_A-p_B \\ne D_{0}$            Parametric Test Assumptions\\[\\begin{aligned}  n_A \\cdot p_A &amp;\\ge 5\\\\  n_A \\cdot (1-p_A) &amp;\\ge 5\\\\  n_B \\cdot p_B &amp;\\ge 5\\\\  n_B \\cdot (1-p_B) &amp;\\ge 5  \\end{aligned}\\]        Test Statistic\\[\\begin{aligned}  Z  &amp;= \\frac{(p_A-p_B) - D_0}{\\sqrt{s^2_p(1-s^2_p)\\left(\\displaystyle\\frac{1}{n_A}+\\displaystyle\\frac{1}{n_B}\\right)}}  \\sim N(0,1)  \\end{aligned}\\]                  $s^{2}_p$ : Pooled Estimator\\[s^{2}_p = \\frac{n_A \\cdot p_A + n_B \\cdot p_B }{n_A + n_B}\\]            Bayesian A/B Test      Prior of $\\pi$ Determination                  전환율 $\\pi$ 은 $n$ 번의 실험에 따른 성공 횟수 $X \\mid \\pi$ 에 대한 성공 확률임\\[X \\mid \\pi \\sim \\text{Bin}(n,\\pi)\\]                    Binomial Dist. 의 성공 확률 $\\pi$ 에 대한 Conjugate Prior Dist. 로서 Beta Dist. 가 적합함\\[\\pi \\sim \\text{Beta}(\\alpha_0,\\beta_0)\\]                  Posterior of $\\pi \\mid X$ Estimation\\[\\pi \\mid X \\sim \\text{Beta}(\\alpha_0 + X, \\beta_0 + n - X)\\]        Beyes Action\\[\\hat{p} = \\text{arg}\\min{\\mathcal{R}(p)}\\]                  $\\mathcal{R}(p)$ : Bayes Risk\\[\\begin{aligned}  \\mathcal{R}(p)  &amp;= \\mathbb{E}_{\\pi \\mid X}\\left[\\text{Loss}(\\pi, p)\\right]\\\\  &amp;\\approx \\frac{1}{k}\\sum_{i=1}^{k}{\\text{Loss}(p^{(i)}, p)}  \\end{aligned}\\]                  Compare $\\hat{p}_A$ and $\\hat{p}_B$  "
  },
  
  {
    "title": "One Class Collaborative Filtering",
    "url": "/posts/occf/",
    "categories": "6.RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, implicit feedback, occf",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "EM Algorithm",
    "url": "/posts/em/",
    "categories": "5.BAYES, 2.posterior approx.",
    "tags": "bayesian, objective function, mle, em algorithm, latent factor",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "E-M Algorithm      E-M Algorithm(Expectation-Maximization): 잠재요인(latent factor)을 수반하는 확률 모형에서, 우도(likelihood)를 직접 최대하기 어려울 경우 그 대리 변수로서 완전 데이터 우도(complete data likelihood)를 최대화하는 파라미터를 반복적으로 갱신함으로써...",
    "content": "E-M Algorithm      E-M Algorithm(Expectation-Maximization): 잠재요인(latent factor)을 수반하는 확률 모형에서, 우도(likelihood)를 직접 최대하기 어려울 경우 그 대리 변수로서 완전 데이터 우도(complete data likelihood)를 최대화하는 파라미터를 반복적으로 갱신함으로써 최우추정을 우회로 수행하는 알고리즘        model assumption:\\[\\begin{aligned}  \\log{p(y,z\\mid\\theta)}  &amp;=\\log{p(y\\mid z,\\theta)}+\\log{p(z\\mid\\theta)}  \\end{aligned}\\]        likelihood:\\[\\begin{aligned}  \\log{p(y\\mid\\theta)}  &amp;=\\log{\\sum_{z}{p(y,z\\mid\\theta)}}  \\end{aligned}\\]        The model assumes that $Y$ is generated from latent factors $Z$. However, only $Y$ is actually observable data, and $Z$ cannot be observed. This incomplete data likelihood takes the form of an integration or summation of latent factors, making it difficult to calculate in practice.\\[\\begin{aligned}  \\max_{\\theta}{\\log{p(y\\mid\\theta)}}  &amp;=\\max_{\\theta}{\\log{\\sum_{z}{p(y,z\\mid\\theta)}}}  \\end{aligned}\\]        EM algorithm searches for parameters that maximize the expected value of the complete data log-likelihood as a proxy for the log-likelihood. The complete data likelihood represents the joint likelihood $p(y,z\\mid\\theta)$ assuming that the latent variable $Z$ is observed.\\[\\max_{\\theta}{\\log{p(y,z\\mid\\theta)}}\\]  Step      expectation step is step for estimating the posterior distribution of latent factors calculated based on the parameters estimated in the previous step.\\[\\begin{aligned}  q(z)  &amp;=p(z\\mid y,\\theta^{(k)})\\\\  &amp;=\\frac{p(y,z\\mid\\theta^{(k)})}{p(y\\mid\\theta^{(k)})}\\\\  &amp;=\\frac{p(y\\mid z,\\theta^{(k)})p(z\\mid\\theta^{(k)})}{\\sum_{z^{\\prime}}{p(y\\mid z^{\\prime},\\theta^{(k)})p(z^{\\prime}\\mid\\theta^{(k)})}}  \\end{aligned}\\]        maximization step is step that re-examines the parameters $\\theta^{(k+1)}$ that maximize the expected joint log-likelihood $p(y,z\\mid\\theta)$ by utilizing the posterior distribution of the latent factor $Z$, estimated based on the parameters $\\theta^{(k)}$ calculated in the previous step.\\[\\begin{aligned}  \\theta^{(k+1)}  &amp;=\\mathrm{arg}\\max_{\\theta}{Q(\\theta\\mid\\theta^{(k)})}  \\end{aligned}\\]        Q function is the objective function of the EM algorithm, which is the expected complete-data log-likelihood, defined by utilizing the posterior distribution of the latent factor $Z$ estimated based on the parameter $\\theta^{(k)}$ calculated in the previous step.\\[\\begin{aligned}  Q(\\theta\\mid\\theta^{(k)})  &amp;=\\underbrace{\\mathbb{E}_{q(z)}\\left[\\log{p(y,z\\mid\\theta)}\\right]}_{\\text{expected complete-data likelihood}}\\\\  &amp;=\\underbrace{\\mathbb{E}_{q(z)}\\left[\\log{p(y\\mid z,\\theta)}\\right]}_{\\text{expected log likelihood}}+\\underbrace{\\mathbb{E}_{q(z)}\\left[\\log{p(z\\mid\\theta)}\\right]}_{\\text{expected log prior}}  \\end{aligned}\\]  Jensen Ulighed      젠센 부등식(Jensen Ulighed):          오목함수의 경우, 정의역의 평균에 대한 함수값이 최대값이 된다. 따라서 입력값의 평균에 대한 함수값은 개별 입력값에 대한 함수값들의 평균보다 항상 크거나 같다.    \\[\\begin{aligned}  f(\\mathbb{E}[X])\\ge \\mathbb{E}[f(X)]  \\end{aligned}\\]    definition:          likelihood: $p(y\\mid\\theta)=\\sum_{z}{p(y,z\\mid\\theta)}$      posterior of latent factor: $q(z)=p(z\\mid y,\\theta^{(k)})$      concave function: $f(x)=\\log{x}$            likelihood transformation:\\[\\begin{aligned}  \\log{p(y\\mid\\theta)}  &amp;=\\log{\\sum_{z}{p(y,z\\mid\\theta)}}\\\\  &amp;=\\log{\\sum_{z}{q(z)\\cdot\\frac{p(y,z\\mid\\theta)}{q(z)}}}\\\\  &amp;=\\log{\\mathbb{E}_{q(z)}\\left[\\frac{p(y,z\\mid\\theta)}{q(z)}\\right]}  \\end{aligned}\\]        $\\because$ jensen ulighed:\\[\\begin{aligned}  \\log{\\mathbb{E}_{q(z)}\\left[\\frac{p(y,z\\mid\\theta)}{q(z)}\\right]}  &amp;\\ge\\mathbb{E}_{q(z)}\\left[\\log{\\frac{p(y,z\\mid\\theta)}{q(z)}}\\right]  \\end{aligned}\\]        right side:\\[\\begin{aligned}  \\mathbb{E}_{q(z)}\\left[\\log{\\frac{p(y,z\\mid\\theta)}{q(z)}}\\right]  &amp;=\\sum_{z}{q(z)\\cdot\\log{\\frac{p(y,z\\mid\\theta)}{q(z)}}}\\\\  &amp;=\\sum_{z}{q(z)\\cdot\\left[\\log{p(y,z\\mid\\theta)}-\\log{q(z)}\\right]}\\\\  &amp;=\\sum_{z}{q(z)\\cdot\\log{p(y,z\\mid\\theta)}}+\\underbrace{\\left(-\\sum_{z}{q(z)\\cdot\\log{q(z)}}\\right)}_{\\text{entropy is const.}}\\\\  &amp;=\\underbrace{\\mathbb{E}_{q(z)}\\left[\\log{p(y,z\\mid\\theta)}\\right]}_{=:Q(\\theta\\mid\\theta^{(k)})}+\\underbrace{H(q)}_{\\ge 0}  \\end{aligned}\\]        therefore, the parameter that maximizes the Q function becomes the parameter that maximizes the lower bound of the likelihood.\\[\\begin{aligned}  \\log{p(y\\mid\\theta)}\\ge Q(\\theta\\mid\\theta^{(k)})+H(q)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Variational Inference",
    "url": "/posts/vi/",
    "categories": "5.BAYES, 2.posterior approx.",
    "tags": "bayesian, objective function, information theory, variational inference",
    "date": "2024-07-30 00:00:00 +0900",
    





    
    "snippet": "Information Theory      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikel...",
    "content": "Information Theory      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Event)일수록 높은 정보량을 가짐(Informative)                  해가 동쪽에서 뜨는 사건은 사람들이 확신하고 있는 사건이므로 정보량이 낮은 반면, 해가 서쪽에서 뜨는 사건은 자연 법칙을 거스르는 극히 드문 사건이므로 정보량이 높음                    독립사건은 추가적인 정보량을 가짐(Addictive Information)                  동전을 두 번 던져서 앞면이 두 번 나오는 사건은 동전을 한 번 던져서 앞면이 나오는 사건보다 정보량이 두 배임                          자기정보(Self-Information): 확률변수 $X \\sim P$ 에 대하여, 사건 $X=x$ 가 발생했을 때의 정보량\\[\\begin{aligned}  I(X=x)  &amp;=-\\log{P(X=x)}  \\end{aligned}\\]        엔트로피(Entropy): 자기정보의 기대값으로서, 주어진 확률분포에서 발생 가능한 사건들의 평균적인 정보량\\[\\begin{aligned}  H(P)  = \\mathbb{E}_{X \\sim P}\\left[I(X)\\right]  = -\\sum_{X}{\\log{P(x)} \\cdot P(x)}  \\end{aligned}\\]          사건의 분포가 결정적일수록(Deterministic) 엔트로피가 감소함      사건의 분포가 균등할수록(Uniform) 엔트로피가 증가함            교차 엔트로피(Cross Entropy): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 가 $P$ 에 대하여 제공하는 정보의 불확실성을 측정하는 지표\\[\\begin{aligned}  H(P,Q)  = \\mathbb{E}_{X \\sim P}\\left[-\\log{Q(X)}\\right]  = -\\sum_{X}{\\log{Q(X)} \\cdot \\log{P(X)}}  \\end{aligned}\\]        쿨백 라이블러 발산(Kullback-Leibler Divergence): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 를 $P$ 의 근사 분포로 사용할 때의 비효율성을 측정하는 지표로서, $P$ 에서 샘플링된 $X$ 에 대하여, $P$ 가 제공하는 평균적인 정보량과 $Q$ 가 제공하는 평균적인 정보량의 차이\\[\\begin{aligned}  KL[P(X) \\parallel Q(X)]  = H(P,Q) - H(P)  = \\sum_{X}{\\log{\\frac{P(X)}{Q(X)}} \\cdot P(X)}  \\end{aligned}\\]  Variational Inference      변분 추론(Variational Inference): 정보 이론을 활용하여 제안 분포 $W \\sim Q$ 를 목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에 근사하는 모수 방법론(Parametric Method)\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg}\\min{KL\\big[Q(W) \\parallel P(W \\mid \\mathcal{D})\\big]}  \\end{aligned}\\]                  목표 분포 $W \\mid \\mathcal{D} \\sim P$ 를 잘 설명하는 제안 분포 $W \\sim Q$ 를 탐색하는 것이 이상적\\[\\begin{aligned}  D_{KL}\\big[P(W \\mid \\mathcal{D}) \\parallel Q(W)\\big]  &amp;= \\mathbb{E}_{W \\mid \\mathcal{D} \\sim P}\\left[\\log{\\frac{P(W \\mid \\mathcal{D})}{Q(W)}}\\right]  \\end{aligned}\\]                    목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에서 샘플을 추출할 수 없으므로 대안으로서 목표 분포로 잘 설명될 수 있는 제안 분포 $W \\sim Q$ 를 탐색함\\[\\begin{aligned}  D_{KL}\\big[Q(W) \\parallel P(W \\mid \\mathcal{D})\\big]  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W \\mid \\mathcal{D})}}\\right]  \\end{aligned}\\]                  Kullback-Leibler divergence segmentation:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W \\mid \\mathcal{D})}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W \\mid \\mathcal{D})}]  \\end{aligned}\\]        posterior is decomposed by Bayes’ theorem:\\[\\begin{aligned}  &amp;\\mathbb{E}_{W \\sim Q}[\\log{P(W \\mid \\mathcal{D})}]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{P(\\mathcal{D} \\mid W) \\cdot P(W)}{P(\\mathcal{D})}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]        Therefore:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\Big(\\mathbb{E}_{W \\sim Q}[\\log{p(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]\\Big)\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]        Some items are tied to the Kullback Leibler divergence:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W)]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W)}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)} - \\log{P(W)}]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W)}]  \\end{aligned}\\]        Finally:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]  ELBO      증거 하한(Evidence Lower B ound): 변분 추론의 목적 함수로서 증거 $\\log{P(\\mathcal{D})}$ 의 하한\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]          $\\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right]$: 기대 로그 우도로서 근사 분포의 데이터 적합도      $KL[Q(W) \\parallel P(W)]$: 근사 분포와 사전 분포 간 쿨백 라이블러 발산으로서 사전 신념 기준 근사 분포의 복잡도            Kullback-Leibler divergence segmentation:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]          $KL\\big[Q(W) \\parallel P(W)\\big]$ : Kullback-Leibler divergence between approx. and prior      $\\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right]$ : expected log likelihood, goodness of fit of the approx. dist. to the data      $\\log{P(\\mathcal{D})}$ : log marginal likelihood            best approx.:\\[\\begin{aligned}  KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  &amp;=0  \\end{aligned}\\]        to summarize the evidence,\\[\\begin{aligned}  \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  &amp;\\ge \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]        since evidence is constant for the parameters,\\[\\begin{aligned}  &amp;\\min{KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]}\\\\  &amp;\\Leftrightarrow \\max{\\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] - KL[Q(W) \\parallel P(W)]}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Markov Chain Monte Carlo",
    "url": "/posts/mcmc/",
    "categories": "5.BAYES, 2.posterior approx.",
    "tags": "bayesian, monte carlo simulation, markov chain, markov chain monte carlo, pymc",
    "date": "2024-07-29 00:00:00 +0900",
    





    
    "snippet": "Markov Chain Monte Carlo      마르코프 체인 몬테 카를로(Markov Chain Monte Carlo) : 이전 단계에서 추출한 표본을 기반으로 다음 단계의 표본을 순차로 추출하여 사후 분포에 근사하는 방법        Random-walk based MCMC          Metropolis algorithm      Met...",
    "content": "Markov Chain Monte Carlo      마르코프 체인 몬테 카를로(Markov Chain Monte Carlo) : 이전 단계에서 추출한 표본을 기반으로 다음 단계의 표본을 순차로 추출하여 사후 분포에 근사하는 방법        Random-walk based MCMC          Metropolis algorithm      Metropolis–Hastings      Random-Walk Metropolis      Independence sampler        Gibbs Sampling based MCMC          Full Gibbs sampler      Blocked Gibbs      Collapsed Gibbs        Gradient based MCMC          Hamiltonian Monte Carlo      No-U-Turn Sampler      Riemannian Manifold HMC      Metropolis Hastings Method      메트로폴리스 헤이스팅스 방법(Metropolis Hastings Method) : 목표 분포의 산 모양을 추정하기 위하여, 확률 밀도가 높은 지역일수록(봉우리가 높은 지역일수록) 그 근방에서 더 많은 조약돌을 모으는 방법                  inital sample:\\[\\theta^{(t=0)}\\]                    sampling candidate state $\\psi$:\\[\\psi \\sim \\mathcal{N}(\\theta^{(t)},\\sigma^2)\\]                    conditional acceptance:\\[\\theta^{(t+1)}  =\\begin{cases}\\begin{aligned}  \\psi, \\quad &amp;\\text{if} \\quad u&lt;\\alpha(\\theta^{(t)},\\psi) \\quad \\text{for} \\quad u \\sim \\text{Uniform}(0,1)\\\\  \\theta^{(t)}, \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]                  목표 분포(Target Dist.) : 파라미터 $\\theta^{(t)}$ 의 사후 확률 분포\\[p(\\theta^{(t)}\\mid \\mathcal{D}) \\propto p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})\\]        제안 분포(Proposal Dist.) : 시점 $t$ 에서 수락된 파라미터 샘플 $\\theta^{(t)}$ 에 기반하여 다음 시점 $t+1$ 에서 샘플링 위치 $\\psi$ 를 제안하는 분포\\[q(\\psi \\mid \\theta^{(t)}) = \\mathcal{N}(\\theta^{(t)},\\sigma^2)\\]                  제안 분포가 $\\theta^{(t)}$ 을 중심으로 하는 종형 분포인 경우:\\[q(\\psi \\mid \\theta^{(t)}) = q(\\theta^{(t)} \\mid \\psi)\\]                    $\\sigma^2$ 의 크기와 샘플링 수렴 여부의 관계:                          수락 확률(Acceptance Prob.) : $\\psi$ 를 다음 시점의 샘플 $\\theta^{(t+1)}$ 로 수락할 확률\\[\\begin{aligned}  \\alpha(\\theta^{(t)}, \\psi)  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})} \\cdot \\frac{q(\\theta^{(t)} \\mid \\psi)}{q(\\psi \\mid \\theta^{(t)})}\\right]}\\\\  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})}\\right]} \\quad \\text{s.t.} \\quad \\psi \\sim \\mathcal{N}(\\theta^{(t)},\\sigma^2)\\\\  &amp;\\propto \\min{\\left[1, \\frac{p(\\psi) \\cdot p(\\mathcal{D} \\mid \\psi)}{p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})}\\right]}  \\end{aligned}\\]  Auto-Correlation      자기상관(Auto-Correlation) : 순차로 발생한 일련의 관측치 ${x^{(t)} \\mid t\\text{ is time point}}$ 간에 존재하는 상관관계              $x^{(t)} \\sim N(0,1) \\quad \\text{for} \\quad x^{(0)} = 0$      $y^{(t)} \\sim N(y^{(t-1)},1) \\quad \\text{for} \\quad y^{(0)} = 0$            자기상관계수(Auto-Correlation Coefficient) : 순서에 의미가 있는 데이터에서, 현재 시점의 값 $x^{(t)}$ 과 그 과거 또는 미래의 값 $x^{(t-k)}$ 간의 상관관계를 측정하는 지표\\[R(k)=\\text{Corr}(x^{(t)},x^{(t-k)})\\]                  $k$ : 시간 간격(Lag)                          솎아내기(Thinning) : 매 $k$ 번째 표본을 선택함으로써 자기상관을 줄이는 방법              통상 $k \\le 10$ 으로 설정함            선행 구간(Burn-in Period) : 수렴 상태에 도달하기 전, 초기값 $x^{(t=0)}$ 의 영향력을 최소화하기 위해 일부 반복을 무시하는 구간      PyMC Summary Indicator      Posterior Mean: 사후 평균 추정치\\[\\hat{\\mu}=\\frac{1}{N}\\sum_{i=1}^{N}{\\theta_{i}}\\]        Posterior Standard Deviation: 사후 평균 추정치의 표준편차\\[\\hat{\\sigma}=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}{(\\theta_{i}-\\hat{\\mu})^{2}}}\\]        Monte Carlo Standard Error: 사후 평균 추정치의 몬테카를로 표준오차\\[\\mathrm{MCSE}_{\\mathrm{mean}}  =\\sqrt{\\mathrm{Var}(\\hat{\\mu})}\\approx \\frac{\\hat{\\sigma}}{\\sqrt{\\mathrm{ESS}}}\\]          Mean: 사후 분포의 중심 위치 추정 불확실성으로서 중심 위치 추정의 안정성      Std: 사후 분포의 폭 추정 불확실성으로서 신뢰구간 추정의 정확성            Effective Sample Size: 샘플 간 자기상관을 보정한 독립 샘플 수\\[\\mathrm{ESS}=\\frac{MN}{1+2\\sum_{t=1}^{\\infty}{\\rho_{t}}}\\]          Bulk: 중심부에서의 표본 독립성으로서 사후 분포의 중심 위치 통계량의 신뢰도      Tail: 꼬리부에서의 표본 독립성으로서 신뢰구간 경계의 신뢰도            Gelman–Rubin Statistic (Potential Scale Reduction Factor): 체인 간 수렴성 평가 지표\\[\\hat{R}=\\sqrt{\\frac{B}{W}}\\]                  Definition:\\[\\begin{aligned}  \\bar{\\theta}^{(k)}:=\\frac{1}{N}\\sum_{i=1}^{N}{\\theta_{i}^{(k)}}, \\quad   \\bar{\\theta}:=\\frac{1}{M}\\sum_{k=1}^{M}{\\bar{\\theta}_{k}}  \\end{aligned}\\]                    Between-chain variance:\\[\\begin{aligned}  B=\\frac{N}{M-1}\\sum_{k=1}^{M}{(\\bar{\\theta}^{(k)} - \\bar{\\theta})^{2}}  \\end{aligned}\\]                    Within-chain variance:\\[\\begin{aligned}  W&amp;=\\frac{1}{M}\\sum_{k=1}^{M}{s_{k}^{2}}\\\\  s_{k}^{2}&amp;=\\frac{1}{N-1}\\sum_{i=1}^{N}{(\\theta_{i}^{(k)}-\\bar{\\theta}^{(k)})^{2}}  \\end{aligned}\\]            Source  https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo"
  },
  
  {
    "title": "Monte Carlo Simulation",
    "url": "/posts/mc/",
    "categories": "5.BAYES, 2.posterior approx.",
    "tags": "bayesian, monte carlo simulation, rejection sampling",
    "date": "2024-07-28 00:00:00 +0900",
    





    
    "snippet": "Monte Carlo Simulation  몬테-카를로 시뮬레이션(Monte-Carlo Simulation): 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법example $\\Pi$  한 변의 길이가 2인 정사각형 내부에 점을 무작위로 찍었을 때, 그 점이 정사각형에 내접하는 원의 내부에 위치할 확률 실험을 전개하여...",
    "content": "Monte Carlo Simulation  몬테-카를로 시뮬레이션(Monte-Carlo Simulation): 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법example $\\Pi$  한 변의 길이가 2인 정사각형 내부에 점을 무작위로 찍었을 때, 그 점이 정사각형에 내접하는 원의 내부에 위치할 확률 실험을 전개하여, 원주율 $\\pi$ 를 추론하시오.  좌표평면 상에서 주어진 조건을 만족하는 원:          정의 \\(C = \\{ (x, y) \\mid x^2 + y^2 = r^2 \\}\\)      면적 $\\pi r^2 = \\pi \\quad (\\because 2r=2)$        좌표평면 상에서 주어진 조건을 만족하는 정사각형:          정의 \\(R = \\{ (x, y) \\mid -1 \\le x \\le 1, -1 \\le y \\le 1\\}\\)      면적 $(2r)^2=4$            정사각형 내부에 점을 무작위로 찍었을 때, 점이 원 내부에 위치할 가능성:\\[\\begin{aligned}  P((x,y) \\in C)  &amp;=\\frac{N_{circle}}{N}  =\\displaystyle\\frac{\\pi r^2}{(2r)^2}  \\end{aligned}\\]          $N$ : 실행 횟수      $N_{circle}$ : 성공 횟수(원 내부에 위치한 횟수)            몬테-카를로 시뮬레이션을 통한 $\\pi$ 추론값 도출:              실행 횟수(num)가 증가할수록 $\\pi$ 의 추론값이 $3.141592\\cdots$ 에 근접해감      Rejection Sampling      기각 샘플링(Rejection Sampling) : 제안 분포로부터 추출한 관측치를 기각하는 과정을 반복하여 제안 분포를 목표 분포와 유사한 형태로 만드는 방법        Target Dist.:\\[\\begin{aligned}  p(\\theta \\mid \\mathcal{D}) \\propto p(\\mathcal{D} \\mid \\theta) \\cdot p(\\theta)  \\end{aligned}\\]        Proposed Dist.:\\[\\begin{aligned}  q(\\theta)  \\end{aligned}\\]          $q(\\theta)$ must be similar in location and distribution to $p(\\theta \\mid \\mathcal{D})$      $p(\\theta \\mid \\mathcal{D}) \\le M \\cdot q(\\theta) \\quad \\text{for} \\quad \\forall \\theta$            Rejection Rule:\\[\\begin{aligned}  \\text{Accept} \\quad \\phi \\quad \\text{if} \\quad u \\le \\frac{p(\\phi \\mid \\mathcal{D})}{M \\cdot q(\\phi)} \\quad \\text{where} \\quad u \\sim \\text{Uniform}(0,1)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Bayes Action",
    "url": "/posts/bayes_action/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "bayesian, optimization, objective function",
    "date": "2024-07-27 00:00:00 +0900",
    





    
    "snippet": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출...",
    "content": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출했다고 하자. 그렇다면 이들 중 무엇을 모수 $\\theta \\mid X$ 의 추정치 $\\hat{\\theta}$ 로 사용하는 것이 적절할까?      Bayes’ Risk : 사후확률분포 $P(\\theta \\mid X)$ 를 사용하여 계산된, 모수 $\\theta$ 에 대하여 추정치 $\\hat{\\theta}$ 를 선택할 때의 기대 손실(Expected Loss)\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;= \\int{\\text{Loss}(\\theta, \\hat{\\theta}) \\cdot P(\\theta \\mid X)}\\text{d}\\theta  \\end{aligned}\\]                  모수 $\\theta \\mid X$ 를 알 수 없으므로, $n$ 번의 샘플링을 통해 도출한 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)} \\sim P(\\theta \\mid X)$ 를 사용하여 근사함\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;\\approx \\frac{1}{N}\\sum_{i=1}^{N}{\\text{Loss}(\\theta^{(i)}, \\hat{\\theta})}  \\end{aligned}\\]                  Bayes Estimator : 모수 $\\theta$ 에 대하여, Bayes’ Risk 를 최소화시키는 추정치 $\\hat{\\theta}$\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathcal{R}(\\hat{\\theta})}  \\end{aligned}\\]                  Posterior Mean : Bayes’ Least Square (BLS) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[(\\theta-\\hat{\\theta})^2\\right]}\\\\  &amp;= \\mathbb{E}_{\\theta \\mid X}(\\theta)  \\end{aligned}\\]                    Posterior Median\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[ \\vert \\theta-\\hat{\\theta} \\vert \\right]}\\\\  &amp;= \\tilde{\\theta}  \\end{aligned}\\]                    Posterior mode : Maximum a posteriori (MAP) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[1_{\\hat{\\theta} \\ne \\theta}\\right]}\\\\  &amp;= \\text{arg} \\max_{\\theta}{P(\\theta \\mid X)}  \\end{aligned}\\]            Loss FunctionContinuous Prob. Variable      Squared Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= (\\theta - \\hat{\\theta})^2  \\end{aligned}\\]        Asymmetric Squared Error Loss\\[\\text{Loss}(\\theta, \\hat{\\theta})  = \\begin{cases}\\begin{aligned}  &amp;(\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} &lt; \\theta&amp;\\\\  &amp;c \\cdot (\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ge \\theta&amp;,\\;0&lt;c&lt;1  \\end{aligned}\\end{cases}\\]        Absolute Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  =  \\vert \\theta - \\hat{\\theta} \\vert   \\end{aligned}\\]  Discrete Prob. Variable      Zero-One Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= 1_{\\hat{\\theta} \\ne \\theta}\\\\  &amp;= \\begin{cases}\\begin{aligned}  &amp;0 \\quad &amp;\\text{if}\\;\\hat{\\theta} = \\theta\\\\  &amp;1 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ne \\theta  \\end{aligned}\\end{cases}  \\end{aligned}\\]        Binary Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\left[\\hat{\\theta} \\cdot \\log{\\theta}+(1-\\hat{\\theta})\\cdot\\log{(1-\\theta)}\\right] \\quad \\text{for}\\;&amp;\\hat{\\theta}\\in\\{0,1\\},\\\\&amp;\\theta\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 베르누이 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Bernoulli}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\theta^{\\hat{\\theta}} \\cdot (1-\\theta)^{1-\\hat{\\theta}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\left[\\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}\\right]  \\end{aligned}\\]                  Categorical Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\sum_{i=1}^{K}{\\hat{\\theta}_{i}\\cdot\\log{\\theta_{i}}} \\quad \\text{for}\\;&amp;\\hat{\\theta}_{i}\\in\\{0,1\\},\\\\&amp;\\theta_{i}\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 카테고리 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Categorical}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\prod_{i=1}^{K}{\\theta_{i}^{\\hat{\\theta}_{i}}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Prior Determination",
    "url": "/posts/prior/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "bayesian, prior, conjugate",
    "date": "2024-07-26 00:00:00 +0900",
    





    
    "snippet": "Prior Determination      사전 확률 분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후 확률 분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후 확률 분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전 확률 분포의 가정에 위...",
    "content": "Prior Determination      사전 확률 분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후 확률 분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후 확률 분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전 확률 분포의 가정에 위배된다는 것을 의미한다. 그래서 이전으로 돌아가 사전 확률 분포가 외부 정보와 조화되도록 변경하는 것이 적절하다. (Andrew Gelman)            관측치 갯수($N$)가 많아질수록 사전 확률 분포의 영향력이 약화됨              동전의 미래 행위에 대한 당신의 견해가 이웃 사람의 견해와 크게 다르더라도, 당신의 견해와 이웃 사람의 견해는 일상적으로 실험적인 던지기의 긴 연속에 베이즈의 정리를 적용하여 변형되어 거의 구별할 수 없게 될 것이다(Edwards, Lindman, and Savage, 1963, p.197). 즉, 다양한 신념들은 충분한 근거가 주어지면 간주관적으로 수렴하며, 이 일치를 객관적 신념 상태로 해석할 수 있다.      Non-Informative Dist.      Principle of Indifference : 가능한 모수 공간에서 특별히 어떤 값을 선호하지 않는 원칙에 따라, 관측치가 사후분포에 미치는 영향력을 최대화하는 방법          무차별의 원리가 주장하는 것은 만약 우리의 관심의 대상이 여러 가지 대안 중 어느 것보다 더 예측할 만한 어떠한 알려진 이유가 없다면 그러한 지식에 상대적으로 이러한 대안 각각에 대한 주장들은 동일한 확률을 갖는다는 점이다(Keynes, 1921, p.42).    \\[\\begin{aligned}  X \\mid \\theta &amp;\\sim \\text{Binomial}(n,\\theta)\\\\  \\theta &amp;\\sim \\text{Uniform}(0,1)  \\end{aligned}\\]  Jacobian Change of Variables      자코비안 변수 변환(Jacobian Change of Variables) : 기본 변수 $\\Theta$, 변환 변수 $\\Psi=g(\\Theta)$ 및 그 밀도 함수 $f$ 에 대하여, 다음을 만족하는 변수 변환 방법\\[\\begin{aligned}  f_{\\Psi}\\left(\\Psi\\right)  &amp;=f_{\\Theta}\\left(\\Theta\\right) \\cdot \\left\\vert \\frac{1}{\\text{det}\\left(\\mathbf{J}\\right)} \\right\\vert\\\\  \\Theta  &amp;= \\begin{pmatrix} \\theta_{1} &amp; \\theta_{2} &amp; \\cdots &amp; \\theta_{n} \\end{pmatrix}\\\\  \\Psi  &amp;= \\begin{pmatrix} \\psi_{1} &amp; \\psi_{2} &amp; \\cdots &amp; \\psi_{m} \\end{pmatrix}  \\end{aligned}\\]                  자코비안 행렬(Jacobian Matrix; $\\mathbb{J}$) : 다변수 벡터 값 함수의 모든 편미분을 모아 만든 행렬\\[\\begin{aligned}  \\mathbf{J}  = \\frac{\\partial \\Psi}{\\partial \\Theta}  = \\begin{pmatrix}  \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_n}\\\\  \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_n}  \\end{pmatrix}  \\end{aligned}\\]                  변환 변수 $\\psi=g(\\theta)$ 가 기본 변수에 대하여 (확률) 밀도의 불변성을 보장한다고 하자\\[\\begin{aligned}  P(a \\le \\theta \\le b)  &amp;= P(g(a) \\le \\psi \\le g(b))\\\\  \\int_{a}^{b}{f_{\\theta}(\\theta)\\text{d}\\theta}  &amp;= \\int_{g(a)}^{g(b)}{f_{\\psi}(\\psi)\\text{d}\\psi}  \\end{aligned}\\]        기본 변수의 단위당 밀도와 변환 변수의 단위당 밀도가 동일함\\[f_{\\theta}(\\theta) \\cdot \\Delta\\theta  =f_{\\psi}(\\psi) \\cdot \\Delta\\psi\\]        $\\because \\Delta\\psi=\\displaystyle\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta$\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\Delta\\psi  &amp;= f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)\\\\  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta  \\end{aligned}\\]        따라서 자코비안 변수 변환은 밀도의 불변성을 보장함\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta\\\\  f_{\\psi}(\\psi) \\cdot \\left\\vert \\frac{\\Delta\\psi}{\\Delta\\theta} \\right\\vert  &amp;= f_{\\theta}(\\theta)\\\\  \\therefore f_{\\psi}(\\psi)  &amp;= f_{\\theta}(\\theta) \\cdot \\left\\vert \\frac{\\Delta\\theta}{\\Delta\\psi} \\right\\vert  \\end{aligned}\\]  Transformation Variant of Flat Prior Dist.      모수 $\\theta$ 가 균등 분포 $\\text{Uniform}(0,1)$ 를 따르는 객관적인 사전확률이라고 하자\\[\\theta \\sim \\text{Uniform}(0,1)\\]        모수 $\\theta$ 를 $\\log{\\displaystyle\\frac{\\theta}{1-\\theta}}$ 로 변수 변환한 $\\psi$ 는 로지스틱 분포 $\\text{Logistic}(0,1)$ 을 따르게 됨\\[\\begin{aligned}  \\psi  &amp;= g(\\theta) = \\log{\\frac{\\theta}{1-\\theta}}\\\\ \\\\  \\theta  &amp;= g^{-1}(\\psi) = \\frac{\\text{exp}(\\psi)}{1+\\text{exp}(\\psi)}\\\\ \\\\  f_{\\psi}(\\psi)  &amp;= f_{\\theta}(g^{-1}(\\psi)) \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi)\\right\\vert \\\\  &amp;= 1 \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi) \\right\\vert \\quad (\\because \\theta \\sim \\text{Uniform}(0,1))\\\\  &amp;= \\frac{\\text{exp}(\\psi)}{(1+\\text{exp}(\\psi))^{2}}\\\\  \\\\  \\therefore \\psi &amp;\\sim \\text{Logistic}(0,1)  \\end{aligned}\\]        즉, 모수 $\\theta$ 의 변수 변환에 의하여 사전분포의 객관성이 상실되었음                  변환 전 : $\\theta \\sim \\text{Uniform}(0,1)$                            변환 후 : $\\psi \\sim \\text{Logistic}(0,1)$                    Jeffreys Priors      Jeffreys Priors : 모수 공간에 대해 불변성을 보장함으로써 변수 변환 후에도 객관성을 보존하는 사전분포\\[\\pi_{J}(\\theta) \\propto \\sqrt{\\mathbf{I}(\\theta)}\\]                  $\\sqrt{\\mathbf{I}(\\theta)}$ : Fisher Information\\[\\begin{aligned}  \\mathbf{I}(\\theta)  = \\mathbb{E}\\left[\\frac{\\text{d}^{2}}{\\text{d}\\theta^{2}}\\log{\\mathcal{L}(\\theta)}\\right]  = \\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta}\\right)^{2}\\right]  \\end{aligned}\\]                  변수 $\\theta$ 에 대한 확률분포가 그 피셔 정보의 자승근에 비례하도록 정의되었다고 하자\\[p(\\theta) \\propto \\sqrt{I(\\theta)}\\]        함수 $g$ 를 통해 변수 $\\theta$ 를 변수 $\\psi$ 로 변환한다고 하자\\[\\psi = g(\\theta)\\]        변환 변수 $\\psi$ 의 확률분포 또한 그 피셔 정보의 자승근에 비례하게 됨\\[p(\\psi) \\propto \\sqrt{I(\\psi)}\\]        미분 법칙에 의해 다음이 성립함\\[\\frac{\\partial \\log{\\mathcal{L}(\\psi)}}{\\partial \\psi}  =\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi}\\]        변환 변수 $\\psi$ 의 피셔 정보 $I(\\psi)$ 는 다음과 같음\\[\\begin{aligned}  I(\\psi)  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi} \\right)^{2}\\right]\\\\  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\theta}\\right)^{2}\\right] \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}\\\\  &amp;=I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}  \\end{aligned}\\]        따라서 변환 변수 $\\psi$ 의 확률분포는 기본 변수 $\\theta$ 의 확률분포의 형태를 유지하되,자코비안 행렬식 $\\left\\vert \\displaystyle\\frac{d\\theta}{d\\psi} \\right\\vert$ 로 보정된 양상을 띠게 됨\\[\\begin{aligned}  p(\\psi) &amp;\\propto \\sqrt{I(\\psi)}\\\\  &amp;= \\sqrt{I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}}\\\\  &amp;= \\sqrt{I(\\theta)} \\cdot \\left\\vert \\frac{d\\theta}{d\\psi} \\right\\vert  \\end{aligned}\\]  Empirical Bayes      실증적 베이즈(Empirical Bayes): 사전 확률 분포를 빈도주의적으로 접근하여 추정하는 방법으로서, 사전 정보가 많지 않지만 관측치가 풍부한 경우 유용하나, 사전 정보가 관측하기 이전에 정의되어야 한다는 원칙에 위배됨          그러므로 하나의 의견이 주어지면, 우리는 진위에 근거하여 그것을 칭찬하거나 책망할 수 있을 뿐이다. 특정한 형태의 습관이 주어지면 우리는 습관이 산출하는 신념도가 그것이 진리로 이끄는 실제 비율에 근접하거나 멀어지는가에 따라서 칭찬하거나 책망할 수 있다. 그렇다면 우리는 의견을 산출하는 습관들을 칭찬하거나 책망하는 것으로부터 파생적으로 의견들을 칭찬하거나 책망할 수 있다(Ramsey, 1926, p.51).            example General Model\\[\\begin{aligned}  X_{i} \\mid \\theta &amp;\\sim N(\\theta, 5^2)\\\\  \\theta &amp;\\sim N(\\mu, \\sigma^2)  \\end{aligned}\\]        Objective Prior:\\[\\theta \\sim N(0, 100^2)\\]        Subjective Prior:\\[\\theta \\sim N(\\mu_{0}, \\sigma_{0}^{2})\\]        Empirical Bayes:\\[\\theta \\sim N\\left(\\frac{1}{N}\\sum_{i=1}^{N}{X_i}, \\frac{1}{N-1}\\sum_{i=1}^{N}{(X_i-\\mu)^2}\\right)\\]  Conjugate Priors      켤레 사전 분포(Conjugate Priors): 관측치 $X$ 와 그 확률분포 \\(\\mathcal{L}_{\\alpha}\\) 에 대하여, 다음의 조건을 만족하는 사전확률분포 \\(\\pi_{\\beta}\\) 가 존재하는 경우, \\(\\pi_{\\beta}\\) 를 \\(\\mathcal{L}_{\\alpha}\\) 의 켤레 사전 분포(Conjugate Prior Dist.)라고 함\\[\\begin{aligned}  \\pi_{\\beta^{\\prime}}(\\theta \\mid X) \\propto \\mathcal{L}_{\\alpha}(\\theta) \\cdot \\pi_{\\beta}(\\theta)  \\end{aligned}\\]          $\\mathcal{L}_{\\alpha}(\\theta)$ : 모수 $\\theta$ 의 우도 함수      $\\pi_{\\beta}(\\theta)$ : 모수 $\\theta$ 의 사전 확률      $\\pi_{\\beta^{\\prime}}(\\theta \\mid X)$ : 모수 $\\theta$ 의 사후 확률      $\\alpha,\\beta,\\beta^{\\prime}$ : 모수들의 집합            예시                            Likelihood          Prior          Posterior                                      $\\text{Bernoulli}(\\theta)$          $\\text{Beta}(\\alpha, \\beta)$          $\\text{Beta}\\Big(\\alpha + n \\cdot \\bar{x}, \\beta + n\\cdot(1-\\bar{x})\\Big)$                          $\\text{Poisson}(\\lambda)$          $\\text{Gamma}(\\alpha, \\beta)$          $\\text{Gamma}(\\alpha+ n \\cdot \\bar{x}, \\beta+n)$                          $\\text{Multinomial}(\\theta)$          $\\text{Dirichlet}(\\alpha)$          $\\text{Dirichlet}(\\alpha+n \\cdot \\bar{x})$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\sigma^2$          $N(\\mu_0, \\sigma_0^2)$          $N\\Bigg( \\displaystyle\\frac{\\displaystyle\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n \\cdot \\bar{x}}{\\sigma^2}}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\displaystyle\\frac{n}{\\sigma^2}}, \\displaystyle\\frac{1}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}} \\Bigg)$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\mu$          $\\text{Inv-Gamma}(\\alpha, \\beta)$          $\\text{Inv-Gamma}\\Bigg(\\alpha + \\displaystyle\\frac{n}{2}, \\beta + \\displaystyle\\frac{n \\cdot (\\bar{x} -\\mu)^2}{2}\\Bigg)$                          $N(\\mu, \\Sigma)$  $\\text{known} \\; \\mu$          $\\text{Inv-Wishart}(\\nu_{0}, S_{0})$          $\\text{Inv-Wishart}(\\nu_{0}+n, S_{0} + n \\cdot \\bar{S})$                    "
  },
  
  {
    "title": "Frequentist vs. Bayesian",
    "url": "/posts/freq_bayes/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "bayesian, optimization, mle, bayes' theorem",
    "date": "2024-07-25 00:00:00 +0900",
    





    
    "snippet": "Probability      귀납법(Induction): 관측된 데이터로부터 일반화된 진술(혹은 모형)을 도출하는 방법                            관점          진리          설명                                      존재론(Ontology)          사실적 진리(Factual ...",
    "content": "Probability      귀납법(Induction): 관측된 데이터로부터 일반화된 진술(혹은 모형)을 도출하는 방법                            관점          진리          설명                                      존재론(Ontology)          사실적 진리(Factual Truth)          실제 세계에서 어떤 일이 일어났는가?                          실증론(Positivism)          빈도적 진리(Frequentist Truth)          반복된 시행에서 수렴하는 비율                          인식론(Epistemology)          인식적 진리(Epistemic Truth)          정보에 따라 믿음이 수렴해가는 대상                            결정론적 귀납화(Determinism): 일반화된 진술의 불확실성을 고려하지 않는 귀납법                  동전을 던지면 앞면이 나온다.                    확률론적 귀납화(Probability Theory): 일반화된 진술의 불확실성을 확률 분포로써 정량화하는 귀납법                  반복 실험 결과, $0.5$ 의 비율로 동전을 던지면 앞면이 나왔다.          동전을 던지면 앞면이 나온다는 진술을 $0.5$ 수준으로 신뢰할 수 있다.                      불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태          우발적 불확실성(Aleatoric Uncertainty): 시스템이 본질적으로 확률적이기에 발생하는 불확실성                  표본 추출의 우발성(Frequentist)          데이터 생성 과정 상의 무작위성(Bayesianism)                    인식적 불확실성(Epistemic Uncertainty): 연구자가 충분한 정보를 확보하지 못했기에 발생하는 불확실성                  모형의 구조적 불완전성          모형 가정의 부적합          데이터 희소성          데이터 신호의 모호성          데이터의 모집단 대표성 부족 등                      확률(Probability): 불확실성을 정량적으로 표현하는 도구                  빈도주의(Frequentist): 확률의 빈도적 해석                  반복 실험 결과, $0.5$ 의 비율로 동전을 던지면 앞면이 나왔다.                          목표: 실증론(Positivism)적 관점에서 모수의 정체를 규명하는 것          준거 집합(Reference Set): 무한 반복 실험 결과들의 집합          확률 해석(Probability Interpretation): 사건이 발생하는 장기 상대 빈도          불확실성(Uncertainty): 모수 추정 과정 상의 불확실성으로서 표본 추출의 우발성          표현: 신뢰구간(모수를 포함하는 구간)과 신뢰수준(반복 실험에서 모수를 포함하는 상대 빈도)                            베이즈주의(Bayesianism): 확률의 주관적 해석                  동전을 던지면 앞면이 나온다는 진술을 $0.5$ 수준으로 신뢰할 수 있다.                          목표: 인식론(Epistemology)적 관점에서 모수에 대한 인지 수준을 향상시키는 것          준거 집합(Reference Set): 단일 사건에 대한 진술 집합          확률 해석(Probability Interpretation): 사건이 발생할 것이라는 진술의 신념도          불확실성(Uncertainty): 모수 자체의 불확실성으로서 인식적 제약으로 인한 모수에 대한 무지          표현: 사후 확률 분포(모수에 대한 진술과 그 신념도의 집합)                    Optimization Methods      최우추정(Maximum Likelihood Estimation) : 우도를 최대화하는 모수의 추정치를 탐색하는 방법\\[\\begin{aligned}  \\max_{\\theta}{p\\left(\\mathcal{D} \\mid \\theta \\right)}  \\end{aligned}\\]          우도(Likelihood): 특정 모수 하에서 사건이 관찰되는 상대 빈도      신뢰 구간(Confidence Interval): 모수를 포함할 것으로 기대되는 구간      신뢰 수준(Confidence Level): 여러 신뢰 구간 중 모수를 포함하는 신뢰 구간의 비율            베이즈 정리(Bayes’ Theorem) : 모수의 사후 확률 분포를 추정하는 방법\\[\\begin{aligned}  \\underbrace{p\\left(\\theta \\mid \\mathcal{D} \\right)}_{\\text{Posterior}}  = \\underbrace{\\frac{p\\left(\\mathcal{D} \\cap \\theta\\right)}{p\\left(\\mathcal{D}\\right)}}_{\\begin{array}{c} \\text{Conditional}\\\\ \\text{Probability} \\end{array}}  = \\frac{\\overbrace{p\\left(\\mathcal{D} \\mid \\theta \\right)}^{\\text{Likelihood}} \\cdot \\overbrace{p\\left(\\theta\\right)}^{\\text{Prior}}}{\\underbrace{p\\left(\\mathcal{D}\\right)}_{\\text{Evidence}}}  \\end{aligned}\\]          사후 확률 분포(Posterior Probability Distribution): 모수에 대한 인식적 불확실성      우도(Likelihood):  데이터에 대한 모수의 상대적 적합성      사전 확률 분포(Prior Probability Distribution): 모수에 대한 사전 정보      증거(Evidence): 데이터가 관찰될 확률      Sample Size: The Necessity for Bayesian  표본의 크기는 결코 크지 않다. 만일 N이 충분한 추정을 얻기에 부족하다면 더 많은 데이터(또는 더 많은 가정)을 확보해야 한다. 그러나 일단 N이 충분히 크다면 데이터를 나눠 더 많은 것(가령 여론조사에서 전국적으로 훌륭한 추정을 얻었다면 남과 여, 지역별, 연령대별 그룹 등으로 나눠 추정할 수 있다)을 얻을 수 있다. N은 충분하지 않다. 만약 충분하더라도 여러분은 이미 더 많은 데이터가 필요한 다음 문제에 직면하기 때문이다. (Andrew Gelman)      대수의 법칙(Law of Large Numbers): 무작위 실험을 반복해서 수행할수록 관측된 상대적 빈도(추정치)가 이론적 확률(모수)에 가까워진다는 법칙        작은 수의 혼란(Law of Small Numbers): 적은 표본에서도 대수의 법칙이 적용될 것이라고 잘못 가정하거나 소규모 데이터로 도출된 결과를 일반화하려는 오류        If the sample size is sufficient,          모수가 특정 값으로 발생할 것이라는 믿음은 신규 관측치에 의해 끊임없이 갱신되어 참값을 중심으로 집중됨. 이는 빈도주의 추론과 베이지안 추론의 결과가 장기적으로 일치함을 의미함.    \\[\\lim_{n \\to \\infty} P(\\theta \\mid X_{1}, X_{2}, \\cdots, X_{n}) \\to \\mathcal{N}(\\theta_{\\text{true}}, \\frac{\\sigma^2}{n})\\]        If the sample size is not large enough,                  빈도주의(Frequentist): 신뢰 수준을 상향 조정하여 모수 추정 과정상의 불확실성을 줄이고자 함\\[\\text{CI}_{\\theta}=\\bar{X}\\pm Z\\cdot\\frac{\\sigma}{\\sqrt{n}}\\]                    베이즈주의(Bayesianism): 모수의 불확실성을 확률로써 표현함\\[p\\left(\\theta \\mid \\mathcal{D}\\right)=\\frac{p\\left(\\mathcal{D} \\mid \\theta\\right) \\cdot p\\left(\\theta\\right)}{p\\left(\\mathcal{D}\\right)}\\]            "
  },
  
  {
    "title": "Bayesian Framework",
    "url": "/posts/bayesian_framework/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "epistemology, bayesian, bayes' theorem",
    "date": "2024-07-24 00:00:00 +0900",
    





    
    "snippet": "Causal Inference      역추리 문제(Inverse Inference Problem) : 다양한 원인 중 하나로부터 발생했음이 틀림없는 한 가지 사건이 발생했다고 가정하고, 그 원인들이 존재할 각각의 확률을 추리하는 문제(이영의, 2015, p.62)\\[\\begin{aligned}  P(\\text{cause} \\mid \\text{outc...",
    "content": "Causal Inference      역추리 문제(Inverse Inference Problem) : 다양한 원인 중 하나로부터 발생했음이 틀림없는 한 가지 사건이 발생했다고 가정하고, 그 원인들이 존재할 각각의 확률을 추리하는 문제(이영의, 2015, p.62)\\[\\begin{aligned}  P(\\text{cause} \\mid \\text{outcome})  = \\frac{P(\\text{cause} \\wedge \\text{outcome})}{P(\\text{outcome})}  = \\frac{P(\\text{outcome} \\mid \\text{cause}) \\cdot P(\\text{cause})}{P(\\text{outcome})}  \\end{aligned}\\]          어떤 알려지지 않은 사건($Z$)이 발생하고($p$) 실패한 횟수($n-p$)가 주어졌을 때, 하나의 시행에서 그 사건이 발생할 확률($\\theta$)이 지정될 수 있는 두 가지 확률($\\alpha, \\beta$) 사이에 있을 기회가 요청된다($\\alpha &lt; \\theta &lt; \\beta$). (Bayes, 1763, p.376)              베이즈 정리는 주어진 환경에서 하나의 사건($Z$)에 대해 동일한 환경에서 그것이 어떤 횟수만큼 발생했고($p$) 어떤 다른 횟수만큼 발생하는 데 실패했다는 것을($n-p$) 제외한 그 밖의 것에 대해 아무 것도 알지 못한다는 가정에서($\\theta \\sim \\text{Uniform}$) 해당 사건이 발생할 확률($\\theta$)을 판단할 방법을 찾는 일이다. (Price, 1763, 서문)            직접 확률(Direct Probability; $P(B \\mid A)$) : 시행의 성질이 먼저 규정되고($P(A)$) 이어서 시행에서($P(B \\mid A)$) 하나 또는 그 이상의 가능한 결과가 발생할 확률($P(A \\wedge B)$) (이영의, 2015, p.62)\\[\\begin{aligned}  P(B \\mid A)  &amp;= \\frac{P(A \\wedge B)}{P(A)}  \\end{aligned}\\]        역확률(Inverse Probability; $P(A \\mid B)$) : 이미 시행의 결과가 제시되고($P(B)$) 그 다음 실제로 실행된 시행이($P(B \\mid A)$) 가능한 시행 중($P(B)=\\int{P(B \\mid A) \\cdot P(A)\\text{d}A}$) 특정 시행에 해당할 확률($P(A \\wedge B)$) (이영의, 2015, p.62)\\[\\begin{aligned}  P(A \\mid B)  &amp;= \\frac{P(A \\wedge B)}{P(B)}  \\end{aligned}\\]  Bayes’ Billiard Table Analogy  당구대 $ABCD$ 를 가정하자. 공 $\\mathcal{W}, \\mathcal{O}$ 가 그 위에 굴려지면 어떤 하나의 동일한 부분에 정지할 동일한 확률을 가진다. $\\mathcal{W}$ 으로 선분 $OS$ 의 위치가 결정된다. 그 우측 또는 좌측에 $\\mathcal{O}$ 이 정지하는가에 따라서 사건 $Z$ 의 발생 또는 실패가 결정된다. $\\mathcal{O}$ 를 연속하여 $n$ 회 던진 결과 $p$ 회만큼 우측에 정지했음이 관찰되었다. 이때 $AD$ 와 $OS$ 사이의 미지의 거리 $\\theta$ 가 두 가지 값 $\\alpha, \\beta$ 사잇값을 취할 확률은?      공 $\\mathcal{W}$ 가 던져지기 이전에 $\\theta$ 가 $\\alpha, \\beta$ 사이에 있고,사건 $Z$ 가 $n$ 번의 시행에서 $p$ 번 발생하고 $n-p$ 번 실패할 확률:\\[\\begin{aligned}  P(\\alpha &lt; \\theta &lt; \\beta, X=p)  &amp;= \\int_{\\alpha}^{\\beta}{\\binom{n}{p} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}  \\end{aligned}\\]        사건 $Z$ 가 $p$ 번 발생할 확률:\\[\\begin{aligned}  P(X=p)  &amp;= P(0 &lt; \\theta &lt; 1, X=p)\\\\  &amp;= \\int_{0}^{1}{\\binom{n}{p} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}  \\end{aligned}\\]        $\\theta$ 의 값에 대해 어느 것도 알려지기 이전에($0&lt;\\theta&lt;1$),사건 $Z$ 가 $n$ 번의 시행에서 $p$ 번 발생하고 $n-p$ 번 실패한 것으로 드러날 때,그로부터 $\\theta$ 가 $\\alpha, \\beta$ 사이에 있다고 추측한다면,그 추측이 옳을 확률:\\[\\begin{aligned}  P(\\alpha &lt; \\theta &lt; \\beta \\mid X=p)  &amp;= \\frac{P(\\alpha &lt; \\theta &lt; \\beta, X=p)}{P(0 &lt; \\theta &lt; 1, X=p)}\\\\  &amp;= \\frac{\\int_{\\alpha}^{\\beta}{\\cancel{\\binom{n}{p}} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}{\\int_{0}^{1}{\\cancel{\\binom{n}{p}} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}\\\\  &amp;= \\frac{\\int_{\\alpha}^{\\beta}{\\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}{\\int_{0}^{1}{\\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}  \\end{aligned}\\]    Scholum  내가 $Z$ 라고 불렀던 그러한 사건의 경우에, 일정 횟수로 시행하고($n$) 그것이 발생하고($p$) 실패한 횟수($n-p$)를 통해, 그것에 대해서는 다른 어떤 것도 알지 못한 상태에서 그것의 확률에 관해 추측할 수 있고(Non-Informative Prior of $\\theta$), 언급한 면적들의 크기를 계산하는 일반적인 방법에 의해 그러한 추측이 옳을 기회를 알 수 있다(Posterior of $\\theta \\mid \\mathcal{D}$).   그리고 동일한 규칙이 그것에 관해 이루어진 어떤 시행에서도, 우리가 사전에 전혀 알지 못하는 확률을 갖는 사건의 경우에도 사용될 수 있다는 것은 다음을 생각해보면 나타난 것 같다. 즉, 어떤 횟수의 시행에서 그것이 다른 횟수보다 어떤 가능한 다른 횟수로 발생할 것이라는 점을 생각할 이유가 없다.   그러므로 나는 다음부터 당연히 사건 $Z$ 에 대해 주어진 규칙($\\theta$)이 또한 어떠한 시행이 이루어지거나 관찰되기 전에(Prior) 어떤 것도 알려지지 않은(Non-Informative) 사건의 확률(Posterior of $\\theta \\mid \\mathcal{D}$)에도 이용될 수 있다고 간주할 것이다. 나는 그러한 사건을 알려지지 않은 사건(Non-Informative Prior)이라고 부를 것이다. (Bayes, 1763, p.393)Bayesian Framework      베이지안 프레임워크(Bayesian Framework): 데이터 관측 이전의 사전 신념(Prior Belief)을 바탕으로, 데이터 관측 이후의 사후 신념(Posterior Belief)을 갱신함으로써 시행의 성질(모수)이 확정적이지 않은 상태에서 그 성질에 대하여 추론하는 방법론\\[\\begin{aligned}  \\underbrace{P\\left(\\Theta \\mid \\mathcal{D} \\right)}_{\\text{Posterior}}  = \\underbrace{\\frac{P\\left(\\mathcal{D} \\cap \\Theta\\right)}{P\\left(\\mathcal{D}\\right)}}_{\\begin{array}{c} \\text{Conditional}\\\\ \\text{Probability} \\end{array}}  = \\frac{\\overbrace{P\\left(\\mathcal{D} \\mid \\Theta \\right)}^{\\text{Likelihood}} \\cdot \\overbrace{P\\left(\\Theta\\right)}^{\\text{Prior}}}{\\underbrace{P\\left(\\mathcal{D}\\right)}_{\\text{Evidence}}}  \\end{aligned}\\]        사후 확률 분포(Posterior Probability Distribution): 모수에 대한 인식적 불확실성으로서, 단일 사건에 대한 다수 진술의 신뢰도 집합을 나타냄\\[\\begin{aligned}  P\\left(\\Theta \\mid \\mathcal{D} \\right)  \\end{aligned}\\]          시행의 성질에 관한 믿음(Posterior)은 관측 가능한 대상이 아니므로 직접적으로 구할 수 없음      베이즈 정리는 이 믿음(Posterior)을 직접 확률(Likelihood)과 사전 정보(Prior)의 조합으로써 간접적으로 도출함            우도(Likelihood):  데이터에 대한 모수의 상대적 적합성으로서, 데이터 생성 과정상의 무작위성으로 인한 우발적 불확실성을 반영함\\[\\begin{aligned}  P\\left(\\mathcal{D} \\mid \\Theta \\right)  \\end{aligned}\\]        사전 확률 분포(Prior Probability Distribution): 모수에 대한 사전 정보\\[\\begin{aligned}  P\\left(\\Theta\\right)  \\end{aligned}\\]        증거(Evidence): 데이터가 관찰될 확률로서, 모수에 대한 신념을 뒷받침하는 증거로 해석됨\\[\\begin{aligned}  P\\left(\\mathcal{D}\\right)  &amp;= \\int{P(\\mathcal{D} \\mid \\Theta) \\cdot P(\\Theta)\\text{d}\\Theta}  \\end{aligned}\\]          베이지안에서는 모수에 대하여 주장함에 있어 현재 주어진 정보, 가령 사전 정보, 데이터 관측 결과 등을 기반으로 함. 따라서 현재까지 관찰된 데이터가 실현될 가능성은 모수에 대한 주장의 증거(Evidence)임.            사후 예측 분포(Posterior Predictive Distribution): 관측 데이터 \\(\\mathcal{D}\\) 를 바탕으로 도출된, 미관측 데이터 \\((x^{*}, y^{*})\\) 가 취할 예측값에 대한 확률 분포\\[\\begin{aligned}  p(y^{*} \\mid x^{*}; \\mathcal{D})  &amp;= \\int{p(y^{*} \\mid x^{*}, \\theta) \\cdot p(\\theta \\mid \\mathcal{D})}\\text{d}\\theta  \\end{aligned}\\]          \\(p(y^{*} \\mid x^{*}, \\theta)\\): 관측 데이터 \\((x^{*}, y^{*})\\) 에 대한 우도      \\(p(\\theta \\mid \\mathcal{D})\\): 관측 데이터 \\(\\mathcal{D}\\) 로부터 도출된 모수 \\(\\theta\\) 에 대한 사후 확률 분포이자, 신규 관측치 \\((x^{*}, y^{*})\\) 관측 전 모수 $\\theta$ 에 대한 사전 확률 분포            사전 예측 분포(Prior Predictive Distribution): 사전 정보만을 바탕으로 도출된 미관측 데이터 \\((x^{*}, y^{*})\\) 가 취할 예측값에 대한 확률 분포\\[\\begin{aligned}  p(y^{*} \\mid x^{*})  &amp;= \\int{p(y^{*} \\mid x^{*}, \\theta) \\cdot p(\\theta)}\\text{d}\\theta  \\end{aligned}\\]          \\(p(y^{*} \\mid x^{*}, \\theta)\\): 신규 관측치 \\((x^{*}, y^{*})\\) 에 대한 우도      \\(p(\\theta)\\): 신규 관측치 \\((x^{*}, y^{*})\\) 관측 전 모수 \\(\\theta\\) 에 대한 사전 확률 분포      [example] 동전 던지기  동전을 던졌을 때 앞면이 나올 확률을 $\\theta$ 라고 하자. $\\theta$ 에 대한 정보가 아무것도 없다고 가정하자. 즉, $\\theta$ 는 0과 1 사이의 무작위수일 것이라고 믿어지고 있다. 동전을 두 번 던졌는데 두 번 다 앞면이 나왔다. 그렇다면 $\\theta$ 에 대한 믿음은 어떻게 변화할까?      Prior Prob. Dist.:\\[\\begin{aligned}  p(\\theta)  =1 \\quad \\because \\theta \\sim \\text{Uniform}(0,1)  \\end{aligned}\\]        Likelihood:\\[\\begin{aligned}  p\\left(X \\mid \\theta\\right)  =\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X} \\quad \\because X \\mid \\theta \\sim \\text{Bin}(n,\\theta)  \\end{aligned}\\]        Evidence:\\[\\begin{aligned}  p(X)  &amp;= \\int_{0}^{1}{p\\left(X \\mid \\theta\\right)}\\text{d}\\theta\\\\  &amp;= \\int_{0}^{1}{\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\int_{0}^{1}{\\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\text{B}(X+1,n-X+1)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{\\Gamma(X+1)\\Gamma(n-X+1)}{\\Gamma(n+2)} \\quad \\because (X+1),(n-X+1) \\in \\mathbb{R}^{+}\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{X!(n-X)!}{(n+1)!} \\quad \\because (X+1),(n-X+1) \\in \\mathbb{Z}^{+}\\\\  &amp;= \\frac{1}{n+1}  \\end{aligned}\\]        Posterior Prob. Dist.:\\[\\begin{aligned}  p\\left(\\theta \\mid X\\right)  &amp;\\propto p\\left(X \\mid \\theta\\right) \\cdot p\\left(\\theta\\right)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}\\\\  \\\\  \\therefore \\theta \\mid X  &amp;\\sim \\text{Beta}(X+1,n-X+1)  \\end{aligned}\\]  Annotation      $\\text{B}(\\alpha,\\beta)$ : 베타 함수\\[\\begin{aligned}  \\text{B}(\\alpha,\\beta)  &amp;= \\int_{0}^{1}{t^{\\alpha-1}(1-t)^{\\beta-1}}\\text{d}t\\\\  &amp;= \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)} \\quad \\text{where}\\; \\alpha,\\beta \\in \\mathbb{R}^{+}  \\end{aligned}\\]        $\\Gamma(n)$ : 감마 함수\\[\\begin{aligned}  \\Gamma(n)  &amp;= \\int_{0}^{\\infty}{t^{(n-1)}e^{-t}}\\text{d}t\\\\  &amp;= (n-1)! \\quad \\text{where}\\; n \\in \\mathbb{Z}^{+}  \\end{aligned}\\]        $\\text{Beta}(\\alpha,\\beta)$ : 베타분포\\[f(x)  = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\text{B}(\\alpha,\\beta)}  \\sim \\text{Beta}(\\alpha,\\beta)\\]  Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Justification of Bayesianism",
    "url": "/posts/justification/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "epistemology, bayesian, bayes' theorem",
    "date": "2024-07-23 00:00:00 +0900",
    





    
    "snippet": "Condition  윤리적으로 중립인 명제에 대하여 그것의 참 여부에 따라 $0-1$ 사이의 서수적 효용을 획득하거나 상실할 수 있는 내기 상황을 가정함으로써, 베이즈주의는 개인의 신념도를 행위의 자발성과 동일시하는 행동주의적 접근을 취한다(이영의, 2015, p.35). 즉, 내기 상황 하에서 신념과 선호를 기대 효용의 형태로 연결하고, 이를 최적화...",
    "content": "Condition  윤리적으로 중립인 명제에 대하여 그것의 참 여부에 따라 $0-1$ 사이의 서수적 효용을 획득하거나 상실할 수 있는 내기 상황을 가정함으로써, 베이즈주의는 개인의 신념도를 행위의 자발성과 동일시하는 행동주의적 접근을 취한다(이영의, 2015, p.35). 즉, 내기 상황 하에서 신념과 선호를 기대 효용의 형태로 연결하고, 이를 최적화 혹은 효용 극대화라는 선택으로써 측정 가능한 형태로 이끌어낸다.Measurement Condition      측정 조건(Measurement Condition)          신념도는 측정될 방법을 규정할 수 있을 경우에만 완전한 의미를 가진다(이영의, 2015, p.35).            램지 가정(Ramsey’s Assumption)          행위의 집합이 주어지면 합리적 행위자는 최대 기대값을 갖는 행위를 선택한다(이영의, 2015, p.35).            기대 효용 이론(Expected Utility Theory)          $X$ 에 대한 행위자의 신념도가 $p$ 이라는 것은 그 행위자는 $X$ 이면 단위 $1$ 을 지불하고 그렇지 않은 경우에는 $0$ 을 지불하는 도박에 대해 $p$ 를 지불할 용의가 있다는 것이다(de Finetti, 1937, p.62).      Consistency Condition      정합성 조건(Consistency Condition)          여러 가지 명제에 대한 개인의 신념도 집합은 일정한 방식으로 상호 간 일치하거나 입증되어야만 한다(이영의, 2015, p.35).            베이즈주의 공준(Bayesianism Postulate)          이상적으로 합리적인 행위자의 신념도는 확률론의 공리체계를 준수한다(이영의, 2015, p.19).            더치북 논증(Dutch Book Argument) | 실용적 정합화          특정인의 확률함수가 공리체계를 만족시키지 못할 경우에, 하나의 내기 전략이 있고 판돈의 집합이 있는 내기 상황에서 그는 결과에 상관없이 항상 일정한 액수를 잃게 된다(이영의, 2015, p.58).            콕스 정리(Cox’s Theorem) | 논리적 정합화          함수 $G,H$ 가 실수 전체에 대하여 연속이고, 한 개인의 신념 함수 $b$ 가 논리 집합 $\\mathcal{L}$ 에 대하여 $b:\\mathcal{L} \\times \\mathcal{L} \\to \\mathbb{R}$ 인 단조 함수라고 하자. 아래 조건을 만족하는 신념 함수 $b$ 는 존재론적으로 유일한 확률 함수 $P$ 와 엄격히 증가하는 실수 함수 $F$ 에 대하여 $b(A \\mid B) = F(P(A \\mid B))$ 임을 만족한다. 즉, 신념 함수 $b$ 는 확률 함수 $P$ 와 동형이다.                      논리 연산의 일관성(Associativity &amp; Consistency): 이변수 함수 $G$ 가 논리 연산 $\\wedge$ 의 구조적 결합성과 일치하기 위해서는 형태가 곱셈형이거나 이와 동형이어야 함\\[\\begin{aligned}  b(A \\wedge B \\mid C)  &amp;= G(b(A \\mid C), b(B \\mid A \\wedge C))  \\end{aligned}\\]                    부정의 일관성(Negation): 일변수 함수 $H$ 가 부정을 나타내기 위해서는 확률의 여사건 법칙 $1-p$ 에 대응하는 형태를 만족해야 함\\[\\begin{aligned}  b(\\neg A \\mid B)  &amp;= H(b(A \\mid B))  \\end{aligned}\\]                    존재 가능성(Non-Triviality): 전적으로 확신하는 신념과 완전히 부정하는 신념은 서로 다른 값이어야 함            Constraining Priors      사전 확률 제약하기(Constraining Priors): 베이즈주의적 합리성이 주관적 신념의 형식적 정합화를 넘어선 정당화를 제공하기 위해서는 사전 확률 분포가 논리적(Logical), 경험적(Empirical), 또는 규범적(Objective) 제약 하에 형성되어야 함        주관적 베이즈주의(Subjective Bayes) | Belief          나는 진심으로 그러한 절대적 의미에서의 모든 확률 개념을 반대한다. (중략) 확률은 우리가 그에 대해 정신적으로 또는 본능적으로 내리는 평가와 독립적으로 존재하지 않는다는 의미에서 “확률은 존재하지 않는다(de Finetti, 1977, p.199).”            경험적 베이즈주의(Empirical Bayes) | Utility          그러므로 하나의 의견이 주어지면, 우리는 진위에 근거하여 그것을 칭찬하거나 책망할 수 있을 뿐이다. 특정한 형태의 습관이 주어지면 우리는 습관이 산출하는 신념도가 그것이 진리로 이끄는 실제 비율에 근접하거나 멀어지는가에 따라서 칭찬하거나 책망할 수 있다. 그렇다면 우리는 의견을 산출하는 습관들을 칭찬하거나 책망하는 것으로부터 파생적으로 의견들을 칭찬하거나 책망할 수 있다(Ramsey, 1926, p.51).            객관적 베이즈주의(Objective Bayes) | Background, Non-Information          무차별의 원리가 주장하는 것은 만약 우리의 관심의 대상이 여러 가지 대안 중 어느 것보다 더 예측할 만한 어떠한 알려진 이유가 없다면 그러한 지식에 상대적으로 이러한 대안 각각에 대한 주장들은 동일한 확률을 갖는다는 점이다(Keynes, 1921, p.42).      Washing Out Priors      객관성(Objectivity)          절차의 합리성과 결과의 합리성이 대응하지 않을 경우는 어떻게 해야 하는가? (중략) 이 부분에서 우리의 논의에서 처음으로 합리성의 문제가 객관성의 문제와 관련된다. 진리성과 관련하여 어느 사회에서나 통용되는 기준들이 있으며 우리는 그것들이 객관적이라고 부른다. (중략) 베이즈주의적 객관성은 확실하지 않은 의견들 간 성립하는 간주관적 일치이다(이영의, 2015, p.41).            사전 확률 씻겨내기(Washing Out Priors)          동전의 미래 행위에 대한 당신의 견해가 이웃 사람의 견해와 크게 다르더라도, 당신의 견해와 이웃 사람의 견해는 일상적으로 실험적인 던지기의 긴 연속에 베이즈의 정리를 적용하여 변형되어 거의 구별할 수 없게 될 것이다(Edwards, Lindman, and Savage, 1963, p.197). 즉, 다양한 신념들은 충분한 근거가 주어지면 간주관적으로 수렴하며, 이 일치를 객관적 신념 상태로 해석할 수 있다.            두브의 마틴게일 수렴 정리(Doob’s Martingale Convergence Theorem)          일반적 환경에서 조건화에 의한 확률 변화는 장기적으로 안정화된다(이영의, 2015, p.54).  \\(\\mathbb{E}\\left[\\theta \\mid \\mathcal{D}_{n}\\right] \\to \\mathbb{E}\\left[\\theta \\mid \\mathcal{D}_{\\infty}\\right]\\)                      마틴게일(Martingale): 현재까지의 모든 정보를 알고 있을 때(\\(\\mathcal{F}_{n}\\)), 다음 단계에서 확률변수 \\(X_{n+1}\\) 의 조건부 기대값 \\(\\mathbb{E}\\left[X_{n+1} \\mid \\mathcal{F}_{n}\\right]\\) 이 현재 값 \\(X_{n}\\) 과 같은 확률 과정\\[\\begin{aligned}  \\mathbb{E}\\left[X_{n+1} \\mid \\mathcal{F}_{n}\\right]  &amp;= X_{n}  \\end{aligned}\\]                  $\\mathcal{F}_{n}$: $n$ 번째 시점까지 보유하고 있는 모든 정보를 나타내는 시그마 필드                          조건화 규칙(Rule of Conditionalization): 인식적 불확실성 하에서의 합리적인 정보 갱신 원칙으로서, $n$ 시점에서 새로운 증거에 의해 형성된 사후 신념을 $n+1$ 시점에서의 사전 정보로서 수용하는 규칙                  엄밀 조건화 규칙(Rule of Strict Conditionalization):\\[\\begin{aligned}  \\Pi\\left(\\Theta\\right)  &amp;= P\\left(\\Theta \\mid \\mathcal{D}\\right)  \\end{aligned}\\]                    제프리 조건화 규칙(Jeffrey’s Conditionalization):\\[\\begin{aligned}  \\Pi\\left(\\Theta\\right)  &amp;= Q\\left(\\mathcal{D}\\right) \\cdot P\\left(\\Theta \\mid \\mathcal{D}\\right) + Q\\left(\\neg\\mathcal{D}\\right) \\cdot p\\left(\\Theta \\mid \\neg\\mathcal{D}\\right)  \\end{aligned}\\]                  $Q\\left(\\mathcal{D}\\right)$: 새로운 증거에 대한 인지 수준                    Problem of Induction      귀납의 문제(Problem of Induction)          특정 사례들로부터 보편 결론을 이끌어낼 수 없다.            후험 일치성(Posterior Consistency)          확률 계산법을 준수하고 조건화 규칙에 따라 개정이 이루어진다면, 그리고 그러한 개정의 결과가 궁극적으로 참으로 수렴한다는 점이 보증된다면, 베이즈주의 추리에서는 귀납의 문제가 성립될 수 없다(이영의, 2015, p.55).            슈바르츠 정리(Schwartz’s Theorem)          관측치 \\(X \\sim P(\\theta)\\), 모수 \\(\\theta \\in \\Theta\\), 사전 확률 분포 \\(\\Pi\\), 참 모수 \\(\\theta^{*}\\) 에 대하여, \\(\\theta^{*}\\) 의 근방에 위치한 \\(\\theta\\) 가 사전 확률 분포에서 양의 질량을 가진다고 하자. 즉, \\(\\Pi\\left(\\{\\theta : D_{KL}\\left[P_{\\theta^{*}} \\Vert P_{\\theta}\\right] &lt; \\epsilon\\}\\right) &gt; 0\\) 이다. 이때 사후 확률 분포는 장기적으로 \\(\\theta^{*}\\) 에 집중된다. 즉, \\(\\Pi\\left(\\theta^{*} \\mid X_{1}, \\cdots, X_{n}\\right) \\xrightarrow{n \\to \\infty} 1\\) 이다.      Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Bayesianism",
    "url": "/posts/bayesianism/",
    "categories": "5.BAYES, 1.bayes basic",
    "tags": "epistemology, bayesian, bayes' theorem",
    "date": "2024-07-22 00:00:00 +0900",
    





    
    "snippet": "Epistemology      인식론(Epistemology): 믿음이 어떻게 정당화되어 앎이 되는가에 대한 철학적 논의          앎은 정당화된 참된 믿음(Knowledge is Justified True Belief)              믿음(Belief): 해당 명제가 참임을 믿고 있다.      사실(Truth): 해당 명제가 사실이...",
    "content": "Epistemology      인식론(Epistemology): 믿음이 어떻게 정당화되어 앎이 되는가에 대한 철학적 논의          앎은 정당화된 참된 믿음(Knowledge is Justified True Belief)              믿음(Belief): 해당 명제가 참임을 믿고 있다.      사실(Truth): 해당 명제가 사실이어야 한다.      정당화(Justification): 믿음에는 근거가 있어야 한다.            베이즈주의(Bayesianism): 수량화된 인식론          확률적 귀납 개념에 따르면 과학 이론은 절대적 확실성을 가질 수 없지만 확실한 참과 확실한 거짓이라는 양극단 사이에 존재하는 인식적 값을 가질 수 있으며, 그 값은 새로운 증거에 의해 변경될 수 있다. (이영의, 2015, p.19)              형식 체계(Formalism): 베이즈 정리(Bayes’ Theorem)      해석 체계(Interpretation): 확률의 주관적 해석(Subjective interpretation)            베이지안 프레임워크(Bayesian Framework)                            Formalism          Bayes Module          Interpretation                                      \\(p(\\theta)\\)          사전 확률 분포(Prior)          신념(Belief)                          \\(p(\\mathcal{D}\\mid\\theta)\\)          우도(Likelihood)          참(Truth)                          \\(p(\\mathcal{D})\\)          증거(Evidence)          근거(Reason)                          \\(p(\\theta\\mid\\mathcal{D})\\)          사후 확률 분포(Posterior)          앎(Knowledge)                          \\(p(\\theta\\mid\\mathcal{D})=\\displaystyle\\frac{p(\\mathcal{D}\\mid\\theta)p(\\theta)}{p(\\mathcal{D})}\\)          베이즈 정리(Bayes’ Theorem)          정당화(Justification)                    Formalism      콜모고로프의 확률 공리(Kolmogorov Probability Axiom)          확률 공간(Probability Space) $[\\Omega, F, P]$ 는 다음을 이른다. 즉, $F$ 는 공집합이 아닌 집합 $\\Omega$ 에 대하여 그 시그마 대수($\\sigma$-Algebra)이다. 이때 확률함수(Probability Function) $P$ 는 $F$ 로부터 다음을 만족하는 실수로의 함수이다.              K1 모든 $A \\in F$ 에 대하여 $P(A) \\ge 0$      K2 $P(\\Omega)=1$      K3 $A \\cap B = \\emptyset$ 인 모든 $A,B \\in F$ 에 대하여 $P(A \\vee B) = P(A) + P(B)$        베이즈주의 확률 공리(Bayesian Probability Axiom)          B1 $A,B \\in S$ 에 대하여 $0 \\le P(B \\mid A) \\le 1$      B2 $A$ 가 $B$ 를 논리적으로 함축하면 $P(B \\mid A) = 1$      B3 $B,C$ 가 상호 배타적이면 $P(B \\vee C\\mid A) = P(B \\mid A) + P(C \\mid A)$      B4 $P(A) \\ne 0$ 인 경우 $P(B \\mid A) = \\displaystyle\\frac{P(A \\wedge B)}{P(A)}$        성질(Property)          T1 $B,C$ 가 독립적이면 $P(B \\wedge C \\mid A) = P(B \\mid A) \\cdot P(C \\mid A)$      T2 $P(\\neg B \\mid A) = 1 - P(B \\mid A)$      T3 $P(B \\vee C \\mid A) = P(B \\mid A) + P(C \\mid A) - P(B \\wedge C \\mid A)$      T4 $P(C \\mid A) = P(B \\mid A) \\cdot P(C \\mid A \\wedge B) + P(\\neg B \\mid A) \\cdot P(C \\mid A \\wedge \\neg B)$        베이즈 정리(Bayes’ Theorem)          BT1 $P(\\theta), P(\\mathcal{D}) &gt; 0$ 이면 $P(\\theta \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\mathcal{D} \\mid \\theta) \\cdot P(\\theta)}{P(\\mathcal{D})}$      BT2 $P(\\theta_{1} \\vee \\cdots \\vee \\theta_{n})=1$ 이고 $\\theta_{i} \\vdash \\neg \\theta_{j}(i \\ne j)$ 이면 $P(\\theta_{k} \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\mathcal{D} \\mid \\theta_{k}) \\cdot P(\\theta_{k})}{\\sum_{i}{P(\\mathcal{D} \\mid \\theta_{i}) \\cdot P(\\theta_{i})}}$      BT3 $P(\\theta \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\theta)}{P(\\theta) + P(\\mathcal{D} \\mid \\neg \\theta) \\cdot P(\\neg \\theta)/P(\\mathcal{D} \\mid \\theta)}$      Interpretation      확률 해석(Probability Interpretation): 확률함수 $P$ 의 의미를 규명하는 해석 체계          해석은 술어 논리, 리만 기하학, 양자역학과 같은 형식체계를 구성하는 공리들과 정의들에 등장하는 미정의된(Undefined) 또는 원초적(Primitive) 용어들에 일상적 의미를 부여하여 그런 공리들과 정리들이 준거 세계에 대해 참이 되도록 하는 작업을 의미한다. (이영의, 2015, p.19)              고전적 해석(Classical interpretation)      논리적 해석(Logical interpretation)      빈도적 해석(Frequentist interpretation)      성향적 해석(Propensity interpretation)      주관적 해석(Subjective interpretation)            주관적 해석(Subjective interpretation) (이영의, 2015, p.34)          베이즈주의는 이처럼 특정 진술에 대한 우리의 믿음, 즉 신념도에 양의 실수를 부여하는 것은 전형적인 확률 판단에 속한다고 보고, 그런 판단을 확률함수 $P$(Probability Function)로 표현한다. 확률함수 $P$ 는 특정 진술을 일정한 수치에 대응시킨다. (이영의, 2015, p.2)              s1 확률은 특정 명제에 대한 행위자의 신념도이다.      s2 확률은 행위, 특히 내기 행위를 조사함으로써 가장 잘 확립될 수 있다.      s3 객관적인 확률은 없다. 만약 객관적 확률이 존재한다면 그것은 이차적 확률이다.      s4 사건은 고유한 확률을 갖지 않는다. 개인은 자신의 확률을 논리적으로 자유롭게 결정할 수 있다.      s5 합리적 개인의 신념은 확률론의 계산법과 무모순적이어야 하고, 동시에 그것에 의해 규제되어야 한다.      Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Logistic Regression Analysis",
    "url": "/posts/logistic_regression_analysis/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, logistic regression analysis, binary data analysis",
    "date": "2024-07-21 00:00:00 +0900",
    





    
    "snippet": "Prerequisite      승산(Odds) : 변수 $Y$ 가 반응할 가능성이, 반응하지 않을 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{odds}(Y)  &amp;= \\frac{P(Y=1)}{1-P(Y=1)}  \\end{aligned}\\]        로짓(Logit; Logarithm Odds) : 승산에 로그를 취한...",
    "content": "Prerequisite      승산(Odds) : 변수 $Y$ 가 반응할 가능성이, 반응하지 않을 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{odds}(Y)  &amp;= \\frac{P(Y=1)}{1-P(Y=1)}  \\end{aligned}\\]        로짓(Logit; Logarithm Odds) : 승산에 로그를 취한 값\\[\\begin{aligned}  \\text{logit}(Y)  &amp;= \\ln{\\text{odds}(Y)}\\\\  &amp;= \\ln{\\frac{P(Y=1)}{1-P(Y=1)}}  \\end{aligned}\\]        승산비(Odds Ratio; OR) : 변수 $X$ 가 참일 때 $Y$ 가 반응할 가능성이, $X$ 가 거짓일 때 $Y$ 가 반응할 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{OR}(Y \\mid X)  &amp;= \\frac{\\text{odds}(Y \\mid X=1)}{\\text{odds}(Y \\mid X=0)}\\\\  &amp;= \\left[\\frac{P(Y=1\\mid X=1)}{1-P(Y=1 \\mid X=1)}\\right] \\bigg/ \\left[\\frac{P(Y=1\\mid X=0)}{1-P(Y=1 \\mid X=0)}\\right]  \\end{aligned}\\]          $\\text{OR}(Y \\mid X) \\approx 1$ : $X$ 의 단위 변동이 $Y$ 의 승산에 영향을 미치지 않음      $\\text{OR}(Y\\mid X) &lt; 1$ : $X$ 의 단위 변동이 $Y$ 의 승산과 음의 상관관계에 있음      $\\text{OR}(Y \\mid X) &gt; 1$ : $X$ 의 단위 변동이 $Y$ 의 승산과 양의 상관관게에 있음      Logistic Regression      로지스틱 회귀 모형(Logistic Regression) : 범주형 반응변수에 대한 회귀 모형    \\[P(y^{(i)}=1)  = \\frac{1}{1+\\exp{\\left[-\\left(\\beta_{0}+\\beta_{1} \\cdot x^{(i)}\\right)\\right]}}\\]  Logistic Function      범주형 반응변수와 회귀식 간 범위 불일치 문제                  범주형 반응변수 $Y$ 의 공역\\[y^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{true}\\\\  0 \\quad &amp;\\text{false}  \\end{aligned}\\end{cases}\\]                    회귀식의 범위\\[\\begin{aligned}  f(x^{(i)})  = \\beta_{0} + \\beta_{1} \\cdot x^{(i)} \\in (-\\infty,\\infty)  \\end{aligned}\\]                    반응변수 공역과 회귀식 범위 간 불일치\\[\\begin{aligned}  y^{(i)} \\ne \\beta_{0} + \\beta_{1} \\cdot x^{(i)}  \\end{aligned}\\]                  반응변수 재정의를 통한 공역 조정                  확률 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad P(Y=1) \\in [0,1]\\]                    승산(odds) 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad \\text{odds}(Y) \\in [0,\\infty)\\]                    로짓(logit) 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad \\text{logit}(Y) \\in (-\\infty,\\infty)\\]                  로지스틱 회귀식 도출                  로짓 변환한 반응변수와 회귀식 연결\\[\\begin{aligned}  \\text{logit}(y^{(i)})  &amp;= \\beta_{0} + \\beta_{1} \\cdot x^{(i)}  \\end{aligned}\\]                    반응변수가 참일 확률에 대한 로지스틱 회귀식 도출\\[\\begin{aligned}  P(y^{(i)}=1)  &amp;= \\frac{1}{1+\\exp\\left[-\\left(\\beta_{0}+\\beta_{1} \\cdot x^{(i)}\\right)\\right]}  \\end{aligned}\\]            $\\beta_{1}$ related to Log Odds Ratio      Logistic Function\\[\\ln{\\frac{P(Y=1)}{1-P(Y=1)}}  =\\beta_0 + \\beta_1 \\cdot X\\]        $\\text{if} \\quad X=1$\\[\\begin{aligned}  \\ln{\\frac{P(Y=1 \\mid X=1)}{1-P(Y=1 \\mid X=1)}}  &amp;= \\beta_0 + \\beta_1 \\times 1 \\\\  &amp;= \\beta_0 + \\beta_1  \\end{aligned}\\]        $\\text{if} \\quad X=0$\\[\\begin{aligned}  \\ln{\\frac{P(Y=1 \\mid X=0)}{1-P(Y=1 \\mid X=0)}}  &amp;= \\beta_0 + \\beta_1 \\times 0 \\\\  &amp;= \\beta_0  \\end{aligned}\\]        $\\beta_1$\\[\\begin{aligned}  \\beta_1  &amp;= \\left(\\beta_0 + \\beta_1\\right) - \\beta_0\\\\  &amp;= \\ln{\\frac{P(Y=1 \\mid X=1)}{1-P(Y=1 \\mid X=1)}} - \\ln{\\frac{P(Y=1 \\mid X=0)}{1-P(Y=1 \\mid X=0)}}\\\\  &amp;= \\ln{\\text{odds}(Y \\mid X=1)} - \\ln{\\text{odds}(Y \\mid X=0)}\\\\  &amp;= \\ln{\\frac{\\text{odds}(Y \\mid X=1)}{\\text{odds}(Y \\mid X=0)}}\\\\  &amp;= \\ln{\\text{OR}(Y \\mid X)}  \\end{aligned}\\]  Maximum Liklihood Estimator      Liklihood Function\\[\\begin{aligned}  \\mathcal{L}(\\theta)  &amp;= \\prod_{i:y=1}{P(x_{i} \\mid \\theta)} \\cdot \\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}  \\end{aligned}\\]          $\\prod_{i:y=1}{P(x_{i} \\mid \\theta)}$ : $\\theta$ 조건부 $Y=1$ 인 관측치들이 발생할 확률      $\\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}$ : $\\theta$ 조건부 $Y=0$ 인 관측치들이 발생할 확률            Maximum Liklihood Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\max_{\\theta}{\\mathcal{L}(\\theta)}\\\\  &amp;= \\text{arg} \\max_{\\theta}{\\prod_{i:y=1}{P(x_{i} \\mid \\theta)} \\cdot \\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}}\\\\  &amp;= \\text{arg} \\max_{\\theta}{\\sum_{i:y=1}{P(x_{i} \\mid \\theta)} + \\sum_{j:y=0}{P(x_{j} \\mid \\theta)}}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Improvement of OLS",
    "url": "/posts/improvement_of_ols/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis",
    "date": "2024-07-20 00:00:00 +0900",
    





    
    "snippet": "Bias-Variance Trade-off  Notation          $Y$ : 실제 관측치      $\\varepsilon \\sim N(0, \\sigma^2)$ : 노이즈      $f(X)$ : 실제 함수      $\\hat{f}(X)$ : $f(X)$ 에 대한 예측값      $\\overline{f}(X)$ : $\\hat{f}(X)$ 의 ...",
    "content": "Bias-Variance Trade-off  Notation          $Y$ : 실제 관측치      $\\varepsilon \\sim N(0, \\sigma^2)$ : 노이즈      $f(X)$ : 실제 함수      $\\hat{f}(X)$ : $f(X)$ 에 대한 예측값      $\\overline{f}(X)$ : $\\hat{f}(X)$ 의 평균            error segmentation:\\[\\begin{aligned}  \\text{Error}  &amp;= \\mathbb{E}\\left[\\left(Y-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2} + \\varepsilon^{2} - 2 \\cdot \\varepsilon \\cdot \\left(f(X)-\\hat{f}(X)\\right) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\varepsilon^{2}\\right] - 2 \\cdot \\mathbb{E}\\left[\\varepsilon\\right] \\cdot \\mathbb{E}\\left[f(X)-\\hat{f}(X) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\sigma^{2}  \\end{aligned}\\]        estimation error:\\[\\begin{aligned}  &amp;\\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)+\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right] + 2 \\cdot \\mathbb{E}\\left[f(X)-\\overline{f}(X)\\right] \\cdot \\mathbb{E}\\left[\\overline{f}(X)-\\hat{f}(X)\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        estimation error consists of bias and variance:\\[\\begin{aligned}  \\mathbb{Bias}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\hat{f}(X)\\right] - f(X)\\\\  \\mathbb{Var}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  \\therefore \\text{Error}  &amp;= \\mathbb{Bias}^{2}\\left[\\hat{f}(X)\\right] + \\mathbb{Var}\\left[\\hat{f}(X)\\right] + \\sigma^{2}  \\end{aligned}\\]        Bias-Variance Trade-off:              Bias is the underfitting problem that occurs when a model does not sufficiently learn the patterns of the training data.      Variance is the overfitting problem that occurs when a model adapts too much to the training data.      Improvement of OLS  최소자승추정량은 BLUE(Best Linear Unbias Estimator)로서, 편향이 $0$ 인 추정량 중 분산이 가장 작은 추정량임. 만약 편향이 $0$ 이어야 한다는 제약 조건을 완화한다면 분산을 더 줄일 수 있지 않을까?  변수 선택(Feature Selection) : $p$ 개의 설명변수 중 반응변수와 관련이 있다고 생각되는 설명변수들을 식별하여 추정하는 방법          전진 선택(Forward Selection)      후진 선택(Backward Elimination)      혼합 선택(Stepwise Selection)        수축(Shrinkage) : $p$ 개의 설명변수를 모두 포함하는 모형을 추정하되, 회귀계수를 최소자승추정량보다 작은 값으로 수축함으로써 분산을 줄이는 방법          Ridge Regression      LASSO Regression        차원축소(Dimension Reduction) : $p$ 개의 설명변수를 저차원 공간으로 사영(Projection)하는 방법          주성분 분석(Principal Component Analysis; PCA)      선형 판별 분석(Linear Discriminant Analysis; LDA)      Feature Selection  Occam’s Razor  Entities should not be multiplied beyond necessity.      전진 선택(Forward Selection) : 어떤 변수도 선택되지 않은 상태에서 가장 설명력이 좋은 변수를 하나씩 추가하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(x_{i})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(x_{j \\ne i};\\hat{x}_{i})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(x_{k \\ne i,j};\\hat{x}_{i},\\hat{x}_{j})]\\\\  &amp;\\vdots  \\end{aligned}\\]        후진 선택(Backward Elimination) : 모든 변수가 포함된 상태에서 시작하여 불필요한 변수를 하나씩 제거하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(\\not{x_{i}})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(\\not{x_{j \\ne i}};\\not{\\hat{x}_{i}})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(\\not{x_{k \\ne i,j}};\\not{\\hat{x}_{i}},\\not{\\hat{x}_{j}})]\\\\  &amp;\\vdots  \\end{aligned}\\]        혼합 선택(Stepwise Selection) : 어떤 변수도 선택되지 않은 상태에서 Forward Selection 과 Backward Elimination 을 번갈아 수행하는 방법  Metrics      Adjusted Coefficient of Determination($\\text{Adj.}R^2$)\\[\\text{Adj.}R^2 = \\frac{(n-1)R^2-p}{n-p-1}\\]        Akaike Information Criteria(AIC)\\[\\begin{aligned}  \\text{AIC}  &amp;= -2\\ln{\\hat{L}}+2k  \\end{aligned}\\]                  $\\hat{L}$ : 모델 적합도로서 \\(\\mathbf{x}_{i}\\) 가 주어졌을 때 $y_{i}$ 가 발생할 가능성\\[\\begin{aligned}  \\hat{L}  &amp;= \\prod_{i=1}^{n}{P(Y=y^{(i)} \\mid X=\\mathbf{x}^{(i)};\\hat{\\mathbf{b}})}\\\\  \\hat{\\mathbf{b}}  &amp;= \\begin{pmatrix}\\hat{\\beta_{0}}&amp;\\hat{\\beta_{1}}&amp;\\cdots&amp;\\hat{\\beta_{d}}\\end{pmatrix}  \\end{aligned}\\]                    $k$ : 모델 복잡도                  Bayesian Information Criteria(BIC)\\[\\begin{aligned}  \\text{BIC}  &amp;= -2\\ln{\\hat{L}}+k\\ln{n}  \\end{aligned}\\]  Shrinkage Methods      p-norm : $n$ 차원 벡터 $\\mathbf{x}=\\begin{pmatrix}x_{1}&amp;x_{2}&amp;\\cdots&amp;x_{n}\\end{pmatrix}$ 의 크기를 정의하는 방법    \\[\\Vert x \\Vert _{p}=(\\vert x_{1} \\vert ^{p}+ \\vert x_{2} \\vert ^{p}+\\cdots+ \\vert x_{n} \\vert ^{p})^{\\frac{1}{p}}\\]        가중치 규제(Weight Regulation) : 회귀계수 최적값을 탐색함에 있어 회귀계수 벡터 $\\beta$ 의 크기에 제약을 두는 것    \\[\\begin{aligned}  \\hat{\\beta}  &amp;= \\text{arg} \\min_{\\beta}{\\left[L_{OLS}+\\lambda \\Vert \\beta \\Vert _{p}^{2}\\right]}  \\end{aligned}\\]          $L_{OLS}(\\beta)$ : 최소자승법에 기초한 손실 함수      $\\beta$ : 회귀계수 벡터      $\\lambda$ : 회귀계수 벡터 $\\beta$ 크기 제약 강도      p=1 : LASSO      p=2 : Ridge      Sourse  http://scott.fortmann-roe.com/docs/BiasVariance.html  https://github.com/lovit/python_ml_intro  https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html  https://observablehq.com/@petulla/l1-l2l_1-l_2l1-l2-norm-geometric-interpretation"
  },
  
  {
    "title": "Variable Issues",
    "url": "/posts/variable_issues/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis",
    "date": "2024-07-19 00:00:00 +0900",
    





    
    "snippet": "Qualitative PredictorsLevel 2  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\...",
    "content": "Qualitative PredictorsLevel 2  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 학생인 사람의 신용카드 대금 평균      $\\beta_1$ : 학생인 사람과 학생이 아닌 사람의 신용카드 대금 평균 차이      Level 3  어느 신용카드 사에서 고객의 인종(황인/흑인/백인)에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d_{1}^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if Black}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\\\  \\quad  d_{2}^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if White}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d_{1}^{(i)} + \\beta_{2} \\cdot d_{2}^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if Black}\\\\  \\beta_{0} + \\beta_{2} + \\varepsilon^{(i)} \\quad &amp;\\text{if White}\\\\  \\beta_{0} + \\varepsilon^{(i)} \\quad &amp;\\text{if Asian}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 황인의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 흑인의 신용카드 대금 평균      $\\beta_1$ : 황인과 흑인의 신용카드 대금 평균 차이      $\\beta_0 + \\beta_2$ : 백인의 신용카드 대금 평균      $\\beta_2$ : 황인과 백인의 신용카드 대금 평균 차이      Qualitative &amp; Quantitative  어느 신용카드 사에서 고객의 신용카드 대금에 관한 회귀 모형을 설계하고자 한다. 고객의 수입과 학생 여부에 관한 데이터를 확보하고 있다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형    \\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 $x$(Income)이 동일한 수준일 때 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : $x$(Income)이 동일한 수준일 때 학생인 사람의 신용카드 대금 평균      $\\beta_1$ : $x$(Income)이 동일한 수준일 때 학생인 사람과 학생이 아닌 사람의 신용카드 대금 평균 차이      $\\beta_2$ : 학생 여부와 무관하게, $x$(Income) 단위 변동에 따른 $y$ 의 변동성      Effect Coding  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      Effect Coding : 각 범주의 효과를 비교하기 위하여 참조 수준을 명시적으로 사용하지 않고 전체 평균과 비교하는 범주형 변수 인코딩 방법        지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  -1 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} - \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 모든 사람들의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 학생인 사람의 신용카드 대금 평균      $\\beta_0 - \\beta_1$ : 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_1$ : 학생 여부에 따른 신용카드 대금 평균의 차이      Interaction Terms      상호작용 효과 (Interaction Effect) : 두 개 이상의 설명변수가 결합하여 반응변수에 미치는 영향이, 각 설명변수의 주효과를 가산한 것과 다를 때 발생하는 효과로서, 한 설명변수가 반응변수에 미치는 효과가 다른 설명변수의 수준에 영향을 받는 경우 발생함\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot x_{1}^{(i)} + \\beta_{2} \\cdot x_{2}^{(i)} + \\underbrace{\\beta_{3} \\cdot x_{1}^{(i)}x_{2}^{(i)}}_{\\text{Interaction Term}} + \\varepsilon^{(i)}\\\\  &amp;= \\beta_{0} + \\underbrace{\\left(\\beta_{1} + \\beta_{3} \\cdot x_{2}^{(i)}\\right)}_{\\tilde{\\beta}_{1}} \\cdot x_{1}^{(i)} + \\beta_{2} \\cdot x_{2}^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\beta_{0} + \\beta_{1} \\cdot x_{1}^{(i)} + \\underbrace{\\left(\\beta_{2} + \\beta_{3} \\cdot x_{1}^{(i)}\\right)}_{\\tilde{\\beta}_{2}} \\cdot x_{2}^{(i)} + \\varepsilon^{(i)}  \\end{aligned}\\]          주효과(Main Effect; $\\beta_{1}, \\beta_{2}$) : 설명변수가 반응변수에 독립적으로 미치는 직접적인 효과      시너지 효과(Synergy Effect; $\\beta_{3}$) : 설명변수 간 상호작용을 통해 나타나는, 가산적이지 않은 효과            계층적 원리(Hierarchical Principle)          교호작용 효과(Interaction Effect)의 유효성이 입증되어 모형에 포함하는 경우, 해당 교호작용을 구성하는 주효과(Main Effects)는 유효성 여부와 상관없이 모형에 포함해야 함. 주효과를 제외하는 경우 교호작용 효과 해석이 불분명해질 수 있기 때문임. 가령 실제 상호작용 효과가 아니라, 주효과의 부분적인 영향을 나타낼 수 있음.            범주형 설명변수와 연속형 설명변수 간 교호작용 효과          어느 신용카드 사에서 고객의 신용카드 대금에 관한 회귀 모형을 설계하고자 한다. 고객의 수입과 학생 여부에 관한 데이터를 확보하고 있다. 이때 수입과 학생 여부에 대한 교호작용 효과의 유효성을 알아보고자 한다.                      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]                    선형 회귀 모형                  학생 여부와 수입 간 교호작용 효과가 있다는 것보다는 학생일 때와 학생이 아닐 때 수입이 신용카드 대금에 미치는 영향력에 차이가 있다는 것으로 해석하는 것이 바람직함        \\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\beta_{2} \\cdot x^{(i)} + \\beta_{3} \\cdot d^{(i)} x^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\left(\\beta_{0} + \\beta_{1}\\right) + \\left(\\beta_{2} + \\beta_{3}\\right) \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]                  $\\beta_2$ : 학생이 아닌 사람의 $x$(Income) 단위 변동에 따른 $y$ 변동성          $\\beta_2 + \\beta_3$ : 학생인 사람의 $x$(Income) 단위 변동에 따른 $y$ 변동성                    "
  },
  
  {
    "title": "Regression Diagnostics",
    "url": "/posts/regression_diagnostics/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis",
    "date": "2024-07-18 00:00:00 +0900",
    





    
    "snippet": "Regression Diagnostics      회귀 진단(Regression Diagnostics) : 고전적 선형 회귀 가정이 위배되는지 진단하는 절차        고전적 선형 회귀 가정이 위배됨에 따라 발생하는 문제점          A.1 반응변수와 설명변수 간 비선형성 문제(Non-linearity Problem)      A.2 오차항 간...",
    "content": "Regression Diagnostics      회귀 진단(Regression Diagnostics) : 고전적 선형 회귀 가정이 위배되는지 진단하는 절차        고전적 선형 회귀 가정이 위배됨에 따라 발생하는 문제점          A.1 반응변수와 설명변수 간 비선형성 문제(Non-linearity Problem)      A.2 오차항 간 상관성 문제(Auto-correlation Problem)      A.3 이상치 및 영향점 문제(Outlier &amp; Influential Points Problem)      A.4 오차항의 이분산성 문제(Hetero-scedasticity Problem)      A.5 설명변수 간 다중공선성 문제(Multi-col-linearity Problem)      Non-linearity Problem      $Y$ 가 $X$ 의 선형 결합이 아니라고 하자\\[\\begin{aligned}  y_i= f(x_i)+\\varepsilon_i  \\end{aligned}\\]        최소자승추정량 \\(\\hat{\\beta}_{1}\\) 을 다음과 같이 이해할 수 있음\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i - \\overline{x})(f(x_i)+\\varepsilon_i - \\overline{f(x)} - \\overline{\\varepsilon})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(\\varepsilon_i-\\overline{\\varepsilon})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot \\varepsilon_i}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} - \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot \\overline{\\varepsilon}}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}  \\end{aligned}\\]        \\(\\hat{\\beta}_{1}\\) 의 기대값은 다음과 같음\\[\\begin{aligned}  \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot \\mathbb{E}\\left[\\varepsilon_i\\right]} \\quad \\text{s.t.} \\quad X \\perp \\varepsilon\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot 0} \\quad (\\because \\varepsilon \\sim N(0,\\sigma^2))\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right]  \\end{aligned}\\]        따라서 \\(\\hat{\\beta}_{1}\\) 은 \\(\\beta_{1}\\) 의 불편추정량이 될 수 없음\\[\\begin{aligned}  \\mathbb{Bias}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] - \\beta_1\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] - \\beta_1\\\\  &amp;\\ne 0  \\end{aligned}\\]  Auto-correlation Problem      최소자승추정량 \\(\\hat{\\beta}_{1}\\) 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{Var}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{Var}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\\\  &amp;= \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]} \\quad (\\because \\sigma_{i^{\\forall}}^{2}=\\sigma^{2})  \\end{aligned}\\]        $\\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right] \\ne 0$ 이므로 최소분산성을 보장할 수 없음\\[\\begin{aligned}  \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}  \\end{aligned}\\]  Durbin-Watson Statistic      더빈-왓슨 통계량(Durbin-Watson Statistic) : 잔차의 1차 자기상관성을 측정하는 지표\\[\\begin{aligned}  DW  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}}  \\end{aligned}\\]          $DW \\approx 0$ : 양의 자기상관이 매우 강함      $DW \\approx 2$ : 자기상관 없음      $DW \\approx 4$ : 음의 자기상관이 매우 강함            $0\\le DW \\le 4 \\quad (\\because -1 \\le \\rho \\le 1)$                  $DW$ 의 분자를 다음과 같이 세분화할 수 있음\\[\\begin{aligned}  \\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}  &amp;= \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2} - 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}\\\\  \\end{aligned}\\]                    $n$ 이 매우 클 경우 다음이 성립함\\[\\begin{aligned}  \\sum_{t=2}^{n}{\\varepsilon_{t}^2}  &amp;\\approx \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2}\\\\  \\therefore \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2}  &amp;\\approx 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t}^2}  \\end{aligned}\\]                    자기상관계수 $\\rho$ 의 정의에 의해 다음이 성립함\\[\\begin{aligned}  \\rho  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\overline{\\varepsilon})(\\varepsilon_{t-1}-\\overline{\\varepsilon})}}{\\sum_{t=1}^{n}{(\\varepsilon_{t}-\\overline{\\varepsilon})^{2}}}\\\\  &amp;= \\frac{\\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}} \\quad(\\because \\varepsilon \\sim N(0, \\sigma^2))\\\\  \\therefore \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}  &amp;= \\rho \\cdot \\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}  \\end{aligned}\\]                    따라서 분자를 다음과 같이 이해할 수 있음\\[\\begin{aligned}  \\therefore \\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}  &amp;= \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2} - 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}\\\\  &amp;\\approx 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t}^2} - 2 \\cdot \\rho \\cdot \\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}\\\\  &amp;\\approx 2(1-\\rho) \\cdot \\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}  \\end{aligned}\\]                    따라서 $DW$ 는 $\\rho$ 와 다음의 관계가 성립함\\[\\begin{aligned}  \\therefore DW  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}}\\\\  &amp;\\approx 2(1-\\rho) \\cdot \\frac{\\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}}{\\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}}\\\\  &amp;= 2(1-\\rho)  \\end{aligned}\\]            Hetero-scedasticity Problem      최소자승추정량 \\(\\hat{\\beta}_{1}\\) 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{Var}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{Var}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} \\quad (\\because \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right] = 0)  \\end{aligned}\\]        $\\sigma_{i}^{2} \\ne \\sigma_{j \\ne i}^{2}$ 이므로 최소분산성을 보장할 수 없음\\[\\begin{aligned}  \\sigma^{2}\\cdot\\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}}  \\end{aligned}\\]  Breusch-Pagan Test      브레쉬-파건 검정(Breusch-Pagan Test) : 잔차의 등분산성에 관한 검정        관심 모수 $\\sigma^2$ 의 점 추정량 도출                  다중선형회귀모형에서 $i$ 번째 관측치의 잔차 $\\varepsilon^{(i)}$ 는 다음과 같이 정의됨\\[\\begin{aligned}  y^{(i)}  &amp;= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{p} \\cdot x^{(i)}_{p} + \\varepsilon^{(i)}\\\\  \\varepsilon^{(i)}  &amp;= y^{(i)} - \\left(\\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{p} \\cdot x^{(i)}_{k} \\right)  \\end{aligned}\\]                    잔차 자승 $\\varepsilon^{2}$ 은 오차 분산 $\\sigma^2$ 의 간접적인 추정치임\\[\\begin{aligned}  \\hat{\\sigma}^{2}  &amp;= \\frac{1}{n-(p+1)} \\cdot \\sum_{i=1}^{n}{(\\varepsilon_{i} - \\overline{\\varepsilon})^{2}}\\\\  &amp;= \\frac{1}{n-(p+1)} \\cdot \\sum_{i=1}^{n}{\\varepsilon_{i}^{2}} \\quad (\\because \\varepsilon \\sim N(0,\\sigma^2))  \\end{aligned}\\]              귀무가설과 대립가설 설정          $H_0:\\quad \\sigma_{i}^2 = \\sigma_{j\\ne i}^2$      $H_1:\\quad \\sigma_{i}^2 \\ne \\sigma_{j\\ne i}^2$            검정통계량 도출\\[BP \\sim \\chi^{2}(p)\\]                  잔차 자승 $\\varepsilon_{i}^{2}$ 에 대한 보조회귀모형 정의\\[\\begin{aligned}  \\varepsilon_{i}^{2}  &amp;= \\gamma_{0} + \\gamma_{1} \\cdot x^{(i)}_{1} + \\cdots + \\gamma_{k} \\cdot x^{(i)}_{p} + \\epsilon^{(i)}  \\end{aligned}\\]                    보조회귀모형의 결정계수 $R^2$ 도출\\[\\begin{aligned}  R^{2}  &amp;= 1 - \\frac{RSS}{TSS}\\\\  &amp;= 1 - \\frac{\\sum_{i=1}^{n}{\\epsilon_{i}^{2}}}{\\sum_{i=1}^{n}{\\left(\\varepsilon_{i}^{2}-\\overline{\\varepsilon^{2}}\\right)^{2}}}  \\end{aligned}\\]                    검정통계량 도출\\[BP = n \\cdot R^2 \\sim \\chi^{2}(p)\\]            Multi-col-linearity Problem      반응변수 $Y$ 가 설명변수 $X_1, X_2$ 의 선형 결합이라고 하자\\[\\begin{aligned}  Y = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\varepsilon  \\end{aligned}\\]        설명변수 $X_1$ 에 대한 가중치 $\\beta_1$ 의 의미\\[\\begin{aligned}  \\beta_1  &amp;= \\frac{\\partial Y}{\\partial X_1}  \\end{aligned}\\]        설명변수 $X_1$ 에 대한 가중치 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_{1}$\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})(y^{(i)}-\\overline{y})}}{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})^{2}}} - \\frac{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})(x^{(i)}_{2}-\\overline{x}_{2})}}{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})^{2}}} \\cdot \\hat{\\beta}_{2}\\\\  &amp;= \\frac{\\mathbb{Cov}\\left[X_1, Y\\right]}{\\mathbb{Var}\\left[X_1\\right]} - \\frac{\\mathbb{Cov}\\left[X_1, X_2\\right]}{\\mathbb{Var}\\left[X_1\\right]} \\cdot \\hat{\\beta}_{2}  \\end{aligned}\\]        $X_2$ 가 $X_1$ 의 선형 결합으로 표현될 수 있다고 하자\\[\\begin{aligned}  X_2 = \\delta + \\alpha \\cdot X_1 + \\epsilon  \\end{aligned}\\]        \\(\\mathbb{Cov}\\left[X_1, X_2\\right] \\ne 0\\) 이므로 \\(\\hat{\\beta}_{1}\\) 은 \\(\\hat{\\beta}_{2}\\) 를 포함하게 되어 \\(Y\\) 에 대한 \\(X_1\\) 만의 순수한 설명력을 의미한다고 해석할 수 없음\\[\\begin{aligned}  Y  &amp;= \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\varepsilon\\\\  &amp;= \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot \\left(\\delta + \\alpha \\cdot X_1\\right) + \\varepsilon\\\\  &amp;= \\left(\\beta_0 + \\delta \\cdot \\beta_2 \\right) + \\left(\\beta_1 + \\alpha \\cdot \\beta_2\\right) \\cdot X_1 + \\varepsilon  \\end{aligned}\\]  VIF      분산팽창계수(Variance Inflation Factor; VIF) : 변동성을 기준으로 다중공선성을 측정하는 지표로서, 통상 10을 초과하는 경우 다중공선성이 높다고 판단함\\[\\begin{aligned}  VIF_k  &amp;= \\frac{1}{1-R_{k}^{2}}  \\end{aligned}\\]          $VIF_i$ : $i$ 번째 설명변수의 분산팽창계수      $R_i^2$ : $i$ 번째 설명변수에 대한 결정계수            $R_k^2$                  다중선형회귀모형은 다음과 같이 정의됨\\[\\begin{aligned}  y^{(i)}  &amp;= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{k} \\cdot x^{(i)}_{p} + \\varepsilon^{(i)}  \\end{aligned}\\]                    $k$ 번째 설명변수에 대한 보조회귀모형 도출\\[\\begin{aligned}  x_{k}^{(i)}  &amp;= \\gamma_{0} + \\gamma_{1} \\cdot x^{(i)}_{1} + \\cdots + \\gamma_{k-1} \\cdot x^{(i)}_{k-1} + \\gamma_{k+1} \\cdot x^{(i)}_{k+1} + \\cdots +\\gamma_{p} \\cdot x^{(i)}_{p} + \\epsilon^{(i)}  \\end{aligned}\\]                    보조회귀모형의 결정계수 $R_k^2$ 도출\\[\\begin{aligned}  R_{k}^{2}  &amp;= 1 - \\frac{RSS_k}{TSS_k}\\\\  &amp;= 1 - \\frac{\\sum_{i=1}^{n}{\\epsilon_{i}^{2}}}{\\sum_{i=1}^{n}{\\left(x_{k}^{(i)}-\\overline{x}_{k}\\right)^{2}}}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Multiple Linear Regression Analysis",
    "url": "/posts/multiple_linear_regression_analysis/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis, f-test",
    "date": "2024-07-17 00:00:00 +0900",
    





    
    "snippet": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+...",
    "content": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+\\varepsilon^{(k)}\\]        VS. Simple Linear Regression                      Simple Linear Regression\\[\\begin{aligned}  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}  \\end{aligned}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제하지 않은 상태에서 추정되었다. 때문에 해당 요인($X_{i}$)과 다른 요인들 간 상관관계가 있을 경우, $\\beta_{i}$ 은 다른 요인들의 변화가 매출에 미치는 영향력을 포함하게 된다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 없다.                            Multiple Linear Regression\\[\\text{Sales}^{(k)}=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제한 상태에서 추정되었다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 있다.                    Normal Equation      정규방정식(Normal Equation) : 최소자승법에 기초하여 추정한 가중치 벡터\\[\\begin{aligned}  \\hat{\\mathbf{b}}  &amp;= \\text{arg} \\min_{\\mathbf{b}}{RSS}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}  \\end{aligned}\\]    정규방정식 도출 과정                  변수 갯수가 $P$ 이고 관측치 갯수가 $N$ 인 다중 선형 회귀 모형을 선형대수로 표현하면 다음과 같음\\[\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\mathbf{b}}\\]                  $\\mathbf{X}_{N \\times P}$ : Design Matrix                            $RSS$ 도출\\[\\begin{aligned}  RSS  &amp;= \\left\\Vert \\mathbf{y} - \\hat{\\mathbf{y}} \\right\\Vert^2\\\\  &amp;= (\\mathbf{y}^T - \\mathbf{b}^T \\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\mathbf{b})\\\\  &amp;= \\mathbf{y}^T \\mathbf{y} - \\mathbf{y}^T \\mathbf{X} \\mathbf{b} - \\mathbf{b}^T \\mathbf{X}^T \\mathbf{y} + \\mathbf{b}^T \\mathbf{X}^T \\mathbf{X} \\mathbf{b}  \\end{aligned}\\]                    $\\because \\mathbf{y}^T \\mathbf{X} \\mathbf{b} = \\left(\\mathbf{b}^T \\mathbf{X}^T \\mathbf{y}\\right)^T = \\mathbf{b}^T \\mathbf{X}^T \\mathbf{y}$\\[RSS = \\mathbf{y}^T \\mathbf{y} - 2 \\mathbf{b}^T \\mathbf{X}^T \\mathbf{y} + \\mathbf{b}^T \\mathbf{X}^T \\mathbf{X} \\mathbf{b}\\]                    $RSS$ 를 $\\mathbf{b}$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial}{\\partial \\mathbf{b}} RSS  &amp;= -2 \\mathbf{X}^T \\mathbf{y} + 2 \\mathbf{X}^T \\mathbf{X} \\mathbf{b}\\\\  &amp;= 0 \\quad (\\because \\min_{\\mathbf{b}}{RSS})  \\end{aligned}\\]                    $\\mathbf{b}$ 에 대하여 정리\\[\\begin{aligned}  \\hat{\\mathbf{b}}  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\\\\  &amp;= \\text{arg} \\min_{\\mathbf{b}}{RSS}  \\end{aligned}\\]                  회귀계수의 해석          설명변수 $X_{i}$ 의 회귀계수 $\\beta_{i}$ 는 다른 모든 설명변수가 일정할 때 $X_{i}$ 가 $1$ 단위 변화함에 따른 $Y$ 변화 단위의 추정치이다. 즉, 다른 모든 설명변수에 대하여 변동이 없는 상태에서, $X_{i}$ 가 $1$ 단위 변화했을 때 $Y$ 가 $\\beta_{i}$ 만큼 변화할 것이라 추정된다.      F-Test for Regression Coefficients      F 검정(F-Test) : 반응변수에 대한 설명변수들의 설명력이 통계적으로 유의한가에 관한 검정        모수(Parameter) 정의:\\[\\begin{aligned}  \\beta_{1}, \\beta_{2}, \\cdots, \\beta_{p}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  \\hat{\\beta}_{1}, \\hat{\\beta}_{2}, \\cdots, \\hat{\\beta}_{p}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}: \\quad \\beta_1=\\beta_2 =\\cdots =\\beta_p=0$      $H_{1}: \\quad \\exists i \\quad \\beta_{i} \\ne 0$            검정통계량(Test Statistic):\\[\\begin{aligned}  F  &amp;= \\frac{\\mathrm{ESS}/p}{\\mathrm{RSS}/(n-p-1)} \\sim \\mathcal{F}(p, n-p-1)  \\end{aligned}\\]  Partial Significance F-Test      부분 유의성 검정(Partial Significance F-Test) : 설명변수 추가에 따른 부분적 효과의 통계적 유의성에 관한 검정          Occam’s RazorEntities should not be multiplied beyond necessity.        모형 예시          $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon$      $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\varepsilon$        귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_3=\\beta_4=0$      $H_{1}: \\quad \\beta_{3} \\ne 0 \\quad \\text{or} \\quad \\beta_{4} \\ne 0$            검정통계량 도출\\[F  = \\frac{(RSS_{0}-RSS)/q}{RSS/(n-p-1)} \\sim F(q, n-p-1)\\]                  $RSS$ : 설명변수 $X_{3}, X_{4}$ 를 추가한 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 + \\beta_3 x^{(i)}_3 + \\beta_4 x^{(i)}_4 \\right) \\right]^2}  \\end{aligned}\\]                    $RSS_{0}$ : 설명변수 $X_{3}, X_{4}$ 를 추가하지 않은 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS_{0}  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 \\right) \\right]^2}  \\end{aligned}\\]            $n$ : 관측치 갯수      $p$ : 총 설명변수 갯수      $q$ : 검정 대상 설명변수($X_{3}, X_{4}$) 를 제외한 설명변수의 갯수      Sourse  https://www.linkedin.com/pulse/understanding-linear-regression-basics-divyesh-sonar-snv4c/"
  },
  
  {
    "title": "Regression Coefficient Estimation",
    "url": "/posts/regression_coefficient_estimation/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis, estimation, ols",
    "date": "2024-07-16 00:00:00 +0900",
    





    
    "snippet": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\va...",
    "content": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left(y_{i} - \\hat{y}_{i} \\right)^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left[ y_{i} - \\left(\\beta_{0} + \\beta_{1} x_{i} \\right) \\right]^2}}  \\end{aligned}\\]        $\\mathcal{L}(\\beta_{0}, \\beta_{1})=\\displaystyle\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}$ 을 $\\beta_{0}$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_{0}}\\mathcal{L}(\\beta_{0}, \\beta_{1})\\\\  &amp;= -2 \\times \\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_{0} + \\beta_{1} x_{i}\\right)\\right]} \\\\  &amp;= -2 \\times \\left[\\sum_{i=1}^{n}{y_{i}} - n \\beta_{0}-\\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\right] \\cdots ①\\\\  &amp;= -2n \\times (\\overline{Y} - \\beta_{0} - \\beta_{1} \\overline{X}) \\\\  &amp;= 0  \\end{aligned}\\]        편향 $\\beta_{0}$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 도출\\[\\therefore  \\hat{\\beta_0}  = \\overline{Y} - \\hat{\\beta_1}\\overline{X} \\quad (\\text{s.t.} \\; n \\ne 0)\\]        $\\mathcal{L}(\\beta_{0}, \\beta_{1})=\\displaystyle\\sum_{i=1}^{n}{e_{i}^{2}}$ 을 $\\beta_0$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_{1}} \\mathcal{L}(\\beta_{0}, \\beta_{1})\\\\  &amp;= -2\\times\\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_{0} + \\beta_{1} x_{i}\\right)\\right] \\times x_{i}}\\\\  &amp;= -2\\times\\left[\\sum_{i=1}^{n}{y_{i}x_{i}}-\\beta_0\\sum_{i=1}^{n}{x_{i}}-\\beta_{1}\\sum_{i=1}^{n}{x_{i}^{2}}\\right] \\cdots ② \\\\  &amp;= 0  \\end{aligned}\\]        식 $①$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ① \\times \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}} - n \\beta_{0} \\sum_{i=1}^{n}{x_{i}} - \\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{0}\\overline{X}-n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\\\  &amp;= 0  \\end{aligned}\\]        식 $②$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ② \\times n \\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_0 \\sum_{i=1}^{n}{x_{i}} - n \\beta_{1} \\sum_{i=1}^{n}{(x_{i})^{2}}\\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n^{2} \\beta_0 \\overline{X} - n \\beta_{1} \\sum_{i=1}^{n}{x_{i}^{2}}\\\\  &amp;= 0  \\end{aligned}\\]        식 ①, ② 의 변형을 뺄셈\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\left(① \\times \\sum_{i=1}^{n}X_{i} - ② \\times n \\right)\\\\  &amp;= \\left[n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\right] -  \\left[n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_1 \\sum_{i=1}^{n}{(x_{i})^{2}}\\right]\\\\  &amp;= \\beta_{1} \\times n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{x_{i}^{2}}-\\left(\\overline{X}\\right)^{2}\\right] - n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}x_{i}}-\\overline{Y}\\overline{X}\\right]\\\\  &amp;= \\beta_{1} \\times n^{2} \\mathrm{Var}\\left[X\\right] - n^{2} \\mathrm{Cov}\\left[Y,X\\right]\\\\  &amp;= 0  \\end{aligned}\\]        가중치 $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 도출\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\mathrm{Cov}\\left[Y,X\\right]}{\\mathrm{Var}\\left[X\\right]}  \\end{aligned}\\]  MLE      우도(Likelihood): 파라미터 $\\theta=(\\beta_{0},\\beta_{1},\\sigma^{2})$ 가 주어졌을 때, 관측치 $y$ 가 발생할 확률\\[\\begin{gathered}  y_{i}  = \\beta_{0}+\\beta_{1}x_{i}+\\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,\\sigma^{2})\\\\  \\Updownarrow\\\\  y_{i} \\sim \\mathcal{N}(\\beta_{0} + \\beta_{1}x_{i},\\sigma^{2})  \\end{gathered}\\]        최우추정법(Maximum Likelihood Estimation): 우도를 최대화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{MLE}  &amp;= \\text{arg}\\max{\\mathcal{L}(\\beta_{0},\\beta_{1}, \\sigma^2)}  \\end{aligned}\\]        $\\hat{\\beta}_{MLE}$ 는 $RSS$ 에 반비례함\\[\\begin{aligned}  \\mathcal{L}(\\beta_{0},\\beta_{1}, \\sigma^2)  &amp;= \\ln\\prod_{i=1}^{n}{\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}}\\exp{\\left[-\\frac{1}{2\\sigma^{2}}(y_{i}-\\beta_{0}-\\beta_{1}x_{i})^{2}\\right]}}\\\\  &amp;= \\sum_{i=1}^{n}{\\left[-\\frac{1}{2}\\ln{2\\pi \\sigma^{2}}-\\frac{1}{2 \\sigma^{2}}(y_{i}-\\beta_{0}-\\beta_{1}x_{i})^{2}\\right]}\\\\  &amp;= -\\frac{n}{2}\\ln{2 \\pi \\sigma^{2}}-\\frac{1}{2 \\sigma^{2}}\\underbrace{\\sum_{i=1}^{n}{(y_{i}-\\beta_{0}-\\beta_{1}x_{i})^{2}}}_{=:RSS}  \\end{aligned}\\]        따라서 \\(\\hat{\\beta}_{OLS}\\) 는 \\(\\hat{\\beta}_{MLE}\\) 의 특수한 형태임\\[\\begin{aligned}  \\therefore \\text{arg} \\max{\\mathcal{L}(\\beta_{0},\\beta_{1}, \\sigma^2)}  &amp;\\propto \\text{arg} \\min{RSS}  \\end{aligned}\\]  Gauss-Markov Assumptions      A.1 반응변수와 설명변수의 선형성 가정          The Linear Model is Correctly Specified.            A.2 관측치 간 오차항의 자기상관 없음(No Autocorrelation) 가정          $\\mathrm{Cov}\\left[\\varepsilon_i, \\varepsilon_j\\right]=0$ If $i \\ne j$            A.3 오차항의 기대값에 관한 가정          $\\mathbb{E}\\left[\\varepsilon_i\\right]=0$ For Every $i=1,\\cdots,n$            A.4 오차항의 등분산성(Homoskedasticity) 가정          $\\mathrm{Var}\\left[\\varepsilon_i\\right]=\\sigma^2$ For Every $i=1,\\cdots,n$            A.5 설명변수의 비확률성 가정 혹은 설명변수 간 통계적 독립성 가정          $X_i$ is Non-Random For Every $i=1,\\cdots,n$      OLS $\\hat{\\beta}_{1}$ subject to Gauss-Markov Assumptions      가중치 $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 은 $Y$ 의 선형 결합\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\mathrm{Cov}\\left[Y,X\\right]}{\\mathrm{Var}\\left[X\\right]}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}(x_{i}-\\overline{x})(y_{i}-\\overline{y})}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\  \\\\  \\sum_{i=1}^{n}{(x_{i}-\\overline{x})(y_{i}-\\overline{y})}  &amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\cdot y_{i}} - \\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\cdot \\overline{y}}\\\\  &amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\cdot y_{i}} - \\overline{y} \\cdot \\sum_{i=1}^{n}{(x_{i}-\\overline{x})}\\\\  &amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\cdot y_{i}}\\\\  \\\\  \\therefore \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\cdot y_{i}}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\  &amp;= w_{1} \\cdot y_{1} + w_{2} \\cdot y_{2} + \\cdots + w_{n} \\cdot y_{n}\\\\  w_{i}  &amp;=\\frac{(x_{i}-\\overline{x})}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}  \\end{aligned}\\]        $w_i$ 에 대하여 다음이 성립함                  $\\sum_{i=1}^{n}{w_{i}}=\\displaystyle\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})}}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}=0$                    $\\sum_{i=1}^{n}{w_{i} \\cdot x_{i}}=1$\\[\\begin{aligned}  \\sum_{i=1}^{n}{w_{i} \\cdot x_{i}}  &amp;= \\sum_{i=1}^{n}{\\frac{(x_{i}-\\overline{x})}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}} \\cdot x_{i}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\cdot x_{i}}}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}\\\\  \\\\  \\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\cdot x_{i}}  &amp;= \\sum_{i=1}^{n}{(x_{i}^{2}-\\overline{x}\\cdot x_{i})}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}^{2}} - \\overline{x}\\cdot\\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}^{2}} - n\\cdot \\overline{x}^{2}\\\\  &amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}\\\\  \\\\  \\therefore \\sum_{i=1}^{n}{w_{i} \\cdot x_{i}}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\cdot x_{i}}}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}\\\\  &amp;= 1  \\end{aligned}\\]                    $\\sum_{i=1}^{n}{w_{i}^{2}}=\\displaystyle\\frac{1}{\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}}$\\[\\begin{aligned}  \\sum_{i=1}^{n}{w_{i}^{2}}  &amp;= \\sum_{i=1}^{n}{\\left(\\frac{(x_{i}-\\overline{x})}{\\sum_{j=1}^{n}(x_{j}-\\overline{x})^{2}}\\right)^{2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\left(\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}\\right)^{2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}} \\cdot \\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}\\\\  &amp;= \\frac{1}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^{2}}}  \\end{aligned}\\]                  따라서 최소자승추정량 \\(\\hat{\\beta}_{1}\\) 과 그 모수 \\(\\beta_{1}\\) 사이에는 다음이 성립함\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\sum_{i=1}^{n}{w_{i} \\cdot y_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{w_{i} \\cdot (\\beta_{0}+\\beta_{1} \\cdot x_{i}+\\varepsilon_{i})}\\\\  &amp;= \\beta_{1} + \\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}  \\end{aligned}\\]  Gauss-Markov Theorem  고전적 선형 회귀 가정(Classical Linear Regression Assumptions or Gauss-Markov Assumptions) 하 최소자승추정량은 선형 불편 추정량 중 분산이 가장 작은 추정량(Best Linear Unbiased Estimator; BLUE)이다.      가중치 $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 의 확률분포\\[\\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\sigma^{2}\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right]\\right)\\]        편향 $\\beta_{0}$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 의 확률분포\\[\\hat{\\beta}_{0} \\sim N\\left(\\beta_{0}, \\sigma^{2} \\left[\\displaystyle\\frac{1}{n} + \\displaystyle\\frac{\\overline{x}^{2}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right]\\right)\\]        오차항 $\\varepsilon$ 의 모분산 $\\sigma^{2}$ 을 그 표본분산으로 추정함\\[\\sigma^{2} \\xrightarrow{\\text{P}} \\frac{\\text{RSS}}{n-2}\\]  OLS is Unbiased Estimator      고전적 선형 회귀 가정 하 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 의 기대값은 다음과 같음\\[\\begin{aligned}  \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\beta_{1} + \\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\beta_{1}\\right] + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}\\right]\\\\  &amp;= \\beta_{1} + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}\\right]\\\\  &amp;= \\beta_{1} + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_{i} \\cdot \\varepsilon_{i}\\right]}\\\\  &amp;= \\beta_{1} + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_{i}\\right] \\cdot \\mathbb{E}\\left[\\varepsilon_{i}\\right]} \\quad \\text{s.t.} \\quad X \\perp \\varepsilon\\\\  &amp;= \\beta_{1} + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_{i}\\right] \\cdot 0} \\quad (\\because \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2))\\\\  &amp;= \\beta_{1}  \\end{aligned}\\]        따라서 고전적 선형 회귀 가정 하 최소자승추정량 $\\hat{\\beta}_1$ 은 $\\beta_1$ 의 불편 추정량임\\[\\begin{aligned}  \\therefore \\mathrm{Bias}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] - \\beta_{1}\\\\  &amp;= 0  \\end{aligned}\\]  OLS is Efficient Estimator      $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathrm{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathrm{Var}\\left[\\beta_{1} + \\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\sum_{i=1}^{n}{w_{i} \\cdot \\varepsilon_{i}}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathrm{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}  \\end{aligned}\\]        $\\because \\mathrm{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]=0$\\[\\begin{aligned}  \\mathrm{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}}  \\end{aligned}\\]        $\\because \\sigma_{i^{\\forall}}^{2}=\\sigma^{2}$\\[\\begin{aligned}  \\mathrm{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\sigma^{2} \\cdot \\sum_{i=1}^{n}{w_{i}^{2}}  \\end{aligned}\\]        따라서 고전적 선형 회귀 가정 하 $\\hat{\\beta}_1$ 은 $\\beta_1$ 의 불편 추정량 중 분산이 가장 작은 추정량임\\[\\sigma^{2} \\cdot \\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathrm{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\]  Sourse  https://medium.com/@luvvaggarwal2002/linear-regression-in-machine-learning-9e8af948d3eb"
  },
  
  {
    "title": "Simple Linear Regression Analysis",
    "url": "/posts/simple_linear_regression_analysis/",
    "categories": "2.STATISTICAL TECHS, 3.regression analysis",
    "tags": "statistics, regression analysis, linear regression analysis, numerical data analysis, t-test, goodness of fit test, r2",
    "date": "2024-07-15 00:00:00 +0900",
    





    
    "snippet": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들...",
    "content": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들이 더 행복한가?      소득이 증가할 때 소비는 얼마나 증가하는가?      교육수준이 높을수록 임금이 증가하는가?        예측 대상이 되는 변수($Y$)          반응변수(Response Variable)      종속변수(Dependent Variable)      내생변수(Endogenous Variable)        예측에 활용되는 변수($X$)          설명변수(Explanatory Variable)      독립변수(Independent Variable)      외생변수(Exogenous Variable)      Simple Linear Regression Model      단순 선형 회귀 모형(Simple Linear Regression Model) : 반응변수와 단일 설명변수 간 선형 상관관계를 모델링하는 모형\\[\\begin{aligned}  Y  &amp;=\\beta_0+\\beta_1X+\\varepsilon\\\\  y_{i}  &amp;=\\beta_0+\\beta_1 x_{i}+\\varepsilon_{i}  \\end{aligned}\\]    회귀계수(Regression Coefficient) : 모형이 추론하고자 하는 모수(Parameter)로서 상수          편향(Bias; $\\beta_0$) : 설명변수의 값이 $0$ 일 때 종속변수의 값      가중치(Weight; $\\beta_1$) : 설명변수가 종속변수에 미치는 영향력의 방향과 강도            오차항(Error Term; $\\varepsilon$) : 확률변수\\[\\begin{aligned}  \\varepsilon = y-\\left(\\beta_{0} + \\beta_{1} x \\right) \\sim N(0, \\sigma^2)  \\end{aligned}\\]                  잔차(Residual; $\\epsilon$) : 최적 회귀계수 하 오차항의 추정치\\[\\epsilon=y-\\left(\\hat{\\beta}_{0} + \\hat{\\beta}_{1} x \\right)\\]            t-Test for Regression Coefficients      t 검정(t-Test): 반응변수와 설명변수 간 상관관계의 통계적 유의성에 관한 가설 검정으로서, 두 변수 간 선형관계 혹은 인과관계의 유의성을 보장하지는 않음        모수(Parameter) 정의:\\[\\begin{aligned}  \\beta_{1}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  \\hat{\\beta}_{1} \\sim \\mathcal{N}(\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right], \\mathrm{SE}\\left[\\hat{\\beta}_{1}\\right]^2), \\quad n &gt; 30  \\end{aligned}\\]                  최소자승추정량의 평균:\\[\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] = \\beta_{1}\\]                    최소자승추정량의 분산:\\[\\mathrm{SE}\\left[\\hat{\\beta}_{1}\\right]^2  = \\sigma^2\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right], \\quad \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)\\]              가설(Hypothesis) 설정:          $H_{0}: \\quad \\beta_{1} = 0$      $H_{1}: \\quad \\beta_{1} \\ne 0$            검정통계량(Test Statistic):\\[\\begin{aligned}  T = \\frac{\\hat{\\beta}_{1}-0}{\\mathrm{SE}\\left[\\hat{\\beta}_{1}\\right]} \\sim t(n-2)  \\end{aligned}\\]  Goodness of Fit      적합도(Goodness of Fit): 모형이 반응변수의 변동을 얼마나 잘 설명하고 있는가    반응변수(Response Variable):                  관측치 기반 회귀식:\\[y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad \\varepsilon_i \\overset{\\text{i.i.d}}{\\sim} \\mathcal{N}(0, \\sigma^2)\\]                    추정치 기반 회귀식:\\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\]                    회귀선은 평균을 지나감:\\[\\overline{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\overline{x}\\]                  반응변수의 변동성(Variability):\\[\\begin{aligned}  \\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} + \\varepsilon_{i}\\right) -\\overline{y}\\right]^{2}} \\\\  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right) + \\varepsilon_i \\right]^{2}} \\\\  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right)^2 + \\varepsilon_{i}^{2} + 2 \\times \\varepsilon_{i} \\times \\left(\\hat{y}_{i}-\\overline{y}\\right)\\right]} \\\\  &amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^{2}} + \\sum_{i=1}^{n}{\\varepsilon_{i}^2} + 2\\times\\sum_{i=1}^{n}{\\varepsilon_{i}\\left(\\hat{y}_{i}-\\overline{y}\\right)} \\\\  &amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^2} + \\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}\\quad(\\because \\sum_{i=1}^{n}{\\hat{y}_{i}-\\overline{y}} = 0)  \\end{aligned}\\]        총변동(Total Sum of Square) : 반응변수의 총 변동성\\[\\mathrm{TSS}  =\\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}\\]        회귀변동(Explained Sum of Square) : 모형에 의해 설명되는 반응변수의 변동성\\[\\mathrm{ESS}  =\\sum_{i=1}^{n}{\\left(\\hat{y}_{i}-\\overline{y}\\right)^2}\\]        잔차변동(Residual Sum of Square) : 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  \\mathrm{RSS}  &amp;=\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}\\\\  &amp;=\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}  \\end{aligned}\\]        결정계수(Coefficient of Determination; $R^2$) : 총변동 대비 회귀변동의 비율로 측정된 적합도\\[\\begin{aligned}  R^2  &amp;= \\frac{\\mathrm{ESS}}{\\mathrm{TSS}} \\\\  &amp;= \\frac{\\mathrm{ESS}}{\\mathrm{ESS} + \\mathrm{RSS}} \\\\  &amp;= 1 - \\frac{\\mathrm{RSS}}{\\mathrm{TSS}}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Test of Independence",
    "url": "/posts/test_of_independence/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, chi-squared test, test of independence, chi-squared distribution",
    "date": "2024-07-13 00:00:00 +0900",
    





    
    "snippet": "Test of Independence      독립성 검정(Test of Independence) : 두 범주형 자료가 통계적으로 독립인지 검정하는 방법          맥주 회사 Alber’s 에서는 라이트 맥주, 일반 맥주, 흑 맥주를 생산하여 유통한다. 이 기업의 시장조사팀은 성별에 따라 선호하는 맥주에 차이가 있는지 알아보고자 한다. 만약 맥주...",
    "content": "Test of Independence      독립성 검정(Test of Independence) : 두 범주형 자료가 통계적으로 독립인지 검정하는 방법          맥주 회사 Alber’s 에서는 라이트 맥주, 일반 맥주, 흑 맥주를 생산하여 유통한다. 이 기업의 시장조사팀은 성별에 따라 선호하는 맥주에 차이가 있는지 알아보고자 한다. 만약 맥주의 품종별 선호도가 성별에 독립적이라면 맥주광고는 모든 고객에 대해 획일적으로 이루어질 것이다. 반면, 품종별 선호도가 성별에 의존적이라면 세분 시장의 목표 고객에 따라 상이한 촉진 전략을 수행해야 할 것이다. 아래 분할표는 무작위 추출된 $150$ 명이 각 맥주에 대해 시음한 후 응답한 품종별 선호도이다. 맥주의 품종별 선호도는 성별에 대하여 독립적이라 볼 수 있는가?        가설(Hypothesis) 설정:          $H_{0}:\\quad$ 품종별 선호도($Y$)는 성별 선호도($X$)에 대하여 독립적이다.      $H_{1}:\\quad$ 품종별 선호도($Y$)는 성별 선호도($X$)에 대하여 독립적이라 볼 수 없다.            검정통계량(Test Statistic):\\[\\begin{aligned}  X \\sim \\chi^{2}(\\nu)  \\end{aligned}\\]          $\\nu=(k-1)(l-1)$      $k$ : 변수 $X$ 의 카테고리 갯수      $l$ : 변수 $Y$ 의 카테고리 갯수      Test Statistic\\[\\begin{aligned}X&amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{l}{Z_{i,j}^2}\\end{aligned}\\]      $Z_{i,j}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[\\begin{aligned}  Z_{i,j}=\\frac{\\Omega_{i,j} - e_{i,j}}{\\sqrt{e_{i,j}}} \\sim N(0,1)  \\end{aligned}\\]        $\\Omega_{i,j}$ : 변수 $X$ 의 $i$ 번째 카테고리와 변수 $Y$ 의 $j$ 번째 카테고리에 해당하는 관측치의 관측 빈도                            품종          라이트          일반          흑          계                                      남성          20          40          20          80                          여성          30          30          10          70                          계          50          70          10          150                          $e_{i,j}$ : $\\Omega_{i,j}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                            품종          라이트          일반          흑                                      남성          26.67          37.33          16.00                          여성          23.33          32.67          14.00                  \\[\\begin{aligned}  e_{i,j}  &amp;= \\mathbb{E}\\left[\\Omega_{i,j} \\right]\\\\  &amp;=n \\cdot p_{i,j}\\\\  &amp;=n \\cdot P(X_{i} \\cap Y_{j})\\\\  &amp;=n \\cdot P(X_{i})P(Y_{j}) \\quad \\left(\\because P(Y_{j} \\mid X_{i})=P(Y_{j})\\right)  \\end{aligned}\\]        $\\sqrt{e_{i,j}}$ : $\\Omega_{i,j}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  \\mathrm{Var}\\left[\\Omega_{i,j}\\right]  &amp;= n \\cdot p_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;= e_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;\\approx e_{i,j} \\cdot 1  \\end{aligned}\\]  "
  },
  
  {
    "title": "Goodness of Fit Test",
    "url": "/posts/goodness_of_fit/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, chi-squared test, goodness-of-fit test, chi-squared distribution",
    "date": "2024-07-12 00:00:00 +0900",
    





    
    "snippet": "Goodness-of-Fit Test      적합성 검정(Goodness-of-Fit Test) : 범주형 자료에 대하여 관찰된 비율이 기대되는 비율과 통계적으로 유의한 차이가 있는지 검정하는 방법          마케팅 조사 기관 Scott 가 수행한 시장 점유율에 대한 조사에서, 몇 년동안 시장점유율은 A사 $30\\%$, B사 $50\\%$, C사...",
    "content": "Goodness-of-Fit Test      적합성 검정(Goodness-of-Fit Test) : 범주형 자료에 대하여 관찰된 비율이 기대되는 비율과 통계적으로 유의한 차이가 있는지 검정하는 방법          마케팅 조사 기관 Scott 가 수행한 시장 점유율에 대한 조사에서, 몇 년동안 시장점유율은 A사 $30\\%$, B사 $50\\%$, C사 $20\\%$ 수준을 보이며 안정적이었다. 최근에 C사는 기능이 향상된 제품을 출시하였다. 이에 신제품의 출시가 시장점유율의 변화에 영향을 미치고 있는지 파악하고자 한다. Scott 가 $200$ 명의 고객을 소비자 패널로 활용하여 조사를 수행한 결과, 아래의 표와 같은 구매 선호도를 얻었다. 신제품 출시에 따라 시장점유율이 변화했다고 볼 수 있는가?            모수(Parameter) 정의:\\[\\begin{aligned}  \\pi_{A},\\quad \\pi_{B},\\quad \\pi_{C}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  p_{A},\\quad p_{B},\\quad p_{C}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}:\\quad \\pi_{A}=0.3 \\; \\text{and} \\; \\pi_{B}=0.5 \\; \\text{and} \\; \\pi_{C}=0.2$      $H_{1}:\\quad \\pi_{A} \\ne 0.3 \\; \\text{or} \\; \\pi_{B} \\ne 0.5 \\; \\text{or} \\; \\pi_{C} \\ne 0.2$            검정통계량(Test Statistic):\\[\\begin{aligned}  X \\sim \\chi^2{(\\nu)}  \\end{aligned}\\]          $\\nu=k-1$      $k$: 카테고리 갯수      Test Statistic\\[\\begin{aligned}X&amp;= \\sum_{i=1}^{k}{Z_{i}^{2}}\\end{aligned}\\]      $Z_{i}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[\\begin{aligned}  Z_{i}  =\\frac{\\Omega_{i} - e_{i}}{\\sqrt{e_{i}}}  \\sim \\mathcal{N}(0,1)  \\end{aligned}\\]        $\\Omega_{i}$ : $i$ 번째 카테고리에 해당하는 관측치의 관측 빈도                            회사          A          B          C          계                                      관측 빈도          48          98          54          200                          $e_{i}$: $\\Omega_{i}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                            회사          A          B          C                                      기대 빈도          60          100          40                  \\[\\begin{aligned}  e_{i}  =\\mathbb{E}\\left[\\Omega_{i} \\right]  = n \\cdot p_{i}  \\end{aligned}\\]        $\\sqrt{e_{i}}$: $\\Omega_{i}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  \\mathrm{Var}\\left[\\Omega_{i}\\right]  &amp;= n \\cdot p_{i} \\cdot (1-p_{i})\\\\  &amp;= e_{i} \\cdot (1-p_{i})\\\\  &amp;\\approx e_{i} \\cdot 1  \\end{aligned}\\]  "
  },
  
  {
    "title": "Shapiro-Wilk Test",
    "url": "/posts/shapiro_wilk_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, t-test, two sample t-test, paired sample t-test, student’s t-distribution",
    "date": "2024-07-11 00:00:00 +0900",
    





    
    "snippet": "Shapiro-Wilk Test      정규성 검정(Shapiro-Wilk Test): 표본 순위와 표준정규분포에서 기대되는 순위 값의 선형 결합을 비교함으로써 표본이 정규 분포를 따르는지 여부를 검정하는 방법    귀무가설과 대립가설 설정:          $H_{0}:\\quad X \\sim N(\\mu, \\sigma^2)$      $H_{1}:\\...",
    "content": "Shapiro-Wilk Test      정규성 검정(Shapiro-Wilk Test): 표본 순위와 표준정규분포에서 기대되는 순위 값의 선형 결합을 비교함으로써 표본이 정규 분포를 따르는지 여부를 검정하는 방법    귀무가설과 대립가설 설정:          $H_{0}:\\quad X \\sim N(\\mu, \\sigma^2)$      $H_{1}:\\quad X \\not\\sim N(\\mu, \\sigma^2)$            검정통계량 정의:\\[\\begin{aligned}  W  &amp;= \\frac{\\left(\\sum_{i=1}^{n} \\beta_{i} X_{i}\\right)^2}{\\sum_{i=1}^{n}\\left(X_{i} - \\overline{X}\\right)^2}  \\end{aligned}\\]        귀무가설 하 검정통계량의 분포 생성:\\[\\begin{aligned}  W_{N} \\sim f_{W_{N}}(W)  \\end{aligned}\\]        표본의 검정통계량 $W_{\\mathrm{obs}}$ 의 $\\mathrm{p-value}$ 도출:\\[\\begin{aligned}  \\mathrm{p-value}  = F_{W_{N}}(W_{\\mathrm{obs}})  = P(W \\le W_{\\mathrm{obs}})  \\end{aligned}\\]        유의수준 $\\alpha$ 하 결론:                  $F_{W}(W) \\le \\alpha$ : $X \\not\\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 현저히 낮다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각한다.                            $\\alpha &lt; F_{W}(W)$ : $X \\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 어느 정도 존재한다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮다고 볼 수 없음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각하지 않는다.                    Test Statistic\\[\\begin{aligned}W&amp;= \\frac{\\left(\\sum_{i=1}^{n} \\beta_{i} X_{i}\\right)^2}{\\sum_{i=1}^{n}\\left(X_{i} - \\overline{X}\\right)^2}\\end{aligned}\\]      $\\mathbf{X}$ : 표본의 관측치 $X_{i}$ 를 크기에 따라 오름차순 정렬한 순위 통계량 벡터\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix}  X_{1}&amp;X_{2}&amp;\\cdots&amp;X_{n}  \\end{pmatrix}^{T}  \\end{aligned}\\]        $\\overline{X}$ : 표본평균\\[\\begin{aligned}  \\overline{X}  &amp;=\\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}  \\end{aligned}\\]        $\\mathbf{b}$ : 순위 통계량 벡터 $\\mathbf{X}$ 의 계수 벡터\\[\\begin{aligned}  \\mathbf{b}  &amp;=\\frac{\\mathbf{m}^{T}\\mathbb{V}^{-1}}{\\Vert \\mathbb{V}^{-1}\\mathbf{m} \\Vert}  \\end{aligned}\\]                  $\\mathbf{m}$ : 기대 순위 통계량 벡터\\[\\begin{aligned}  \\mathbf{m}  &amp;=\\begin{pmatrix}  \\mathbb{E}\\left[X_{1}\\right]&amp;\\mathbb{E}\\left[X_{2}\\right]&amp;\\cdots&amp;\\mathbb{E}\\left[X_{n} \\right]  \\end{pmatrix}^{T}  \\end{aligned}\\]                    $\\mathbb{V}$ : 기대 순위 통계량의 공분산 행렬\\[\\begin{aligned}  \\mathbb{V}_{i,j}=\\mathrm{Cov}\\Big(\\mathbb{E}\\left[X_{i}\\right],\\mathbb{E}\\left[X_{j}\\right]\\Big)  \\end{aligned}\\]            Generate Dist. of Test Stats      표준정규분포로부터 $n$ 개의 관측치로 구성된 표본을 반복적으로 생성\\[\\begin{aligned} \\mathbf{Y}^{(k)} &amp;= \\begin{pmatrix} Y_{1}^{(k)}&amp;Y_{2}^{(k)}&amp;\\cdots&amp;Y_{n}^{(k)} \\end{pmatrix}^{T} \\quad \\text{for} \\quad Y^{(k)}_{i} \\sim N(0,1) \\end{aligned}\\]        표본 $\\mathbf{Y}^{(1)},\\mathbf{Y}^{(2)},\\cdots$ 에 대하여 검정통계량 도출\\[\\begin{aligned} W^{(k)} &amp;=\\frac{\\left(\\sum_{i=1}^{k} \\beta_{i} Y_{i}\\right)^2}{\\sum_{i=1}^{k}\\left(Y_{i} - \\overline{Y}\\right)^2} \\end{aligned}\\]        $n$ 의 크기에 따른 $W$ 의 경험적 분포 도출\\[\\begin{aligned} W_{N} \\sim f_{W_{N}}(W) \\end{aligned}\\]  "
  },
  
  {
    "title": "Paired Sample t-Test",
    "url": "/posts/paired_sample_t_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, t-test, two sample t-test, paired sample t-test, student’s t-distribution",
    "date": "2024-07-10 00:00:00 +0900",
    





    
    "snippet": "Paired Sample t-Test      쌍체표본 t 검정(Paired Sample t-Test) : 쌍을 이루는 두 변수 간 차이의 평균이 기대되는 값($\\mu_0$)과 통계적으로 유의한 차이가 있는지 검정하는 방법          주식시장의 변동은 일부 투자자들로 하여금 주식을 팔고 그들의 자금을 더 안전한 투자로 이동시키게 만든다. 최근 주...",
    "content": "Paired Sample t-Test      쌍체표본 t 검정(Paired Sample t-Test) : 쌍을 이루는 두 변수 간 차이의 평균이 기대되는 값($\\mu_0$)과 통계적으로 유의한 차이가 있는지 검정하는 방법          주식시장의 변동은 일부 투자자들로 하여금 주식을 팔고 그들의 자금을 더 안전한 투자로 이동시키게 만든다. 최근 주식시장의 변동이 주식 보유에 어느 정도 영향을 미쳤는지를 결정하기 위해 주식을 소유하고 있는 170 명을 대상으로 서베이를 실시하였다. 실험 대상자들의 재작년 말과 작년 말 주식 보유액을 기록하였다. 주식 보유액이 감소했다고 추론할 수 있는가?              쌍체표본(Paired Sample) : 동일한 대상에 대하여 두 번의 측정을 통해 얻은 표본, 혹은 변수 간 상관관계가 존재하는 두 대상에 대하여 측정을 통해 얻은 표본            모수(Parameter) 정의:\\[\\begin{aligned}  \\mu_{D}  &amp;= \\frac{1}{N}\\sum_{i=1}^{N}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  \\overline{X}_{D}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}:\\quad \\mu_{D} = \\mu_{0}$      $H_{1}:\\quad \\mu_{D} \\ne \\mu_{0}$            검정통계량(Test Statistic):\\[\\begin{aligned}  T \\sim t(\\nu)  \\end{aligned}\\]  Test Statistic\\[\\begin{aligned}T&amp;= \\frac{\\overline{X}-\\mu_{0}}{s_{D} / \\sqrt{n}}\\end{aligned}\\]      \\(\\mathbb{E}\\left[\\overline{X}_{D}\\right]\\):\\[\\begin{aligned}  \\mathbb{E}\\left[ \\overline{X}_{D}\\right]  &amp;= \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{1}{n}\\left(\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right)\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}}\\right]-\\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\overline{X}_{A}\\right]-\\mathbb{E}\\left[\\overline{X}_{B}\\right]\\\\  &amp;= \\mu_A - \\mu_B\\\\  &amp;= \\mu_{D}  \\end{aligned}\\]        \\(\\mathrm{Var}\\left[\\overline{X}\\right]\\):\\[\\begin{aligned}  \\mathrm{Var}\\left[\\overline{X}\\right]  &amp;= \\mathrm{Var}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\overline{X}_{A}-\\overline{X}_{B}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\overline{X}_{A}\\right] + \\mathrm{Var}\\left[\\overline{X}_{B}\\right] - 2 \\times \\mathrm{Cov} \\left[\\overline{X}_{A}, \\overline{X}_{B}\\right]\\\\  &amp;=\\frac{s_{A}^{2}}{n}+\\frac{s_{B}^{2}}{n}-2\\times\\frac{r_{A,B}}{n}\\\\  &amp;=\\frac{1}{n}\\left(s_{A}^{2} + s_{B}^{2} - 2 \\times r_{A,B}\\right)\\\\  &amp;=\\frac{s_{D}^2}{n}  \\end{aligned}\\]        Standardized $T$:\\[\\begin{aligned}  T  &amp;= \\frac{\\overline{X}_{D}-\\mu_{0}}{s_{D}/\\sqrt{n}}\\\\  &amp;= \\frac{\\overline{X}_{D}-\\mu_{D}}{s_{D}/\\sqrt{n}} + \\frac{\\mu_{D}-D_{0}}{s_{D}/\\sqrt{n}}\\\\  &amp;= \\frac{\\mu_{D}-\\mu_{0}}{s_{D}/\\sqrt{n}} \\quad (\\because \\mathbb{E}\\left[\\overline{X}_{D}\\right]=\\mu_{D})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Levene’s Test",
    "url": "/posts/levene_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, f-test, equal-variance test, levene’s test, f distribution",
    "date": "2024-07-09 00:00:00 +0900",
    





    
    "snippet": "Levene’s Test      레벤의 검정(Levene’s Test): 두 개 이상의 독립표본이 등분산성(Homogeneity of Variances)을 만족하는지 검정하는 방법        모수(Parameter) 정의:\\[\\begin{aligned}  \\sigma_{1}^{2},\\sigma_{2}^{2},\\cdots,\\sigma_{k}^{2} ...",
    "content": "Levene’s Test      레벤의 검정(Levene’s Test): 두 개 이상의 독립표본이 등분산성(Homogeneity of Variances)을 만족하는지 검정하는 방법        모수(Parameter) 정의:\\[\\begin{aligned}  \\sigma_{1}^{2},\\sigma_{2}^{2},\\cdots,\\sigma_{k}^{2}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  s_{1}^{2},s_{2}^{2},\\cdots,s_{k}^{2}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}:\\quad \\forall i \\quad \\sigma_{i}^{2} / \\sigma_{j \\ne i}^{2} = 1$      $H_{1}:\\quad \\exists i \\quad \\sigma_{i}^{2} / \\sigma_{j \\ne i}^{2} \\ne 1$            검정통계량(Test Statistic):\\[\\begin{aligned}  F \\sim \\mathcal{F}(k-1, N-k)  \\end{aligned}\\]        F 분포(F-Distribution) : 서로 독립인 확률변수 $V_{1}\\sim\\chi^2(\\nu_1),V_{2}\\sim\\chi^2(\\nu_2)$ 간 비율로 구성되는 확률변수의 분포\\[F=\\frac{V_1/\\nu_1}{V_2/\\nu_2} \\sim \\mathcal{F}(\\nu_1,\\nu_2)\\]  Test Statistic\\[\\begin{aligned}F = \\frac{\\text{SSB} / (k-1)}{\\text{SSW} / (N-k)}\\end{aligned}\\]      SSB(Sum of Square Between):\\[\\text{SSB}=\\sum_{i=1}^{k}{N_{i}\\left(\\overline{Z}^{(i)}-\\overline{Z}\\right)^2} \\sim \\chi^2(k-1)\\]          $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}\\) 의 평균      $\\overline{Z}$ : 모든 관측치 $X_{\\forall}$ 에 대하여 그 절대편차 \\(Z\\) 의 평균      $k$ : 표본 내 집단 갯수            SSW(Sum of Square Within):\\[\\text{SSW}=\\sum_{i=1}^{k}\\sum_{j=1}^{N_{i}}{\\left(Z^{(i)}_{j}-\\overline{Z}^{(i)}\\right)^2} \\sim \\chi^2(N-k)\\]          \\(Z^{(i)}_{j}=\\vert X^{(i)}_{j}-\\overline{X}^{(i)} \\vert\\) : \\(i\\) 번째 집단의 \\(j\\) 번째 관측치 \\(X^{(i)}_{j}\\) 의 절대편차      $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}\\) 의 평균      $N$ : 표본 내 관측치 갯수      "
  },
  
  {
    "title": "Student's t-Test",
    "url": "/posts/student_t_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, t-test, two sample t-test, independent samples t-test, student’s t-test, student’s t-distribution",
    "date": "2024-07-08 00:00:00 +0900",
    





    
    "snippet": "Student’s t-Test      스튜던트의 t 검정(Student’s t-Test): 독립표본 t 검정(Independent Samples t-Test) 중 등분산 t 검정으로서($\\sigma_{1} = \\sigma_{2}$), 등분산 가정이 성립하는 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저...",
    "content": "Student’s t-Test      스튜던트의 t 검정(Student’s t-Test): 독립표본 t 검정(Independent Samples t-Test) 중 등분산 t 검정으로서($\\sigma_{1} = \\sigma_{2}$), 등분산 가정이 성립하는 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저 리그 야구경기를 마무리하는 데 걸리는 시간에 대한 우려가 팬과 구단주 사이에서 점차 더 커지고 있다. 이 문제의 심각성을 평가하기 위해서, 한 통계 전문가는 5년 전과 금년에 임의표본을 구성하는 경기들을 마무리하는데 걸린 시간을 기록하였다. 한 경기를 마무리하는 데 걸리는 시간이 5년 전보다 금년이 더 길다고 결론을 내릴 수 있는가?            모수(Parameter) 정의:\\[\\begin{aligned}  \\mu_{1} - \\mu_{2}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  \\overline{X}_{1}-\\overline{X}_{2}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}:\\quad \\mu_1-\\mu_2=D_{0}$      $H_{1}:\\quad \\mu_1-\\mu_2 \\ne D_{0}$            검정통계량(Test Statistic):\\[\\begin{aligned}  T \\sim t(\\nu_{1} + \\nu_{2})  \\end{aligned}\\]        합동분산(Pooled Variance): 등분산 가정이 성립하는 두 독립표분의 분산을 각각의 자유도로 가중평균한 값\\[\\begin{aligned}  s_{p}^{2}  &amp;= \\frac{\\nu_{1} \\cdot s_{1}^{2} + \\nu_{2} \\cdot s_{2}^{2}}{\\nu_{1} + \\nu_{2}}  \\end{aligned}\\]  Test Statistic\\[\\begin{aligned}T&amp;= \\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{s_{p}^{2}/n_{1}+s_{p}^{2}/n_{2}}}\\end{aligned}\\]      \\(\\mathbb{E}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]\\):\\[\\begin{aligned}  \\mathbb{E}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]  &amp;= \\mathbb{E}\\left[\\overline{X}_{1}\\right] - \\mathbb{E}\\left[\\overline{X}_{2}\\right]\\\\  &amp;= \\mu_{1} - \\mu_{2}  \\end{aligned}\\]        \\(\\mathrm{Var}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]\\):\\[\\begin{aligned}  \\mathrm{Var}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]  &amp;= \\mathrm{Var}\\left[\\overline{X}_{1}\\right] + \\mathrm{Var}\\left[\\overline{X}_{2}\\right] - 2 \\times \\mathrm{Cov}\\left[\\overline{X}_{1}, \\overline{X}_{2}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\overline{X}_{1}\\right] + \\mathrm{Var}\\left[\\overline{X}_{2}\\right] \\quad (\\because \\mathrm{Cov}\\left[\\overline{X}_{1}, \\overline{X}_{2}\\right] = 0)\\\\  &amp;= \\frac{s_{p}^{2}}{n_{1}} + \\frac{s_{p}^{2}}{n_{2}}  \\end{aligned}\\]        Standardized $T$:\\[\\begin{aligned}  T  &amp;= \\frac{(\\overline{X}_{1}-\\overline{X}_{2})-D_{0}}{s_{p}^{2}/n_{1} + s_{p}^{2}/n_{2}}\\\\  &amp;= \\frac{(\\overline{X}_{1}-\\overline{X}_{2})-(\\mu_{1}-\\mu_{2})}{s_{p}^{2}/n_{1} + s_{p}^{2}/n_{2}} + \\frac{(\\mu_{1}-\\mu_{2})-D_{0}}{s_{p}^{2}/n_{1} + s_{p}^{2}/n_{2}}\\\\  &amp;= \\frac{(\\mu_{1}-\\mu_{2})-D_{0}}{s_{p}^{2}/n_{1} + s_{p}^{2}/n_{2}} \\quad (\\because \\mathbb{E}\\left[\\overline{X}\\right]=\\mu)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Welch’s t-Test",
    "url": "/posts/welch_t_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test, t-test, two sample t-test, independent samples t-test, welch’s t-test, student’s t-distribution",
    "date": "2024-07-07 00:00:00 +0900",
    





    
    "snippet": "Welch’s t-Test      웰치의 t 검정(Welch’s t-Test): 독립표본 t 검정(Independent Samples t-Test) 중 이분산 t 검정으로서($\\sigma_{1} \\ne \\sigma_{2}$), 등분산 가정이 성립하지 않는 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저 ...",
    "content": "Welch’s t-Test      웰치의 t 검정(Welch’s t-Test): 독립표본 t 검정(Independent Samples t-Test) 중 이분산 t 검정으로서($\\sigma_{1} \\ne \\sigma_{2}$), 등분산 가정이 성립하지 않는 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저 리그 야구경기를 마무리하는 데 걸리는 시간에 대한 우려가 팬과 구단주 사이에서 점차 더 커지고 있다. 이 문제의 심각성을 평가하기 위해서, 한 통계 전문가는 5년 전과 금년에 임의표본을 구성하는 경기들을 마무리하는데 걸린 시간을 기록하였다. 한 경기를 마무리하는 데 걸리는 시간이 5년 전보다 금년이 더 길다고 결론을 내릴 수 있는가?            모수(Parameter) 정의:\\[\\begin{aligned}  \\mu_{1} - \\mu_{2}  \\end{aligned}\\]        점 추정량(Point Estimator) 도출:\\[\\begin{aligned}  \\overline{X}_{1}-\\overline{X}_{2}  \\end{aligned}\\]    가설(Hypothesis) 설정:          $H_{0}:\\quad \\mu_1-\\mu_2=D_{0}$      $H_{1}:\\quad \\mu_1-\\mu_2 \\ne D_{0}$            검정통계량(Test Statistic):\\[\\begin{aligned}  T \\sim t(\\nu_W)  \\end{aligned}\\]        Welch-Satterthwaite 자유도(Welch-Satterthwaite Degree of Freedom): \\(\\overline{X}_{1} - \\overline{X}_{2}\\) 의 종합적인 변동성을 각 표본들이 변동성에 대하여 기여한 정도로써 가중 평균한 값\\[\\begin{aligned}  \\nu_{W}  &amp;= \\frac{\\left(s_{1}^{2}/n_{1} + s_{2}^{2}/n_{2}\\right)^{2}}{(s_{1}^{2}/n_{1})/\\nu_{1} + (s_{2}^{2}/n_{2})/\\nu_{2}}  \\end{aligned}\\]  Test Statistic\\[\\begin{aligned}T&amp;= \\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{s_{1}^{2}/n_{1}+s_{2}^{2}/n_{2}}}\\end{aligned}\\]      \\(\\mathbb{E}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]\\):\\[\\begin{aligned}  \\mathbb{E}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]  &amp;= \\mathbb{E}\\left[\\overline{X}_{1}\\right] - \\mathbb{E}\\left[\\overline{X}_{2}\\right]\\\\  &amp;= \\mu_{1} - \\mu_{2}  \\end{aligned}\\]        \\(\\mathrm{Var}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]\\):\\[\\begin{aligned}  \\mathrm{Var}\\left[\\overline{X}_{1}-\\overline{X}_{2}\\right]  &amp;= \\mathrm{Var}\\left[\\overline{X}_{1}\\right] + \\mathrm{Var}\\left[\\overline{X}_{2}\\right] - 2 \\times \\mathrm{Cov}\\left[\\overline{X}_{1}, \\overline{X}_{2}\\right]\\\\  &amp;= \\mathrm{Var}\\left[\\overline{X}_{1}\\right] + \\mathrm{Var}\\left[\\overline{X}_{2}\\right] \\quad (\\because \\mathrm{Cov}\\left[\\overline{X}_{1}, \\overline{X}_{2}\\right] = 0)\\\\  &amp;= \\frac{s_{1}^{2}}{n_{1}} + \\frac{s_{2}^{2}}{n_{2}}  \\end{aligned}\\]        Standardized $T$:\\[\\begin{aligned}  T  &amp;= \\frac{(\\overline{X}_{1}-\\overline{X}_{2})-D_{0}}{s_{1}^{2}/n_{1} + s_{2}^{2}/n_{2}}\\\\  &amp;= \\frac{(\\overline{X}_{1}-\\overline{X}_{2})-(\\mu_{1}-\\mu_{2})}{s_{1}^{2}/n_{1} + s_{2}^{2}/n_{2}} + \\frac{(\\mu_{1}-\\mu_{2})-D_{0}}{s_{1}^{2}/n_{1} + s_{2}^{2}/n_{2}}\\\\  &amp;= \\frac{(\\mu_{1}-\\mu_{2})-D_{0}}{s_{1}^{2}/n_{1} + s_{2}^{2}/n_{2}} \\quad (\\because \\mathbb{E}\\left[\\overline{X}\\right]=\\mu)  \\end{aligned}\\]  "
  },
  
  {
    "title": "A/B Test",
    "url": "/posts/ab_test/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, design of experiments, a/b test",
    "date": "2024-07-06 00:00:00 +0900",
    





    
    "snippet": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더...",
    "content": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더 높은 성과를 보이는지 판단함. 이때 두 집단을 무작위로 추출함으로써, 두 집단이 제3의 요인들에 대하여 완전히 동질적일 수는 없지만 확률적으로 유사한 분포를 가지도록 함.      refer. Correlation VS. Causality  Example: 아이스크림 판매량과 물놀이 사고 간 관계성  한 지자체에서 물놀이 사고를 줄이는 것을 목표로 하고 있다. 조사 결과 아이스크림 판매량과 물놀이 사고 빈도 간의 상관관계가 높음을 알 수 있었다. 즉, 아이스크림 판매량이 증가하면 물놀이 사고가 증가하는 것이 데이터로부터 파악되었다. 이를 근거로 아이스크림 판매량 증가가 물놀이 사고 증가의 원인이라고 판단하였고, 물놀이 사고를 줄이기 위해 아이스크림 가격을 올려 판매량을 줄이는 정책을 입안하였다.  아이스크림 판매량과 물놀이 사고를 동시에 증가시키는 제3의 요인이 존재한다면?  Example: 웹사이트 디자인 개편과 매출 증가 간 관계성  어떤 쇼핑몰 웹 사이트에서 3개월에 걸쳐 디자인 개편 프로젝트를 진행하였고, 지난주에 성공적으로 새 디자인을 적용하였다. 그랬더니 갑자기 그 전에 비해 일 매출이 $10\\%$ 증가했다. 매출 증가는 웹사이트 디자인 개편 덕분이라고 판단할 수 있는가?  새 디자인이 적용된 날 갑자기 경쟁 쇼핑몰이 문을 닫았다면?  새 디자인이 적용된 날 갑자기 인기 상품이 입고되었다면?  새 디자인이 적용된 날 갑자기 경기가 좋아졌다면?Mean of a continuous random variable            문제      관심모수      점추정량      가정      검정가설      검정방법                  단일 집단의 평균      $\\mu$      $\\bar{X}$      $n&gt;30$      $H_0: \\mu=\\mu_0$      One Sample t-Test              두 집단 간 평균 비교  (독립표본)      $\\mu_1-\\mu_2$      \\(\\bar{X}_{1} - \\bar{X}_{2}\\)      $(n_1 + n_2)&gt;30$      $H_0: \\mu_1 - \\mu_2 = 0$      Two Sample t-Test              두 집단 간 평균 비교  (쌍체표본)      $\\mu_d$      $\\bar{X}_d$      $n&gt;30$      $H_0: \\mu_d=0$      Paired Sample t-Test              셋 이상 그룹 간 평균 비교      $\\mu_1, \\cdots, \\mu_m$      $\\bar{X}_1, \\cdots, \\bar{X}_m$      $n_i&gt;30$  $\\sigma_{i}^{2}=\\sigma_{j}^{2}$      $H_0: \\mu_1 = \\cdots = \\mu_m$      ANOVA      Proportion of a discrete random variable            문제      관심모수      점추정량      가정      검정가설      검정방법                  단일 집단의 비율      $\\pi$      $p$      $np&gt;5$  $n(1-p)&gt;5$      $H_0: \\pi=\\pi_0$      One Sample z-Test              두 집단 간 비율 비교      $\\pi_1 - \\pi_2$      $p_1 - p_2$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1-\\pi_2=0$      Two Sample z-Test              적합성 검정      $\\pi_1, \\cdots, \\pi_m$      $p_1, \\cdots, p_m$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1=p_{0}^{(1)}, \\cdots, \\pi_m=p_{0}^{(m)}$      Chi-square test              독립성 검정                    $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0:$ 두 범주형 변수가 독립      Chi-square test      Sourse  https://varify.io/en/blog/ab-testing/"
  },
  
  {
    "title": "Hypothesis Testing",
    "url": "/posts/hypothesis_testing/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, estimation, z-test, t-test",
    "date": "2024-07-05 00:00:00 +0900",
    





    
    "snippet": "Hypothesis Testing  통계적 가설(Statistical Hypothesis) : 모집단의 모수에 대한 주장          귀무가설(Null-Hypothesis; $H_0$) : 사실이 아니라는 충분한 근거를 얻기 전에는 사실이라고 믿어지는 가설      대립가설(Alternative Hypothesis; $H_1$) : 연구자의 주장으...",
    "content": "Hypothesis Testing  통계적 가설(Statistical Hypothesis) : 모집단의 모수에 대한 주장          귀무가설(Null-Hypothesis; $H_0$) : 사실이 아니라는 충분한 근거를 얻기 전에는 사실이라고 믿어지는 가설      대립가설(Alternative Hypothesis; $H_1$) : 연구자의 주장으로서 귀무가설이 기각될 때 채택되는 가설        가설검정(Hypothesis Testing) : 귀무가설을 기각할 충분한 증거가 있는지 살핌으로써 대립가설을 우회로 증명하는 절차          귀무가설과 대립가설 설정      유의수준 설정      모수 추정법 적용 가능 여부 검토      검정통계량과 p-value 도출      귀무가설 기각 여부 결정      검정 결과 해석      Type      양측검정(Two-Sided Test) : 귀무가설에 대한 기각역을 양측에 설정하는 검정    \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu\\ne70  \\end{aligned}\\]        단측검정(One-Sided Test) : 귀무가설에 대한 기각역을 단측에만 설정하는 검정                  우측검정 : 기각역을 우측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu \\le 70,\\\\  H_1&amp;:\\;\\mu &gt; 70  \\end{aligned}\\]                    좌측검정 : 기각역을 좌측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu&lt;70  \\end{aligned}\\]            Error      오류(Error) : 사실과 다르게 판단함              제1종 오류(Type 1 Error) : 귀무가설이 참일 때 귀무가설을 기각하는 오류      제1종 오류(Type 2 Error) : 귀무가설이 거짓일 때 귀무가설을 기각하지 않는 오류            검정의 유의수준(Significance Level) : 제1종 오류를 범할 확률\\[\\alpha\\]          통계학에서는 보수적 태도(귀무가설을 기각하지 않으려는 태도)를 취하므로 제1종 오류에 민감함            검정의 신뢰수준(Confidence Level) : 제1종 오류를 범할 확률 $\\alpha$ 에 대하여, 귀무가설이 참일 때 귀무가설을 기각하지 않을 확률\\[1-\\alpha\\]        검정의 검정력(Power) : 제2종 오류를 범할 확률 $\\beta$ 에 대하여, 귀무가설이 거짓일 때 귀무가설을 기각할 확률\\[1-\\beta\\]  Test Statistic      검정통계량(Test Statistic) : 귀무가설이 참이라고 가정했을 때 얻은 결과    \\[\\begin{aligned}  Z  &amp;= \\frac{\\overline{X}-\\mu_{0}}{\\sigma / \\sqrt{n}}  \\end{aligned}\\]        검정통계량의 분포:\\[\\begin{aligned}  Z  &amp;= \\frac{\\overline{X}-\\mu_{0}}{\\sigma / \\sqrt{n}}\\\\  &amp;= \\frac{\\overline{X}-\\mu}{\\sigma / \\sqrt{n}} + \\frac{\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}}\\\\  &amp;= \\frac{\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}} \\quad (\\because \\mathbb{E}\\left[\\overline{X}\\right]=\\mu)  \\end{aligned}\\]                  귀무가설이 참일 경우($\\mu = \\mu_{0}$):\\[\\begin{aligned}  Z \\sim \\mathcal{N}(0,1) \\quad (\\because \\frac{\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}} = 0)  \\end{aligned}\\]                    귀무가설이 참이 아닐 경우($\\mu \\ne \\mu_{0}$):\\[\\begin{aligned}  Z \\sim \\mathcal{N}(\\frac{\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}},1)  \\quad (\\because \\frac{\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}} \\ne 0)  \\end{aligned}\\]                  유의확률(Significance Probability Value) : 검정통계량($Z$)보다 극단적인 결과($Y$)가 관측될 확률로서, 표본이 귀무가설과 양립하는 정도    \\[\\begin{aligned}  \\mathrm{p-value}  &amp;= P\\left(\\vert Y \\vert \\ge \\vert Z \\vert \\mid H_{0}\\right), \\quad Y \\sim N(0,1)  \\end{aligned}\\]  Rejection &amp; Interpretation      기각역(Critical Region): 귀무가설을 기각하는 영역\\[\\begin{aligned}  Z \\notin \\mathcal{R}  \\end{aligned}\\]                  기각치(Reject Value)를 활용한 기각역 설정:\\[Z_{\\alpha/2},\\quad Z_{\\alpha}\\]                  양측검정: \\(\\mathcal{R}:=\\left\\{Z \\mid \\vert Z \\vert &gt; Z_{\\alpha/2}\\right\\}\\)          우측검정: \\(\\mathcal{R}:=\\left\\{Z \\mid Z &gt; Z_{\\alpha}\\right\\}\\)          좌측검정: \\(\\mathcal{R}:=\\left\\{Z \\mid Z &lt; -Z_{\\alpha}\\right\\}\\)                            유의수준(Significance Level)을 활용한 기각역 설정:\\[\\begin{aligned}  \\mathcal{R}  :=\\left\\{Z \\mid \\mathrm{p-value}(Z) \\ge \\alpha\\right\\}  \\end{aligned}\\]                  통계적 유의성(Statistically Significant) : 실험 결과가 우연에 의한 것이 아니라 실제 현상을 반영한다고 판단할 수 있는 정도                  Reject $H_{0}$:                  귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각하지 않는다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_{0}$ 과 통계적으로 유의한 차이가 있다고 볼 수 없다. 이에 따라 귀무가설은 제한적으로 사실이라 간주될 수 있다.                            Fail to Reject $H_{0}$:                  귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각한다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_0$ 과 통계적으로 유의한 차이가 있다. 이에 따라 대립가설은 잠정적으로 사실이라 간주될 수 있다.                    Sourse  https://u5man.medium.com/to-err-is-human-what-the-heck-is-type-i-and-type-ii-error-b2c78190a45c  https://wikidocs.net/163986"
  },
  
  {
    "title": "Estimation",
    "url": "/posts/estimation/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, estimation, z-test, t-test",
    "date": "2024-07-04 00:00:00 +0900",
    





    
    "snippet": "Point Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                      모수      ...",
    "content": "Point Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                      모수          $\\theta$          $\\mu$          $\\sigma^2$          $\\pi$                          점 추정량          $\\hat{\\theta}$          $\\overline{X}$          $S^2$          $P$                          불편 추정량(Unbiased Estimator) : 기대값이 모수와 같아 모수로부터 음이나 양으로 편향되지 아니한 추정량\\[\\begin{aligned}  \\mathrm{Bias}\\left[\\hat{\\theta}\\right]  = \\mathbb{E}\\left[\\hat{\\theta}\\right] - \\theta  = 0  \\end{aligned}\\]        효율적 추정량(Efficient Estimator) : 모수의 불편 추정량 중 분산이 최소인 불편 추정량\\[\\begin{aligned}  \\min{\\mathbb{E}\\left[(\\hat{\\theta}-\\theta)^2\\right]}  = \\min{\\left(\\mathrm{Var}[\\hat{\\theta}] + \\mathrm{Bias}[\\hat{\\theta}]^2\\right)}  \\end{aligned}\\]          BLUE(Best Linear Unbiased Estimator): 불편 선형 추정량 중 가장 효율적인 추정량으로서, 대표적으로 표본평균 $\\overline{X}$ 가 모평균 $\\mu$ 의 BLUE 임            일치 추정량(Consistent Estimator) : 표본의 크기 $n$ 이 커질수록 평균자승오차가 $0$ 에 수렴하는 추정량\\[\\begin{aligned}  \\lim_{n \\rightarrow \\infty}{\\mathbb{E}[(\\hat{\\theta}-\\theta)^{2}]}  &amp;= \\lim_{n \\rightarrow \\infty}{\\mathrm{Var}[\\hat{\\theta}]} + \\lim_{n \\rightarrow \\infty}{\\mathrm{Bias}^{2}[\\hat{\\theta}]}\\\\  &amp;= 0  \\end{aligned}\\]  Confidence Intervals      신뢰 구간(Confidence Intervals) : 신뢰 가능한 수준 하에서 모수를 포함할 수 있다고 추정되는 구간으로서 신뢰수준을 담보한 구간 추정량(Interval Estimator)\\[\\text{CI}:=\\left(\\overline{X}-z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}, \\overline{X}+z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}\\right)\\]                  신뢰수준(Confidence Level) : 신뢰구간이 담보하는, 해당 구간이 모수를 포함할 가능성으로서, $N$ 번의 반복실험에서 신뢰구간이 모수를 포함하는 상대 빈도\\[P(\\mu \\in \\text{CI})=1-\\alpha\\]                    오차한계(Margin of Error) : 모수 $\\mu$ 와 그 점 추정량 $\\overline{X}$ 에 대하여 신뢰구간의 끝(한계)과 $\\mu$ 사이의 최대 차이로서, $\\mu$ 와 $\\overline{X}$ 의 차이(오차)를 수용할 수 있는 범위를 결정하는 값\\[z_{\\alpha / 2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]                  신뢰구간의 길이(Length)\\[\\text{Length}(\\text{CI}) = 2 \\times z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]          $(1-\\alpha)\\uparrow \\; \\Rightarrow L\\uparrow$ : 신뢰수준이 높을수록 신뢰구간의 길이가 증가함      $\\sigma\\uparrow \\; \\Rightarrow L\\uparrow$ : 모집단의 분포가 널리 퍼져 있을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함      $n\\downarrow \\; \\Rightarrow L\\uparrow$ : 표본의 크기가 작을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함            신뢰구간의 도출                  중심극한정리에 의해 $n$ 이 충분히 크면 다음이 성립함\\[\\begin{aligned}  \\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})  \\end{aligned}\\]                    확률변수 $\\overline{X}$ 를 다음과 같이 표준화할 수 있음\\[\\begin{aligned}  Z=\\displaystyle\\frac{\\overline{X} - \\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)  \\end{aligned}\\]                    $100(1-\\alpha)\\%$ 신뢰수준 하 신뢰구간은 다음과 같음\\[\\begin{aligned}  P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})  &amp;=P(-z_{\\alpha/2}&lt;\\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}&lt;z_{\\alpha/2})\\\\  &amp;=P(-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\overline{X}-\\mu&lt;z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(-\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;-\\mu&lt;-\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\mu&lt;\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=1-\\alpha  \\end{aligned}\\]            "
  },
  
  {
    "title": "Mult-VAE",
    "url": "/posts/vacf/",
    "categories": "6.RECOMMENDER SYSTEM, 3.ae based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, autoencoder, bayesian",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "Mult-VAE  문제 의식          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측을 선호, 미관측을 비선호로 확정적으로 간주하기에 불확실한 요소가 존재함(관측 불완전성)          클래스 불균형 문제(Class Imbalance): 관측과 미관측의 비율...",
    "content": "Mult-VAE  문제 의식          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측을 선호, 미관측을 비선호로 확정적으로 간주하기에 불확실한 요소가 존재함(관측 불완전성)          클래스 불균형 문제(Class Imbalance): 관측과 미관측의 비율이 균등하지 않아 모든 상호작용을 $0$ 으로 예측할 위험이 있음(데이터 희소성)                            Competitive Relationship between Items: 사용자 선택 과정에는 아이템 간 암묵적인 경쟁적 구조가 존재하므로 사용자가 특정 아이템과 상호작용할 확률은 다른 아이템과 상호작용할 확률과 독립적으로 계산되어서는 안 됨            Uncertainty of Latent Representation: 관측 불완전성, 데이터 희소성 등 암시적 피드백 데이터의 정보 불확실성으로 인하여 사용자 잠재 선호를 확정적으로 도출하기에 문제가 있으므로 사용자 선호가 취할 수 있는 다양한 가능성을 고려해야 함        Mult-VAE(Multinomial Variational AutoEncoder): 확률적 생성 과정을 통해 표현의 다양성을 확보하되, 사전 정보로 규제함으로써 과잉 표현을 규제하고 일반화를 도모하는 오토인코더 기반 협업필터링 모형          Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T.  (2018, April).  Variational autoencoders for collaborative filtering.  In Proceedings of the 2018 world wide web conference (pp. 689-698).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item implicit feedback matrix  $f(\\cdot)$: encoder networks  $g(\\cdot)$: decoder networksHow to Modeling      Bayesian Framework                  $Q$ is approx. dist. of latent preference vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u} \\sim \\mathcal{N}(\\mu_{u}, \\text{diag}(\\sigma_{u}^{2}))  \\end{aligned}\\]                  $\\mu_{u}, \\text{diag}(\\sigma_{u}^{2})$ is inferred by encoder networks $f(\\cdot)$                            $\\Pi$ is prior dist. of latent preference vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u} \\sim \\mathcal{N}(0, \\mathbf{I})  \\end{aligned}\\]                    $P$ is likelihood:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u} \\sim \\text{Multinomial}(\\vert \\mathcal{R}_{u}^{+} \\vert, \\delta[g(\\overrightarrow{\\mathbf{z}}_{u})])  \\end{aligned}\\]                  \\(\\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u}\\) is generated by decoder networks \\(g(\\cdot)\\)          to reflect the competitive relationship between items when the user selects an item,                          likelihood is multinomial dist., not $n$ independent binomial dist.              $\\delta(\\cdot)$ is softmax function, not sigmoid function                                                Objective Function is ELBO:\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max{\\mathbb{E}_{\\mathbf{Z} \\mid \\mathbf{Y} \\sim Q}[\\log{p(\\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u})}] - \\beta \\cdot KL[Q(\\overrightarrow{\\mathbf{z}}_{u}) \\Vert \\Pi(\\overrightarrow{\\mathbf{z}}_{u})]}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Sample Dist.",
    "url": "/posts/sample_dist/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, sample, sample distribution",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "Sample Analysis  표본 분석(Sample Analysis) : 전체 모집단에서 일부 표본을 추출하여 분석하고, 이를 통해 전체 모집단의 특성(모수)을 추론하는 통계적 방법          표본의 평균 $\\overline{X}$ 이 모집단의 평균 $\\mu$ 를 얼마나 잘 추정하는가      확률변수 $\\overline{X}$ 의 기대값 $\\...",
    "content": "Sample Analysis  표본 분석(Sample Analysis) : 전체 모집단에서 일부 표본을 추출하여 분석하고, 이를 통해 전체 모집단의 특성(모수)을 추론하는 통계적 방법          표본의 평균 $\\overline{X}$ 이 모집단의 평균 $\\mu$ 를 얼마나 잘 추정하는가      확률변수 $\\overline{X}$ 의 기대값 $\\mathbb{E}\\left[\\overline{X}\\right]$ 은 상수 $\\mu$ 에 가까운가      추정량 $\\overline{X}$ 의 기대값 $\\mathbb{E}\\left[\\overline{X}\\right]$ 과 모수 $\\mu$ 사이에는 얼마나 큰 추정오차가 존재하는가            모수 추정량과 추정치          모수는 그 값이 알려져 있지 않은 고정된 수이다. 이 값을 추정하기 위하여 표본의 통계량을 사용하므로, 통계량은 모수의 추정량이라 할 수 있다. 그런데 모집단에서 어떤 표본을 추출하느냐에 따라 통계량의 실현값이 달라진다. 따라서 모수는 상수(Constant), 통계량은 확률변수(Random Variable) 라고 볼 수 있다.                      추정량(Estimator) : 모수를 추정하는 값으로서 표본의 통계량(Statistics)\\[\\begin{aligned}  \\hat{\\mu}  = \\overline{X}  = \\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}  \\end{aligned}\\]                    추정치(Estimate) : 특정 표본에서 얻어진 추정량의 실현값(Realized Value)\\[\\begin{aligned}  \\hat{\\mu}_{k}  = \\overline{x}_{k}  = \\frac{1}{\\vert \\Omega_{k} \\vert}\\sum_{i \\in \\Omega_{k}}{x_{i}}  \\end{aligned}\\]            Sampling Distribution  표본분포(Sampling Distribution) : 모수 추정량의 확률분포로서 주로 모평균 $\\mu$ 의 추정량 $\\overline{X}$ 의 분포에 관하여 논의함\\[\\begin{aligned}\\overline{X} \\sim \\mathcal{N}(\\mu,\\frac{\\sigma^{2}}{n}) \\quad \\text{s.t.} \\quad n&gt;30\\end{aligned}\\]      표본평균 $\\overline{X}$ 의 기대값:\\[\\begin{aligned}  \\mathbb{E}\\left[\\overline{X}\\right]  &amp;= \\mathbb{E}\\left[\\frac{1}{n}(X_{1}+X_{2}+\\cdots+X_{n})\\right]\\\\  &amp;=\\frac{1}{n}\\left(\\mathbb{E}\\left[X_{1}+X_{2}+\\cdots+X_{n}\\right]\\right)\\\\  &amp;=\\frac{1}{n}\\left(\\mathbb{E}\\left[X_{1}\\right]+\\mathbb{E}\\left[X_{2}\\right]+\\cdots+\\mathbb{E}\\left[X_{n}\\right]\\right)\\\\  &amp;=\\frac{1}{n}\\left(\\mu + \\mu + \\cdots + \\mu \\right)\\\\  &amp;=\\mu  \\end{aligned}\\]        표본평균 $\\overline{X}$ 의 분산:\\[\\begin{aligned}  \\mathrm{Var}\\left[\\overline{X}\\right]  &amp;= \\mathrm{Var}\\left[\\frac{1}{n}(X_{1}+X_{2}+\\cdots+X_{n})\\right]\\\\  &amp;=\\mathrm{Var}\\left[\\frac{1}{n}X_{1}\\right]+\\mathrm{Var}\\left[\\frac{1}{n}X_{2}\\right]+\\cdots+\\mathrm{Var}\\left[\\frac{1}{n}X_{n}\\right]   \\quad \\because \\mathrm{Cov}\\left[\\overline{x}_i, \\overline{x}_j\\right]=0\\\\  &amp;=\\frac{1}{n^2}\\mathrm{Var}\\left[X_{1}\\right]+\\frac{1}{n^2}\\mathrm{Var}\\left[X_{2}\\right]+\\cdots+\\frac{1}{n^2}\\mathrm{Var}\\left[X_{n}\\right]\\\\  &amp;=\\frac{1}{n^2}\\sigma^2 + \\frac{1}{n^2}\\sigma^2 + \\cdots + \\frac{1}{n^2}\\sigma^2\\\\  &amp;=\\frac{1}{n^2}(\\sigma^2 + \\cdots + \\sigma^2)\\\\  &amp;=\\frac{\\sigma^2}{n}  \\end{aligned}\\]        표준오차(Standard Error) : $\\overline{X}$ 의 표준편차\\[\\begin{aligned}  \\mathrm{SE}  =\\sqrt{\\frac{\\sigma^2}{n}}  =\\mathbb{E}\\left[\\vert\\overline{X}-\\mu\\vert\\right]  \\end{aligned}\\]  Central Limit Theorem      큰 수의 법칙(Law of Large Numbers): 표본의 수가 증가할수록, 그 표본의 평균은 모집단의 기댓값에 수렴한다는 법칙          무작위 표본 $X_{1},X_{2},\\cdots,X_{n}$ 이 동일한 분포를 따르고, 그 기대값 $\\mathbb{E}\\left[X_{i}\\right]=\\mu$ 일 때, 표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 에 수렴함    \\[\\begin{aligned}  \\overline{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}{X_{i}} \\to \\mu \\quad (n \\to \\infty)  \\end{aligned}\\]        중심극한정리(Central Limit Theorem): 표본의 수가 증가할수록, 그 표본의 평균의 분포가 가우시안 분포에 근사한다는 정리          평균이 $\\mu$ 이고, 분산이 $\\sigma^2$ 인 모집단에서 크기가 $n$ 인 표본을 추출하는 경우 $n$ 이 증가할수록 표본평균 $\\overline{X}$ 의 분포는 가우시안 분포 $\\mathcal{N}(\\mu,\\sigma^{2}/n)$ 에 근사함    \\[\\begin{aligned}  \\overline{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n}) \\quad \\text{s.t.} \\quad n &gt; 30  \\end{aligned}\\]  "
  },
  
  {
    "title": "Random Sample",
    "url": "/posts/sample/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics, sample, parameter",
    "date": "2024-07-02 00:00:00 +0900",
    





    
    "snippet": "Statistical Inference      통계적 추론(Statistical Inference): 무작위추출한 표본(모집단 부분집합)의 측정치를 모집단의 측정치에 대한 추정치로 사용하여, 표본을 통해 모집단의 성격을 추정하는 작업                  모집단(Population): 연구자가 관심을 가지는 전체 대상 집합\\[\\begin{a...",
    "content": "Statistical Inference      통계적 추론(Statistical Inference): 무작위추출한 표본(모집단 부분집합)의 측정치를 모집단의 측정치에 대한 추정치로 사용하여, 표본을 통해 모집단의 성격을 추정하는 작업                  모집단(Population): 연구자가 관심을 가지는 전체 대상 집합\\[\\begin{aligned}  \\mathcal{X}  &amp;:=\\left\\{X_{i}\\right\\}_{i=1}^{N}  \\end{aligned}\\]                    표본(Sample): 모집단에서 일부를 추출한 부분 집합\\[\\begin{aligned}  \\mathbf{x}  &amp;:=\\left\\{x_{i}\\right\\}_{i=1}^{n},\\quad \\mathbf{x} \\subseteq \\mathcal{X}  \\end{aligned}\\]              표본오차(Sampling Error) : 모집단의 모수와 표본의 통계량 간 차이로서 통계적 추론에서 최소화하고자 하는 대상          응답오차(Response Error): 응답자의 응답 거부 혹은 잘못된 응답으로 인해 발생하는 오차      측정오차(Measurement Error): 데이터의 틀린 측정이나 기입으로 인해 발생하는 오차      표본선택편향(Sample Selection Bias): 모집단의 각 관측치들이 표본에 포함될 확률이 서로 다른 경우      표본오차(Sampling Error): 응답오차, 측정오차, 표본선택편향이 해결되었음에도 발생하는 실제값과 예측값의 차이            무작위 표본(Random Sample): 모집단의 각 개체가 표본으로 선택될 확률이 동일하도록 무작위로 추출된 표본\\[\\begin{aligned}  \\{X_1, X_2, \\cdots, X_n\\}  \\end{aligned}\\]                  동등한 선택 확률(Equal Probability of Selection): 모집단의 각 개체가 표본의 원소로서 선택될 확률이 모두 같고,\\[P(X_{i}=x_{i})=\\frac{1}{N}\\]                    모집단 대표성(Representativeness of the Sample): 원소 $X_1, X_2, \\cdots, X_n$ 이 모두 모집단의 분포를 따르는 확률변수이고,\\[\\begin{aligned}  \\mathbb{E}\\left[X_{i}\\right]  &amp;=\\mu\\\\  \\mathrm{Var}\\left[X_{i}\\right]  &amp;=\\sigma^{2}  \\end{aligned}\\]                    표본 간 독립성(Independence): 원소 $X_1, X_2, \\cdots, X_n$ 이 모두 통계적으로 독립인 경우\\[P(X_{j} \\mid X_{i \\ne j}) = P(X_{j})\\]            Parameter      모수(Parameter): 모집단(Population)의 특성을 수치로 요약한 값                  모평균(Population Mean):\\[\\begin{aligned}  \\mu  &amp;:= \\frac{1}{N}(X_{1}+X_{2}+\\cdots+X_{N})\\\\  &amp;:= \\frac{1}{N}\\sum_{i=1}^{N}{X_{i}}  \\end{aligned}\\]                    모분산(Population Variance):\\[\\begin{aligned}  \\sigma^2  &amp;:= \\frac{1}{N}\\left[(X_{1}-\\mu)^{2} + (X_{2}-\\mu)^{2} + \\cdots + (X_{N}-\\mu)^{2}\\right]\\\\  &amp;:= \\frac{1}{N}\\sum_{i=1}^{N}{(X_{i}-\\mu)^{2}}  \\end{aligned}\\]                  통계량(Statistic): 표본(Sample)의 특성을 수치로 요약한 값                  표본평균(Sample Mean):\\[\\begin{aligned}  \\overline{x}  &amp;:= \\frac{1}{n}(x_{1}+x_{2}+\\cdots+x_{n})\\\\  &amp;:= \\frac{1}{n}\\sum_{i=1}^{n}{x_{i}}  \\end{aligned}\\]                    표본분산(Sample Variance):\\[\\begin{aligned}  s^{2}  &amp;:= \\frac{1}{\\nu}\\left[(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{n}-\\overline{x})^{2}\\right]\\\\  &amp;:= \\frac{1}{\\nu}\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}  \\end{aligned}\\]                  note 자유도(Degree of Freedom; $\\nu$) : 주어진 자료 내에서 독립적으로 변할 수 있는 확률변수의 수          어떠한 자료에 대하여 그 기술통계량이 주어지는 경우, 특정 관측치의 정보가 불분명하더라도 해당 관측치가 취할 수 있는 값은 제한되어 있음. 표본분산 $s^2$ 을 계산하기 위해서는 표본평균 $\\overline{x}$ 을 먼저 계산해야 하므로, 표본분산 계산 시 동원되는 관측치 중 독립적으로 변할 수 있는 관측치의 수는 $n-1$ 임. 이 경우 관측치 수 $n$ 이 아니라 자유도 $\\nu=n-1$ 로 나눈 값이 모분산 $\\sigma^2$ 의 비편향 추정량이 됨.      "
  },
  
  {
    "title": "What? Statistics",
    "url": "/posts/statistics/",
    "categories": "2.STATISTICAL TECHS, 2.statistics",
    "tags": "statistics",
    "date": "2024-07-01 00:00:00 +0900",
    





    
    "snippet": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : ...",
    "content": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : 데이터를 수집, 정리, 제시, 요약하는 방법을 연구함      추론통계학(Inferential Statistics) : 표본으로부터 모집단의 성격을 추정하는 방법을 연구함      What? Descriptive StatisticData Set  구성          관측치(Observation) : 분석하려는 집합에 속한 하나의 개체      변수(Variable) : 개체의 특징        Data Type          정량적 자료(Quantitative Data) : 수로 표현되는 자료로서 숫자 자체가 의미를 가지는 자료                  이산형 자료(Discrete Data) : 셀 수 있는 정수 형태의 자료          연속형 자료(Continuous Data) : 셀 수 없는 실수 형태의 자료                    정성적 자료(Qualitative Data) : 범주(Category)에 따라 나뉘는 자료      Descriptive Statistic      기술통계량(Descriptive Statistic) : 숫자로 측정한 데이터 세트의 특징    명목 척도(Nominal Scale)                  고유한 값(Unique Value)만을 구분하는 척도                  전공 : 경영학, 경제학, 통계학                      순서 척도(Ordinal Scale)                  값들 사이에 분명한 순위가 있는 척도                  직급 : 사원, 대리, 팀장, 과장, 차장, 부장                            값의 간격은 의미를 갖지 않음              구간 척도(Interval Scale)                  값의 간격이 산술적 의미를 갖는 척도                  기온 $0^{\\circ}C$ 와 $10^{\\circ}C$ 의 간격은 기온 $20^{\\circ}C$ 와 $30^{\\circ}C$ 의 간격과 동일함                            값 사이의 비율은 산술적 의미를 갖지 않음                  기온 $30^{\\circ}C$ 가 $20^{\\circ}C$ 보다 $50%$ 더 따뜻하다고 볼 수 없음                      비율 척도(Ratio Scale)                  값 사이의 비율이 산술적 의미를 갖는 척도                  순익 $2,000,000$ 원은 순익 $1,000,000$ 원 보다 순익 두 배라고 볼 수 있음                            $0$ 이 절대영점으로서 의미를 가짐                  매출 $0$ 원은 매출이 하나도 없음을 의미함                    Summary Quantitative Data      중심 위치 측도 : 대표값으로서 값의 대부분이 어디쯤 위치하는지 측정하는 지표        변이 측도 : 관측치들이 얼마나 퍼져 있는가를 나타내는 측도  중심 위치 측도      평균(Mean; $\\mu$) : 관측치들의 합을 그 갯수로 나눈 값\\[\\mu = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}\\]        중위수(Median; $Q_2$) : 모든 관측치를 크기에 따라 오름차순 정렬했을 때 중앙에 오는 값                  평균 vs. 중위수 : 관측치에 이상치가 포함되어 있거나, 분포가 지나치게 비대칭일 경우, 중위수가 대표값으로서 선호됨                          사분위수(Quartile; $Q_i$) : 모든 관측치를 크기에 따라 오름차순으로 정렬했을 때, 하위 25%($Q_1$), 하위 50%($Q_2$), 하위 75%($Q_3$)에 해당하는 값      변이 측도      범위(Range) : 최대값과 최소값의 차이\\[\\text{R}=X_{max}-X_{min}\\]        사분위범위(Interquartile Range) : 관측치를 크기를 기준으로 오름차순 정렬했을 때 제3사분위수와 제1사분위수의 차이\\[\\text{IQR}=Q_{3}-Q_{1}\\]        평균절대편차(Mean Absolute Deviation; MAD) : 관측치와 평균 사이 거리의 평균\\[\\text{MAD} = \\frac{1}{N}\\sum_{i=1}^{N} \\vert X_{i}-\\mu \\vert\\]        분산(Variance; $\\sigma^2$) : 관측치와 평균 간 편차 자승의 평균\\[\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2\\]        표준편차(Standard Deviation; $\\sigma$) : 분산의 자승근\\[\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2}\\]          자료에서 사용된 단위와 동일한 단위로 측정되므로 해석에 용이함      변이 측도를 활용한 이상치 판별      경험 법칙(Empirical Rule) : 관측치 분포가 종 모양의 대칭 형태를 띠는 경우, 실증적으로 획득된 분포에 대한 일반적인 원칙이 성립함              $(\\mu - 1\\sigma, \\mu + 1\\sigma)$ 에는 관측치의 약 68%가 존재함      $(\\mu - 2\\sigma, \\mu + 2\\sigma)$ 에는 관측치의 약 95%가 존재함      $(\\mu - 3\\sigma, \\mu + 3\\sigma)$ 에는 관측치의 약 99%가 존재함            사분위수 범위를 활용한 이상치 판별              이상치 판단 기준으로서 상한선 및 하한선 설정                  상한선 : $Q_{3}+1.5\\cdot\\text{IQR}$          하한선 : $Q_{1}-1.5\\cdot\\text{IQR}$                            내부 범위 설정\\[\\text{Outlier} \\notin [Q_{1}-1.5\\cdot\\text{IQR}, Q_{3}+1.5\\cdot\\text{IQR}]\\]            변수 간 관계      공분산(Covariance) : 두 변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]          $\\sigma_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\sigma_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\sigma_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음            피어슨 상관계수(Pearson Correlation Coefficient; PCC) : 공분산의 단위 의존적(Unit-Dependent)인 문제를 완화한 지표로서, 공분산을 두 변수의 편차의 곱으로 나눈 값\\[\\rho_{XY} = \\frac{\\sigma_{XY}}{\\sigma_{X}\\sigma_{Y}}\\]          $-1\\le\\rho_{XY}\\le1$      $\\rho_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\rho_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\rho_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음      Summary with Graphs수치형 변수      Box Plot : 사분위수를 기준으로 데이터의 대략적인 분포를 나타낸 그래프            Histogram : 데이터 범위를 동일 간격 구간으로 나누어 해당 구간에 위치한 데이터 갯수를 나타낸 그래프                      Density Estimate : 커널밀도추정법을 통해 히스토그램을 연속된 곡선으로 나타낸 그래프                          Q-Q Normality Plot : 데이터 분포 형태가 정규 분포에 얼마나 근접한지 나타내는 그래프      수치형 변수 간 관계      히트 맵(Heatmap) : 두 변수 간 상관관계가 강할수록 채도를 짙게 나타낸 그래프            산점도(Scatter Plot)      범주형 변수      도수분포표(Frequency Table) : 각 범주에 해당하는 관측치 갯수를 요약한 표            Bar Plot : 도수분포표의 값을 막대 높이로 나타낸 그래프            Pie Chart : 도수분포표의 빈도 비율을 부채꼴 모양으로 나타낸 그래프      범주형 변수 간 관계      분할표(Cross Table) : 두 범주형 변수에 의해 생성되는 범주별 빈도수를 요약한 표            Mosaic Plot : 분할표에서 각 범주의 비율을 상자의 너비와 높이로 나타낸 그래프      Sourse  https://thirdspacelearning.com/gcse-maths/statistics/frequency-table/  https://www.jaspersoft.com/articles/what-is-a-bar-chart  https://proclusacademy.com/blog/customize_matplotlib_piechart/  https://www.questionpro.com/cross-tabulation.html"
  },
  
  {
    "title": "CDAE",
    "url": "/posts/cdae/",
    "categories": "6.RECOMMENDER SYSTEM, 3.ae based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, autoencoder",
    "date": "2024-06-19 00:00:00 +0900",
    





    
    "snippet": "CDAE  문제 의식: AutoRec 의 한계점          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측과 미관측이 특정한 선택 경로와 제약 조건 하에서 발생했다는 점을 간과하고 선호와 비선호로 이분하는 데서 오는 체계적 왜곡          클래스 불균형 문제...",
    "content": "CDAE  문제 의식: AutoRec 의 한계점          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측과 미관측이 특정한 선택 경로와 제약 조건 하에서 발생했다는 점을 간과하고 선호와 비선호로 이분하는 데서 오는 체계적 왜곡          클래스 불균형 문제(Class Imbalance): AutoRec 은 명시적 피드백 데이터 하에서 관측만을 사용하여 최적화를 수행하나, 암시적 피드백 데이터 하에서 이는 모든 상호작용을 $1$ 로 예측하는 문제를 야기함                    Personalization Problem: AutoRec 은 행렬 복원에 초점을 맞추어 최적화를 수행하므로 히스토리는 유사하나 잠재적 선호 구조(latent preference structure)는 다른 사용자들 간에 제공되는 추천의 개인화가 미흡할 수 있음        CDAE(Collaborative Denoising AutoEncoder): 잡음을 활용하여 암시적 피드백 데이터 하에서 손상된 선호도를 복원하고, 사용자 잠재 벡터를 활용하여 개인화 성능 향상을 꾀하는 오토인코더 기반 협업필터링 모형          Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M.  (2016, February).  Collaborative denoising auto-encoders for top-n recommender systems.  In Proceedings of the ninth ACM international conference on web search and data mining (pp. 153-162).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item implicit feedback matrix  $\\mathbf{X} \\in \\mathbb{R}^{M \\times N}$: masked $\\mathbf{Y}$  $\\mathbf{M} \\in \\mathbb{R}^{M \\times N}$: masking matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\mathbf{V} \\in \\mathbb{R}^{M \\times K}$: linear transformation matrix @ encoder  $\\mathbf{W} \\in \\mathbb{R}^{K \\times M}$: linear transformation matrix @ decoder  $\\overrightarrow{\\beta} \\in \\mathbb{R}^{K}$: bias vector @ encoder  $\\overrightarrow{\\mathbf{b}} \\in \\mathbb{R}^{M}$: bias vector @ decoder  $f(\\cdot)$: activation function @ encoder  $g(\\cdot)$: activation function @ decoderHow to Modeling      Generate Masking Noise\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\overrightarrow{\\mathbf{y}}_{u} \\odot \\overrightarrow{\\mathbf{m}}_{u}, \\quad \\overrightarrow{\\mathbf{m}}_{u} \\sim \\text{Bernouli}(1-p)^{N}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{m}}_{u} \\sim \\text{Bernouli}(1-p)^{N}\\): \\(m_{u,i} \\sim \\text{Bernouli}(1-p)\\) independently            Prediction\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{u}  &amp;= g\\left[\\mathbf{W} \\cdot f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{x}}_{u} + \\overrightarrow{\\mathbf{u}}_{u} + \\overrightarrow{\\beta}) + \\overrightarrow{\\mathbf{b}} \\right]  \\end{aligned}\\]                  Encoder(Dimensionality Reduction):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u}  &amp;= f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{x}}_{u} + \\overrightarrow{\\mathbf{u}}_{u} + \\overrightarrow{\\beta})  \\end{aligned}\\]                    Decoder(Reconstruction):\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{u}  &amp;= g(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{u} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                  Optimization\\[\\begin{aligned}  \\Theta  &amp;= \\text{arg} \\min{\\frac{1}{M}\\sum_{u=1}^{M}{\\mathbb{E}_{\\mathbf{X} \\sim P(\\cdot \\mid \\mathbf{Y})}[\\mathcal{L}(\\mathbf{y}_{u}, \\hat{\\mathbf{y}}_{u})] + \\frac{\\lambda}{2} \\Vert \\Theta \\Vert_{F}^{2}}}  \\end{aligned}\\]          \\(\\mathcal{L}(\\mathbf{y}_{u}, \\hat{\\mathbf{y}}_{u})\\): Reconstruction Loss      \\(\\mathbb{E}_{\\mathbf{X} \\sim P(\\cdot \\mid \\mathbf{Y})}\\): Average Loss because of Stochasticity of Noise      \\(\\Theta\\): Learning Parameters      \\(\\Vert \\cdot \\Vert_{F}^{2}\\): Regularization Term      "
  },
  
  {
    "title": "AutoRec",
    "url": "/posts/autorec/",
    "categories": "6.RECOMMENDER SYSTEM, 3.ae based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, autoencoder",
    "date": "2024-06-05 00:00:00 +0900",
    





    
    "snippet": "AutoRec  문제 의식          RBM-CF(Restricted Boltzmann Machines for Collaborative Filtering): 확률적 생성 모형으로서, 평점값마다 별도의 파라미터를 설정하므로 학습 파라미터 수가 급증하고, 확률 생성 과정을 근사 학습하므로 수렴 속도가 느림      LLORMA(Local Low-Ra...",
    "content": "AutoRec  문제 의식          RBM-CF(Restricted Boltzmann Machines for Collaborative Filtering): 확률적 생성 모형으로서, 평점값마다 별도의 파라미터를 설정하므로 학습 파라미터 수가 급증하고, 확률 생성 과정을 근사 학습하므로 수렴 속도가 느림      LLORMA(Local Low-Rank Matrix Approximation): 행렬분해 기반 잠재요인 모형으로서, 사용자 취향이 전역적으로 일관되지 않을 수 있다는 전제 하에 사용자-아이템 상호작용 행렬을 다수의 하위 행렬로 재구성하고, 각각을 지역적 저차원(Local Low Rank)으로 근사하나, 구조가 복잡함        AutoRec: 오토인코더 기반 협업필터링 모형으로서, 연속적 출력값을 결정론적 함수로 도출하는 단일 신경망 구조를 통해 선행 협업필터링 모형에 비해 계산 효율성과 구조적 간결성을 도모함          Sedhain, S., Menon, A. K., Sanner, S., &amp; Xie, L.  (2015, May).  Autorec: Autoencoders meet collaborative filtering.  In Proceedings of the 24th international conference on World Wide Web (pp. 111-112).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$: user-item explicit feedback matrix  $\\mathbf{V} \\in \\mathbb{R}^{M \\times K}$: linear transformation matrix @ encoder  $\\mathbf{W} \\in \\mathbb{R}^{K \\times M}$: linear transformation matrix @ decoder  $\\overrightarrow{\\beta} \\in \\mathbb{R}^{K}$: bias vector @ encoder  $\\overrightarrow{\\mathbf{b}} \\in \\mathbb{R}^{M}$: bias vector @ decoder  $f(\\cdot)$: activation function @ encoder  $g(\\cdot)$: activation function @ decoderHow to Modeling      Prediction\\[\\begin{aligned}  \\hat{\\mathbf{r}}_{i}  &amp;= g\\left[\\mathbf{W} \\cdot f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{r}}_{i} + \\overrightarrow{\\beta}) + \\overrightarrow{\\mathbf{b}} \\right]  \\end{aligned}\\]                  Encoder(Dimensionality Reduction):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{i}  &amp;= f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{r}}_{i} + \\overrightarrow{\\beta})  \\end{aligned}\\]                    Decoder(Reconstruction):\\[\\begin{aligned}  \\hat{\\mathbf{r}}_{i}  &amp;= g(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                  Optimization\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\min{\\sum_{i=1}^{N}{\\Vert \\overrightarrow{\\mathbf{r}}_{i} - h(\\overrightarrow{\\mathbf{r}}_{i} ; \\Theta) \\Vert_{\\mathcal{O}}^{2}} + \\frac{\\lambda}{2}\\Vert \\Theta \\Vert_{F}^{2}}  \\end{aligned}\\]          \\(h(\\overrightarrow{\\mathbf{r}}_{i} ; \\Theta)\\): Reconstruction Output      \\(\\Theta\\): Learning Parameters      \\(\\Vert \\cdot \\Vert_{\\mathcal{O}}^{2}\\): L2 Loss Computed only for Observed Entries      \\(\\Vert \\cdot \\Vert_{F}^{2}\\): Regularization Term      "
  },
  
  {
    "title": "User Free Models",
    "url": "/posts/user_free_models/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, matrix factorization, attention mechanism",
    "date": "2024-05-22 00:00:00 +0900",
    





    
    "snippet": "SLIM  문제 의식: 효율성과 정확성의 Trade-off          이웃 기반 협업 필터링(Neighborhood-based Collaborative Filtering): 유사도 기반 휴리스틱 함수를 통해 예측하므로 계산 효율성은 높지만 아이템 간 관계 학습이 불가하여 추천 정확도가 낮음      잠재요인 모형(Latent Factor Mode...",
    "content": "SLIM  문제 의식: 효율성과 정확성의 Trade-off          이웃 기반 협업 필터링(Neighborhood-based Collaborative Filtering): 유사도 기반 휴리스틱 함수를 통해 예측하므로 계산 효율성은 높지만 아이템 간 관계 학습이 불가하여 추천 정확도가 낮음      잠재요인 모형(Latent Factor Model): 사용자, 아이템 간 관계 학습을 수반하므로 추천 정확도는 높지만 계산 비용이 발생하여 실시간 추천에 부적합        SLIM(Sparse LInear Methods): 아이템 간 유사도를 선형 회귀계수 행렬로 학습하고 이를 기반으로 예측을 수행하는 선형 회귀 모형          Ning, X., &amp; Karypis, G.  (2011, December).  Slim: Sparse linear methods for top-n recommender systems.  In 2011 IEEE 11th international conference on data mining (pp. 497-506).  IEEE.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\mathbf{W} \\in \\mathbb{R}^{N \\times N}$: sparse aggregation coefficient matrix  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      Linear Regression:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\mathbf{W}_{i} \\cdot \\mathbf{Y}_{u*}\\\\  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{w_{i,j} \\cdot y_{u,j}}  \\end{aligned}\\]        Objective Function:\\[\\begin{gathered}  \\hat{\\mathbf{W}}  = \\text{arg} \\min{\\frac{1}{2} \\Vert \\mathbf{Y} - \\mathbf{Y}\\mathbf{W}\\Vert_{F}^{2} + \\frac{\\beta}{2} \\Vert \\mathbf{W} \\Vert_{F}^{2} + \\lambda \\Vert \\mathbf{W} \\Vert_{1}}\\\\  \\text{subject to} \\quad  \\begin{aligned}  \\mathbf{W} &amp;\\ge 0\\\\  \\text{diag}(\\mathbf{W})&amp;=0  \\end{aligned}  \\end{gathered}\\]          \\(\\Vert \\mathbf{Y} - \\mathbf{Y}\\mathbf{W}\\Vert_{F}^{2}\\): Reconstruction Loss      \\(\\Vert \\mathbf{W} \\Vert_{F}^{2}\\): L2 Norm Regulation to Prevent Overfitting      \\(\\Vert \\mathbf{W} \\Vert_{1}\\): L1 Norm Regulation to Induce Sparsity      FISM  문제 의식: SLIM 의 사용자 선호 구성 방식          SLIM 은 아이템 간 유사도를 휴리스틱 함수가 아니라 학습을 통해 도출한다는 점에서 아이템 기반 협업 필터링의 정확도 문제를 개선함      하지만 사용자의 타깃 아이템에 대한 선호 구성 시 히스토리를 구성하는 아이템들이 서로 독립적으로 기여한다고 가정함      이 독립성 가정은 사용자 선호가 과거 경험의 단순 집계로 환원될 수 있다는 잘못된 전제에 기반함      즉, 사용자 선호가 히스토리 아이템들의 집합적 구성과 그 내부의 상호작용 구조에 의해 형성된다는 점을 간과함        FISM(Factored Item Similarity Models): 사용자 선호를 히스토리 아이템들의 집합적 평균으로 구성하는 아이템 기반 협업 필터링 모형          Kabbur, S., Ning, X., &amp; Karypis, G.  (2013, August).  Fism: factored item similarity models for top-n recommender systems.  In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 659-667).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: target item idx  $j=1,2,\\cdots,N$: history item idx  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vectorHow to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(j)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        History Item Aggregation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\frac{1}{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert^{\\beta}}\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\overrightarrow{\\mathbf{q}}_{j}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$            Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{p}}_{i}  \\end{aligned}\\]  NAIS  문제 의식: FISM 의 히스토리 아이템 집계 방식          FISM 은 사용자 선호 표현 시 히스토리 아이템 간 기여도 차이를 간과하여 히스토리 아이템들을 단순 평균함        NAIS(Neural Attentive Item Similarity Model): 사용자 선호를 히스토리 아이템으로써 구성하되, 개별 아이템의 기여도에 따라 가중 평균하는 아이템 기반 협업 필터링 모형          He, X., He, Z., Song, J., Liu, Z., Jiang, Y. G., &amp; Chua, T. S.  (2018).  NAIS: Neural attentive item similarity model for recommendation.  IEEE Transactions on Knowledge and Data Engineering, 30(12), 2354-2366.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: target item idx  $j=1,2,\\cdots,N$: history item idx  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vectorHow to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(i)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(j)  \\end{aligned}\\]        History Item Aggregation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{ATTN}(\\overrightarrow{\\mathbf{p}}_{i}, \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:], \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{p}}_{i}  \\end{aligned}\\]  How to Attention      Attention Weight is Calculated by Smoothed Softmax:\\[\\begin{aligned}  \\alpha_{i,j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})}}{\\left[\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})}}\\right]^{\\beta}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$            Attention Score Function:                  Concatenation:\\[\\begin{aligned}  f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})  &amp;= \\overrightarrow{\\mathbf{w}} \\cdot \\text{ReLU}(\\mathbf{W}[\\overrightarrow{\\mathbf{p}}_{i} \\oplus \\overrightarrow{\\mathbf{q}}_{j}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                    Element-wise Product:\\[\\begin{aligned}  f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})  &amp;= \\overrightarrow{\\mathbf{w}} \\cdot \\text{ReLU}(\\mathbf{W}[\\overrightarrow{\\mathbf{p}}_{i} \\odot \\overrightarrow{\\mathbf{q}}_{j}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]            "
  },
  
  {
    "title": "Latent Factor Model with Attention Mechanism",
    "url": "/posts/lfm_attn/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, mlp, attention mechanism",
    "date": "2024-05-08 00:00:00 +0900",
    





    
    "snippet": "DACR: History Embedding with ATTN  문제 의식: Implicit Feedback Problem          DeepCF                  표현 학습(Representation Learning): 사용자와 아이템 간 선형 관계를 바탕으로 저차원 잠재요인 공간을 효율적으로 구성          매칭 함수 학습(M...",
    "content": "DACR: History Embedding with ATTN  문제 의식: Implicit Feedback Problem          DeepCF                  표현 학습(Representation Learning): 사용자와 아이템 간 선형 관계를 바탕으로 저차원 잠재요인 공간을 효율적으로 구성          매칭 함수 학습(Matching Function Learning): 다양한 매칭 함수를 근사하여 사용자와 아이템 간 비선형 상호작용 포착                    Implicit Feedback Problem                  관측치의 불완전성(Observation Incompleteness): 관측과 미관측이 반드시 선호와 비선호를 의미하지 않음          선호의 비가시성(Hidden Signal): 관측치의 불완전성으로 인하여 선호의 정도나 의도를 포착하기 어려움          즉, 암시적 피드백 데이터는 행동 매칭 데이터이기에 선호 매칭에 사용하기 위해서는 내재된 선호 정보를 부각하고 잡음을 여과하는 절차가 필요함                      DACR(Deep Collaborative Recommendation Algorithm Based on Attention Mechanism): 사용자, 아이템 표현 및 그 결합 표현에 어텐션 메커니즘(Attention Mechanism)을 적용하여 차원별 가중치를 명시적으로 설계함으로써 입력 중 집중할(Focus) 정보를 선별하여 강조하는 앙상블 모형          Cui, C., Qin, J., &amp; Ren, Q.  (2022).  Deep collaborative recommendation algorithm based on attention mechanism.  Applied Sciences, 12(20), 10594.        Components          ARL: Attention Representation Learning      AML: Attnetion Matching Function Learning      DACR: ARL &amp; AML Emsemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$  $\\delta$: softmax function  $\\sigma$: sigmoid functionHow to Modeling      DACR is ARL &amp; AML Emsemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ARL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AML)}}])  \\end{aligned}\\]  ARL      Linear Transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]          $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{D}$      $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{D}$            Attention Weight:\\[\\begin{aligned}  \\alpha_{u}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{p}}_{u} + \\overrightarrow{\\mathbf{b}})\\\\  \\alpha_{i}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{q}}_{i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        Representation Learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{p}}_{u} \\oplus [\\alpha_{u} \\odot \\overrightarrow{\\mathbf{p}}_{u}]\\right)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{q}}_{i} \\oplus [\\alpha_{i} \\odot \\overrightarrow{\\mathbf{q}}_{i}]\\right)  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        if use ARL as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  AML      History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Vector Concatenation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i}  \\end{aligned}\\]        Attention Weight:\\[\\begin{aligned}  \\alpha_{u,i}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{x}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        Matching Function Learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{x}}_{u,i} \\oplus [\\alpha_{u,i} \\odot \\overrightarrow{\\mathbf{x}}_{u,i}]\\right)  \\end{aligned}\\]        if use AML as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  DRNet: Aggregate User’s Histories  문제 의식          기존 협업 필터링이 모델링하는 관계 유형                  잠재요인 모형(Latent Factor Model): 사용자-아이템 관계 모델링, 개인화 추천 성능 우수 (ex. NCF)          아이템 기반 협업 필터링(User Free Model): 아이템-아이템 관계 모델링, 데이터 희소성 강건 (ex. SLIM, FISM)                    어텐션 기반 히스토리 아이템 집계 방식 (ex. NAIS)                  사용자가 과거에 더 선호한 아이템일수록 새로운 아이템 선택에 더 큰 영향력을 행사함          사용자의 선호 정도에 기반하여 집중도를 차등 부여하여 집계할 필요가 있음                      DRNet(Dual Relation Net-work) : 사용자-아이템 매칭 함수와 아이템-아이템 매칭 함수를 병렬 학습하는 모형          Ji, D., Xiang, Z., &amp; Li, Y.  (2020).  Dual relations network for collaborative filtering.  IEEE Access, 8, 109747-109757.        Components          Affection Network: Modeling User-Item Relation      Association Network: Modeling Item-Item Relation      Dual-Relation Network: Affection Network &amp; Association Network Combination      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user id embedding vector @ affection network  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item id embedding vector @ affection network  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector @ association network  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vector @ association network  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      Dual-Relation Network:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma\\left(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AFFECT)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ASSO)}}]\\right)  \\end{aligned}\\]  Affection Network      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]  Association Network      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(i)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(j)  \\end{aligned}\\]        Global Item Vector of User $u$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\text{ATTN}(\\overrightarrow{\\mathbf{h}},\\text{Affection}(u,\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}), \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u} \\odot \\overrightarrow{\\mathbf{p}}_{i})  \\end{aligned}\\]  How to Attention      Query Vector is Global Context Vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}  \\end{aligned}\\]        Key Vector is Generated by Affection Network:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AFFECT)}}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        Global Item Vector of User $u$ is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\alpha_{u,j} \\cdot \\overrightarrow{\\mathbf{q}}_{j}}  \\end{aligned}\\]        Attention Weight is Calculated by Smoothed Softmax:\\[\\begin{aligned}  \\alpha_{u,j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}},\\overrightarrow{\\mathbf{z}}_{u,j}^{\\text{(AFFECT)}})}}{\\left[\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}},\\overrightarrow{\\mathbf{z}}_{u,j}^{\\text{(AFFECT)}})}}\\right]^{\\beta}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$: Smoothing Factor            Attention Score Function is Dot Product:\\[\\begin{aligned}  f(q,k)  &amp;= q \\cdot k  \\end{aligned}\\]  DELF: Aggregate User &amp; Item’s Histories  문제 의식: 아이디 임베딩(ID Embedding)과 히스토리 임베딩(History Embedding)의 상호 보완적 관계          아이디 임베딩은 고유 정보를 보존한 표현을 생성하는 데 강점      히스토리 임베딩은 맥락 정보를 반영한 표현을 생성하는 데 강점        DELF(Dual Embedding based Deep Latent Factor Model): 사용자와 아이템의 아이디 임베딩과 히스토리 임베딩을 조합하여 다양한 매칭 함수를 병렬 학습하는 모형          Cheng, W., Shen, Y., Zhu, Y., &amp; Huang, L.  (2018, July).  DELF: A dual-embedding based deep latent factor model for recommendation.  In IJCAI (Vol. 18, pp. 3329-3335).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user ID embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item ID embedding vector  $\\overrightarrow{\\mathbf{m}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{n}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\text{ATTN}(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}}, \\mathbf{H}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:], \\mathbf{Y}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\text{ATTN}(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}}, \\mathbf{H}[\\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\},:], \\mathbf{X}[\\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\},:])  \\end{aligned}\\]        Pairwise Neural Interaction Layers:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}^{(1)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(2)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{m}}_{u} \\oplus \\overrightarrow{\\mathbf{n}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(3)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{n}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(4)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{m}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{(1)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(2)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(3)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(4)}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  How to Attention      Another ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{v}  &amp;=\\text{Emb}(v)\\\\  \\overrightarrow{\\mathbf{y}}_{j}  &amp;=\\text{Emb}(j)  \\end{aligned}\\]        Query Vector is Global Context Vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}^{\\text{(user)}},  \\quad  \\overrightarrow{\\mathbf{h}}^{\\text{(item)}}  \\end{aligned}\\]        Key Vector is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}_{v}  &amp;= \\text{tanh}(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{x}}_{v} + \\overrightarrow{\\mathbf{b}})\\\\  \\overrightarrow{\\mathbf{h}}_{j}  &amp;= \\text{tanh}(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{y}}_{j} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        History Embedding Vector is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\alpha_{j} \\cdot \\overrightarrow{\\mathbf{y}}_{j}}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;= \\sum_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}{\\alpha_{v} \\cdot \\overrightarrow{\\mathbf{x}}_{v}}\\\\  \\end{aligned}\\]        Attention Weight is Calculated by Softmax:\\[\\begin{aligned}  \\alpha_{j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}},\\overrightarrow{\\mathbf{h}}_{j})}}{\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}},\\overrightarrow{\\mathbf{h}}_{j})}}}\\\\  \\alpha_{v}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}},\\overrightarrow{\\mathbf{h}}_{v})}}{\\sum_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}},\\overrightarrow{\\mathbf{h}}_{v})}}}  \\end{aligned}\\]        Attention Score Function is Dot Product:\\[\\begin{aligned}  f(q,k)  &amp;= q \\cdot k  \\end{aligned}\\]  "
  },
  
  {
    "title": "Latent Factor Model with CNN",
    "url": "/posts/lfm_cnn/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, cnn",
    "date": "2024-04-24 00:00:00 +0900",
    





    
    "snippet": "ConvNCF: Using CNN as Matching Function  문제 의식: NeuMF 의 다차원 고차 상호작용 포착 한계점          GMF 는 동일 차원 상호작용만 포착하므로 다차원 고차 상호작용 반영 불가      NCF 는 다양한 매칭 함수 근사 가능하나 고차원 입력 시 파라미터 수 폭증        ConvNCF: 외적과 합성곱...",
    "content": "ConvNCF: Using CNN as Matching Function  문제 의식: NeuMF 의 다차원 고차 상호작용 포착 한계점          GMF 는 동일 차원 상호작용만 포착하므로 다차원 고차 상호작용 반영 불가      NCF 는 다양한 매칭 함수 근사 가능하나 고차원 입력 시 파라미터 수 폭증        ConvNCF: 외적과 합성곱 신경망을 활용하여 다차원 간 고차 상호작용을 포착하는 단일 모형          He, X., Du, X., Wang, X., Tian, F., Tang, J., &amp; Chua, T. S.  (2018).  Outer product-based neural collaborative filtering.  arXiv preprint arXiv:1808.03912.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\mathbf{E}_{u,i} \\in \\mathbb{R}^{K \\times K}$: interaction map of user $u$ and item $i$  $\\overrightarrow{\\mathbf{x}}_{u,i}$: interdimensional high-level interaction vector of user $u$ and item $i$  $\\overrightarrow{\\mathbf{z}}_{u,i} \\in \\mathbb{R}^{K}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u) \\in \\mathbb{R}^{K}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i) \\in \\mathbb{R}^{K}  \\end{aligned}\\]        Outer product of user $u$ and item $i$:\\[\\begin{aligned}  \\mathbf{E}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\otimes \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        Capture interdimensional high-level interaction of user $u$ and item $i$:    \\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u,i}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{u,i})\\right]  \\end{aligned}\\]          \\(\\mathcal{W} \\in \\mathbb{R}^{2 \\times 2}\\): Kernel Window Dimension      The number of Filters per Kernel Size is 32      Dimension of Feature Map is reduced $K \\times K, K/2 \\times K/2, \\cdots, 1 \\times 1$            Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u,i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  COMET: Using CNN as Aggregating Histories  문제 의식: 히스토리의 다차원 고차 상호작용 구조 모델링 부재          아이디 임베딩(ID Embedding): 맥락 정보 없이 목표 사용자-아이템 쌍 상호작용만을 반영함      히스토리 임베딩(History Embedding): 맥락 정보를 반영하나 맥락 내 구조적 관계 정보를 모델링하지 않음      실제 추천은 사용자의 히스토리 아이템 간 상호작용과, 아이템에 반응한 사용자 간 집합의 구조적 맥락에서 발생함        COMET(COnvolutional diMEnsion inTeraction): 히스토리 간 다차원 고차 상호작용 구조를 반영한 듀얼 임베딩(Dual-Embedding) 기반 잠재요인 모형          Lin, Z., Feng, L., Guo, X., Zhang, Y., Yin, R., Kwoh, C. K., &amp; Xu, C.  (2023).  Comet: Convolutional dimension interaction for collaborative filtering.  ACM Transactions on Intelligent Systems and Technology, 14(4), 1-18.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user id embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item id embedding vector  \\(\\mathbf{E}_{u} \\in \\mathbb{R}^{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert \\times K}\\): history embedding map of user $u$  \\(\\mathbf{E}_{i} \\in \\mathbb{R}^{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert \\times K}\\): history embedding map of item $i$  $\\overrightarrow{\\mathbf{x}}_{u}$: history interaction vector of user $u$  $\\overrightarrow{\\mathbf{x}}_{i}$: history interaction vector of item $i$  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Interaction Modeling:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\cdots (\\left\\{\\overrightarrow{\\mathbf{q}}_{j} \\mid \\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}\\right\\})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\cdots (\\left\\{\\overrightarrow{\\mathbf{p}}_{v} \\mid \\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}\\right\\})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\left[(\\overrightarrow{\\mathbf{p}}_{u} + \\overrightarrow{\\mathbf{u}}_{u}) \\odot (\\overrightarrow{\\mathbf{q}}_{i} + \\overrightarrow{\\mathbf{v}}_{i})\\right])  \\end{aligned}\\]  Interaction Modeling      History Embedding Maps:\\[\\begin{aligned}  \\mathbf{E}_{u}  = \\begin{bmatrix}  \\overrightarrow{\\mathbf{q}}_{1 \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}\\\\  \\overrightarrow{\\mathbf{q}}_{2 \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}\\\\  \\vdots\\\\  \\overrightarrow{\\mathbf{q}}_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}  \\end{bmatrix},\\quad  \\mathbf{E}_{i}  = \\begin{bmatrix}  \\overrightarrow{\\mathbf{p}}_{1 \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}\\\\  \\overrightarrow{\\mathbf{p}}_{2 \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}\\\\  \\vdots\\\\  \\overrightarrow{\\mathbf{p}}_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}  \\end{bmatrix}  \\end{aligned}\\]        CNN:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{u})\\right]\\\\  \\overrightarrow{\\mathbf{x}}_{i}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{i})\\right]  \\end{aligned}\\]          \\(\\mathcal{W} \\in \\mathbb{R}^{\\vert \\mathcal{R}^{+} \\setminus \\{u,i\\} \\vert \\times H}\\): Kernel Window Dimension                  \\(H \\in \\{1,8,32,128\\}\\): Kernel Window Size          The number of Filters per Kernel Size is 8          Max Pooling Applied                          Generate History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Distance Embedding based Latent Factor Model",
    "url": "/posts/dist_embedding/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, mlp",
    "date": "2024-04-10 00:00:00 +0900",
    





    
    "snippet": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수...",
    "content": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수 학습(Matching Function Learning)          사용자-아이템 쌍을 입력으로 하여 매칭 함수를 직접 학습하는 방법      복잡하고 비선형적인 매칭 함수를 근사할 수 있음      DDFL      문제 의식: 내적(Dot Product) 혹은 코사인 유사도(Cosine Similarity)를 매칭 함수로 사용하여 학습된 사용자, 아이템 표현은 삼각 부등식(Triangular Inequality)을 만족하기 어려움    삼각 부등식(Triangular Inequality)                  세 점 사이의 거리에 대한 제한 조건으로서, $A$ 와 $C$ 사이 거리는 $A$ 에서 $B$, 그리고 $B$ 에서 $C$ 로 우회하는 거리보다 크거나 같아야 함\\[\\begin{aligned}  \\text{d}\\left[A,C\\right] \\le \\text{d}\\left[A,B\\right] + \\text{d}\\left[B,C\\right]  \\end{aligned}\\]                    사용자 $u$ 가 아이템 $i$ 를 직접적으로 선호하는 정도는, 사용자 $u$ 가 아이템 $j$ 를 선호하는 정도 및 아이템 $i$ 와 $j$ 간 유사한 정도의 합보다 작거나 같아야 함\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}  \\le \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}  + \\overrightarrow{\\mathbf{q}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}  \\end{aligned}\\]              DDFL(Deep Dual Function Learning-based Model) : 거리 함수 학습 모듈과 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          Shah, S. T. U., Li, J., Guo, Z., Li, G., &amp; Zhou, Q.  (2020, September).  DDFL: a deep dual function learning-based model for recommender systems.  In International Conference on Database Systems for Advanced Applications (pp. 590-606).  Cham: Springer International Publishing.        Components          MeFL: Metric Function Learning      MaFL: Matching Function Learning      DDFL: MeFL &amp; MaFL Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector @ MeFL  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector @ MeFL  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector @ MaFL  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector @ MaFL  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      DDFL is MeFL &amp; MaFL Ensemble:                  predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(MeFL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(MaFL)}})  \\end{aligned}\\]                    final matching score of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]            MeFL      Conversion Transformation:\\[\\begin{aligned}  x_{u,i}  &amp;=\\alpha\\left(1-y_{u,i}\\right)  \\end{aligned}\\]          $y_{u,i} \\in \\mathbf{Y}$ is Implicit Feedback      $\\alpha$ is Distance Factor            History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{X}_{u*}\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{X}_{*i}  \\end{aligned}\\]        Calculate Euclidean Distance:\\[\\begin{aligned}  \\text{dist}[\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{q}}_{i}]  &amp;= \\Vert \\overrightarrow{\\mathbf{p}}_{u} - \\overrightarrow{\\mathbf{q}}_{i} \\Vert_{2}\\\\  &amp;= \\sqrt{\\sum_{k=1}^{K}{(p_{k}^{(u)} - q_{k}^{(i)})^{2}}}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\text{dist}[\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{q}}_{i}])  \\end{aligned}\\]        if use MeFL as a single prediction module:                  compute distance:\\[\\begin{aligned}  \\hat{d}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]                    convert distance to matching score:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= 1 - \\frac{\\hat{d}_{u,i}}{\\alpha}  \\end{aligned}\\]            MaFL      History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        if use MaFL as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Dual Embedding based Latent Factor Model",
    "url": "/posts/dual_embedding/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, mlp",
    "date": "2024-03-27 00:00:00 +0900",
    





    
    "snippet": "Embedding Type  아이디 임베딩(ID Embedding)          Embedding user and item identifiers into a low-dimensional vector space      사용자의 고유한 선호 정보나 아이템의 고유한 특징 정보를 반영한 표현을 도출함      사용자와 아이템의 맥락 정보가 부족하여 행동...",
    "content": "Embedding Type  아이디 임베딩(ID Embedding)          Embedding user and item identifiers into a low-dimensional vector space      사용자의 고유한 선호 정보나 아이템의 고유한 특징 정보를 반영한 표현을 도출함      사용자와 아이템의 맥락 정보가 부족하여 행동 패턴이나 구매 패턴을 반영하기 어려움        히스토리 임베딩(History Embedding)          Generate each user and item expressions based on past interaction history      사용자의 행동 패턴이나 아이템의 구매 패턴을 반영한 표현을 도출함      사용자와 아이템을 상호간에 의존하여 표현하므로 고유 정보를 보존하기 어려움      DNCF  문제 의식: 아이디 임베딩(ID Embedding)과 히스토리 임베딩(History Embedding)의 분리로 인한 표현력의 제약          DELF 는 아이디 임베딩과 히스토리 임베딩을 분리하여 매칭 함수 학습을 수행함      각 표현이 서로의 표현력을 보완하거나 강화하지 못함        DNMF(Deep Neural Matrix Factorization): 아이디 임베딩과 히스토리 임베딩을 결합한 하나의 표현을 생성하여 NeuMF 의 표현력을 강화하는 앙상블 모형          He, G., Zhao, D., &amp; Ding, L.  (2021).  Dual-embedding based neural collaborative filtering for recommender systems.  arXiv preprint arXiv:2102.02549.        Components          DGMF: Dual-Embedding based Generalized Matrix Factorization      DMLP: Dual-Embedding based Multi-Layer Perceptron      DNMF: DGMF &amp; DMLP Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user ID embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item ID embedding vector  $\\overrightarrow{\\mathbf{m}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{n}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\overrightarrow{\\mathbf{u}}_{u}$: user embedding combination vector  $\\overrightarrow{\\mathbf{v}}_{i}$: item embedding combination vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      DNMF is DGMF &amp; DMLP Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(DGMF)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(DMLP)}}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  DGMF      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Embedding Combination:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Agg}(\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{m}}_{u})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Agg}(\\overrightarrow{\\mathbf{q}}_{i}, \\overrightarrow{\\mathbf{n}}_{i})  \\end{aligned}\\]          element-wise sum      element-wise mean      concatenation      attention            Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        If use DGMF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  DMLP      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Embedding Combination:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{m}}_{u}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\overrightarrow{\\mathbf{q}}_{i} \\oplus \\overrightarrow{\\mathbf{n}}_{i}  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        If use DMLP as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  "
  },
  
  {
    "title": "History Embedding based Latent Factor Model",
    "url": "/posts/hist_embedding/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, mlp",
    "date": "2024-03-13 00:00:00 +0900",
    





    
    "snippet": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수...",
    "content": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수 학습(Matching Function Learning)          사용자-아이템 쌍을 입력으로 하여 매칭 함수를 직접 학습하는 방법      복잡하고 비선형적인 매칭 함수를 근사할 수 있음      DMF  문제 의식: 아이디 임베딩(ID Embedding) 입력 표현의 한계점          아이디 임베딩 방식은 초기 표현(식별자)의 정보량이 부족하여 학습이 느리거나 성능이 제한됨        DMF(Deep Matrix Factorization): 사용자-아이템 상호작용 행렬과 그 전치 행렬을 초기 표현으로 사용하여 저차원 표현 학습을 수행하는 모형          Xue, H. J., Dai, X., Zhang, J., Huang, S., &amp; Chen, J.  (2017, August).  Deep matrix factorization models for recommender systems.  In IJCAI (Vol. 17, pp. 3203-3209).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\cos(\\overrightarrow{\\mathbf{u}}_{u}, \\overrightarrow{\\mathbf{v}}_{i})\\\\  &amp;= \\frac{\\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{v}}_{i}}{\\Vert \\overrightarrow{\\mathbf{u}}_{u} \\Vert \\cdot \\Vert \\overrightarrow{\\mathbf{v}}_{i} \\Vert}  \\end{aligned}\\]  DeepCF  문제 의식: 표현 학습 방식과 매칭 함수 학습 방식의 상호 보완적 관계          표현 학습은 저차원 유사도 구조를 포착하여 사용자, 아이템의 일반화된 표현을 도출하는 데 강점      매칭 함수 학습은 사용자와 아이템 간 복잡하고 비선형적인 상호작용 과정을 근사하는 데 강점        DeepCF: 표현 학습 모듈과 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          Deng, Z. H., Huang, L., Wang, C. D., Lai, J. H., &amp; Yu, P. S.  (2019, July).  Deepcf: A unified framework of representation learning and matching function learning in recommender system.  In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 61-68).        Components          CFNet-rl: Representation Learning      CFNet-ml: Matching Function Learning      CFNet: CFNet-rl &amp; CFNet-ml Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      CFNet is CFNet-rl &amp; CFNet-ml Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(RL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ML)}}])  \\end{aligned}\\]  CFNet-rl      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        if use CFNet-rl as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  CFNet-ml      generate user latent factor vector through linear transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}  \\end{aligned}\\]        generate user latent factor vector through linear transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        if use CFNet-ml as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  J-NCF  문제 의식          아이디 임베딩(ID Embedding): 사용자와 아이템 표현을 무작위로 초기화한 후 매칭 함수 학습을 수행하므로 표현 학습이 미흡함 (ex. NCF)      히스토리 임베딩(History Embedding): 사용자-아이템 상호작용 행렬과 그 전치 행렬을 활용하여 표현 학습을 수행하나 매칭 함수는 선형 유사도 함수에 의존함 (ex. DMF)      앙상블(Ensemble): 표현 학습과 매칭 함수 학습을 분리하여 수행하므로 각 모듈이 서로의 학습을 보완하거나 강화하지 못함 (ex. CFNet)        J-NCF(Joint Neural Collaborative Filtering): 표현 학습과 매칭 함수 학습을 통합 훈련(Joint Training)하는 모형          Chen, W., Cai, F., Chen, H., &amp; Rijke, M. D.  (2019).  Joint neural collaborative filtering for recommender systems.  ACM Transactions on Information Systems (TOIS), 37(4), 1-30.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        matching function learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "ID Embedding based Latent Factor Model",
    "url": "/posts/id_embedding/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, ncf, neural networks, mlp",
    "date": "2024-02-29 00:00:00 +0900",
    





    
    "snippet": "How to aggregate  요소별 곱(Element-wise Product): 두 벡터 간 상응하는 차원끼리 곱셈하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 독립성 가정      사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 반영 표현      동일 차원 상호작용만 포...",
    "content": "How to aggregate  요소별 곱(Element-wise Product): 두 벡터 간 상응하는 차원끼리 곱셈하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 독립성 가정      사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 반영 표현      동일 차원 상호작용만 포착하므로 다차원 상호작용 반영 불가        벡터 결합(Vector Concatenation): 두 벡터를 결합하는 방법          사용자, 아이템 잠재요인 공간 독립 가정      사용자, 아이템 벡터 정보 보존 표현      모형이 사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 직접 학습        외적(Outer Product): 두 벡터 간 외적하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 종속성 가정      그 대각성분은 요소별 곱셈에서 포착하는 동일 차원 간 상호작용 신호에 해당함      NeuMF  문제 의식: 내적(Inner Product) 기반 잠재요인 모형의 한계점          내적은 사용자와 아이템 간 동일 차원 상호작용을 포착하고 이를 단순 합산하는 방법임      사용자와 아이템 간 상호작용은 개별 차원에서 출력하는 신호 간에 경중이 있을 수 있음      사용자와 아이템 간 상호작용은 비선형적일 수 있고, 다차원 간에도 성립할 수 있음        NeuMF: 선형 매칭 함수 학습 모듈과 비선형 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S.  (2017, April).  Neural collaborative filtering.  In Proceedings of the 26th international conference on world wide web (pp. 173-182).        Components          GMF(Generalized Matrix Factorization) : 요소별 곱 기반 선형 매칭 함수 모듈      NCF(Neural Collaborative Filtering) : 벡터 결합 및 다층 신경망(MLP) 기반 비선형 매칭 함수 학습 모듈      NeuMF(Neural Matrix Factorization) : GMF 와 NCF 의 예측 벡터(Predictive Vector)를 종합하여 예측을 수행하는 앙상블 모형      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{u}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\mathbf{v}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\mathbf{z}_{u,i} \\in \\mathbb{R}^{K}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      NeuMF is GMF &amp; NCF Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\mathbf{w} \\cdot [\\mathbf{z}_{u,i}^{\\text{(GMF)}} \\oplus \\mathbf{z}_{u,i}^{\\text{(NCF)}}])  \\end{aligned}\\]  GMF      ID Embedding:\\[\\begin{aligned}  \\mathbf{u}_{u}  &amp;= \\text{Emb}(u)\\\\  \\mathbf{v}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\mathbf{z}_{u,i}  &amp;= \\mathbf{u}_{u} \\odot \\mathbf{v}_{i}  \\end{aligned}\\]        If use GMF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\mathbf{w} \\cdot \\mathbf{z}_{u,i})  \\end{aligned}\\]  NCF      ID Embedding:\\[\\begin{aligned}  \\mathbf{u}_{u}  &amp;= \\text{Emb}(u)\\\\  \\mathbf{v}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\mathbf{z}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{u}_{u} \\oplus \\mathbf{v}_{i})  \\end{aligned}\\]        If use NCF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\mathbf{w} \\cdot \\mathbf{z}_{u,i})  \\end{aligned}\\]  Source  https://iq.opengenus.org/neural-collaborative-filtering/"
  },
  
  {
    "title": "Deep Learning based Collaborative Filtering",
    "url": "/posts/dl_based_cf/",
    "categories": "6.RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "ai application, recommender system, collaborative filtering, ncf, autoencoder",
    "date": "2024-02-15 00:00:00 +0900",
    





    
    "snippet": "MLP  Merit          User, Item Representation Learning      Matching function learning      Modeling nonlinear interactions between users and items      ID Embedding      ID Embedding: Embedding us...",
    "content": "MLP  Merit          User, Item Representation Learning      Matching function learning      Modeling nonlinear interactions between users and items      ID Embedding      ID Embedding: Embedding user and item identifiers into a low-dimensional vector space            NCF: ID Embedding based Latent Factor Model(Linear and Non-Linear Matching Function Ensemble)          He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S.  (2017, April).  Neural collaborative filtering.  In Proceedings of the 26th international conference on world wide web (pp. 173-182).      History Embedding      History Embedding: Generate each user and item expressions based on past interaction history              by aggregating the raw representations of one entity with which the another entity interacted      by reducing the dimensionality of the user-item interaction matrix and its transpose        DMF: History Embedding based Latent Factor Model(Representation Learning)          Xue, H. J., Dai, X., Zhang, J., Huang, S., &amp; Chen, J.  (2017, August).  Deep matrix factorization models for recommender systems.  In IJCAI (Vol. 17, pp. 3203-3209).        DeepCF: History Embedding based Latent Factor Model(Representation Learning and Matching Function Learning Ensemble)          Deng, Z. H., Huang, L., Wang, C. D., Lai, J. H., &amp; Yu, P. S.  (2019, July).  Deepcf: A unified framework of representation learning and matching function learning in recommender system.  In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 61-68).        J-NCF: History Embedding based Latent Factor Model(Representation Learning and Matching Function Learning Serial)          Chen, W., Cai, F., Chen, H., &amp; Rijke, M. D.  (2019).  Joint neural collaborative filtering for recommender systems.  ACM Transactions on Information Systems (TOIS), 37(4), 1-30.      Dual Embedding      Dual Embedding: Use both ID Embedding and History Embedding            DNCF: Dual Embedding based Latent Factor Model(Ensemble combining ID embedding and history embedding)          He, G., Zhao, D., &amp; Ding, L.  (2021).  Dual-embedding based neural collaborative filtering for recommender systems.  arXiv preprint arXiv:2102.02549.      Distance Embedding      Distance Embedding: Calculate Similarity through distance, not inner product, outer product, or concatenation        DDFL: Distance Embedding based Latent Factor Model          Shah, S. T. U., Li, J., Guo, Z., Li, G., &amp; Zhou, Q.  (2020, September).  DDFL: a deep dual function learning-based model for recommender systems.  In International Conference on Database Systems for Advanced Applications (pp. 590-606).  Cham: Springer International Publishing.      AutoEncoder  Merit          Restore the user-item interaction matrix      Dimensionality Reduction of the user-item interaction matrix      Feature Extraction        AutoRec: AutoEncoder Application          Sedhain, S., Menon, A. K., Sanner, S., &amp; Xie, L.  (2015, May).  Autorec: Autoencoders meet collaborative filtering.  In Proceedings of the 24th international conference on World Wide Web (pp. 111-112).        CDAE: Denoising AutoEncoder Application          Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M.  (2016, February).  Collaborative denoising auto-encoders for top-n recommender systems.  In Proceedings of the ninth ACM international conference on web search and data mining (pp. 153-162).        VACF: Variational AutoEncoder Application          Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T.  (2018, April).  Variational autoencoders for collaborative filtering.  In Proceedings of the 2018 world wide web conference (pp. 689-698).      CNN  Merit          Modeling interdimensional high-level interactions between users and items        ConvNCF: Using CNN as Matching Function          He, X., Du, X., Wang, X., Tian, F., Tang, J., &amp; Chua, T. S.  (2018).  Outer product-based neural collaborative filtering.  arXiv preprint arXiv:1808.03912.        COMET: Using CNN as Aggregating Histories          Lin, Z., Feng, L., Guo, X., Zhang, Y., Yin, R., Kwoh, C. K., &amp; Xu, C.  (2023).  Comet: Convolutional dimension interaction for collaborative filtering.  ACM Transactions on Intelligent Systems and Technology, 14(4), 1-18.      Attention Mechanism  Merit          Select important information and remove noise      Aggregate histories        DACR: History Embedding based Latent Factor Model Assist.          Cui, C., Qin, J., &amp; Ren, Q.  (2022).  Deep collaborative recommendation algorithm based on attention mechanism.  Applied Sciences, 12(20), 10594.        DRNet: Aggregate user’s histories          Ji, D., Xiang, Z., &amp; Li, Y.  (2020).  Dual relations network for collaborative filtering.  IEEE Access, 8, 109747-109757.        DELF: Aggregate user and item’s histories          Cheng, W., Shen, Y., Zhu, Y., &amp; Huang, L.  (2018, July).  DELF: A dual-embedding based deep latent factor model for recommendation.  In IJCAI (Vol. 18, pp. 3329-3335).      "
  },
  
  {
    "title": "Collaborative Filtering",
    "url": "/posts/cf/",
    "categories": "6.RECOMMENDER SYSTEM, 1.recsys basic",
    "tags": "ai application, recommender system, collaborative filtering, latent factor model, matrix factorization",
    "date": "2024-02-01 00:00:00 +0900",
    





    
    "snippet": "Collaborative Filtering      협업 필터링(Collaborative Filtering): 과거 여러 사용자들이 다양한 아이템에 대하여 평가 점수를 매긴 기록을 활용하여 아직 상호작용하지 않은 아이템에 대한 사용자의 평점을 추론하는 방법론              사용자 기반 협업 필터링(User-Based Collaborative ...",
    "content": "Collaborative Filtering      협업 필터링(Collaborative Filtering): 과거 여러 사용자들이 다양한 아이템에 대하여 평가 점수를 매긴 기록을 활용하여 아직 상호작용하지 않은 아이템에 대한 사용자의 평점을 추론하는 방법론              사용자 기반 협업 필터링(User-Based Collaborative Filtering): Identify like-minded users      아이템 기반 협업 필터링(Item-Based Collaborative Filtering): Identify buying patterns            사용자-아이템 상호작용 행렬(User-Item Interaction Matrix): $M$ 명의 사용자와 $N$ 가지 아이템 간의 상호작용을 수치적으로 표현한 행렬로서, 통상 행 벡터는 사용자를, 열 벡터는 아이템을 의미함    \\[r_{u,i} \\in \\mathbf{R} \\in \\mathbb{R}^{M \\times N}\\]          협업 필터링은 실질적으로 사용자-아이템 상호작용 행렬의 결측치(위 예시의 $-1$)를 채우는 방법이므로 행렬 완성 문제라고도 부름      Function      Bias-aware Collaborative Filtering Function\\[\\begin{aligned}  \\hat{r}_{u,i}  &amp;= \\mu + \\beta_{u} + \\beta_{i} + \\text{what}  \\end{aligned}\\]          $\\hat{r}_{u,i}$: 사용자 $u$ 의 아이템 $i$ 에 대한 평점 예측값      $\\mu$: 커뮤니티 평점 평균      $\\beta_{u}$: 사용자 $u$ 의 평균 평점 편차로서 사용자의 평점 척도      $\\beta_{i}$: 아이템 $i$ 의 평균 평점 편차로서 아이템의 인기도            What?          k-NN Algorithm(Memory based Collaborative Filtering)      Matrix Factorization Algorithm(Latent Factor Model)      Memory based Collaborative Filtering      메모리 기반 협업 필터링(Memory based Collaborative Filtering): (사용자 기반 협업 필터링 기준으로) 사용자가 상호작용하지 않은 아이템에 대한 선호를 예측함에 있어, 해당 아이템에 대한 피어 그룹의 선호를 유사도만큼 가중 평균하는 방법\\[\\begin{aligned}  \\text{what}  &amp;= \\frac{\\sum_{v \\in p(i \\mid u)}{\\text{sim}(u,v) \\cdot \\left(r_{v,i}-\\overline{r}_{v}\\right)}}{\\sum_{v \\in p(i \\mid u)}{\\vert \\text{sim}(u,v) \\vert}}  \\end{aligned}\\]          $v \\in p(i \\mid u)$ : 타깃 사용자 $u$ 의 $k$-Nearest Neighbor 중 타깃 아이템 $i$ 에 대하여 펑점을 매긴 사용자 집합으로서 피어 그룹(Peer Group)      How to Calculate $\\text{sim}(u,v)$      피어슨 상관계수(Pearson Correlation Coefficient): 사용자 벡터 간 평점 척도에 차이가 클 경우 유용함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;= \\frac{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{u,j}-\\overline{r}_{u}\\right)\\cdot\\left(r_{v,j}-\\overline{r}_{v}\\right)}}{\\sqrt{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{u,j}-\\overline{r}_{u}\\right)^{2}}}\\cdot\\sqrt{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{v,j}-\\overline{r}_{v}\\right)^{2}}}}  \\end{aligned}\\]        코사인 유사도(Cosine Measure): 상호작용 데이터가 희박할 경우 유용함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;= \\frac{\\mathbf{r}_{u} \\cdot \\mathbf{r}_{v}}{\\Vert \\mathbf{r}_{u} \\Vert_{L2} \\cdot \\Vert \\mathbf{r}_{v} \\Vert_{L2}}  \\end{aligned}\\]          \\(\\mathbf{r}_{u} \\in \\mathbf{R}_{M \\times N}\\) : 사용자-아이템 상호작용 행렬의 행 벡터로서 사용자 벡터      Discount Methods      유사도 할인(Discounted Similarity): 두 사용자 간 공동으로 상호작용한 아이템 갯수($\\vert I_{u} \\cap I_{v}\\vert$)가 적을 경우, 유사도 값을 신뢰하기 어려우므로 이에 비례하여 유사도를 할인함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;\\leftarrow \\underbrace{\\frac{\\min{\\Big(\\vert I_{u} \\cap I_{v}\\vert, \\beta\\Big)}}{\\beta}}_{\\text{Discount Factor}} \\cdot \\text{sim}(u,v)  \\end{aligned}\\]        중요도 할인(Discounted Importance): 대중성 있는 아이템의 경우 사용자가 이미 경험했거나 인지하고 있지만 소비하지 아니하기로 결정한 아이템일 가능성이 높으므로, 대중성에 비례하여 아이템의 중요도(평점)을 할인함\\[\\begin{aligned}  \\mathbf{r}_{i}  &amp;\\leftarrow \\underbrace{\\log{\\frac{M}{m_{i}}}}_{\\text{Discount Factor}} \\cdot \\mathbf{r}_{i}  \\end{aligned}\\]          \\(\\mathbf{r}_{i} \\in \\mathbf{R}_{M \\times N}\\): 사용자-아이템 상호작용 행렬의 열 벡터로서 아이템 벡터      $M$: 총 사용자 수      $m_{i}$: 아이템 $i$ 에 대하여 상호작용한 사용자 수      Latent Factor Model      잠재요인 모형(Latent Factor Model) : 사용자 벡터와 아이템 벡터를 정체를 알 수 없는 $k$ 개의 특징 공간으로 사상하는 방법              협업 필터링에서 사용자는 아이템들에 대한 평점 집합으로(Row vector of the user-item interaction matrix), 아이템은 사용자들로부터 받은 평점 집합으로(Column vector of the user-item interaction matrix) 표현됨. 이처럼 사용자와 아이템은 각각 서로를 표현하는 벡터 공간 축이 되므로 직접 비교할 수 없음. 잠재요인 모형은 공통된 표현 수단인 잠재요인을 가정함으로써 이 문제를 해결함.      MF      Matrix Factorization: Original Latent Factor Model\\[\\begin{aligned}  \\text{what}  &amp;= \\mathbf{p}_{u} \\cdot \\mathbf{q}_{i}  \\end{aligned}\\]          \\(\\mathbf{p}_{u} \\in \\mathbf{P}_{M \\times K}\\): 사용자-잠재요인 벡터로서, 사용자 $u$ 의 선호 정보로 해석됨      \\(\\mathbf{q}_{i} \\in \\mathbf{Q}_{N \\times K}\\): 아이템-잠재요인 벡터로서, 아이템 $i$ 의 특징 정보로 해석됨            SVD++ : 특정 사용자가 특정 아이템에 대하여 매길 평점을 추론함에 있어, 목표 아이템 외에 사용자가 상호작용했던 다른 아이템들의 잠재요인 정보들을 함께 고려하는 방법\\[\\begin{aligned}  \\mathbf{p}_{u} \\leftarrow \\mathbf{p}_{u} + \\frac{\\sum_{j \\in R(u)}{\\mathbf{q}_{j}}}{\\sqrt{\\vert R(u)\\vert}}  \\end{aligned}\\]          \\(\\displaystyle\\frac{\\sum_{j \\in R(u)}{\\mathbf{q}_{j}}}{\\sqrt{\\vert R(u)\\vert}}\\): 사용자 $u$ 가 상호작용한 아이템 벡터의 평균으로서, $u$ 가 상호작용한 아이템들의 평균적인 특성      $R(u)$: 사용자 $u$ 가 상호작용한 아이템 집합      Optimization      Objective Function for Bias-unaware Matrix Factorization\\[\\begin{aligned}  \\hat{\\mathbf{p}}_{u}, \\hat{\\mathbf{q}}_{i}  &amp;= \\text{arg} \\min_{\\Theta}{\\mathcal{J}\\left(r_{u,i},\\hat{r}_{u,i}\\right) + \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}}  \\end{aligned}\\]        교대최소제곱법(Alternating Least Square; ALS): $\\mathbf{P},\\mathbf{Q}$ 에 대하여 한 번에 하나의 행렬을 고정한 상태에서 다른 행렬을 최적화하는 과정을 번갈아 반복하여 수렴시키는 최적화 알고리즘으로서, 최소자승법을 활용하므로 각 사용자의 상호작용 데이터를 독립적으로 연산할 수 있어 병렬 처리에 적합함        Objective Function:\\[\\begin{aligned}  \\hat{\\mathbf{p}}_{u}  &amp;= \\text{arg} \\min_{\\mathbf{p}}{\\Vert \\mathbf{r}_{u} - \\mathbf{Q} \\cdot \\mathbf{p}_{u}\\Vert^{2} + \\lambda \\Vert \\mathbf{p}_{u} \\Vert^{2}}, \\quad \\text{where Q is fixed}\\\\  \\hat{\\mathbf{q}}_{i}  &amp;= \\text{arg} \\min_{\\mathbf{q}}{\\Vert \\mathbf{r}_{i} - \\mathbf{P} \\cdot \\mathbf{q}_{i}\\Vert^{2} + \\lambda \\Vert \\mathbf{q}_{i} \\Vert^{2}}, \\quad \\text{where P is fixed}  \\end{aligned}\\]        Optimality Condition:\\[\\begin{aligned}  \\frac{\\partial L}{\\partial \\mathbf{p}_{u}}  &amp;= -2\\mathbf{Q}^{T} \\cdot \\left(\\mathbf{r}_{u} - \\mathbf{Q} \\cdot \\mathbf{p}_{u}\\right) + 2\\lambda \\cdot \\mathbf{p}_{u} = 0\\\\  \\frac{\\partial L}{\\partial \\mathbf{q}_{i}}  &amp;= -2\\mathbf{P}^{T} \\cdot \\left(\\mathbf{r}_{i} - \\mathbf{P} \\cdot \\mathbf{q}_{i}\\right) + 2\\lambda \\cdot \\mathbf{q}_{i} = 0  \\end{aligned}\\]        Optimality Params:\\[\\begin{aligned}  \\mathbf{p}_{u}  &amp;\\leftarrow \\left(\\mathbf{Q}^{T}\\mathbf{Q} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{Q}^{T}\\mathbf{r}_{u}\\\\  \\mathbf{q}_{i}  &amp;\\leftarrow \\left(\\mathbf{P}^{T}\\mathbf{P} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{P}^{T}\\mathbf{r}_{i}  \\end{aligned}\\]  Source  https://towardsdatascience.com/essentials-of-recommendation-engines-content-based-and-collaborative-filtering-31521c964922  https://buomsoo-kim.github.io/recommender%20systems/2020/09/25/Recommender-systems-collab-filtering-12.md/"
  },
  
  {
    "title": "AutoEncoder",
    "url": "/posts/ae/",
    "categories": "3.MACHINE LEARNING TECHS, 4.neural networks",
    "tags": "machine learning, deep learning, neural networks, unsupervised learning, feature engineering, autoencoder, ffnn, mlp",
    "date": "2024-01-25 00:00:00 +0900",
    





    
    "snippet": "AutoEncoder      오토인코더(AutoEncoder; AE) : 입력 데이터를 압축시켜 저차원 특징 공간으로 축소한 후, 이를 다시 확장하여 원본으로 복원하는 인공신경망 아키텍처    \\[X \\xrightarrow{\\text{Encoder}} Z \\xrightarrow{\\text{Decoder}} \\hat{X}\\]        Encoder...",
    "content": "AutoEncoder      오토인코더(AutoEncoder; AE) : 입력 데이터를 압축시켜 저차원 특징 공간으로 축소한 후, 이를 다시 확장하여 원본으로 복원하는 인공신경망 아키텍처    \\[X \\xrightarrow{\\text{Encoder}} Z \\xrightarrow{\\text{Decoder}} \\hat{X}\\]        Encoder:\\[\\begin{aligned}  \\mathbf{z} = F\\left(\\mathbf{x} ; \\Theta \\right)  \\end{aligned}\\]          \\(F_{\\Theta}\\) : Encoder Layer      \\(\\mathbf{x}\\) : Input Data      \\(\\mathbf{z}\\) : Latent Space            Decoder:\\[\\begin{aligned}  \\hat{\\mathbf{x}} = G\\left(\\mathbf{z} ; \\Phi \\right)  \\end{aligned}\\]          \\(G_{\\Phi}\\) : Encoder Layer      \\(\\mathbf{z}\\) : Latent Space      \\(\\hat{\\mathbf{x}}\\) : Output Data            Optimization:\\[\\begin{aligned}  \\hat{\\mathbf{z}}, \\hat{\\Theta}, \\hat{\\Phi} &amp;= \\text{arg}\\min{\\mathcal{L}\\left(\\mathbf{x}, \\hat{\\mathbf{x}}\\right)}  \\end{aligned}\\]  Variations      적층 오토인코더(Stacked AutoEncoder or Deep AutoEncoder) : 입력층과 잠재공간, 잠재공간과 출력층 사이에 여러 장의 은닉층을 추가함으로써 기본 오토인코더보다 복잡하고 비선형적인 데이터 패턴을 잘 포착하도록 함            희소 오토인코더(Sparse AutoEncoder; SAE) : 입력 데이터를 고차원으로 확장했다가 본래 차원으로 축소하는 과정을 통해 저차원에서는 발견하기 어려운 잠재 정보나 패턴을 포착하도록 함                      희소성 제약(Sparse Constraint) : 특히 Sparse AutoEncoder 에서, 데이터 과적합을 방지하고 핵심 정보만 선택적으로 학습하기 위하여 은닉층 뉴런 중 일부만 활성화되도록 강제하는 기법\\[\\begin{aligned}  \\mathcal{L}=\\frac{1}{N}\\sum_{i=1}^{N}{\\Vert \\mathbf{x}_{i} - \\hat{\\mathbf{x}}_{i} \\Vert^{2}} + \\beta \\cdot \\underbrace{\\Omega(\\overrightarrow{\\mathbf{h}} \\mid m, \\rho)}_{\\begin{array}{c} \\text{Sparse} \\\\ \\text{Penalty} \\end{array}}  \\end{aligned}\\]                    Sparse Penalty Function : 은닉층 뉴런들이 평균적으로 목표 희소성 비율에 가깝게 활성화되도록 하기 위함으로, 대개 쿨백 라이블러 발산(Kullback–Leibler Divergence)을 활용함\\[\\begin{aligned}  \\Omega(\\overrightarrow{\\mathbf{h}} \\mid m, \\rho)  &amp;= \\sum_{j=1}^{m}{D_{KL}\\left[\\rho \\parallel \\hat{\\rho}_{j}\\right]}\\\\  &amp;= \\sum_{j=1}^{m}{\\rho \\cdot \\log{\\frac{\\rho}{\\hat{\\rho}_{j}}} + (1-\\rho) \\cdot \\log{\\frac{1-\\rho}{1-\\hat{\\rho}_{j}}}}  \\end{aligned}\\]                  $m$ : 은닉층 뉴런 수          $\\rho$ : 목표 희소성 비율          \\(\\hat{\\rho}_{j}=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}{h_{j}^{(i)}}\\) : 은닉층 뉴런 $j$ 의 평균 출력값                          잡음 제거 오토인코더(Denoising AutoEncoder; DAE) : 원본 데이터에 잡음을 추가하여 입력한 후, 원본을 복원함으로써 잡음에 대한 강건성을 확보하고 데이터의 본질적인 특징에 집중할 수 있도록 함                      How to Generate Noise\\[\\begin{aligned}  \\tilde{\\mathbf{x}} &amp;= g(\\mathbf{x} \\mid \\theta)  \\end{aligned}\\]                              Gaussian Noise:\\[\\begin{aligned}  g(\\mathbf{x} \\mid \\sigma)= \\mathbf{x} + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,\\sigma^2)  \\end{aligned}\\]                                Salt and Pepper Noise:\\[g(\\mathbf{x} \\mid p)=\\begin{cases}\\begin{aligned}  \\mathbf{x} \\quad &amp; 1-p\\\\  \\mathbf{v}_{\\text{min}} \\quad &amp; \\frac{p}{2}\\\\  \\mathbf{v}_{\\text{max}} \\quad &amp; \\frac{p}{2}  \\end{aligned}\\end{cases}\\]                                Masking Noise:\\[\\begin{aligned}  g(\\mathbf{x} \\mid p)= \\mathbf{x} \\cdot m, \\quad m \\sim \\text{Bernouli}(1-p)  \\end{aligned}\\]                              Source  https://velog.io/@jochedda/%EB%94%A5%EB%9F%AC%EB%8B%9D-Autoencoder-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EC%A2%85%EB%A5%98"
  },
  
  {
    "title": "Recurrent Neural Networks",
    "url": "/posts/rnn/",
    "categories": "3.MACHINE LEARNING TECHS, 4.neural networks",
    "tags": "machine learning, deep learning, neural networks, rnn, time series, nlp",
    "date": "2024-01-24 00:00:00 +0900",
    





    
    "snippet": "Why? Recurrent-Net      Time series data is datawhere there is a sequence between features:            Fully connected layers treat the positions of input features equally,so they do not structural...",
    "content": "Why? Recurrent-Net      Time series data is datawhere there is a sequence between features:            Fully connected layers treat the positions of input features equally,so they do not structurally reflect order information between features:            RNN(Recurrent Neural Networks) involves preprocessing operationsthat preserve sequence information:      Vanilla RNN      update hidden state $\\mathbf{z}_{t}$:\\[\\begin{aligned}  \\mathbf{z}_{t}  &amp;= \\text{tanh}(\\mathbf{U}\\cdot\\mathbf{x}_{t}+\\mathbf{W}\\cdot\\mathbf{z}_{t-1}+\\mathbf{b}_{h})  \\end{aligned}\\]          $\\text{tanh}$ : activation function      $\\mathbf{x}_{t}$ : input value @ $t$      $\\mathbf{U}$ : weight matrix of input value @ $t$      $\\mathbf{z}_{t-1}$ : hidden state @ $t-1$      $\\mathbf{W}$ : weight matrix of hidden state @ $t-1$      $\\mathbf{b}_{h}$ : bias            print output $\\mathbf{y}_{t}$\\[\\begin{aligned}  \\mathbf{y}_{t}  &amp;= \\text{softmax}(\\mathbf{V}\\cdot\\mathbf{z}_{t}+\\mathbf{b}_{o})  \\end{aligned}\\]          $\\text{softmax}$ : activation function      $\\mathbf{z}_{t}$ : hidden state @ $t$      $\\mathbf{V}$ : weight matrix of hidden state @ $t$      $\\mathbf{b}_{o}$ : bias      LSTM      vanilla rnn suffers from the problems of long-term dependencies:              Long-term dependencies are problems in which the initial order information is not preserved as the sequence gets longer due to the vanishing gradient.            LSTM(Long Short-Term Memory) is technique to alleviate vanishing gradient through gate adjustment:              forget gate: generate forget rule      input gate: generate remember rule and cell state update      cell state: determine how much to remember and how much to forget      output gate: generate hidden state and output            forget gate:            input gate:            cell state:            output gate:      Sourse  https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr"
  },
  
  {
    "title": "Convolutional Neural Networks",
    "url": "/posts/cnn/",
    "categories": "3.MACHINE LEARNING TECHS, 4.neural networks",
    "tags": "machine learning, deep learning, neural networks, cnn, cv",
    "date": "2024-01-23 00:00:00 +0900",
    





    
    "snippet": "Why? Conv-Net      image data is spatially structured data:            fully connected layers flatten the dimensionality of the input,collapsing its spatial structure:            CNN(Convolutional ...",
    "content": "Why? Conv-Net      image data is spatially structured data:            fully connected layers flatten the dimensionality of the input,collapsing its spatial structure:            CNN(Convolutional Neural Networks) involves preprocessing operationsthat preserve spatial structure:      How to Extract Features      Components              합성곱 레이어(Convolution Layer)      합동 레이어(Pooling Layer)      평탄화 레이어(Flatten Layer)      완전 연결 계층(Fully-Connected Layer)            합성곱 연산(Convolution Operation): 입력값의 부분 공간을 커널(Kernel)과 요소별 곱셈(Element-wise Product) 및 그 결과를 합산하여 피처 맵(Feature Map)을 추출하는 연산            커널(Kernel): 입력값의 부분 공간과 요소별 곱셈(Element-wise Product)하는 여과기(Filter)            피처 맵(Feature Map) : 합성곱 연산 결과 입력값 형상의 특징으로서 반환된 새로운 배열로서 원소값은 부분 공간이 커널과 매칭되는 정도를 나타냄            합동 연산(Pooling Operation): 피처 맵(Featur Map)에 대하여 그 부분 공간마다 대표값을 추출하여 요약된 행렬을 구성하는 연산      Sourse  https://medium.com/@PK_KwanG/cnn-step-2-flattening-50ee0af42e3e  https://medium.com/@alejandro.itoaramendia/convolutional-neural-networks-cnns-a-complete-guide-a803534a1930"
  },
  
  {
    "title": "Neural Networks",
    "url": "/posts/nn/",
    "categories": "3.MACHINE LEARNING TECHS, 4.neural networks",
    "tags": "machine learning, deep learning, neural networks, ffnn, mlp",
    "date": "2024-01-22 00:00:00 +0900",
    





    
    "snippet": "Neural NetworksPerceptron      퍼셉트론(Perceptron) : 다수의 신호를 입력 받아 하나의 신호를 출력하는 알고리즘    \\[\\begin{aligned}  y = \\begin{cases}  0 \\quad &amp; \\mathbf{w} \\cdot \\mathbf{x} \\le \\theta \\\\  1 \\quad &amp; \\ma...",
    "content": "Neural NetworksPerceptron      퍼셉트론(Perceptron) : 다수의 신호를 입력 받아 하나의 신호를 출력하는 알고리즘    \\[\\begin{aligned}  y = \\begin{cases}  0 \\quad &amp; \\mathbf{w} \\cdot \\mathbf{x} \\le \\theta \\\\  1 \\quad &amp; \\mathbf{w} \\cdot \\mathbf{x} &gt; \\theta \\\\  \\end{cases}, \\quad x \\in \\{0,1\\}  \\end{aligned}\\]        논리 회로(Logic Gate) : 하나 이상의 논리 입력을 받아 일정한 논리 연산을 거쳐 논리 출력을 얻는 회로                                Gate          Desc                                      AND          입력값이 모두 $1$ 이면 $1$ 을 출력함                          OR          입력값이 하나라도 $1$ 이면 $1$ 을 출력함                          NOT          입력값이 $0$ 이면 $1$ 을, $1$ 이면 $0$ 을 출력함                          NAND          입력값이 모두 $1$ 이면 $0$ 을 출력함                          NOR          입력값이 하나라도 $1$ 이면 $0$ 을 출력함                          XOR          입력값이 서로 다르면 $1$ 을, 같으면 $0$ 을 출력함                          XNOR          입력값이 서로 다르면 $0$ 을, 같으면 $1$ 을 출력함                          MLP(Multi-Layer Perceptron)                      단층 퍼셉트론은 선형 분류기로서 게이트를 다양한 가중치 조합을 통해 표현할 수 있으나, 비선형 분류기를 요하는 일부 게이트(XOR, XNOR)에 대해서는 표현이 불가능함                            이는 NAND, OR, AND 게이트를 표현하는 퍼셉트론들의 조합으로 표현할 수 있음                                                    $X_{1}$              $X_{2}$              $Z_{1}$ NAND              $Z_{2}$ OR              $Y$ AND                                                          $0$              $0$              $1$              $0$              $0$                                      $0$              $1$              $1$              $1$              $1$                                      $1$              $0$              $1$              $1$              $1$                                      $1$              $1$              $0$              $1$              $0$                                          Neural Network      인공신경망(Artifical Neural Network) : 생물학적 신경망에서 영감을 얻은 통계학적 학습 알고리즘            MLP(Multi-Layer Perceptron) is FC(Fully-Connected) FFNN(Feed-Forward Neural Network)              Layer : 하나 이상의 퍼셉트론으로 구성된 모듈      FC(Fully-Connected) : 레이어의 모든 뉴런이 다음 레이어의 모든 뉴런과 연결된 상태      FFNN(Feed-Forward Neural Network) : 신호가 하나의 방향으로만 전달되는 인공신경망            MLP Definition    \\[\\begin{aligned}  \\hat{y}  &amp;= \\text{MLP}(\\mathbf{x})\\\\  &amp;= F^{(N)} \\circ \\cdots \\circ F^{(i)} \\circ \\cdots \\circ F^{(1)}(\\mathbf{x})  \\end{aligned}\\]          $F^{(i)} = h \\circ g$ : Single Layer      \\(\\mathbf{y}^{(i)}\\) : Activation Value      $h(\\mathbf{z}^{(i)})$ : Activation Function      \\(\\mathbf{z}^{(i)}\\) : Net Input      \\(g(\\mathbf{y}^{(i-1)})=\\mathbf{W}^{(i)} \\cdot \\mathbf{y}^{(i-1)} + \\mathbf{b}^{(i)}\\) : Summed Input Function or Weighted Sum Function            활성화 함수(Activation Function) : 다음 레이어 뉴런으로의 전달 여부를 판단하는 함수($h(\\cdot)$)                                           Function          Output                                      Step          \\(\\text{step}(x)=\\begin{cases} 1, \\ \\text{if} \\ x&gt;0 \\\\ 0, \\ \\text{otherwise} \\end{cases}\\)          \\(y \\in \\{0, 1\\}\\)                          Sigmoid          \\(\\text{sigmoid}(x)=\\displaystyle\\frac{1}{1+e^{-x}}\\)          \\(y \\in [0, 1]\\)                          TANH          \\(\\begin{aligned}\\text{tanh}(x)&amp;=\\frac{\\text{sinh}(x)}{\\text{cosh}(x)} \\\\ &amp;=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\\end{aligned}\\)          \\(y \\in [-1, 1]\\)                          ReLU          \\(\\text{ReLU}(x)=\\max(0,x)\\)          \\(y \\in [0, \\infty]\\)                          Softmax          \\(\\text{softmax}(x)_{i} = \\displaystyle\\frac{\\exp{x_i}}{\\sum_{j \\ne i}{\\exp{x_j}}}\\)          \\(y \\in [0, 1]\\)                    Backward PropagationGradient Descent      그라디언트(Gradient) : 다변수 함수에 대하여 모든 방향으로의 순간변화율 벡터    \\[\\begin{aligned}  \\nabla{f(x_{1},x_{2},\\cdots,x_{n})}  &amp;= \\begin{pmatrix}  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{1}}\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{2}}\\\\  \\vdots\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{n}}\\\\  \\end{pmatrix}  \\end{aligned}\\]        경사하강법(Gradient Descent) : 손실 함수의 도함수(그라디언트)를 최소화하는 가중치를 추정하는 방법    \\[\\begin{aligned}  \\Theta \\gets \\Theta - \\eta \\cdot \\nabla_{\\Theta}\\mathcal{L}  \\end{aligned}\\]          $\\Theta$ : Learning Parameter      $\\eta$ : Learning Rate or Learning Step      $\\nabla_{\\Theta}\\mathcal{L}$ : Gradient of the Loss Function is Learning Direction      Backward Propagation      역전파(Backward Propagation) : 경사하강법을 활용하여 오차를 출력층에서 입력층 방향으로 전파하며 가중치를 조정하는 학습 방법            Learning Direction                  손실 $\\mathcal{L}$ 를 $1$ 번째 계층의 $1$ 번째 가중치 $w^{(1)}_{1}$ 에 대하여 미분하면 다음과 같음\\[\\begin{aligned}  \\frac{\\partial}{\\partial w^{(1)}_{1}}\\mathcal{L}(y,\\hat{y})  &amp;= \\frac{\\partial \\mathcal{L}}{\\partial\\cancel{\\mathbf{y}^{(N)}}}  \\times \\frac{\\partial\\cancel{\\mathbf{y}^{(N)}}}{\\partial\\cancel{\\mathbf{z}^{(N)}}}  \\times \\frac{\\partial\\cancel{\\mathbf{z}^{(N)}}}{\\partial\\cancel{\\mathbf{y}^{(N-1)}}}  \\times \\cdots \\times  \\frac{\\partial\\cancel{\\mathbf{y}^{(1)}}}{\\partial\\cancel{\\mathbf{z}^{(1)}}}  \\times   \\frac{\\partial\\cancel{\\mathbf{z}^{(1)}}}{\\partial w^{(1)}_{1}}  \\end{aligned}\\]                    위 각 항목을 일반화하면 다음과 같음\\[\\begin{aligned}  \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}^{(N)}}  =1, \\quad  \\frac{\\partial \\mathbf{y}^{(i)}}{\\partial \\mathbf{z}^{(i)}}  =h^{\\prime}(\\mathbf{z}^{(i)}), \\quad  \\frac{\\partial \\mathbf{z}^{(i)}}{\\partial \\mathbf{y}^{(i-1)}}  =\\mathbf{W}^{(i)}, \\quad  \\frac{\\partial \\mathbf{z}^{(k)}}{\\partial \\mathbf{W}^{(k)}}  =\\mathbf{y}^{(k-1)}  \\end{aligned}\\]                    따라서 파라미터 갱신 방향은 다음과 같이 일반화할 수 있음\\[\\begin{aligned}  \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}^{(k)}}  &amp;= \\mathbf{y}^{(k-1)} \\times \\prod_{i=k+1}^{N}{\\mathbf{W}^{(i)}} \\times \\prod_{i=k}^{N}{h^{\\prime}(\\mathbf{z}^{(i)})}  \\end{aligned}\\]            Optimizer      Update Learning Rate-based Approach                      Adagrad : 이전까지 누적 갱신 규모를 반영하여 학습률을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\frac{\\eta}{\\sqrt{\\phi_{t}}} \\times \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}}\\\\  \\phi_{t}  &amp;= \\phi_{t-1} + \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}} \\odot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}}  \\end{aligned}\\]                    RMSProp : 이전까지 누적 갱신 규모를 지수가중이동평균하여 반영하여 학습률을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\frac{\\eta}{\\sqrt{\\phi_{t}}} \\times \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}}\\\\  \\phi_{t}  &amp;= \\rho \\cdot \\phi_{t-1} + (1-\\rho) \\cdot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}} \\odot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}}  \\end{aligned}\\]                  Update Learning Direction-based Approach                      Momentum : 직전 시점 갱신 방향을 관성 계수($\\gamma$)만큼 반영하여 갱신 방향을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\phi_{t}\\\\  \\phi_{t}  &amp;= \\eta \\cdot \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}} + \\gamma \\cdot \\phi_{t-1}  \\end{aligned}\\]            Sourse  https://codetorial.net/tensorflow/basics_of_optimizer.html  https://namu.wiki/jump/JsjHPjk9qYK%2Fl54QLaGyq5jupzXBHwWbSS0dMWuO%2B3lzPTdSDH1TiTY1jg9ysGRCY1f5J8NIWqRsnWauQXGsLQ%3D%3D  https://gentlesark.tistory.com/44  https://www.asimovinstitute.org/neural-network-zoo/  https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html  https://towardsdatascience.com/an-intuitive-explanation-of-gradient-descent-83adf68c9c33"
  },
  
  {
    "title": "What? Recommender System",
    "url": "/posts/what_recsys/",
    "categories": "6.RECOMMENDER SYSTEM, 1.recsys basic",
    "tags": "ai application, recommender system, metric",
    "date": "2024-01-18 00:00:00 +0900",
    





    
    "snippet": "What? RecSys      추천시스템(Recommender System): 정보과부하 문제(Information Overload Problem)를 해결하기 위한 개인화 정보 필터링 서비스(Personalized Information Filtering Service) 로서, 사용자에게 적합한 아이템을 제안함으로써 개인화된 경험을 제공하는 기술   ...",
    "content": "What? RecSys      추천시스템(Recommender System): 정보과부하 문제(Information Overload Problem)를 해결하기 위한 개인화 정보 필터링 서비스(Personalized Information Filtering Service) 로서, 사용자에게 적합한 아이템을 제안함으로써 개인화된 경험을 제공하는 기술          정보과부하 문제(Information Overload Problem): 인간이 처리할 수 있는 정보량 이상의 정보가 제공되어 오히려 개인의 정보 학습 및 의사결정이 방해 받는 현상            검색 엔진과 비교                                       Search Engine          Recommender System                                      사용자의 자세          능동성          수동성                          사용자 선호 파악          검색어          알고리즘                          사용자 선호 정보          검색 키워드          사용자 프로파일  아이템 프로파일  사용자 과거 행동                          사용자-아이템 상호작용 데이터(User-Item Interaction Data): 사용자의 아이템에 대한 선호 여부 및 정도를 포함하는 데이터          명시적 선호 데이터(Explicit Rating Data): 제시된 평가 시스템에 따라 직접 표출된 선호도      암시적 선호 데이터(Implicit Rating Data): 행동을 통해 우회로 표출된 선호도                  암시적 선호를 순서적으로 나타내는 경우, 이를 선호보다는 확신으로 해석함                    순서적 선호 데이터(Ordinal Rating Data): 정해진 숫자 또는 연속적인 범위로 표시된 선호도      단항 선호 데이터(Unary Rating Data): 상호작용이 있었다는 사실을 기록한 데이터      Filtering Methods      Most Popular(Best Seller)        내용 기반 필터링 기법(Content-based Filtering Method; CB): 타깃 사용자가 상호작용한 아이템의 콘텐츠를 분석하여 이와 유사한 콘텐츠를 보유하고 있는 아이템을 추천하는 방법          Show me more of the same what I’ve liked!                협업 필터링 기법(Collaborative Filtering Method; CF): 타깃 사용자의 구매 기록을 바탕으로 유사한 사용자 혹은 아이템을 탐색하여 추천하는 방법          Tell me what’s popular among my peers!                하이브리드 기법(Hybrid Method): 협업 필터링 기법과 내용 기반 필터링 기법을 결합하는 방법                                       Content-based Filtering          Collaborative Filtering                                      빅데이터          X          Rating Sparsity Problem                          사용자 의존성          X          Cold Start Problem                          아이템 커스터마이징          X          Grey Sheep Problem                          도메인 지식 필요성          Feature Engineering Problem          X                          도메인 종속성          X          CORS Problem  (Cross-Origin Resource Sharing)                          추천 결과의 참신성          X          Popularity Bias Problem                          추천 결과의 의외성          Trival Recommendation Problem          X                    Goal  추천시스템의 목적: 고객 가치 창출을 통한 기업 이윤 도모          가치 명제(Value Proposition): 고객이 필요로 하는 가치를 창출하기 위한 상품 및 서비스 조합      구매 가치(Purchase Value): 상품 및 서비스를 구매함으로써 고객이 직접적으로 얻게 되는 실용 가치      브랜드 가치(Brand Value): 브랜드에 대한 고객의 주관적/무형적 평가에 기초한, 고객이 특정 브랜드를 소유 및 경험함으로써 누리는 심리적 가치      관계 가치(Relationship Value): 특정 기업에 대한 구매 가치나 브랜드 가치를 넘어서 기업이 고객과 형성하게 되는 관계의 양적, 질적 정도        좋은 추천시스템의 요건          효과적(Effective): 사용자에게 얼마나 잘 맞는 아이템을 제안할 수 있는가      효율적(Efficient): 제안 생성 및 제공 과정에서 컴퓨팅 자원을 얼마나 잘 활용할 수 있는가      설명력(Explainable): 사용자에게 아이템을 제안한 근거나 로직을 설명할 수 있는가      설득력(Persuasive): 사용자가 제안된 아이템을 실제로 구매하거나 사용하도록 유도할 수 있는가        효과적인 추천의 목표          적합성(Relevance): 사용자가 관심 있을 것으로 짐작되는 아이템을 제안함      참신성(Novelty): 사용자가 이전에 관측하지 못했을 것으로 짐작되는 아이템을 제안함      의외성(Serendipity): 사용자가 예상하지 못했을 것으로 짐작되는 아이템을 제안함      다양성(Diversity): 제안된 정보 묶음이 확일적이지 않고 다양한 특성을 가진 정보들로 구성되어 있음      MetricsFocusing on Relevance  Ordinal Rating Prediction          RMSE(Root Mean Squared Error)      MAE(Mean Absolute Error)        Unary Rating Prediction          Recall      Precision      F1-Score        Top-K Rank Prediction          NDCG(Normalized Discounted Cumulative Gain): under the Explicit Ratings      MAP(Mean Average Precision): under the Implicit Ratings      MRR(Mean Reciprocal Rank)      Focusing on Diversity  Variance-based Diversity          Shanon Entropy      Simpson Concentration      Renyi Entropy        Equity-based Diversity          The Gini Coefficient derived from a Lorenz curve      Source  https://www.idownloadblog.com/2016/04/26/youtube-new-homepage-design/  https://towardsdatascience.com/essentials-of-recommendation-engines-content-based-and-collaborative-filtering-31521c964922"
  },
  
  {
    "title": "t-SNE",
    "url": "/posts/tsne/",
    "categories": "3.MACHINE LEARNING TECHS, 3.dimensionality reduction algorithm",
    "tags": "machine learning, unsupervised learning, feature engineering, dimensionality reduction, information theory, tsne",
    "date": "2024-01-17 00:00:00 +0900",
    





    
    "snippet": "Prerequisite      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Even...",
    "content": "Prerequisite      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Event)일수록 높은 정보량을 가짐(Informative)                  해가 동쪽에서 뜨는 사건은 사람들이 확신하고 있는 사건이므로 정보량이 낮은 반면, 해가 서쪽에서 뜨는 사건은 자연 법칙을 거스르는 극히 드문 사건이므로 정보량이 높음                    독립사건은 추가적인 정보량을 가짐(Addictive Information)                  동전을 두 번 던져서 앞면이 두 번 나오는 사건은 동전을 한 번 던져서 앞면이 나오는 사건보다 정보량이 두 배임                          자기정보(Self-Information): 확률변수 $X \\sim P$ 에 대하여, 사건 $X=x$ 가 발생했을 때의 정보량\\[\\begin{aligned}  I(X=x)  &amp;=-\\log{P(X=x)}  \\end{aligned}\\]        엔트로피(Entropy): 자기정보의 기대값으로서, 주어진 확률분포에서 발생 가능한 사건들의 평균적인 정보량\\[\\begin{aligned}  H(P)  = \\mathbb{E}_{X \\sim P}\\left[I(X)\\right]  = -\\sum_{X}{\\log{P(x)} \\cdot P(x)}  \\end{aligned}\\]          사건의 분포가 결정적일수록(Deterministic) 엔트로피가 감소함      사건의 분포가 균등할수록(Uniform) 엔트로피가 증가함            교차 엔트로피(Cross Entropy): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 가 $P$ 에 대하여 제공하는 정보의 불확실성을 측정하는 지표\\[\\begin{aligned}  H(P,Q)  = \\mathbb{E}_{X \\sim P}\\left[-\\log{Q(X)}\\right]  = -\\sum_{X}{\\log{Q(X)} \\cdot \\log{P(X)}}  \\end{aligned}\\]        쿨백 라이블러 발산(Kullback-Leibler Divergence): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 를 $P$ 의 근사 분포로 사용할 때의 비효율성을 측정하는 지표로서, $P$ 에서 샘플링된 $X$ 에 대하여, $P$ 가 제공하는 평균적인 정보량과 $Q$ 가 제공하는 평균적인 정보량의 차이\\[\\begin{aligned}  KL[P(X) \\parallel Q(X)]  = H(P,Q) - H(P)  = \\sum_{X}{\\log{\\frac{P(X)}{Q(X)}} \\cdot P(X)}  \\end{aligned}\\]  t-SNE      t-분포 확률적 이웃 임베딩(t-Distribution Stochastic Neighbor Embedding): 고차원 공간 상에서의 관측치 간 거리를 보존하면서 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소 기법      Similarity Dist. in High Rank      Gaussian Kernel:\\[\\begin{aligned}  \\mathcal{K}(\\mathbf{x}_{i}, \\mathbf{x}_{j})  &amp;= \\exp{\\left[-\\frac{\\Vert \\mathbf{x}_{i}-\\mathbf{x}_{j}\\Vert^{2}}{2\\sigma_{i}^{2}}\\right]}  \\end{aligned}\\]        Gaussian-based Conditional Probabilities:\\[\\begin{aligned}  p(j \\mid i)  &amp;= \\frac{\\mathcal{K}(\\mathbf{x}_{i}, \\mathbf{x}_{j})}{\\sum_{k \\ne i}{\\mathcal{K}(\\mathbf{x}_{i}, \\mathbf{x}_{k})}}  \\end{aligned}\\]        Symmetrization of probability through joint probability calculation:\\[\\begin{aligned}  p(i,j)  &amp;= \\frac{p(j \\mid i) + p(i \\mid j)}{2n}  \\end{aligned}\\]  Similarity Dist. in Low Rank      Cauchy Dist. Kernel:\\[\\begin{aligned}  \\mathcal{K}(\\mathbf{y}_{i}, \\mathbf{y}_{j})  &amp;= \\frac{1}{1 + \\Vert \\mathbf{y}_{i} - \\mathbf{y}_{j} \\Vert^{2}}  \\end{aligned}\\]          cauchy dist. is t-dist. when the degree of freedom is $1$            L1 Regularization:\\[\\begin{aligned}  q(i,j)  &amp;= \\frac{\\mathcal{K}(\\mathbf{y}_{i}, \\mathbf{y}_{j})}{\\sum_{k \\ne l}{\\mathcal{K}(\\mathbf{y}_{k}, \\mathbf{y}_{l})}}  \\end{aligned}\\]  Optimization      Objective Function:\\[\\begin{aligned}  \\mathcal{L}  &amp;=\\sum_{i}{KL[P(i) \\parallel Q(i)]}\\\\  &amp;= \\sum_{i}\\sum_{j}{\\log{\\frac{p(i,j)}{q(i,j)}} \\cdot p(i,j)}  \\end{aligned}\\]        Optimization:\\[\\begin{aligned}  \\hat{\\mathbf{Y}}  &amp;= \\left\\{\\mathbf{y}_{i} \\mid \\text{arg} \\min{\\mathcal{L}}\\right\\}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Principal Component Analysis",
    "url": "/posts/pca/",
    "categories": "3.MACHINE LEARNING TECHS, 3.dimensionality reduction algorithm",
    "tags": "machine learning, unsupervised learning, feature engineering, dimensionality reduction, variance, pca, lda",
    "date": "2024-01-16 00:00:00 +0900",
    





    
    "snippet": "PrerequisiteProjection      벡터 $\\mathbf{a}$ 를 벡터 $\\mathbf{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\mathbf{b}}(\\mathbf{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &amp;= \\frac{(\\mathbf{a}-p\\mathbf...",
    "content": "PrerequisiteProjection      벡터 $\\mathbf{a}$ 를 벡터 $\\mathbf{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\mathbf{b}}(\\mathbf{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &amp;= \\frac{(\\mathbf{a}-p\\mathbf{b})^{T}\\mathbf{b}}{\\Vert \\mathbf{a}\\Vert \\cdot \\Vert\\mathbf{b}\\Vert}\\\\  &amp;= 0\\\\  \\therefore \\text{proj}_{\\mathbf{b}}(\\mathbf{a})  &amp;= p\\mathbf{b}\\\\  &amp;= \\left(\\frac{\\mathbf{a}^{T}\\mathbf{b}}{\\Vert\\mathbf{b}\\Vert^{2}}\\right)\\mathbf{b}  \\end{aligned}\\]          $p=\\displaystyle\\frac{\\mathbf{a}^{T}\\mathbf{b}}{\\Vert\\mathbf{b}\\Vert^{2}}$ : 정사영 벡터의 크기      $\\mathbf{b}$ : 정사영 벡터의 방향      Covariance Matrix      공분산(Covariance) : 두 확률변수의 선형관계를 나타내는 지표로서, 두 확률변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]        공분산행렬(Covariance Matrix) : $n$ 개 변수들 간 공분산을 나열한 $n \\times n$ 정방행렬\\[\\Sigma=  \\begin{matrix}  &amp; \\mathbf{A} &amp; \\mathbf{B} &amp; \\mathbf{C} \\\\  \\mathbf{A} &amp; \\sigma_{A}^2 &amp; \\sigma_{AB} &amp; \\sigma_{AC} \\\\  \\mathbf{B} &amp; \\sigma_{BA} &amp; \\sigma_{B}^2 &amp; \\sigma_{BC} \\\\  \\mathbf{C} &amp; \\sigma_{CA} &amp; \\sigma_{CB} &amp; \\sigma_{C}^2  \\end{matrix}\\]  Linear Transformation      행렬 $\\mathbf{X}$ 을 통한 선형변환은 어떤 좌표를 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계에서 \\(\\mathbf{x}_{1},\\mathbf{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계로 변환하는 것을 의미함\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix} \\mathbf{x}_{1}&amp;\\mathbf{x}_{2} \\end{pmatrix}  \\end{aligned}\\]        벡터 $\\mathbf{v}$ 는 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 를 나타냄\\[\\begin{aligned}  \\mathbf{v}  &amp;= \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= -1\\begin{pmatrix}1\\\\0\\end{pmatrix} + 2\\begin{pmatrix}0\\\\1\\end{pmatrix}\\\\  \\end{aligned}\\]        $\\mathbf{X}$ 를 통한 선형 변환 결과 \\(\\mathbf{v}\\) 는 \\(\\mathbf{x}_{1},\\mathbf{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 로 변환되었음\\[\\begin{aligned}  \\mathbf{X}\\cdot\\mathbf{v}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\cdot \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix}-5\\\\2\\end{pmatrix}\\\\  &amp;= -1\\mathbf{x}_{1} + 2\\mathbf{x}_{2}  \\end{aligned}\\]  Eigen-Vector      고유벡터(Eigen-Vector; $\\mathbf{v}$): 정방행렬 $A_n$ 으로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 $\\mathbf{0}$ 이 아닌 벡터\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\mathbf{v}   = \\lambda \\mathbf{v}  \\end{aligned}\\]        고유값(Eigen-Value; $\\lambda$): 고유벡터의 선형변환 전 크기 대비 선형변환 후 크기의 비율  Principal Component Analysis      주성분 분석(Principal Component Analysis; PCA): 고차원 데이터에 대하여, X의 방향적 분포를 가장 잘 설명하는 새로운 저차원 직교 좌표를 학습하는 기법              주성분(Principal Component; PC): 새로운 저차원 직교 좌표            방법: 관측치 간 상대적 특성을 잘 보존하는 성분들을 추출함              $\\text{component}$ : 주성분 벡터 $\\mathbf{w}$      $\\text{datapoint}$ : 관측치 벡터 $\\mathbf{x}\\in \\mathbf{X}$      $\\text{projected data}$ : 주성분 벡터에 대한 관측치 벡터의 정사영 벡터 $\\text{proj}_{\\mathbf{w}}(\\mathbf{x})$      $D_{1}$ : 관측치 벡터에 대하여 보존하는 정보로서 분산      $D_{2}$ : 관측치 벡터에 대하여 유실하는 정보      $D_{3}$ : 관측치 벡터의 본래 정보      How to Extract      관측치 행렬 $X_{N \\times P}$ 를 단위벡터 $\\mathbf{w}$ 에 정사영한다고 하자\\[\\begin{aligned}  proj_{\\mathbf{w}}(\\mathbf{X})  &amp;= \\frac{&lt;\\mathbf{X},\\mathbf{w}&gt;}{\\Vert w \\Vert ^2}\\cdot\\mathbf{w}\\\\  &amp;= (\\mathbf{w}^{T}\\mathbf{X})\\cdot\\mathbf{w} \\quad (\\because \\Vert w \\Vert=1)  \\end{aligned}\\]          $\\mathbf{w}$ : 정사영 벡터의 방향      $\\mathbf{w}^{T}\\mathbf{X}$ : 정사영 벡터의 크기            $\\mathbf{w}$ 에 정사영된 관측치들의 분산 $\\mathbf{V}$ 은 다음과 같음\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\mathbf{w}^{T}\\mathbf{X})(\\mathbf{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}(\\mathbf{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\mathbf{w})\\\\  &amp;= \\mathbf{w}^{T}\\Sigma\\mathbf{w}  \\end{aligned}\\]          $\\Sigma=\\displaystyle\\frac{1}{n}\\mathbf{X}\\mathbf{X}^{T}$ : 관측치 행렬 $X$ 의 공분산 행렬            $\\mathbf{V}$ 을 최대화하는 $\\mathbf{w}$ 를 채택한다고 하자\\[\\hat{\\mathbf{w}}  = \\text{arg} \\max_{\\mathbf{w}}{\\mathbf{w}^{T}\\Sigma\\mathbf{w}}  \\quad \\text{s.t.} \\quad  \\mathbf{w}^{T}\\mathbf{w}=1\\]        라그랑주 승수법에 기초하여 $\\hat{\\mathbf{w}}$ 도출\\[\\begin{aligned}  L(\\mathbf{w},\\lambda)  &amp;= \\mathbf{w}^{T}\\Sigma\\mathbf{w}-\\lambda(\\mathbf{w}^{T}\\mathbf{w}-1)\\\\  \\frac{\\partial L(\\mathbf{w},\\lambda)}{\\mathbf{w}}  &amp;= 0\\\\  \\therefore (\\Sigma-\\lambda\\mathbf{I})\\hat{\\mathbf{w}}  &amp;=0  \\end{aligned}\\]        $\\mathbf{V}$ 를 최대화하는 주성분 $\\mathbf{w}$ 은 $\\mathbf{X}$ 의 공분산 행렬 $\\Sigma$ 의 고유벡터임\\[\\begin{aligned}  \\Sigma  &amp;= \\mathbb{V}\\mathbb{\\Lambda}\\mathbb{V}^{-1},\\\\  \\mathbb{V}  &amp;= \\begin{pmatrix}\\mathbf{w}_{1}&amp;\\mathbf{w}_{2}&amp;\\cdots&amp;\\mathbf{w}_{p}\\end{pmatrix}\\\\  \\mathbb{\\Lambda}  &amp;= \\text{diag}(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{p})  \\end{aligned}\\]  Explanatory Power      주성분 벡터의 고유값: 관측치 행렬 $\\mathbf{X}$ 에 대하여 주성분 벡터에 대한 정사영 벡터 간 분산\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\mathbf{w}^{T}\\mathbf{X})(\\mathbf{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}\\mathbf{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\mathbf{w}\\\\  &amp;= \\mathbf{w}^{T}\\Sigma\\mathbf{w}\\\\  &amp;= \\hat{\\mathbf{w}}^{T}\\lambda\\hat{\\mathbf{w}} \\quad (\\because \\Sigma\\hat{\\mathbf{w}}-\\lambda\\hat{\\mathbf{w}}=0)\\\\  &amp;= \\lambda \\quad (\\because \\mathbf{w}^{T}\\mathbf{w}=1)  \\end{aligned}\\]        주성분 벡터의 설명력: 관측치 행렬 $\\mathbf{X}_{N \\times P}$ 에 대하여 생성 가능한 $P$ 개의 주성분 벡터 고유값 합계 대비 해당 주성분 벡터 고유값 비율\\[\\frac{\\lambda_{k}}{\\sum_{i=1}^{p}{\\lambda_{i}}}\\]  Linear Discriminant Analysis      선형 판별 분석(Linear Discriminant Analysis; LDA): 고차원 데이터에 대하여, 주어진 클래스를 가장 잘 구분할 수 있는 새로운 저차원 직교 좌표(선형 판별 함수)를 찾는 기법            방법: 클래스 간 분산은 최대화하는 동시에 클래스 내 관측치 간 분산은 최소화하는 성분들을 추출함\\[\\hat{\\mathbf{w}}  =\\text{arg} \\max_{\\mathbf{w}}{\\frac{\\Sigma^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}}  \\quad \\text{s.t.} \\quad  \\mathbf{w}^{T}\\mathbf{w}=1\\]          $\\Sigma^{2}$ : 정사영 후 클래스 간 분산      $\\sigma_{i}^{2}$ : 정사영 후 $i$ 번째 클래스 내 관측치 간 분산      How to Extract      정사영 후 범주 간 분산 $\\Sigma^{2}$:\\[\\begin{aligned}  \\Sigma^{2}  &amp;= (\\mathbf{\\mu}_{1}-\\mathbf{\\mu}_{2})(\\mathbf{\\mu}_{1}-\\mathbf{\\mu}_{2})^{T}\\\\  &amp;= (\\mathbf{w}^{T}\\mathbf{m}_{1}-\\mathbf{w}^{T}\\mathbf{m}_{2})(\\mathbf{w}^{T}\\mathbf{m}_{1}-\\mathbf{w}^{T}\\mathbf{m}_{2})^{T}\\quad(\\because \\mathbf{\\mu}_{i}=\\mathbf{w}^{T}\\mathbf{m}_{i})\\\\  &amp;= \\mathbf{w}^{T}(\\mathbf{m}_{1}-\\mathbf{m}_{2})(\\mathbf{m}_{1}-\\mathbf{m}_{2})^{T}\\mathbf{w}\\\\  &amp;= \\mathbf{w}^{T}\\mathbf{S}_{B}\\mathbf{w}  \\end{aligned}\\]          \\(\\mathbf{m}_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 중심점 벡터      \\(\\mathbf{\\mu}_{i}=\\text{proj}_{\\mathbf{w}}(\\mathbf{m}_{i})\\) : \\(\\mathbf{m}_{i}\\) 의 정사영 벡터      \\(\\mathbf{S}_{B}\\) : 범주 \\(C_{i},C_{j}\\) 간 편차      \\(\\Sigma\\) : 정사영 후 범주 \\(C_{i},C_{j}\\) 간 편차            정사영 후 범주 내 분산 $\\sigma_{i}^{2}$:\\[\\begin{aligned}  \\sigma_{i}^{2}  &amp;= \\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\mathbf{y}_{j}-\\mathbf{\\mu}_{i})(\\mathbf{y}_{j}-\\mathbf{\\mu}_{i})^{T}}\\quad(\\mathbf{x}_{j} \\in C_{i})\\\\  &amp;= \\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\mathbf{w}^{T}\\mathbf{x}_{j}-\\mathbf{w}^{T}\\mathbf{m}_{i})(\\mathbf{w}^{T}\\mathbf{x}_{j}-\\mathbf{w}^{T}\\mathbf{m}_{i})^{T}}\\quad(\\because \\mathbf{y}_{j}=\\mathbf{w}^{T}\\mathbf{x}_{j})\\\\  &amp;= \\mathbf{w}^{T}\\left[\\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\mathbf{x}_{j}-\\mathbf{m}_{i})(\\mathbf{x}_{j}-\\mathbf{m}_{i})^{T}}\\right]\\mathbf{w}\\\\  &amp;= \\mathbf{w}^{T}\\mathbf{S}_{i}\\mathbf{w}  \\end{aligned}\\]          \\(\\mathbf{x}_{j} \\in C_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 \\(j\\) 번째 관측치 벡터      \\(\\mathbf{y}_{j}=\\text{proj}_{\\mathbf{w}}(\\mathbf{x}_{j})\\) : \\(\\mathbf{x}_{j}\\) 의 정사영 벡터      \\(S_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차      \\(\\sigma_{i}\\) : 정사영 후 \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차            목적 함수 재정의\\[\\begin{aligned}  \\hat{\\mathbf{w}}  =\\text{arg} \\max_{\\mathbf{w}}{\\frac{\\mathbf{w}^{T}\\mathbf{S}_{B}\\mathbf{w}}{\\mathbf{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\mathbf{w}}}  \\quad \\text{s.t.} \\quad   \\mathbf{w}^{T}\\mathbf{w}=1  \\end{aligned}\\]        라그랑주 승수법을 통한 최적화 문제 풀이\\[\\begin{aligned}  L(\\mathbf{w},\\lambda)  &amp;= \\frac{\\mathbf{w}^{T}\\mathbf{S}_{B}\\mathbf{w}}{\\mathbf{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\mathbf{w}}-\\lambda(\\mathbf{w}^{T}\\mathbf{w}-1)\\\\  \\frac{\\partial L(\\mathbf{w},\\lambda)}{\\partial \\mathbf{w}}  &amp;= 0\\\\  \\therefore \\left[\\mathbf{S}_{B}^{-1}(\\mathbf{S}_{1}+\\mathbf{S}_{2})-\\lambda\\mathbf{I}\\right]\\hat{\\mathbf{w}}  &amp;=0  \\end{aligned}\\]  Sourse  http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/"
  },
  
  {
    "title": "Dimensionality Reduction",
    "url": "/posts/dimensionality_reduction/",
    "categories": "3.MACHINE LEARNING TECHS, 3.dimensionality reduction algorithm",
    "tags": "machine learning, unsupervised learning, feature engineering, dimensionality reduction",
    "date": "2024-01-15 00:00:00 +0900",
    





    
    "snippet": "Curse of Dimensionality      차원의 저주(Curse of Dimensionality) : 고차원일수록 관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해져서 알고리즘이 제대로 학습하지 못하는 현상            차원 축소의 당위성          Manifold hypothesis      M...",
    "content": "Curse of Dimensionality      차원의 저주(Curse of Dimensionality) : 고차원일수록 관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해져서 알고리즘이 제대로 학습하지 못하는 현상            차원 축소의 당위성          Manifold hypothesis      Many high-dimensional data sets that occur in the real world actually lie along low-dimensional latent manifolds inside that high-dimensional space.          Dimensionality Reduction Methods  차원 선택(Feature Selection) : 유효한 차원을 선별하는 방법                  Filter Approach                    Wrapper Approach                  Forward Selection          Backward Elimination          Stepwise Selection                      차원 추출(Feature Extraction) : 원본의 상대적 특징을 보존하는 새로운 차원을 추출하는 방법          $\\text{arg} \\max_{\\mathbf{w}}{\\sigma^{2}}$                  주성분 분석(Principle Component Analysis; PCA)          선형 판별 분석(Linear Discriminant Analysis; LDA)                    $\\text{arg} \\max_{\\mathbf{w}}{\\text{dist}}$                  다차원 척도법(Multi-Dimensional Scaling; MDS)                    Reveal Non-Linear Structure                  t-SNE(t-distributed Stochastic Neighbor Embedding)          LLE(Locally Linear Embedding)          ISOMAP(ISOmetric feature MAPping)                    "
  },
  
  {
    "title": "Hierarchical Clustering",
    "url": "/posts/hierarchical_clustering/",
    "categories": "3.MACHINE LEARNING TECHS, 2.clustering algorithm",
    "tags": "machine learning, unsupervised learning, clustering",
    "date": "2024-01-11 00:00:00 +0900",
    





    
    "snippet": "Hierarchical Clustering      계층적 군집화(Hierarchical Clustering): 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram): 결합 혹은 분할하는 순서를 나타내는 계층적 ...",
    "content": "Hierarchical Clustering      계층적 군집화(Hierarchical Clustering): 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram): 결합 혹은 분할하는 순서를 나타내는 계층적 트리모형            종류              상향식 군집화(Agglomerative Clustering) : 개별 개체들을 유사한 개체/군집과 계층적으로 통합해가는 방식      하향식 군집화(Divisive Clustering) : 표본을 유의미하게 구분되는 지점마다 계층적으로 분할해가는 방식      How to Agglomerative Clustering      모든 개체를 개별 군집으로서 정의함\\[C_{i} = \\{\\overrightarrow{x}_{i}\\} \\quad \\text{for} \\quad i=1,2,\\cdots, n\\]        군집 간 거리 행렬을 계산함\\[\\mathbf{D}_{i,j}=d(C_{i},C_{j})\\]        가장 가까운 두 개의 군집을 하나의 군집으로 통합함\\[\\begin{aligned} C_{k}&amp;=\\hat{C}_{i} \\cup \\hat{C}_{j}\\\\ \\hat{C}_{i},\\hat{C}_{j}&amp;=\\text{arg} \\min_{C_{i},C_{j}}{d(C_{i},C_{j})} \\end{aligned}\\]        군집 간 거리 행렬을 갱신함\\[\\mathbf{D}_{N} = \\mathbf{D}_{N-1} \\quad \\text{Recalculate} \\quad d(C_{i^{\\forall} \\ne k},C_{k})\\]        모든 개체가 하나의 군집으로 통합될 때까지 ③, ④의 과정을 반복함  How to Calculate Distance      Single Linkage(Minimum Distance) : 각 군집에 속한 개체들 사이 거리 최소값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\min_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Complete Linkage(Maximum Distance) : 각 군집에 속한 개체들 사이 거리 최대값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\max_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Average Linkage(Mean Distance) : 각 군집에 속한 개체들 사이 거리 평균\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{a} \\in \\mathbf{A}}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Centroid Linkage(Distance Between Centroids) : 각 군집 중심 간 거리\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= d(\\overrightarrow{\\mu}_{A},\\overrightarrow{\\mu}_{B})\\\\  \\overrightarrow{\\mu}_{A}  &amp;= \\frac{1}{\\vert\\mathbf{A}\\vert}\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{\\overrightarrow{a}}\\\\  \\overrightarrow{\\mu}_{B}  &amp;= \\frac{1}{\\vert\\mathbf{B}\\vert}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{\\overrightarrow{b}}  \\end{aligned}\\]        Ward’s Method : 병합 후 SSE와 병합 전 개별 군집의 SSE의 합의 차\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{c} \\in \\mathbf{C}}{d(\\overrightarrow{c},\\overrightarrow{\\mu}_{C})} - \\Big[\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{d(\\overrightarrow{a},\\overrightarrow{\\mu}_{A})} + \\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{b},\\overrightarrow{\\mu}_{B})}\\Big]\\\\  \\mathbf{C}  &amp;= \\mathbf{A} \\cup \\mathbf{B}  \\end{aligned}\\]  Sourse  https://towardsdatascience.com/hierarchical-clustering-explained-e59b13846da8  https://harshsharma1091996.medium.com/hierarchical-clustering-996745fe656b"
  },
  
  {
    "title": "DBSCAN",
    "url": "/posts/dbscan/",
    "categories": "3.MACHINE LEARNING TECHS, 2.clustering algorithm",
    "tags": "machine learning, unsupervised learning, clustering, density",
    "date": "2024-01-10 00:00:00 +0900",
    





    
    "snippet": "DBSCAN      DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만...",
    "content": "DBSCAN      DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empty Subset                      Maximality                  표본 $D$ 에 속하는 관측치 벡터 $\\mathbf{p}, \\mathbf{q}$ 에 대하여, $\\mathbf{p} \\in C \\subseteq D$ 이고, $\\mathbf{q}$ 가 $\\mathbf{p}$ 로부터 밀도 기준 도달 가능한(Directly Density-Reachable) 벡터이면, $\\mathbf{q} \\in C$ 임                            Connectivity                  군집 $C$ 에 속하는 관측치 벡터 $\\mathbf{p}, \\mathbf{q}$ 간에는 밀도 기준 연결되어 있음(Density-Connected)                    Concept$\\varepsilon$-neighborhood of a point  표본 $D$ 에 속하는 관측치 벡터 $\\mathbf{p}$ 에 대하여, $\\mathbf{p}$ 의 이웃 집합 $N_{\\varepsilon}(\\mathbf{p})$ 은 $\\mathbf{p}$ 와의 거리가 $\\varepsilon$ 이하인 관측치 벡터 $\\mathbf{q}$ 의 집합임\\[N_{\\varepsilon}(\\mathbf{p})=\\{\\mathbf{q} \\in D \\mid d(\\mathbf{p},\\mathbf{q}) \\le \\varepsilon\\}\\]Directly Density-Reachable  Core Point Condition 을 만족하는 관측치 벡터 $\\mathbf{p} \\in D$ 에 대하여, 그 이웃 관측치 벡터($\\varepsilon$-neighborhood of a point) $\\mathbf{q}$ 는 $\\mathbf{p}$ 로부터 밀도 기준 직접 도달 가능한(Directly Density-Reachable) 관측치 벡터임      Core Point Condition\\[\\vert N_{\\varepsilon}(\\mathbf{p}) \\vert \\ge \\text{MinPts}\\]        Reachability\\[\\mathbf{q} \\in N_{\\varepsilon}(\\mathbf{p})\\]  Density-Reachable  Core Point Condition 을 만족하는 관측치 벡터 \\(\\mathbf{p} \\in D\\) 에 대하여, \\(\\mathbf{p}\\) 와 \\(\\mathbf{q}\\) 사이에 \\(\\mathbf{p}\\) 로부터 밀도 기준 직접 도달 가능한 관측치 벡터 \\(\\mathbf{x}_{1},\\mathbf{x}_{2},\\cdots,\\mathbf{x}_{n}\\) 이 연쇄적으로 존재한다면, \\(\\mathbf{q}\\) 는 \\(\\mathbf{p}\\) 로부터 밀도 기준 도달 가능한(Density-Reachable) 관측치 벡터임  \\(\\vert N_{\\varepsilon}(\\mathbf{p})\\vert \\ge \\text{MinPts}\\) : Core Point Condition  \\(\\mathbf{x}_{1} \\in N_{\\varepsilon}(\\mathbf{p})\\) : Reachability  \\(\\vert N_{\\varepsilon}(\\mathbf{x}_{\\forall})\\vert \\ge \\text{MinPts}\\) : \\(\\mathbf{x}_{\\forall}\\) 의 이웃 벡터 갯수가 하한선 $\\text{MinPts}$ 이상임  \\(\\mathbf{x}_{i+1} \\in N_{\\varepsilon}(\\mathbf{x}_{i})\\) : \\(\\mathbf{x}_{i+1}\\) 는 \\(\\mathbf{x}_{i}\\) 의 이웃 벡터임  \\(\\mathbf{q} \\in N_{\\varepsilon}(\\mathbf{x}_{n})\\) : \\(\\mathbf{q}\\) 는 \\(\\mathbf{x}_{n}\\) 의 이웃 벡터임Density-Connected  Core Point Condition 을 만족하는 관측치 벡터 \\(\\mathbf{p},\\mathbf{q} \\in D\\) 에 대하여, \\(\\mathbf{p}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 동시에 \\(\\mathbf{q}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 관측치 벡터 \\(\\mathbf{x} \\in D\\) 가 적어도 하나 존재한다면, \\(\\mathbf{p},\\mathbf{q}\\) 는 밀도 기준 연결되어 있음(Density-Connected)  $\\vert N_{\\varepsilon}(\\mathbf{p})\\vert \\ge \\text{MinPts}$  $\\mathbf{x} \\in N_{\\varepsilon}(\\mathbf{p})$  $\\vert N_{\\varepsilon}(\\mathbf{q})\\vert \\ge \\text{MinPts}$  $\\mathbf{x} \\in N_{\\varepsilon}(\\mathbf{q})$Sourse  https://ai.plainenglish.io/dbscan-density-based-clustering-aaebd76e2c8c  https://journals.sagepub.com/doi/10.1177/1748301817735665"
  },
  
  {
    "title": "k-Means",
    "url": "/posts/k_means/",
    "categories": "3.MACHINE LEARNING TECHS, 2.clustering algorithm",
    "tags": "machine learning, unsupervised learning, clustering, distance",
    "date": "2024-01-09 00:00:00 +0900",
    





    
    "snippet": "k-Means      k-Means: 중심점 기반 배타적 분리형 군집화 알고리즘으로서, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화하는 군집을 탐색함    \\[\\begin{aligned}  \\min_{\\mu_{i}}{\\sum_{i=1}^{k}\\sum_{\\mathbf{x}_{j} \\in C_{i}}{\\Vert\\mathbf{x}...",
    "content": "k-Means      k-Means: 중심점 기반 배타적 분리형 군집화 알고리즘으로서, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화하는 군집을 탐색함    \\[\\begin{aligned}  \\min_{\\mu_{i}}{\\sum_{i=1}^{k}\\sum_{\\mathbf{x}_{j} \\in C_{i}}{\\Vert\\mathbf{x}_{j}-\\mu_{i}\\Vert^{2}}}  \\end{aligned}\\]  Centroid Search Process      군집 갯수 설정\\[\\begin{aligned} X=C_{1} \\cup C_{2} \\cup \\cdots \\cup C_{k}, \\quad C_{i} \\cap C_{j \\ne i} = \\emptyset \\end{aligned}\\]        $k$ 개의 초기 군집 중심 벡터 $\\mathbf{c}$ 임의 선정\\[\\begin{aligned} M=\\left\\{\\mu_{1},\\mu_{2},\\cdots,\\mu_{k}\\right\\} \\end{aligned}\\]        모든 관측치 벡터 $\\mathbf{x}$ 를 가장 가까운 거리에 위치한 중심 벡터 $\\mu$ 의 군집에 배타적으로 할당\\[\\begin{aligned} \\mathbf{x}_{j} \\rightarrow C_{i} \\quad \\text{s.t.} \\quad  &amp; i=\\text{arg} \\min_{i}{\\Vert\\mathbf{x}_{j}-\\mu_{i}\\Vert^{2}}\\\\ &amp; \\mu_{i} \\in C_{i} \\end{aligned}\\]        각 군집별 할당된 관측치 벡터들의 평균 벡터로 군집 중심 벡터 갱신\\[\\begin{aligned} \\mu_{i} &amp;=\\frac{1}{\\vert C_{i} \\vert}\\sum_{\\mathbf{x}_{j}\\in C_{i}}{\\mathbf{x}_{j}} \\end{aligned}\\]        ③, ④의 과정을 반복하여 최적의 군집 중심 벡터 집합 $\\hat{M}$ 탐색\\[\\begin{aligned} \\hat{M} &amp;= \\left\\{\\mu_{i} \\mid \\text{arg} \\min_{\\mu_{i}}{\\sum_{i=1}^{k}\\sum_{\\mathbf{x}_{j} \\in C_{i}}{\\Vert\\mathbf{x}_{j}-\\mu_{i}\\Vert^{2}}}\\right\\} \\end{aligned}\\]  Limitation      Sensitive to initial cluster centroids            Sensitive to outliers            Difficulty detecting clusters of non-spherical shapes            Difficulty detecting clusters of different sizes            Difficulty detecting clusters of different densities      Sourse  https://ai-times.tistory.com/158  https://github.com/pilsung-kang/multivariate-data-analysis/blob/master/09%20Clustering/09-2_K-Means%20Clustering.pdf  https://github.com/lovit/python_ml_intro/blob/master/lecture_notes/10_clustering.pdf  https://paulvanderlaken.com/2018/12/12/visualizing-the-inner-workings-of-the-k-means-clustering-algorithm/"
  },
  
  {
    "title": "Clustering",
    "url": "/posts/clustering/",
    "categories": "3.MACHINE LEARNING TECHS, 2.clustering algorithm",
    "tags": "machine learning, unsupervised learning, clustering, metric",
    "date": "2024-01-08 00:00:00 +0900",
    





    
    "snippet": "Cluster Analysis      군집 분석(Cluster Analysis): 표본을 관측치 간 유사성과 상이성을 계산하여 군집 내 응집도를 최대화하는 동시에 군집 간 분리도를 최대화하는 $k$ 개의 군집으로 분할하는 작업              Cluster analysis or clustering is the task of grouping a...",
    "content": "Cluster Analysis      군집 분석(Cluster Analysis): 표본을 관측치 간 유사성과 상이성을 계산하여 군집 내 응집도를 최대화하는 동시에 군집 간 분리도를 최대화하는 $k$ 개의 군집으로 분할하는 작업              Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. (by.Wikipedia)            구분          Hard(or Crisp) Clustering      Soft(or Fuzzy) Clustering      Partitional Clustering      Hierarchical Clustering      Metrics  External : 정답 정보와의 비교          Rand Statistic      Jaccard Coefficient      Folks and Mallows Index      Hurbert $\\Gamma$ Statistic      V-Measure        Internal : 군집 내 응집도          Cophenetic Correlation Coefficient      Sum of Squared Error(SSE)      Cohesion and Separation        Relative : 군집 간 분리도          Dunn Family of Indices      Davies-Bouldin Index      Semi-partial R-squared      SD Validity Index      Silhouette      External Metrics      V-Measure : 정확성과 완전성의 조화평균\\[\\begin{aligned}  \\text{V}  &amp;= 2\\times\\frac{H(C \\mid K) \\cdot C(K \\mid C)}{H(C \\mid K) + C(K \\mid C)}  \\end{aligned}\\]          $H(C \\mid K)$ : 정확성(Homogeneity)      $C(K \\mid C)$ : 완전성(Completeness)            정확성(Homogeneity) : 각 군집의 클래스에 대한 엔트로피 합계\\[\\begin{aligned}  H(C \\mid K)  &amp;= -\\sum_{k=1}^{K}{\\sum_{c=1}^{C}{P(c \\mid k) \\cdot \\log{P(c \\mid k)}}}  \\end{aligned}\\]          $k$ : 군집 번호      $c$ : 클래스 번호      $P(c \\mid k)$ : 군집 $K=k$ 가 주어졌을 때, 클래스 $C=c$ 가 발생할 가능성            완전성(Completeness) : 각 클래스의 군집에 대한 엔트로피 합계\\[\\begin{aligned}  C(K \\mid C)  &amp;= -\\sum_{c=1}^{C}{\\sum_{k=1}^{K}{P(k \\mid c) \\cdot \\log{P(k \\mid c)}}}  \\end{aligned}\\]          $P(k \\mid c)$ : 클래스 $C=c$ 가 주어졌을 때, 군집 $K=k$ 가 발생할 가능성      Internal Metrics      Sum of Squared Error(SSE) : 각 군집의 중심점 벡터와 해당 군집 내 관측치 벡터 간 거리 자승으로 측정한 군집 응집도\\[\\begin{aligned}  \\text{SSE}  &amp;= \\sum_{k=1}^{K}{\\sum_{\\mathbf{x}_{i} \\in C_{k}}{\\Vert \\mathbf{x}_{i}-\\mu_{k} \\Vert^2}}  \\end{aligned}\\]          $k$ : 군집 번호      $C_{k}$ : $k$ 번째 군집      \\(\\mathbf{x}_{i} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 $i$ 번째 관측치 벡터      \\(\\mu_{k} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 중심 벡터      Relative Metrics      Dunn Index : 군집 내 응집도(Cohesion) 최대값 대비 군집 간 분리도(Separation) 최소값 비율\\[\\begin{aligned}  \\text{DI}  &amp;= \\frac{\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}}{\\max_{1 \\le k \\le K}{\\Delta(C_{k})}}  \\end{aligned}\\]          $\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}$ : 군집 간 분리도 최소값으로서 분리도에 대한 최악의 경우      $\\max_{1 \\le k \\le K}{\\Delta(C_{k})}$ : 군집 내 응집도 최대값으로서 응집도에 대한 최악의 경우            실루엣 계수(Silhouette) : 군집 내 응집성(cohesion)과 군집 간 분리도(separation)를 종합적으로 고려하여 측정한 개별 관측치 벡터에 대한 군집화 적합성의 평균값\\[\\begin{aligned}  \\text{S}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\frac{b(\\mathbf{x}_{i})-a(\\mathbf{x}_{i})}{\\max{[a(\\mathbf{x}_{i}),b(\\mathbf{x}_{i})]}}}  \\end{aligned}\\]          \\(a(\\mathbf{x}_{i})\\) : 관측치 벡터 \\(\\mathbf{x}_{i}\\) 기준 군집 내 응집도로서, 해당 관측치와 같은 군집에 속한 관측치와의 평균 거리      \\(b(\\mathbf{x}_{i})\\) : 관측치 벡터 \\(\\mathbf{x}_{i}\\) 기준 군집 간 분리도로서, 해당 관측치와 다른 군집에 속한 관측치와의 평균 거리 중 최소값      Sourse  https://www.scaler.com/topics/supervised-and-unsupervised-learning/  https://towardsdatascience.com/a-brief-introduction-to-unsupervised-learning-20db46445283  https://tyami.github.io/machine%20learning/clustering/"
  },
  
  {
    "title": "Ensemble",
    "url": "/posts/ensemble/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning, supervised learning, ensemble, categorical data analysis",
    "date": "2024-01-06 00:00:00 +0900",
    





    
    "snippet": "Ensemble      앙상블 기법(Ensemble) : 예측 오차를 줄이기 위하여 다양한 모형들을 결합하는 기법    예측 오차를 어떻게 줄일 것인가?          By Reducing Variance, Prevent Overfitting      By Reducing Bias, Prevent Underfitting        모형 간 다양성...",
    "content": "Ensemble      앙상블 기법(Ensemble) : 예측 오차를 줄이기 위하여 다양한 모형들을 결합하는 기법    예측 오차를 어떻게 줄일 것인가?          By Reducing Variance, Prevent Overfitting      By Reducing Bias, Prevent Underfitting        모형 간 다양성을 어떻게 확보할 것인가?          Provide different random subset of the training data to each other      Using some measurement ensuring it is substantially different from the other members        모형별 결과물을 어떻게 결합할 것인가?          Simple Voting      Weighted Voting      Bias-Variance Trade-off  Notation          $Y$ : 실제 관측치      $\\varepsilon \\sim N(0, \\sigma^2)$ : 노이즈      $f(X)$ : 실제 함수      $\\hat{f}(X)$ : $f(X)$ 에 대한 예측값      $\\overline{f}(X)$ : $\\hat{f}(X)$ 의 평균            error segmentation:\\[\\begin{aligned}  \\text{Error}  &amp;= \\mathbb{E}\\left[\\left(Y-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2} + \\varepsilon^{2} - 2 \\cdot \\varepsilon \\cdot \\left(f(X)-\\hat{f}(X)\\right) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\varepsilon^{2}\\right] - 2 \\cdot \\mathbb{E}\\left[\\varepsilon\\right] \\cdot \\mathbb{E}\\left[f(X)-\\hat{f}(X) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\sigma^{2}  \\end{aligned}\\]        estimation error:\\[\\begin{aligned}  &amp;\\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)+\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right] + 2 \\cdot \\mathbb{E}\\left[f(X)-\\overline{f}(X)\\right] \\cdot \\mathbb{E}\\left[\\overline{f}(X)-\\hat{f}(X)\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        estimation error consists of bias and variance:\\[\\begin{aligned}  \\mathrm{Bias}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\hat{f}(X)\\right] - f(X)\\\\  \\mathrm{Var}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  \\therefore \\text{Error}  &amp;= \\mathrm{Bias}^{2}\\left[\\hat{f}(X)\\right] + \\mathrm{Var}\\left[\\hat{f}(X)\\right] + \\sigma^{2}  \\end{aligned}\\]        Bias-Variance Trade-off:              Bias is the underfitting problem that occurs when a model does not sufficiently learn the patterns of the training data.      Variance is the overfitting problem that occurs when a model adapts too much to the training data.      Why? Ensemble\\[\\begin{aligned}\\xi_{\\text{ensemble}} \\le \\xi_{\\text{avg}}\\end{aligned}\\]      $m$ 번째 모형의 예측값을 다음과 같이 정의하자\\[\\begin{aligned}  \\underbrace{y_{m}(x)}_{\\begin{array}{c} \\text{predict value} \\\\ \\text{of m-th model} \\end{array}}  &amp;= \\underbrace{f(x)}_{\\text{real value}} + \\underbrace{\\epsilon_{m}(x)}_{\\begin{array}{c} \\text{error} \\\\ \\text{of m-th model} \\end{array}}  \\end{aligned}\\]        $m$ 번째 모형의 예측 오차의 자승을 다음과 같이 나타낼 수 있음\\[\\begin{aligned}  \\therefore \\mathbb{E}\\left[\\epsilon_{m}^{2}(x)\\right]  &amp;= \\mathbb{E}\\left[\\left(y_{m} - f(x)\\right)^{2}\\right]  \\end{aligned}\\]        개별 모형의 예측 오차 자승 평균 $\\xi_{\\text{avg}}$\\[\\begin{aligned}  \\xi_{\\text{avg}}  &amp;= \\frac{1}{M}\\sum_{m=1}^{M}{\\mathbb{E}\\left[\\epsilon_{m}^{2}(x)\\right]}  \\end{aligned}\\]        앙상블 모형의 예측 오차 자승 $\\xi_{\\text{ensemble}}$\\[\\begin{aligned}  \\xi_{\\text{ensemble}}  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{y_{m}(x)}-f(x)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{y_{m}(x)}-\\frac{1}{M}\\sum_{m=1}^{M}{f(x)}\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{\\epsilon_{m}(x)}\\right)^{2}\\right]  \\end{aligned}\\]        Cauchy-Schwartz Inequation\\[\\begin{aligned}  \\left(\\alpha_{1} \\cdot \\beta_{1} + \\cdots + \\alpha_{n} \\cdot \\beta_{n}\\right)^{2} \\le \\left(\\alpha_{1}^{2}+\\cdots+\\alpha_{n}^{2}\\right)\\left(\\beta_{1}^{2}+\\cdots+\\beta_{n}^{2}\\right)  \\end{aligned}\\]        $\\text{if} \\quad \\alpha_{m}=1, \\beta_{m}=\\epsilon_{m}(x)$\\[\\begin{aligned}  \\left(\\sum_{m=1}^{M}{1 \\cdot \\epsilon_{m}(x)}\\right)^{2} \\le M \\cdot \\sum_{m=1}^{M}{\\epsilon_{m}^{2}(x)}  \\end{aligned}\\]        $\\times \\displaystyle\\frac{1}{M^{2}}$\\[\\begin{aligned}  \\underbrace{\\left(\\frac{1}{M}\\sum_{m=1}^{M}{\\epsilon_{m}(x)}\\right)^{2}}_{\\xi_{\\text{ensemble}}} \\le \\underbrace{\\frac{1}{M} \\sum_{m=1}^{M}{\\epsilon_{m}^{2}(x)}}_{\\xi_{\\text{avg}}}  \\end{aligned}\\]  Bagging      Bagging(Bootstrap Aggregating) : 데이터 세트로부터 생성된 $M$ 개의 부트스트랩(Bootstrap)을 통해 $M$ 개의 개별 모형들을 병렬 학습하는 방법    \\[\\begin{aligned}  y(x)  &amp;= \\delta\\Big[y_{1}(x), y_{2}(x), \\cdots, y_{M}(x)\\Big]  \\end{aligned}\\]          By Reducing Variance, Prevent Overfitting      Provide different random subset of the training data to each other            부트스트랩(Bootstrap) : 전체 데이터 세트를 $K$ 개의 데이터 블록으로 분할한 후 $K$ 번 복원추출하여 재구성한 훈련용 데이터 세트                  데이터 세트 \\(x \\in \\mathcal{D}\\) 를 \\(k\\) 개의 데이터 블록 \\(\\Lambda^{(1)}, \\cdots, \\Lambda^{(K)}\\) 으로 나누자\\[\\begin{aligned}  \\mathcal{D}  &amp;= \\left\\{ x_{1}, x_{2}, \\cdots, x_{N} \\right\\}\\\\  &amp;= \\Lambda^{(1)} \\cup \\Lambda^{(2)} \\cup \\cdots \\cup \\Lambda^{(K)} \\quad \\text{s.t.}\\quad \\Lambda^{(i)} \\cap \\Lambda^{(j \\ne i)} = \\emptyset  \\end{aligned}\\]                    \\(\\Lambda^{(k)}\\) 를 \\(K\\) 번 복원추출하여 \\(m\\) 번째 모형의 훈련용 데이터 세트를 구성함\\[\\begin{aligned}  \\Omega^{(m)}_{\\text{trn}}  &amp;= \\left\\{\\Lambda^{(k)}_{l} \\mid \\Lambda^{(k)} \\subseteq \\mathcal{D}, k \\in \\{1, 2, \\cdots, K\\}, l=1,2,\\cdots,K\\right\\}  \\end{aligned}\\]                  OOB(Out of Bag) : 부트스트랩에 포함되지 않는 데이터 블록 집합으로서 검증용 데이터 세트로 활용됨                  $m$ 번째 모형의 검증용 데이터 세트는 해당 모형의 부트스트랩에 포함되지 않은 데이터 블록으로 구성함\\[\\begin{aligned}  \\Omega^{(m)}_{\\text{val}}  &amp;= \\bigcup_{k=1}^{K}{\\Lambda^{(k)}} \\setminus \\Omega^{(m)}_{\\text{trn}}  \\end{aligned}\\]                    하나의 데이터 블록이 부트스트랩에 포함되지 않을 확률\\[\\begin{aligned}  \\lim_{K \\rightarrow \\infty}{\\left(1-\\frac{1}{K}\\right)^{K}}  = e^{-1} \\approx 0.368  \\end{aligned}\\]                  Result Aggregating Function($\\delta(\\cdot)$)          Simple Voting      Weighted Voting(training accuarcy of individual models)      Weighted Voting(probability result)      Staking      Boosting      Boosting : 직렬로 나열된 개별 모형들에 대하여 모든 훈련 데이터 세트를 순차 학습하되, 현재 순번 모형이 오류를 줄이는 데 실패한 데이터 포인트에 대하여, 해당 포인트의 중요도를 가중함으로써 다음 모형이 더 집중하여 학습시키는 방법    \\[\\begin{aligned}  y_{M}(x)  &amp;= \\sum_{t=1}^{M}{\\alpha_{t} \\cdot h_{t}(x)}  \\end{aligned}\\]          By Reducing Bias, Prevent Underfitting      Using some measurement ensuring it is substantially different from the other members            예측값 $y_{t}(x)$ 및 모형 $h_{t}(x)$                  $t$ 번째 순번에서 $i$ 번째 관측치의 예측값 $y_{t}(x_{i})$ 을 다음과 같이 정의하자\\[\\begin{aligned}  \\underbrace{y_{t}(x_{i})}_{\\begin{array}{c} \\text{predict value} \\\\ \\text{of t-th model} \\end{array}}  &amp;= \\underbrace{f(x_{i})}_{\\text{real value}} + \\underbrace{\\epsilon_{t}(x_{i})}_{\\begin{array}{c} \\text{error} \\\\ \\text{of t-th model} \\end{array}}  \\end{aligned}\\]                    $t+1$ 번째 순번에서 $i$ 번째 관측치의 예측값 $y_{t+1}(x_{i})$ 을 다음의 규칙에 따라 갱신함\\[\\begin{aligned}  y_{t+1}(x_{i})  &amp;= y_{t}(x_{i}) + \\alpha_{t+1} \\cdot h_{t+1}(x_{i})  \\end{aligned}\\]                    이때 $t+1$ 번째 순번 모형 $h_{t+1}$ 을 다음과 같이 도출함\\[\\begin{aligned}  h_{t+1}  &amp;= \\text{arg} \\min_{h}{\\sum_{i=1}^{n}{L\\left[\\epsilon_{t}(x_{i}), h(x_{i})\\right]}}  \\end{aligned}\\]                  모형별 중요도(가중 평균)                  $t$ 번째 순번 모형의 중요도 $\\alpha_{t}$ 를 다음과 같이 정의함\\[\\begin{aligned}  \\alpha_{t}  &amp;= \\frac{1}{2}\\ln{\\frac{1-\\xi_{t}}{\\xi_{t}}}  \\end{aligned}\\]                    이때 $t$ 번째 순번 모형의 예측 오류율 $\\xi_{t}$ 은 다음과 같음\\[\\begin{aligned}  \\xi_{t}  &amp;= \\frac{\\sum_{i=1}^{n}{w_{i} \\cdot \\mathbb{I}\\left[h_{t}(x_{i}) \\ne f(x_{i})\\right]}}{\\sum_{j=1}^{n}{w_{j}}}  \\end{aligned}\\]                  관측치별 중요도                  $t$ 번째 순번에서 $i$ 번째 관측치 $x_{i} \\in \\mathcal{D}$ 의 중요도 $P(x_{i})$ 를 다음과 같이 정의하자\\[\\begin{aligned}  P(x_{i})  &amp;= \\frac{w_{i}}{\\sum_{j=1}^{n}{w_{j}}}  \\end{aligned}\\]                    $i$ 번째 관측치 $x_{i} \\in \\mathcal{D}$ 의 가중치 $w_i$ 를 다음의 규칙에 따라 갱신함\\[\\begin{aligned}  w_i  &amp; \\leftarrow w_{i} \\cdot \\exp{\\bigg[\\alpha_{t} \\cdot \\mathbb{I}\\left[h_{t}(x_{i}) \\ne f(x_{i})\\right]\\bigg]}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Decision Tree",
    "url": "/posts/decision_tree/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning, supervised learning, gini, entropy, categorical data analysis",
    "date": "2024-01-05 00:00:00 +0900",
    





    
    "snippet": "Decision Tree      결정 트리(Decision Tree): 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘              루트 노드(Root Node) : 깊이가 $0$ 인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : ...",
    "content": "Decision Tree      결정 트리(Decision Tree): 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘              루트 노드(Root Node) : 깊이가 $0$ 인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건      리프 노드(Leaf Node) : 하위 노드가 존재하지 않는 노드로서 최종 범주      서브트리(Subtree) : 어떠한 규칙 노드를 루트 노드로 가지는 하위 트리로서 판별 규칙 집합의 부분집합      Recursive Partitioning      재귀적 분기(Recursive Partitioning) : 판별 규칙을 기준으로 상위 노드를 분할하여 순도가 높은 하위 노드를 생성하는 반복적인 과정                  판별 규칙 : 어떤 분기에서 하나의 설명변수를 사용하여 생성한 분할 조건                            순도(Purity) : 어떤 노드에 속한 관측치들이 동일한 범주에 속하는 정도                          순도를 정확히 측정하기 어려우므로 그 대리변수로서 불순도(Impurity)를 사용함                    Discriminant Rule      어떤 노드에 대하여, 설명변수 $X_{i} \\ge x_{i}$ 를 기준으로 해당 노드를 분할한다고 하자\\[\\begin{aligned}  y=\\begin{cases}  N_{\\text{Left}},\\quad &amp; \\text{if} \\quad X_{i} \\ge x_{i}\\\\  N_{\\text{Right}},\\quad &amp; \\text{if} \\quad X_{i} &lt; x_{i}\\\\  \\end{cases}  \\end{aligned}\\]        판별 규칙 $X_{i} \\ge x_{i}$ 의 비용 $\\mathcal{J}(X_{i} \\ge x_{i})$ 는 다음과 같음\\[\\begin{aligned}  \\mathcal{J}(X_{i} \\ge x_{i})  &amp;= \\frac{m_{\\text{Left}}}{m}I_{\\text{Left}} + \\frac{m_{\\text{Right}}}{m}I_{\\text{Right}}  \\end{aligned}\\]          $m$ : 결정 노드에 속한 관측치 갯수      $m_{\\text{Left}}$ : 좌측 하위 노드로 분기한 관측치 갯수      $I_{\\text{Left}}$ : 좌측 하위 노드의 불순도      $m_{\\text{Right}}$ : 우측 하위 노드로 분기한 관측치 갯수      $I_{\\text{Right}}$ : 우측 하위 노드의 불순도            설명변수 $X_{i}$ 기준 분할 시 최적의 분기점 $\\hat{x}_{i}$ 는 다음과 같음\\[\\begin{aligned}  \\hat{x}_{i}  =\\text{arg} \\min_{x_{i}}{\\mathcal{J}(X_{i} \\ge x_{i})}  \\end{aligned}\\]        특정 노드를 분할하는 최적의 설명변수 $\\hat{X}_{i}$ 는 다음과 같음\\[\\begin{aligned}  \\hat{X}_{i}  = \\text{arg} \\min_{X_{i}}{\\left\\{\\min{\\mathcal{J}(X_{1})},\\min{\\mathcal{J}(X_{2})},\\cdots,\\min{\\mathcal{J}(X_{n})}\\right\\}}  \\end{aligned}\\]  Impurity      지니 지수(Gini Index) : 불순도를 경제적 불평등 개념 에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율            엔트로피 지수(Entropy Index) : 불순도를 정보 획득의 불확실성 개념 에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= -\\sum_{i=1}^{c}{\\left[p_{i} \\cdot \\log_{2}{p_{i}}\\right]}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율      Pruning      가지치기(Pruning) : 자세하게 구분된 영역을 통합함으로써 과적합을 방지하는 기법으로서, Full Tree 를 생성하여 모든 노드에 대하여 비용 복잡도 지수를 계산하고, 그 값이 가장 낮은 노드에 대하여 가지치기를 반복적으로 수행하면서 최적의 가지치기 강도 $\\alpha$ 하 트리를 도출함        비용 복잡도 지수(Cost-Complexity)\\[\\begin{aligned}  R_{\\alpha}(T)  &amp;= L(T) + \\alpha \\cdot \\vert\\text{Leaf}(T)\\vert\\\\  L(T)  &amp;= \\sum_{m=1}^{\\vert\\text{Leaf}(T)\\vert}{\\sum_{\\mathbf{x}_{i} \\in R_{m}}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}}  \\end{aligned}\\]          $T$ : 타깃 노드를 루트 노드로 하는 서브트리      $\\text{Leaf}(T)$ : $T$ 의 리프 노드 집합      $R_{m} \\in \\text{leaf}(T)$ : $T$ 의 $m$ 번째 리프 노드      \\(\\mathbf{x}_{i} \\in R_{m}\\) : \\(R_{m}\\) 에 속한 \\(i\\) 번째 관측치 벡터      $\\alpha$ : 가지치기 강도      $L(T)$ : $T$ 의 훈련 관측치에 대한 예측 손실      $R_{\\alpha}(T)$ : 타깃 노드의 비용 복잡도 지수      DTR      재귀적 분기\\[\\begin{aligned}  \\hat{X}_{i}  &amp;= \\text{arg} \\min_{X_{i}}{\\{\\mathcal{J}(X_{1},\\hat{x}_{1}),\\mathcal{J}(X_{2},\\hat{x}_{2}),\\cdots,\\mathcal{J}(X_{n},\\hat{x}_{n})\\}}\\\\  \\hat{x}_{i}  &amp;= \\text{arg} \\min_{x_{i}}{\\mathcal{J}(X_{i},x_{i})}\\\\  \\mathcal{J}(X_{i},x_{i})  &amp;= \\frac{m_{\\text{Left}}}{m}L_{\\text{Left}}+\\frac{m_{\\text{Right}}}{m}L_{\\text{Right}}  \\end{aligned}\\]        손실 함수                      판별 분석 : 불순도(Impurity)를 최소화하도록 분기\\[\\begin{aligned}  \\mathcal{L}_{\\text{GINI}}(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]                    회귀 분석 : 오차(Error)를 최소화하도록 분기\\[\\begin{aligned}  \\mathcal{L}_{\\text{MSE}}(N_{k})  &amp;= \\sum_{i=1}^{m}{(y_{i}-\\hat{y}_{i})^2}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Support Vector Machine",
    "url": "/posts/svm/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning, supervised learning, distance, kernel function, categorical data analysis",
    "date": "2024-01-04 00:00:00 +0900",
    





    
    "snippet": "Support Vector Machine      서포트 벡터 머신(Support Vector Machine): 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) ...",
    "content": "Support Vector Machine      서포트 벡터 머신(Support Vector Machine): 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장 가까이 위치한 벡터      마진(Margin) : 인접한 두 범주의 서포트 벡터를 지나는 평행한 두 직선 사이의 유클리드 거리      Decision Function      Class of New Obs \\(\\mathbf{q}\\):\\[\\begin{aligned}  y_{q}  &amp;= \\begin{cases}  +1, \\quad &amp;\\text{if} \\quad f(\\mathbf{q}) &gt; 0 \\\\  -1, \\quad &amp;\\text{if} \\quad f(\\mathbf{q}) &lt; 0 \\\\  \\end{cases}  \\end{aligned}\\]        Decision Function is the Projection Distance between the Hyperplane and the Vector:\\[\\begin{aligned}  f(\\mathbf{q})  &amp;= \\mathbf{w}^{*} \\cdot \\mathbf{q} + b^{*}\\\\  &amp;= \\left(\\sum_{i \\in SV}{\\lambda_{i}y_{i}\\mathbf{x}_{i}}\\right) \\cdot \\mathbf{q} + \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\mathbf{x}_{j}\\mathbf{x}_{i}\\right]}  \\end{aligned}\\]  Concept      Hyper-Plane\\[\\begin{aligned}  \\mathbf{w}^{T}\\mathbf{x}+b  &amp;=0  \\end{aligned}\\]          \\(\\mathbf{x}\\) : 초평면 위에 위치한 벡터      \\(\\mathbf{w}\\) : 초평면의 법선 벡터      \\(b\\) : 편향으로서 세로축 절편            Class\\[\\begin{aligned}  y_{i} = \\begin{cases}  +1,\\quad &amp;\\text{if} \\quad \\mathbf{x}_{i} \\in \\mathbf{X}^{+}\\\\  -1,\\quad &amp;\\text{if} \\quad \\mathbf{x}_{i} \\in \\mathbf{X}^{-}  \\end{cases}  \\end{aligned}\\]        Support Vector                  Left Support Vector \\(\\mathbf{x}^{+}\\):\\[\\begin{aligned}  \\mathbf{w}^{T}\\mathbf{x}^{+}+b  &amp;=+1  \\end{aligned}\\]                    Right Support Vector \\(\\mathbf{x}^{-}\\):\\[\\begin{aligned}  \\mathbf{w}^{T}\\mathbf{x}^{-}+b  &amp;=-1  \\end{aligned}\\]            Margin      우측 서포트 벡터 \\(\\mathbf{x}^{-}\\) 를 방향 \\(\\mathbf{w}\\) 으로 크기 \\(\\text{margin}\\) 만큼 이동하면 좌측 서포트 벡터 \\(\\mathbf{x}^{+}\\) 에 안착한다고 하자\\[\\begin{aligned}  \\mathbf{x}^{+}  &amp;= \\mathbf{x}^{-} + \\text{margin} \\cdot \\mathbf{w}  \\end{aligned}\\]        \\(\\mathbf{w}^{T}\\mathbf{x}^{+}+b=1\\) 을 다음과 같이 재정의할 수 있음\\[\\begin{aligned}  \\mathbf{w}^{T}\\mathbf{x}^{+}+b  &amp;=1\\\\  \\mathbf{w}^{T}\\left(\\mathbf{x}^{-} + \\text{margin} \\cdot \\mathbf{w}\\right)+b  &amp;=1\\\\  \\mathbf{w}^{T}\\mathbf{x}^{-} + \\text{margin} \\cdot \\mathbf{w}^{T}\\mathbf{w} + b  &amp;=1\\\\  \\left(\\mathbf{w}^{T}\\mathbf{x}^{-} + b\\right) + \\text{margin} \\cdot \\mathbf{w}^{T}\\mathbf{w}  &amp;=1\\\\  -1 + \\text{margin} \\cdot  \\Vert \\mathbf{w} \\Vert ^2  &amp;= 1  \\end{aligned}\\]        따라서 마진을 다음과 같이 도출할 수 있음\\[\\begin{aligned}  \\text{margin}  &amp;= \\frac{2}{ \\Vert \\mathbf{w} \\Vert ^2}  \\end{aligned}\\]  Maximum Margin      Definition of Optimization Problem                  Objective Function:\\[\\begin{aligned}  \\max{\\frac{2}{ \\Vert \\mathbf{w} \\Vert ^2}}  \\Rightarrow \\min{\\frac{1}{2} \\Vert \\mathbf{w} \\Vert ^2}  \\end{aligned}\\]                    Constraint:\\[\\begin{aligned}  y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i}+b\\right)  \\ge 1  \\end{aligned}\\]                  Lagrangian Function                  Lagrangian Function:\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{w},b,\\lambda)  &amp;=\\frac{1}{2} \\Vert \\mathbf{w} \\Vert ^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\left[y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i}+b\\right)-1\\right]}  \\end{aligned}\\]                  $\\lambda_{i}\\ge 0$ : 라그랑주 승수                            Complementary Slackness, KKT Conditions:\\[\\begin{aligned}  \\lambda_{i}\\cdot\\left[y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i}+b\\right)-1\\right]  &amp;=0  \\end{aligned}\\]                  Support Vector : \\(y_{i \\in SV}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i \\in SV}+b\\right)-1=0 \\quad \\because \\mathbf{w}^{T}\\mathbf{x}_{i \\in SV}+b = 1\\)          Others : \\(\\lambda_{i \\notin SV}=0 \\quad \\because \\mathbf{w}^{T}\\mathbf{x}_{i \\notin SV}+b &gt; 1\\)                          Maximum Margin\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max{\\mathcal{L}\\left(\\mathbf{w},b,\\lambda\\right)}  \\end{aligned}\\]                  The Normal Vector \\(\\mathbf{w}^{*}\\) that maximizes the margin is:\\[\\mathbf{w}^{*}  = \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\mathbf{x}_{i}}\\]                    The Bias \\(b^{*}\\) that maximizes the margin is:\\[\\begin{aligned}  b^{*}  &amp;= y_{i \\in SV} - \\mathbf{w}^{T}\\mathbf{x}_{i \\in SV}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}{\\left[y_{i} - \\mathbf{w}^{T}\\mathbf{x}_{i}\\right]}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}{\\left[y_{i} - \\left(\\sum_{j \\in SV}{\\lambda_{j}y_{j}\\mathbf{x}_{j}}\\right)\\mathbf{x}_{i}\\right]}\\quad \\because \\mathbf{w}^{*}=\\sum_{i}{\\lambda_{i}y_{i}\\mathbf{x}_{i}}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\mathbf{x}_{j}\\mathbf{x}_{i}\\right]}  \\end{aligned}\\]                    The Support Vector \\(\\mathbf{x}_{SV} \\in SV\\) that maximizes the margin is:\\[\\begin{aligned}  SV   &amp;= \\left\\{\\mathbf{x}_{SV} \\mid \\mathbf{w}^{*} \\cdot \\mathbf{x}_{SV} + b^{*} = \\vert 1 \\vert \\right\\}\\\\  &amp;= \\left\\{\\mathbf{x}_{SV} \\mid \\left(\\sum_{i=1}^{n}{\\lambda_{i}^{*}y_{i}\\mathbf{x}_{i}}\\right) \\cdot \\mathbf{x}_{SV} + \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\mathbf{x}_{j}\\mathbf{x}_{i}\\right]}= \\vert 1 \\vert  \\right\\}  \\end{aligned}\\]            Soft Margin  Soft Margin : 마진 위반 $\\xi$ 를 허용하여 일부 이상 관측치를 배제했을 때 마진을 최대화하는 초평면을 탐색함          마진 위반(Margin Violation; $\\xi$) : 초평면 근방에서 발생 가능한 소수의 이상 관측치에 대한 오류로서, 해당 관측치로부터 서포트 벡터를 지나고 초평면과 평행한 직선까지의 유클리드 거리            Definition of Optimization Problem\\[\\begin{aligned}  \\min{\\left[\\frac{1}{2}{ \\Vert \\mathbf{w} \\Vert ^2}+C\\sum_{i=1}^{n}{\\xi_i}\\right]}  \\quad \\text{s.t.} \\quad &amp;y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i}+b\\right) \\ge 1-\\xi_i,\\\\  &amp;\\xi_i \\ge 0  \\end{aligned}\\]          $\\xi_{i}$ : 관측치 벡터 $\\mathbf{x}_{i}$ 에 대한 마진 위반              $C$ : 마진 위반에 대한 규제 강도                          Lagrangian Function\\[\\begin{aligned}  \\mathcal{L}(\\mathbf{w},b,\\lambda,\\xi,\\mu)  &amp;= \\left[\\frac{1}{2} \\Vert \\mathbf{w} \\Vert ^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\left[y_{i}\\left(\\mathbf{w}^{T}+b\\right)-\\left(1-\\xi_{i}\\right)\\right]}\\right] + \\left[C\\sum_{i=1}^{n}{\\xi_{i}}-\\sum_{i=1}^{b}{\\mu_{i}\\xi_{i}}\\right]  \\end{aligned}\\]          $\\lambda \\ge 0$ : 제약 조건 \\(y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}+b\\right) \\ge 1-\\xi_{i}\\) 에 대한 라그랑주 승수      $\\mu \\ge 0$ : 제약 조건 $\\xi_{i} \\ge 0$ 에 대한 라그랑주 승수      SVR      Optimization\\[\\begin{aligned}  \\hat{\\Theta}  =\\text{arg} \\min{\\left[\\frac{1}{2} \\Vert \\mathbf{w} \\Vert^{2} + C\\sum_{i=1}^{n}{\\left(\\xi_{i}+\\eta_{i}\\right)}\\right]}  \\end{aligned}\\]        Constraint                      판별 분석 : 마진 범위 이내에 관측치 벡터가 존재하지 않음\\[\\begin{aligned}  \\text{s.t.}\\quad  &amp;y_{i}\\left(\\mathbf{w}^{T}\\mathbf{x}_{i}+b\\right) \\ge 1 + \\xi_{i}\\\\  &amp;\\xi_{i} \\ge 0  \\end{aligned}\\]                    회귀 분석 : 마진 범위 이내에 모든 관측치 벡터가 존재함\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp; \\varepsilon + \\xi_{i} + f\\left(\\mathbf{x}\\right) - y_{i} \\ge 0,\\\\  &amp; \\varepsilon + \\eta_{i} - f\\left(\\mathbf{x}\\right) + y_{i} \\ge 0,\\\\  &amp; \\xi_{i}, \\eta_{i} \\ge 0  \\end{aligned}\\]            Sourse  https://velog.io/@shlee0125  https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927"
  },
  
  {
    "title": "k-NN",
    "url": "/posts/knn/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning, supervised learning, distance, categorical data analysis",
    "date": "2024-01-03 00:00:00 +0900",
    





    
    "snippet": "k-Nearest Neighbors      k-최근접 이웃(k-Nearest Neighbors): 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]  Distance      맨해튼 거리(Manhattan Distance; L1): 두...",
    "content": "k-Nearest Neighbors      k-최근접 이웃(k-Nearest Neighbors): 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]  Distance      맨해튼 거리(Manhattan Distance; L1): 두 점 사이의 엣지(Edge) 갯수    \\[\\begin{aligned}  \\mathrm{d}(\\mathbf{a},\\mathbf{b})  = \\Vert \\mathbf{a} - \\mathbf{b} \\Vert _{L1}  = \\sum_{i=1}^{n}{\\vert a_i - b_i \\vert}  \\end{aligned}\\]          \\(\\mathbf{e}_{1}, \\mathbf{i}_{2}, \\cdots, \\mathbf{e}_{n}\\) 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\mathbf{a}, \\mathbf{b}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리를 합산한 값            유클리드 거리(Euclidean Distance; L2): 두 점 사이의 직선 거리    \\[\\begin{aligned}  \\mathrm{d}(\\mathbf{a},\\mathbf{b})  = \\Vert \\mathbf{a} - \\mathbf{b} \\Vert _{L2}  = \\sqrt{\\sum_{i=1}^{n}{(a_i - b_i)^{2}}}  \\end{aligned}\\]          \\(\\mathbf{e}_{1}, \\mathbf{e}_{2}, \\cdots, \\mathbf{e}_{n}\\) 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 \\(\\mathbf{a}, \\mathbf{b}\\) 에 대하여 각 축 방향으로의 기저벡터 단위 거리의 제곱을 합산한 후 제곱근한 값            코사인 거리(Cosine Distance; $\\cos$): 임의의 두 점에 대하여, 원점과 각 점을 잇는 직선의 사이각 $\\theta$ 의 코사인 값    \\[\\begin{aligned}  \\mathrm{d}(\\mathbf{a},\\mathbf{b})  = \\cos{\\theta}  = \\frac{\\mathbf{a}^{T}\\mathbf{b}}{\\Vert \\mathbf{a} \\Vert \\cdot \\Vert \\mathbf{b} \\Vert}  = \\frac{\\sum_{i=1}^{n}{a_{i}b_{i}}}{\\sqrt{\\sum_{i=1}^{n}{a_{i}^{2}}} \\cdot \\sqrt{\\sum_{i=1}^{n}{b_{i}^{2}}}}  \\end{aligned}\\]        하버사인 거리(Haversine Distance; $\\text{hav}$): 구 표면상에 존재하는 두 지점에 대하여, 위도($\\varphi$), 경도($\\lambda$) 및 호 중심각($\\Theta$)을 활용하여 측정한 호의 길이                      반지름이 $r$, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta  \\end{aligned}\\]                    점 $A$,$B$ 의 위도가 $\\varphi_{A}$,$\\varphi_{B}$, 경도가 $\\lambda_{A}$,$\\lambda_{B}$ 이고, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호의 길이 $\\text{hav}{\\Theta}$ 는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\text{hav}(\\varphi_{B}-\\varphi_{A})  + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})  \\end{aligned}\\]                    $\\sin$, $\\cos$, $\\text{hav}$ 의 관계는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\sin^{2}{\\frac{\\Theta}{2}}\\\\  &amp;= \\frac{1-\\cos{\\Theta}}{2}  \\end{aligned}\\]                    따라서 반지름, 경도, 위도가 주어졌을 때 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta\\\\  &amp;= r \\cdot \\text{archav}(\\text{hav}{\\Theta})\\\\  &amp;= 2r \\cdot \\arcsin(\\sqrt{\\text{hav}{\\Theta}})\\\\  &amp;= 2r \\cdot \\arcsin\\left(\\sqrt{\\text{hav}(\\varphi_{B}-\\varphi_{A}) + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})}\\right)  \\end{aligned}\\]            Sourse  https://076923.github.io/posts/Python-opencv-43/"
  },
  
  {
    "title": "Supervised Model Selection",
    "url": "/posts/supervised_model_selection/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning, supervised learning, metric, cross validation",
    "date": "2024-01-02 00:00:00 +0900",
    





    
    "snippet": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitiv...",
    "content": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitive) 중 잘못 예측한(False) 항목  FN(False Negative) : 부정으로 예측한 것(Negative) 중 잘못 예측한(False) 항목Sensitive to Threshold      정확도(Accuracy) : 전체 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}  \\end{aligned}\\]        민감도(Sensitivity) 혹은 재현율(Recall) : 실제 긍정인 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}  \\end{aligned}\\]          제1종 오류(참을 거짓으로 예측하는 오류; FN)를 강조하는 지표            특이도(Specificity) : 실제 부정인 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}  \\end{aligned}\\]        정밀도(Precision) : 긍정으로 예측한 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}  \\end{aligned}\\]          제2종 오류(거짓을 참으로 예측하는 오류; FP)를 강조하는 지표            F1-Score : 재현율과 정밀도의 조화 평균\\[\\begin{aligned}  2 \\times \\frac{\\text{Prec} \\times \\text{Rec}}{\\text{Prec} + \\text{Rec}}  \\end{aligned}\\]  AUROC : Robust to Threshold      ROC Curve(Receiver Operating Characteristic Curve) : $\\text{FPR}$ 값에 따른 $\\text{TPR}$ 의 변화 추이를 나타낸 곡선            AUROC(Area Under ROC) : ROC Curve 아래 면적\\[\\begin{aligned}  0.5 \\le \\text{AUROC} \\le 1  \\end{aligned}\\]                  FNR(False Negative Rate) : 실제 긍정인 관측치(TP+FN) 대비 잘못 예측한 관측치(FN) 비율\\[\\begin{aligned}  \\text{FNR}  &amp;=\\frac{\\text{FN}}{\\text{TP}+\\text{FN}}  \\end{aligned}\\]                    TPR(True Positive Rate) : 실제 긍정인 관측치(TP+FN) 대비 옳게 예측한 관측치(TP) 비율\\[\\begin{aligned}  \\text{TPR}  &amp;=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}} = 1-\\text{FNR}  \\end{aligned}\\]                    FPR(False Possitive Rate) : 실제 부정인 관측치(TN+FP) 대비 잘못 예측한 관측치(FP) 비율\\[\\begin{aligned}  \\text{FPR}  &amp;=\\frac{\\text{FP}}{\\text{TN}+\\text{FP}}  \\end{aligned}\\]                    TNR(True Negative Rate) : 실제 부정인 관측치(TN+FP) 대비 옳게 예측한 관측치(TN) 비율\\[\\begin{aligned}  \\text{TNR}  &amp;=\\frac{\\text{TN}}{\\text{TN}+\\text{FP}} = 1-\\text{FPR}  \\end{aligned}\\]            Regression Metrics      AE(Average Error) : 오차의 합계로서 오차의 방향에 따라 크기가 상쇄되어 계산될 수 있음\\[\\begin{aligned}  \\text{AE}  &amp;=\\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)}  \\end{aligned}\\]        MSE(Mean Squared Error) : 오차 자승의 평균\\[\\begin{aligned}  \\text{MSE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}  \\end{aligned}\\]        RMSE(Root Mean Squared Error) : 오차 자승의 평균의 자승근\\[\\begin{aligned}  \\text{RMSE}  &amp;= \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}}  \\end{aligned}\\]        MAE(Mean Absolute Error) : 오차 절대값의 평균\\[\\begin{aligned}  \\text{MAE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\vert y_{i}-\\hat{y}_{i} \\vert}  \\end{aligned}\\]        MAPE(Mean Absolute Percentage Error) : 실제값 대비 오차 비율 절대값의 평균\\[\\begin{aligned}  \\text{MAPE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\left\\vert \\frac{y_{i}-\\hat{y}_{i}}{y_{i}} \\right\\vert}  \\end{aligned}\\]  SplitGeneralization Problem      일반화(Generalization) : 모델링 목적으로서, 모델이 훈련 관측치에서 학습한 패턴을 사용하여 이전에 보지 못한 관측치에 대하여 예측하는 것        문제점 : 과적합 현상                      과대적합(Overfitting) : 모델이 일반적이지 않은, 즉 훈련 관측치에서만 포착되는 노이즈나 이상치까지 학습하여 신규 관측치에 대해서는 제대로 기능하지 못하는 상태                    과소적합(Underfitting) : 모델이 훈련 관측치에서 나타나는 일반적인 패턴을 충분히 학습하지 못하여 관측치의 다양성과 복잡성을 잡아내지 못하는 상태                  해결 방법 : $E_{\\text{GEN}}$ 최소화                      Training Error : Training Data Set 에 대한 오차\\[\\begin{aligned}  E_{\\text{TRN}}  &amp;= \\sum^{N_{\\text{TRN}}}_{i=1}{\\mathcal{L}\\left(y_{i},\\hat{y}_{i}\\right)}  \\end{aligned}\\]                    Generalization Error : Unseen Data Set 에 대한 오차\\[\\begin{aligned}  E_{\\text{GEN}}  &amp;= \\int{\\mathcal{L}\\left(y_{i},\\hat{y}_{i}\\right)}  \\end{aligned}\\]            Estimation      $E_{\\text{GEN}}$ 측정 상의 문제점 : Unseen Data Set 자체에 대해서 알 수 없으므로 이상적인 개념임        Split Seen Data Set : $E_{\\text{GEN}}$ 를 추정하기 위하여 추정량 $E_{\\text{VAL}}$, $E_{\\text{TST}}$ 를 제시함          Training : 모델 훈련 시 사용하는 표본으로서, 해당 표본으로부터 $E_{val}$ 을 추정함      Validation : 모델 간 성능 비교 시 사용하는 표본으로서, 해당 표본으로부터 $E_{tst}$ 를 추정함      Test : 최종 선택된 모델 성능 측정 시 사용하는 표본으로서, 해당 표본로부터 $E_{gen}$ 를 추정함      Cross Validation      교차 검증(Cross Validation) : 표본을 여러 세트로 나누어 모델을 여러 번 학습하고 평가함으로써 모델의 일반화 성능을 측정하는 절차        LOOCV(Leave-One-Out Cross Validation) : $n$ 개의 표본을 $n-1$ 개의 training 과 $1$ 개의 validation 으로 나누어 $n$ 번 학습하는 방식            k-Fold Cross Validation : $n$ 개의 표본을 $k$ 개의 데이터 세트로 나누고, $k-1$ 개는 training 으로, $1$ 개는 validation 으로 구분하여 $k$ 번 학습하는 방식      "
  },
  
  {
    "title": "What? Data Science",
    "url": "/posts/data_science/",
    "categories": "3.MACHINE LEARNING TECHS, 1.supervised learning algorithm",
    "tags": "machine learning",
    "date": "2024-01-01 00:00:00 +0900",
    





    
    "snippet": "Data-Driven Decision MakingData-Driven Decision Making Process  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Expl...",
    "content": "Data-Driven Decision MakingData-Driven Decision Making Process  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend          Ability to Drill Down to the Root-cause      Ability to Isolate All Confounding Information        Predictive : Forcasts What Might Happned          Business Have Remained Fairly Consistent Over Time      Historical Patterns Being Used to Predict Specific Outcomes Using Algorithms      Decisions are Automated Using Algorithms and Tech.        Prescriptive : What Do I Need to Do?          Recommends Action Based On The Forecast      Applying Advanced Analytical Techs to Make Specific Recommendatons      Data-Driven Problem-Solving Process      문제 정의          어떤 문제를 해결할 것인가?이를 위해 필요한 데이터는 무엇인가?            데이터 획득          어떻게 데이터를 수집할 것인가?            데이터 탐색          데이터 전처리탐색적 자료 분석            모델링          문제에 맞는 기계학습 알고리즘 선택모델 구축            배포          제품 배포 및 시스템 유지 보수      Data Science      데이터 과학(Data Science)          정형, 비정형의 다양한 데이터로부터 지식 및 시사점을 도출하는 데 과학적 방법론을 동원하는 융합 분야(출처 : 위키백과)            빅데이터(Bigdata)          통상적으로 사용되는 데이터 수집, 관리, 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터(출처 : 위키백과)              Volume(Data Quantity)      Variety(Data Types)      Velocity(Data Speed)      Value(Data Impact)            데이터 마이닝(Data Mining)          대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 짜임을 분석하여 가치 있는 정보를 빼내는 과정(출처 : 위키백과)            기계학습(Machine Learning)          기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야(출처 : 위키백과)            인공지능(Artificial Intelligence; AI)          인간의 학습, 추론, 지각 능력을 인공적으로 구현하려는 컴퓨터 과학의 세부 분야(출처 : 위키백과)      Type of Machine Learning  지도학습(Supervised Learning) : 정답 세트가 존재하는 데이터를 활용하는 학습 방법                  판별 분석(Classificaiton Analysis) : 범주형 값을 가지는 종속변수를 예측하는 방법론                            회귀 분석(Regression Analysis) : 수치형 값을 가지는 종속변수를 예측하는 방법론                      비지도학습(Unsupervised Learning) : 정답 세트가 존재하지 않는 데이터를 활용하는 학습 방법                  군집화(Clustering) : 유사한 개체들의 집단을 만든 후 새 개체가 어떤 집단과 유사한지 예측하는 방법론                            차원축소(Dimensionality Reduction) : 고차원 데이터를 저차원 데이터로 변환하는 방법론                    Data Preprocessing      데이터 전처리(Data Preprocessing) : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정        데이터 품질에 영향을 끼치는 인자          Noise : 데이터 측정 시 무작위로 발생하여 오류를 발생시키는 문제      Outlier : 대부분의 데이터와 다른 특성을 보이거나 특정 속성의 값이 유별난 데이터      Artifact : 어떤 요인으로 인해 반복적으로 발생하는 왜곡이나 오류      Precision : 동일한 결과물을 반복적으로 측정하였을 때 각 측정값 사이의 일관성 문제      Bias : 측정 장비에 포함된 시스템 상 문제      Accuacy : 측정 장비의 한계로 정확하지 않은 수를 측정함에 따라 발생하는 문제      Inconsistent Value : 데이터 불일치 문제      Duplicate : 데이터 중복 문제      Process      Data Integration : 동일한 단위, 양식으로 데이터를 결합하는 절차    Data Cleansing : 낮은 품질의 데이터를 활용할 수 있도록 하는 절차          중복값 제거      결측치 처리      이상치 처리        Data Transformation : 데이터 형식 및 구조를 학습에 적합하도록 변환하는 절차          표준화(Standardization)      정규화(Normalization)        Data Reduction : 고차원 데이터를 저차원 데이터로 변환하는 절차Sourse  https://www.spotfire.com/glossary/what-is-regression-analysis  https://www.engati.com/glossary/classification-algorithm  https://medium.com/@baharzerenturk/hierarchical-clustering-analysis-dendogram-6b76f5f33fa8  https://www.mlguru.ai/Learn/ai-use-cases-dimensionality-reduction"
  },
  
  {
    "title": "SubTree",
    "url": "/posts/subtree/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-12 00:00:00 +0900",
    





    
    "snippet": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 ...",
    "content": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 내역을 저장하는 폴더                    Initial Configgit clone &lt;UPSTREAM-URL&gt;cd &lt;UPSTREAM-PATH&gt;git remote add upstream &lt;UPSTREAM-URL&gt;git remote add origin &lt;ORIGIN-URL&gt;Creategit subtree add --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree add : 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 내역을 저장할 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 를 생성함Pull : Update Changes in Origin to Upstreamgit subtree pull --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree pull : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 변경 사항을 병합(pull)함Push : Update Changes in Upstream to Origingit subtree push --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree push : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에서 직접 갱신한 내역을 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 에 추가함Splitgit subtree split --prefix=&lt;SUBTREE-PATH&gt; -b &lt;NEW-BRANCH&gt;  subtree split : 하위 저장소와 연동되어 있는 폴더 &lt;SUBTREE-PATH&gt; 에 관한 커밋을 추출하여 새로운 브랜치를 생성함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Interlock",
    "url": "/posts/interlock/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-11 00:00:00 +0900",
    





    
    "snippet": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격...",
    "content": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격 저장소의 별명 및 경로를 조회함      Interlockgit remote add &lt;NICKNAME&gt; &lt;REMOTE-REPO-PATH&gt;      remote add : 로컬 저장소에 원격 저장소를 연결함    &lt;NICKNAME&gt; : 호출 시 사용할 원격 저장소 별칭          upstream : 최상위 원격 저장소      origin : 여러 개의 원격 저장소를 위계를 세워 연동하지 않는 한 통상 해당 이름을 사용함      alt        &lt;REMOTE-REPO-PATH&gt; : 연결할 원격 저장소의 경로Renamegit remote rename &lt;EXISITING-NAME&gt; &lt;NEW-NAME&gt;  remote rename : 원격 저장소 별명을 &lt;EXISITING-NAME&gt; 에서 &lt;NEW-NAME&gt; 으로 변경함Changegit remote set-url &lt;NICKNAME&gt; &lt;NEW-PATH&gt;  remote set-url : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소 경로를 변경함Resetgit remote remove &lt;NICKNAME&gt;  remote remove : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소와의 연결을 해제함DownLoad Remote Repository복제하기git clone &lt;OPTION&gt; &lt;REMOTE-REPO-PATH&gt;      clone : 원격 저장소의 커밋 내역을 가져와서 로컬에 새로운 저장소를 생성함        &lt;OPTION&gt;          None      -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제함      --single-branch -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제 후 해당 브랜치만 추적함      --depth &lt;N&gt; : 최신 커밋 HEAD 로부터 특정 깊이까지만 복제함      가져와서 병합하기git pull &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;      pull : 원격 저장소의 커밋 내역을 가져와서 로컬 저장소의 내역과 병합함        &lt;OPTION&gt;          None : fetch + merge      -r : fetch + rebase      가져와서 임시 분기하기git fetch &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;:&lt;NEW-NAME&gt;  fetch : 원격 저장소의 커밋 내역을 가져와서 브랜치명 &lt;NEW-NAME&gt; 으로 임시 분기한 상태로 열람함          &lt;NEW-NAME&gt; 을 별도로 지정하지 않으면 FETCH_HEAD 로 자동 설정함        &lt;OPTION&gt;          None      --dry-run : 원격 저장소의 커밋 내역을 로컬로 가져오지 않고, 가져올 것이 있는지 여부만 확인      --all : 원격 저장소의 모든 브랜치에 대한 내역을 가져옴      Upload Local Changes to RemotePushgit push &lt;OPTION&gt; &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;      push : 로컬 브랜치의 커밋(변경 확정 내역)을 원격 브랜치에 반영함        &lt;OPTION&gt;          None      --all : 모든 로컬 브랜치에 대하여 기능함      --tags : 모든 로컬 태그에 대하여 기능함      --force : 충돌 시 경고를 무시하고 강제로 기능함      --dry-run : 실제로 푸시하지 않고 어떤 변경 사항이 발생할지 미리 확인함      Trackinggit push --set-upstream &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;  push --set-upstream : 현재 체크인한 로컬 브랜치를 원격 저장소 &lt;REMOTE-NICKNAME&gt; 의 브랜치 &lt;REMOTE-BRANCH-NAME&gt; 에 연동함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Branch",
    "url": "/posts/branch/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-10 00:00:00 +0900",
    





    
    "snippet": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들...",
    "content": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들을 기록하는 브랜치                    최종본 커밋을 기록하는 브랜치에는 최종본 내역 이외의 내역을 남기지 않음                  Main Branch 에는 최종본 커밋만을 기록함          Sub Branch 에는 작업 커밋을 기록함                          방법 : Five Branch Style              Main : 최종본 커밋을 기록하는 브랜치      Develop : Feature 들을 병합하는 브랜치      Feature : Develop 로부터 작업 주제에 따라 추가 분기하는 브랜치      Release : Develop 에서 확정되어 최종본이 된 커밋을 Main 으로 배포하는 브랜치      Hot-Fix : Develop 을 거치지 않고 수정하고 싶을 때 Main 에서 임시 분기하는 브랜치      PruningSearchgit branch &lt;OPTION&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 로컬 저장소에 존재하는 브랜치 목록을 조회함      -vv : 로컬 저장소에 존재하는 브랜치 및 각 브랜치가 추적하는 원격 브랜치 목록을 조회함      Create, Rename, Deletegit branch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 현재 체크인하고 있는 커밋으로부터 분기하는 새로운 브랜치 &lt;BRANCH-NAME&gt; 를 생성함      -m : 현재 체크인하고 있는 브랜치 이름을 &lt;BRANCH-NAME&gt; 으로 변경함      -d : 브랜치 &lt;BRANCH-NAME&gt; 를 삭제함      Check-Ingit switch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      switch : 브랜치 및 커밋의 전환에 대하여 기능함        &lt;OPTION&gt;          -c : 현재 체크인하고 있는 커밋에서 분기하는 새로운 브랜치를 만들고 해당 브랜치로 체크인함      IntegrationMergegit switch &lt;OPTION&gt; &lt;BASE-BRANCH&gt;git merge &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;      merge : 현재 체크인한 브랜치에서 다른 브랜치를 병합하여 새로운 커밋을 생성함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Rebasegit switch &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;git rebase &lt;OPTION&gt; &lt;BASE-BRANCH&gt;      rebase : 현재 체크인한 브랜치 내역을 다른 브랜치와 공통분모가 되는 커밋에 삽입함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit Control",
    "url": "/posts/commit_control/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-09 00:00:00 +0900",
    





    
    "snippet": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석...",
    "content": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석 목록 조회      Commitgit show &lt;COMMIT-HASH&gt;      show : 특정 커밋의 정보를 상세 조회함        &lt;COMMIT-HASH&gt;          None : HEAD 커밋      Differencegit diff &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt;      diff : 커밋 간 변경 사항의 차이점을 조회함        &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt; : &lt;COMMIT-1&gt; 에만 존재하는 변경 사항  Move      커밋 전환의 이해              커밋을 이동하는 것은 변수 HEAD 가 가리키는 커밋을 변경하는 작업임            변수 HEAD 의 이해              변수 HEAD 는 현재 체크인하고 있는 브랜치를 가리키고, 각 브랜치는 마지막 커밋을 가리킴      즉, 변수 HEAD 는 현재 체크인하고 있는 브랜치를 참조하여 마지막 커밋을 간접으로 가리키게 됨            DETACHED HEAD                      정의 : HEAD 가 브랜치를 참조하지 않고 커밋을 직접 가리키는 상태                    문제점                  이동한 커밋에서 새로운 커밋을 생성하면 해당 커밋은 브랜치를 벗어나 단독으로 존재하는 상태가 됨          본래 커밋은 직접 지목되지 않고 브랜치를 참조하여 지목되므로 해당 커밋을 가리킬 방법이 없음          이러한 경우 새로운 커밋에서 시작하는 새로운 브랜치를 생성하여 해결함                    refer. Commit Hashgit switch &lt;COMMIT-HASH&gt;refer. Taggit switch tags/&lt;TAG-NAME&gt;Copy &amp; PastePaste# 커밋을 붙여넣을 브랜치로 이동git switch &lt;BRANCH-NAME&gt;# 커밋 붙여넣기git cherry-pick &lt;COMMIT-HASH&gt;  cherry-pick : 현재 위치한 브랜치에 특정 커밋을 기록함If Conflict# 충돌 사항 수정 후 해당 파일들을 스테이지에 올리기git add &lt;conflict files&gt;# 일시중지 작업에 대하여 재개 혹은 중단git cherry-pick &lt;OPTION&gt;  &lt;OPTION&gt; : 일시중지 작업에 대하여 기능함          --continue : 작업 재개      --abort : 작업 중단 및 일시중단 이전 상태로 복원      Cancel커밋 되돌리기git revert &lt;COMMIT-HASH&gt;  revert : 특정 커밋 상태로 되돌리는 새로운 커밋을 생성함커밋 삭제하기git reset &lt;OPTION&gt; &lt;COMMIT-HASH&gt;      reset : 특정 커밋 이후에 추가 기록된 커밋들을 모두 삭제하고 해당 커밋으로 되돌림        &lt;OPTION&gt;              --hard : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 해제하고, 해당 커밋 이후에 기록된 커밋을 삭제함      --mixed : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 유지하되, 해당 커밋 이후에 기록된 커밋을 삭제함      --soft : HEAD 를 해당 커밋으로 되돌리되, 파일의 modified 및 staged 상태를 유지하고, 해당 커밋 이후에 기록된 커밋을 유지함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "File Control",
    "url": "/posts/file_control/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-08 00:00:00 +0900",
    





    
    "snippet": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&g...",
    "content": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&gt; &lt;OPTION&gt;      stash apply : 임시 저장 항목을 HEAD 커밋에 불러와서 적용함        option          None : 임시 저장 항목을 불러와서 HEAD 커밋과 병합한 후 변경 사항을 스테이지 영역에 추가함      --index : HEAD 커밋과 병합 시 충돌 사항을 조회함      임시 저장 항목 삭제하기git stash drop &lt;STASH-NAME&gt;  stash drop : 특정 임시 저장 항목을 삭제함git stash clear  stash clear : 임시 저장 목록을 초기화함파일 상태 다루기.gitignoreWORKING-DIRECTORY-PATH/.gitignore  .gitignore : 워킹 디렉토리 하위 항목 중 Git 의 추적에서 제외할 항목을 설정하는 파일rmgit rm &lt;OPTION&gt; &lt;FILE-NAME&gt;      rm : 파일을 삭제하거나 추적에서 제외함        &lt;OPTION&gt;          None : 파일을 삭제함      --cached : 파일을 untracked 상태로 전환하고 워킹 디렉토리에서는 삭제하지 않음      -r : 워킹 디렉토리의 하위 항목을 모두 삭제함      --dry-run : 명령어 실행 시 어떤 파일들이 삭제될 것인지 조회함      파일 상태 복원하기git restore &lt;OPTION&gt; &lt;FILE-NAME&gt;  restore : 파일 상태를 특정 시점으로 복원할 때 사용하는 명령어          커밋을 이동하는(변수 HEAD 의 아규먼트를 변경하는) 작업이 아니므로 detached HEAD 를 초래하지 않음      단, restore 상태에서 커밋 생성 시 detached HEAD 발생함        &lt;OPTION&gt;          None : 파일 상태를 HEAD 시점으로 복원함      --worktree : modified 파일의 상태를 HEAD 시점으로 복원함      --staged : staged 파일의 상태를 HEAD 시점으로 복원함      --source=&lt;COMMIT-HASH&gt; : 파일 상태를 특정 커밋 시점으로 복원함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit",
    "url": "/posts/commit/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-07 00:00:00 +0900",
    





    
    "snippet": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대...",
    "content": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대기하는 상태      Committed : 변경 사항이 확정되어 브랜치에 기록된 상태      Statusgit status  status : 현재 체크인하고 있는 로컬 저장소 브랜치의 상태를 조회함          현재 위치하고 있는 로컬 브랜치      modified 파일 목록      staged 파일 목록      untracked 파일 목록      Differencegit diff &lt;OPTION&gt; &lt;FILE-NAME&gt;      diff : modified 파일의 변경 사항을 조회함        &lt;OPTION&gt;          None : unstaged area 와 stage area 간 변경 사항 조회      HEAD : unstaged area 와 최신 커밋 HEAD 간 변경 사항 조회      --staged : stage area 와 최신 커밋 HEAD 간 변경 사항 조회      Commit ProcessAddgit add &lt;FILE-NAME&gt;  add : modified 파일을 스테이지 영역에 추가함Commitgit commit &lt;OPTION&gt;      commit : staged 파일의 변경 사항을 확정하여 로컬 브랜치에 기록함        &lt;OPTION&gt;          None      -m \"COMMIT MESSAGE\" : 텍스트 에디터를 열지 않고 커멘트 창에서 커밋 메시지를 작성함      --date=\"YYYY-MM-DD HH:MM:SS\" : 커밋한 시각을 명시함      --signoff : 커밋 메시지 끝에 커밋한 사용자의 user.name 과 user.email 을 표기함      --allow-empty : 변경 사항이 없는 빈 커밋을 생성함      --amend : 현재 staged 파일들의 변경 사항을 최신 커밋에 추가 기록하여 새로운 커밋을 생성하고, 기존 커밋을 삭제함      Commit Message Rule  제목(header), 본문(body), 바닥글(footer)은 빈 행(\\n)으로 구분함  본문과 바닥글은 생략해도 무방함  제목은 50글자 이내로 제한함  제목의 첫 글자는 대문자로 작성함  제목 끝에는 마침표를 넣지 않음  제목은 명령문으로 사용하며 과거형을 사용하지 않음  본문에는 HOW 보다는 WHAT, WHY 에 대해서 서술함  본문의 각 행은 72글자 내로 제한함  바닥글에는 참조 정보를 기입함Type            type      설명                  docs      문서 갱신, 주석 추가 또는 데이터의 출처와 처리 방법 등을 문서화              feat      새로운 데이터 분석 기능이나 알고리즘 추가              fix      버그 수정 또는 데이터 정제 과정에서의 오류 수정              perf      성능 향상을 위한 코드 수정              style      코드 스타일 변경 또는 주석의 스타일 수정              refactor      데이터 처리 또는 분석 코드의 구조 변경              data      데이터셋의 추가, 업데이트, 또는 데이터 전처리과정에 관련된 작업              test      새로운 테스트 추가 또는 기존 테스트 수정              chore      빌드 시스템 설정 변경, 라이브러리 업데이트 또는 그 외 기타 작업      TagSearchgit tag -list &lt;OPTION&gt;      tag -list : 로컬 브랜치의 태그 목록을 조회함        &lt;OPTION&gt;          None : 전체 태그 목록      &lt;CONDITION.*&gt; : 키워드 CONDITION 을 포함하는 태그 목록      git show &lt;TAG-NAME&gt;      show : 특정 태그 정보를 상세조회함          태그 주석(Tag Annotation)      태그 작성자(Tagger)      태그 날짜(Date)      해당 태그가 가리키는 커밋      Creategit tag &lt;OPTION&gt; &lt;TAG-NAME&gt; &lt;COMMIT-HASH&gt;      tag : 특정 커밋에 태그를 부착함        &lt;OPTION&gt;          None : 기본 태그(LightWeight Tag)              -a : 주석 태그(Annotated Tag)          git tag -a &lt;TAG-NAME&gt; -m \"Annotation\" &lt;COMMIT-HASH&gt;                    Deletegit tag -d &lt;TAG-NAME&gt;      tag -d : 로컬 저장소의 특정 태그를 삭제함        &lt;TAG-NAME&gt;          $(git tag -l) : 로컬 저장소의 모든 태그를 삭제함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "What? GIT",
    "url": "/posts/git/",
    "categories": "0.AI DEV. ENV., 1.GIT",
    "tags": "DVCS, GIT",
    "date": "2023-03-06 00:00:00 +0900",
    





    
    "snippet": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중...",
    "content": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중앙 집중 방식 : 데이터를 통합 관리하는 중앙 서버에 최종본 한 벌을 두고 로컬에서 서버에 접근하는 방식          분산 저장 방식 : 개별 노드가 네트워크를 통해 개별 노드가 확정본 변경 사항을 동기화하면서 공동으로 관리하는 방식                            버전 관리 시스템                  정의 : 확정본 및 이로부터 분기되어 변경된 사항을 추적/관리하는 시스템                      복사본을 이용한 버전 관리                                            버전 관리 시스템을 이용한 버전 관리                                            기능 및 관련 도구          병렬 작업 : Branch(데이터 형상 변경 내역 흐름)      변경점 관리 : Commit(데이터 형상 변경 내역)      확정본 관리 : Tag(데이터 변경 내역에 다는 꼬리표)      Traking Working DirectoryGit DownLoad  Git DownLoadTrackinggit initEnroll GitHub Accountgit config --global user.name &lt;NAME&gt;git config --global user.email &lt;EMAIL&gt;Configworking-directory-path/.git/config  설정 파일 config 는 워킹 디렉토리의 숨김 폴더 .git 내부에 위치함Searchgit config &lt;SCOPE&gt; &lt;FIELD&gt;      config : config 파일에 대하여 기능함    &lt;SCOPE&gt; : 범위          --system : 시스템 전체 설정      --global : 홈 디렉토리 설정      --local : 워킹 디렉토리 설정        &lt;FIELD&gt; : 아규먼트에 대하여 기능할 속성 파라미터          --list : 모든 속성 파라미터의 아규먼트를 반환함      user.name : 워킹 디렉토리에 연동할 깃허브 계정 닉네임      user.email : 워킹 디렉토리에 연동할 깃허브 계정 이메일      core.editor      color.ui      alias.[alias-name]      Setgit config &lt;SCOPE&gt; &lt;FIELD&gt; &lt;VALUE&gt;  config : config 파일에 대하여 기능함  &lt;VALUE&gt; : 필드에 할당할 아규먼트Resetgit config &lt;SCOPE&gt; &lt;OPTION&gt; &lt;FIELD&gt;  &lt;OPTION&gt;          --unset : 특정 필드의 아규먼트를 초기화함      --unset-all : 모든 필드의 아규먼트를 초기화함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Integration",
    "url": "/posts/integration/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-16 00:00:00 +0900",
    





    
    "snippet": "Integration      미분(Differentiation): $F(x)$ 를 $\\Delta x$ 단위로 쪼개는 방법\\[\\begin{aligned}  f(x)  &amp;= \\frac{F(x + \\Delta x)-F(x)}{\\Delta x}  \\end{aligned}\\]        적분(Integration): 미분소 $f(x) \\times \\...",
    "content": "Integration      미분(Differentiation): $F(x)$ 를 $\\Delta x$ 단위로 쪼개는 방법\\[\\begin{aligned}  f(x)  &amp;= \\frac{F(x + \\Delta x)-F(x)}{\\Delta x}  \\end{aligned}\\]        적분(Integration): 미분소 $f(x) \\times \\Delta x$ 를 쌓는 방법\\[\\begin{aligned}  F(x)  &amp;=\\sum_{i}{f(x_{i}) \\times \\Delta x}  \\end{aligned}\\]        부정적분(Indefinite Integral): 미분의 역연산으로서, 어떤 함수 $f(x)$ 를 미분계수로 취하는 모든 함수 $F(x) + C$ 를 구하는 연산\\[\\begin{aligned}  F(x) + C  &amp;= \\int{f(x)\\mathrm{d}x}\\\\  &amp;= \\lim_{\\Delta x \\to 0}{\\sum_{i}{f(x_{i}) \\times \\Delta x}}  \\end{aligned}\\]          $F(x)$: 원시 함수      $f(x)$: 피적분 함수 혹은 미분계수      $C$: 적분 상수        부정적분의 연산 규칙          $\\int{\\alpha \\cdot f(x)\\mathrm{d}x} = \\alpha \\cdot \\int{f(x)\\mathrm{d}x}$      $\\int{[f(x) \\pm g(x)] \\mathrm{d}x} = \\int{f(x)\\mathrm{d}x} \\pm \\int{g(x)\\mathrm{d}x}$      $\\int{x^{n}\\mathrm{d}x} = x^{n+1}/(n+1) + C$      $\\int{e^{x}\\mathrm{d}x} = e^{x}+C$      $\\int{1/x\\mathrm{d}x} = \\ln{\\vert x \\vert}+C$      $\\int{f^{\\prime}(x)/f(x)\\mathrm{d}x} = \\ln{\\vert f(x) \\vert}+C$            정적분(Definite Integral) : $x \\in [a,b]$ 과 피적분함수 $f(x)$ 로 둘러싸인 면적의 너비를 구하는 연산\\[\\begin{aligned}  S  &amp;= \\lim_{\\Delta x \\to 0}{\\sum_{i=a}^{b}{f(x_{i}) \\times \\Delta x}}\\\\  &amp;= \\int_{a}^{b}{f(x)\\mathrm{d}x} \\\\  &amp;= F(b) - F(a)  \\end{aligned}\\]          $a$ : 적분의 아래 한계      $b$ : 적분의 위의 한계        정적분의 연산 규칙          $\\mathrm{d}/\\mathrm{d}x \\int_{a}^{x}{f(t)\\mathrm{d}t} = f(x)$      $\\int_{a}^{b}{\\alpha f(x)\\mathrm{d}x} = \\alpha \\int_{a}^{b}{f(x)\\mathrm{d}x}$      $\\int_{a}^{b}{[f(x) \\pm g(x)]\\mathrm{d}x} = \\int_{a}^{b}{f(x)\\mathrm{d}x} \\pm \\int_{a}^{b}{g(x)\\mathrm{d}x}$      $\\int_{a}^{a}{\\alpha f(x)\\mathrm{d}x} = 0$      $\\int_{a}^{b}{\\alpha f(x)\\mathrm{d}x} = -\\int_{b}^{a}{\\alpha f(x)\\mathrm{d}x}$      $\\int_{a}^{b}{\\alpha f(x)\\mathrm{d}x} + \\int_{b}^{c}{\\alpha f(x)\\mathrm{d}x} = \\int_{a}^{c}{\\alpha f(x)\\mathrm{d}x},\\quad (a&lt;b&lt;c)$      Multiple Integral      중적분(Multiple Integral) : 영역 $B$ 에서 적분 가능한 다변수함수 $y=f(x_{1},x_{2},\\cdots,x_{N})$ 에 대하여 변수 $x_{1},x_{2},\\cdots,x_{N}$ 에 대한 정적분\\[\\begin{aligned}  \\int_{x_{N}} \\cdots \\int_{x_2} \\int_{x_1} f(x_{1},x_{2},\\cdots,x_{n}) \\mathrm{d}x_{1} \\mathrm{d}x_{2} \\cdots \\mathrm{d}x_{N}  \\end{aligned}\\]        영역 $B$ 를 다음과 같이 정의하자\\[\\begin{aligned}  B  &amp;= [a,b]\\times[c,d]\\\\  &amp;= \\{(x,y) \\mid a \\leq x \\leq b, c \\leq y \\leq d\\}  \\end{aligned}\\]        2변수함수 $z=f(x,y)$ 는 영역 $B$ 에서 적분 가능한 함수임\\[\\begin{aligned}  \\lim_{x \\to k-0}{f(x,y)}=\\lim_{x \\to k+0}{f(x,y)}=f(k,y) \\quad (a \\leq k \\leq b)\\\\  \\lim_{y \\to k-0}{f(x,y)}=\\lim_{y \\to k+0}{f(x,y)}=f(x,k)\\quad(c \\leq k \\leq d)\\\\  \\end{aligned}\\]        피적분함수 $z=f(x,y)$ 를 영역 $B$ 에서 $y$ 에 대하여 적분하면:\\[\\begin{aligned}  g(x)  &amp;= \\int_{c}^{d}{z\\mathrm{d}y}\\\\  &amp;= \\int_{c}^{d}{f(x,y)\\mathrm{d}y}\\\\  &amp;= F(x,d)-F(x,c)  \\end{aligned}\\]        $x$ 에 관한 함수 $g(x)$ 를 영역 $B$ 에서 $x$ 에 대하여 적분하면:\\[\\begin{aligned}  \\int_{a}^{b}{g(x)\\mathrm{d}x}  &amp;= G(b) - G(a)  \\end{aligned}\\]        이상을 요약하면 다음과 같음\\[\\begin{aligned}  \\int_{a}^{b}\\left(\\int_{c}^{d}{z}\\mathrm{d}y\\right)\\mathrm{d}x  &amp;= \\int_{a}^{b}\\int_{c}^{d}{f(x,y)}\\mathrm{d}y\\mathrm{d}x  \\end{aligned}\\]  Integration by Parts      부분적분(Integration by Parts): 곱의 적분법\\[\\begin{aligned}  \\int{u(x)v^{\\prime}(x)\\mathrm{d}x}  &amp;= u(x)v(x) - \\int{u^{\\prime}(x)v(x)\\mathrm{d}x}  \\end{aligned}\\]          $\\int{u^{\\prime}(x)\\mathrm{d}x}=\\mathrm{d}u$      $\\int{v^{\\prime}(x)\\mathrm{d}x}=\\mathrm{d}v$            $x$ 에 대하여 미분 가능한 함수 $u(x),v(x)$ 의 곱을 $x$ 에 대하여 미분하면:\\[\\begin{aligned}  \\frac{\\mathrm{d}}{\\mathrm{d}x}uv  &amp;= u\\frac{\\mathrm{d}v}{\\mathrm{d}x} + v\\frac{\\mathrm{d}u}{\\mathrm{d}x}  \\end{aligned}\\]        양변에 $\\mathrm{d}x$ 를 곱하면:\\[\\begin{aligned}  \\mathrm{\\mathrm{d}}(uv)  &amp;= u \\cdot \\mathrm{d}v + v \\cdot \\mathrm{d}u  \\end{aligned}\\]        양변의 일부 항목을 이항하면:\\[\\begin{aligned}  u \\cdot \\mathrm{d}v  &amp;= \\mathrm{d}(uv) - v \\cdot \\mathrm{d}u  \\end{aligned}\\]        양변을 적분하면:\\[\\begin{aligned}  \\int{u \\cdot \\mathrm{d}v}  &amp;= uv - \\int{v \\cdot \\mathrm{d}u}  \\end{aligned}\\]  Integration of Rational Functions      유리함수의 적분법(integration of rational functions): $x$ 에 대하여 적분 가능한 두 함수 $f(x),g(x)$ 로 구성된 피적분함수 $f(x)/g(x)$ 의 적분법\\[\\begin{aligned}  \\int{\\frac{f(x)}{g(x)}\\mathrm{d}x}  \\end{aligned}\\]        $f(x),g(x)$ 를 다음과 같이 가정하자\\[\\begin{aligned}  f(x)  &amp;= x^{3}-x^{2}-2\\\\  g(x)  &amp;= x^{2}-x  \\end{aligned}\\]        $f(x)$ 를 $g(x)$ 로 나누면:\\[\\begin{aligned}  f(x) \\div g(x)  &amp;= \\frac{x^{3}-x^{2}-2}{x^{2}-x}\\\\  &amp;= \\frac{x^{2}(x-1)-2}{x(x-1)}\\\\  &amp;= x - \\frac{2}{x(x-1)}  \\end{aligned}\\]        나머지를 부분분수분해하면:\\[\\begin{aligned}  \\frac{2}{x(x-1)}  &amp;= 2 \\times \\frac{1}{(x-1)-x}\\left(\\frac{1}{x}-\\frac{1}{x-1}\\right)\\\\  &amp;= -\\frac{2}{x} + \\frac{2}{x-1}  \\end{aligned}\\]        $f(x)/g(x)$ 를 재정의하면:\\[\\begin{aligned}  \\frac{f(x)}{g(x)}  &amp;= x + \\frac{2}{x} - \\frac{2}{x-1}  \\end{aligned}\\]        양변을 적분하면:\\[\\begin{aligned}  \\int{\\frac{f(x)}{g(x)}\\mathrm{d}x}  &amp;= \\int{\\left[x + \\frac{2}{x} - \\frac{2}{x-1}\\right]\\mathrm{d}x}\\\\  &amp;= \\int{x\\mathrm{d}x} + \\int{\\frac{2}{x}\\mathrm{d}x} - \\int{\\frac{2}{x-1}\\mathrm{d}x}  \\end{aligned}\\]  Improper Integral      이상적분(Improper Integral): 극한치의 적어도 한 개가 무한일 경우의 적분법\\[\\begin{aligned}  \\int_{a}^{\\infty}{f(x)\\mathrm{d}x},\\quad \\int_{\\infty}^{b}{f(x)\\mathrm{d}x}  \\end{aligned}\\]        피적분함수 $f(x)=1/x^{2}$ 에 대한 정적분:\\[\\begin{aligned}  \\int_{1}^{\\infty}{\\frac{1}{x^2}\\mathrm{d}x}  \\end{aligned}\\]        적분의 위의 한계 $\\infty$ 를 상수 $k$ 로 치환하면:\\[\\begin{aligned}  \\int_{1}^{\\infty}{\\frac{1}{x^2}\\mathrm{d}x}  &amp;= \\lim_{k\\to\\infty}{\\int_{1}^{k}{\\frac{1}{x^2}\\mathrm{d}x}}  \\end{aligned}\\]        $f(x)$ 를 $[1,k]$ 에서 정적분하면:\\[\\begin{aligned}  \\int_{1}^{k}{\\frac{1}{x^2}\\mathrm{d}x}  &amp;= \\left[-\\frac{1}{x}\\right]^{x=k}_{x=1}\\\\  &amp;= -\\frac{1}{k}+1  \\end{aligned}\\]        $k \\to \\infty$ 일 때 위 식의 값은 다음과 같음\\[\\begin{aligned}  \\lim_{k\\to\\infty}{\\left[-\\frac{1}{k}+1\\right]}  &amp;= 1  \\end{aligned}\\]  "
  },
  
  {
    "title": "Lagrange Multipliers",
    "url": "/posts/lagrange_multipliers/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-15 00:00:00 +0900",
    





    
    "snippet": "Lagrange Multipliers      라그랑주 승수법(Lagrange Multipliers) : 제약 조건이 주어진 최적화 문제(즉, 제한된 범위 내에서 최대값이나 최소값을 구하는 문제)를 해결하기 위한 수학적 기법으로서, 주로 다변수 함수의 최적화 문제 풀이에 사용됨\\[\\begin{aligned}  \\Theta^{*} =  \\begin{ca...",
    "content": "Lagrange Multipliers      라그랑주 승수법(Lagrange Multipliers) : 제약 조건이 주어진 최적화 문제(즉, 제한된 범위 내에서 최대값이나 최소값을 구하는 문제)를 해결하기 위한 수학적 기법으로서, 주로 다변수 함수의 최적화 문제 풀이에 사용됨\\[\\begin{aligned}  \\Theta^{*} =  \\begin{cases}  \\text{arg} \\min{\\mathcal{L}} \\quad &amp; \\text{minimum}\\\\  \\text{arg} \\max{\\mathcal{L}} \\quad &amp; \\text{maximun}  \\end{cases}  \\end{aligned}\\]  How to Solve  Notation:          $f(x,y,\\cdots)$ : 목적 함수      $g_{i}(x,y,\\cdots)=0$ : $i$ 번째 등식 제약 조건      $h_{j}(x,y,\\cdots) \\le 0$ : $j$ 번째 비등식 제약 조건      $\\lambda_{i}$ : $i$ 번째 등식 제약 조건의 라그랑주 승수로서 해당 제약 조건의 영향력      $\\mu_{j}$ : $j$ 번째 비등식 제약 조건의 라그랑주 승수로서 해당 제약 조건의 영향력            Lagrangian Function:\\[\\begin{aligned}  &amp;\\mathcal{L}(x,y,\\cdots,\\lambda_{1}, \\cdots, \\mu_{1},\\cdots)\\\\  &amp;= f(x,y,\\cdots) + \\sum_{i}{\\lambda_{i} \\cdot g_{i}(x,y,\\cdots)} + \\sum_{j}{\\mu_{j} \\cdot h_{j}(x,y,\\cdots)}  \\end{aligned}\\]        how to solve:\\[\\begin{aligned}  \\nabla\\mathcal{L}\\left(x^{*},y^{*},\\cdots,\\lambda^{*}_{1}, \\cdots, \\mu_{1}^{*}, \\cdots\\right)  &amp;= 0  \\end{aligned}\\]  KKT      KKT 조건(Karush-Kuhn-Tucker Conditions): 비등식 제약 하 최적화 문제에서 라그랑주 승수법을 적용하기 위한 조건        1차 최적성 조건(Stationarity): 목적 함수의 기울기와 제약 조건의 기울기가 균형을 이룸\\[\\begin{aligned}  \\nabla f(x^{*}) + \\sum_{i}{\\lambda_{i} \\cdot \\nabla g_{i}(x^{*})} + \\sum_{j}{\\mu_{j} \\cdot \\nabla h_{j}(x^{*})} = 0  \\end{aligned}\\]        제약 조건의 만족(Primal Feasibility): 최적의 해가 주어진 제약 조건을 만족해야 함\\[\\begin{aligned}  \\forall g(x^{*}) = 0, \\quad \\forall h(x^{*}) \\le 0  \\end{aligned}\\]        이중성 조건 (Dual Feasibility): 비등식 제약 조건에 대한 라그랑주 승수는 음수가 될 수 없음\\[\\begin{aligned}  \\forall\\mu \\ge 0  \\end{aligned}\\]        슬랙 조건 (Complementary Slackness): 비등식 제약 조건이 활성(active)일 때만 해당 제약 조건이 최적화 문제에 영향을 미침\\[\\begin{aligned}  \\forall\\mu \\cdot \\forall h(x^{*}) = 0  \\end{aligned}\\]  "
  },
  
  {
    "title": "Partial Derivative",
    "url": "/posts/partial_derivative/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-14 00:00:00 +0900",
    





    
    "snippet": "Partial Derivative      2변수함수 \\(y=f(x,z)\\) 는 $XYZ$-공간에서의 곡면임    \\[\\begin{aligned}  \\left\\{(x,y,z) \\mid (x,z) \\in D(f)\\right\\}  \\end{aligned}\\]        편미분(Partial Derivative): 다변수함수 $y=f(x,z)$ 에 대하여...",
    "content": "Partial Derivative      2변수함수 \\(y=f(x,z)\\) 는 $XYZ$-공간에서의 곡면임    \\[\\begin{aligned}  \\left\\{(x,y,z) \\mid (x,z) \\in D(f)\\right\\}  \\end{aligned}\\]        편미분(Partial Derivative): 다변수함수 $y=f(x,z)$ 에 대하여, 변수 $x$ 를 제외한 다른 변수들을 상수로 고정하였을 때, $x$ 의 단위 변화에 따른 $y$ 의 순간변화율\\[\\begin{aligned}  \\frac{\\partial}{\\partial x}f(x,z)  &amp;= \\lim_{\\Delta x \\to 0}{\\frac{f(x+\\Delta x,z)-f(x,z)}{\\Delta x}}  \\end{aligned}\\]        고계편도함수(Partial Derivative Function): 다변수함수에 대하여 그 편도함수의 편도함수                  1계편도함수:\\[\\begin{aligned}  f_{X}(x,z)  &amp;= \\frac{\\partial}{\\partial x}f(x,z)\\\\  f_{Z}(x,z)  &amp;= \\frac{\\partial}{\\partial z}f(x,z)  \\end{aligned}\\]                    2계편도함수:\\[\\begin{aligned}  (f_{X})_{X}  &amp;= f_{XX}(x,z)  = \\frac{\\partial^{2}}{\\partial x^{2}}f(x,z)\\\\  (f_{Z})_{Z}  &amp;= f_{ZZ}(x,z)  = \\frac{\\partial^{2}}{\\partial z^{2}}f(x,z)\\\\  (f_{X})_{Z}  &amp;= f_{XZ}(x,z)  = \\frac{\\partial^{2}}{\\partial x \\partial z}f(x,z)\\\\  (f_{Z})_{X}  &amp;= f_{ZX}(x,z)  = \\frac{\\partial^{2}}{\\partial z \\partial x}f(x,z)  \\end{aligned}\\]                  헤시안 행렬(Hessian Matrix): 다변수함수의 고계편도함수를 표현한 행렬\\[\\begin{aligned}  D^{2}f(x,z)  &amp;:=\\begin{bmatrix}  f_{XX} &amp; f_{XZ}\\\\  f_{XZ} &amp; f_{ZZ}  \\end{bmatrix}  \\end{aligned}\\]        그라디언트(Gradient): $N$ 변수함수 $y=f(x_{1},x_{2},\\cdots,x_{N})$ 에 대하여 각 변수에 대한 일계편도함수로 구성된 벡터    \\[\\begin{aligned}  \\nabla f  &amp;= \\begin{bmatrix}  \\displaystyle\\frac{\\partial f}{\\partial x_{1}} &amp; \\displaystyle\\frac{\\partial f}{\\partial x_{2}} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial f}{\\partial x_{N}}  \\end{bmatrix}^{T}  \\end{aligned}\\]          \\(\\nabla f \\vert_{(x_{1},x_{2},\\cdots,x_{n})}\\) 는 점 \\((x_{1},x_{2},\\cdots,x_{n})\\) 에서 \\(f\\) 의 값이 가장 가파르게 증가하는 방향임      Critical Point      임계점(Critical Point) : 함수의 1계편도함수 값이 $0$ 이거나 존재하지 않는 지점\\[\\begin{aligned}  f_{X} = 0, \\quad f_{Z} = 0  \\end{aligned}\\]        극점(Local Extremum Point) : 임계점 중에서 극값을 갖는 지점으로서, $f$ 의 임계점 $(a,b)$ 의 모든 열린 근방 $(x,z)$ 에 대하여 다음 중 하나만을 만족하는 경우    \\[\\begin{cases}  f(a,b) \\leq f(x,z) \\quad &amp;\\text{maximum}\\\\  f(a,b) \\geq f(x,z) \\quad &amp;\\text{minimum}  \\end{cases}\\]        안장점(Saddle Point) : 임계점 중에서 극값을 갖지 않는 점으로서, 어떤 측면에서는 극소값이 되고, 동시에 다른 측면에서는 극대값이 되는 지점    \\[\\begin{aligned}  f(a,b) \\leq f(x,z) \\quad \\text{and} \\quad f(a,b) \\geq f(x,z)  \\end{aligned}\\]        헤시안 행렬식 값에 따른 극값 판별:\\[\\begin{aligned}  \\Delta  &amp;= \\mathrm{det}(D^{2}f(x,z)\\vert_{(a,b)})\\\\  &amp;= f_{XX}(x,b)\\vert_{x=a} \\cdot f_{ZZ}(a,z)\\vert_{z=b}-f^{2}_{XZ}(x,z)\\vert_{(a,b)}  \\end{aligned}\\]          $\\Delta = 0$: 극값의 존재 여부를 결정할 수 없음      $\\Delta &lt; 0$: $(a,b)$ 에서 안장점을 가짐      $\\Delta &gt; 0$: $(a,b)$ 에서 극값을 가짐      "
  },
  
  {
    "title": "Taylor Series",
    "url": "/posts/taylor_series/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-13 00:00:00 +0900",
    





    
    "snippet": "      극점(Extremum): 함수 $f:X \\to Y$ 에 대하여 함수값 $y=f(x)$ 의 국소적인 최대 혹은 최소 지점            극대점(Local Maximum): 주위 모든 점의 함수값 이상의 함수값을 가지는 지점으로서, 함수 $f$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c\\in[a,b]$ 에서 극대값을 가지면 다음...",
    "content": "      극점(Extremum): 함수 $f:X \\to Y$ 에 대하여 함수값 $y=f(x)$ 의 국소적인 최대 혹은 최소 지점            극대점(Local Maximum): 주위 모든 점의 함수값 이상의 함수값을 가지는 지점으로서, 함수 $f$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c\\in[a,b]$ 에서 극대값을 가지면 다음을 만족함\\[\\begin{aligned}  \\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)\\Big\\vert_{x=c}=0,  \\quad  \\frac{\\mathrm{d}^{2}}{\\mathrm{d}x^{2}}f(x)\\Big\\vert_{x=c}&lt;0  \\end{aligned}\\]        극소점(Local Minimum): 주위 모든 점의 함수값 이하의 함수값을 가지는 지점으로서, 함수 $f$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c\\in[a,b]$ 에서 극소값을 가지면 다음을 만족함\\[\\begin{aligned}  \\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)\\Big\\vert_{x=c}=0,  \\quad  \\frac{\\mathrm{d}^{2}}{\\mathrm{d}x^{2}}f(x)\\Big\\vert_{x=c}&gt;0  \\end{aligned}\\]  Taylor Polynomial      테일러 다항식(Taylor Polynomial) : $x=a$ 에서 미분 가능한 함수 $f:X \\to Y$ 에 대하여, $f$ 와 $x=a$ 에서 근사하는 $n$ 차 함수\\[\\begin{aligned}  f(x)  \\approx \\sum_{k=0}^{n}{\\frac{f^{k}(a)}{k!}(x-a)^{k}},  \\quad  f^{k}(a)  = \\frac{\\mathrm{d}^{k}}{\\mathrm{d}x^{k}}f(x)\\Big\\vert_{x=a}  \\end{aligned}\\]        테일러 급수(Taylor Series) : $n \\to \\infty$ 인 경우의 테일러 다항식\\[\\begin{aligned}  f(x)  &amp;\\approx f(a)  + f^{(1)}(a)(x-a)  + \\frac{f^{(2)}(a)}{2!}(x-a)^{2}  + \\cdots  + \\frac{f^{(k)}(a)}{k!}(x-a)^{k}  + \\cdots  \\end{aligned}\\]        매클로린 급수(Maclaurin’s Series) : $a=0$ 인 경우의 테일러 급수\\[\\begin{aligned}  f(x)  &amp;\\approx f(0)  + f^{(1)}(0)x  + \\frac{f^{(2)}(0)}{2!}x^{2}  + \\cdots  + \\frac{f^{(k)}(0)}{n!}x^{k}  + \\cdots  \\end{aligned}\\]        선형 근사(Linear Approximation) : $x=a$ 에서 $f: X \\to Y$ 에 근사하는 $1$ 차 함수\\[\\begin{aligned}  f(x) \\approx f(a) + f^{\\prime}(a)(x-a)  \\end{aligned}\\]  Moment      적률(Moment): 확률변수 $X$ 의 $n$ 차 적률은 확률변수 $X^{n}$ 의 기대값임\\[\\begin{aligned}  \\mathbb{E}\\left[X^{n}\\right]  &amp;= \\begin{cases}  \\sum_{x}{x^{n}f(x)}\\\\  \\int_{-\\infty}^{\\infty}{x^{n}f(x)\\text{d}x}  \\end{cases}  \\end{aligned}\\]                  원점 적률(Origin Moment): 원점에 대한 적률로서 평균\\[\\begin{aligned}  \\mu^{\\prime}_{n}  &amp;= \\mathbb{E}\\left[X^{n}\\right]  \\end{aligned}\\]                    중심 적률(Central Moment): 중심점(혹은 평균) $\\mu$ 에 대한 적률로서 분산\\[\\begin{aligned}  \\mu_{n}  &amp;= \\mathbb{E}\\left[(X-\\mu)^{n}\\right]  \\end{aligned}\\]                  적률생성함수(Moment Generating Function): 특정 분포의 적률을 생성하는 함수\\[\\begin{aligned}  M_{X}(t)  = \\mathbb{E}\\left[e^{tX}\\right]  = \\int_{-\\infty}^{\\infty}{e^{tX}f(x)\\text{d}x}  \\end{aligned}\\]                  적률생성함수의 매클로린 전개:\\[\\begin{aligned}  \\mathbb{E}\\left[e^{tX}\\right]  \\approx \\mathbb{E}\\left[\\sum_{n=0}^{\\infty}{\\frac{t^{n}X^{n}}{n!}}\\right]  = \\sum_{n=0}^{\\infty}{\\frac{t^{n}}{n!}\\mathbb{E}\\left[X^{n}\\right]}  \\end{aligned}\\]                    확률변수 $X$ 의 원점에 대한 $n$ 차 적률은 적률생성함수를 $t=0$ 에서 $t^{n}$ 에 대하여 미분한 값임:\\[\\begin{aligned}  \\mathbb{E}\\left[X^{n}\\right]  &amp;\\approx \\frac{\\text{d}^{n}}{\\text{d}t^{n}}M_{X}(t) \\Big\\vert_{t=0}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Differentiation",
    "url": "/posts/differentiation/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-12 00:00:00 +0900",
    





    
    "snippet": "Differentiation      평균변화율: 함수 $f:X \\to Y$ 의 정의역과 공역을 각각 $x \\in X, y \\in Y$ 라고 했을 때, 구간 $[x,a]$ 에서 $x$ 의 변화 $\\Delta x$ 에 따른 $y$ 의 평균적인 변화폭 $\\Delta y / \\Delta x$\\[\\begin{aligned}  \\frac{\\Delta y}{\\D...",
    "content": "Differentiation      평균변화율: 함수 $f:X \\to Y$ 의 정의역과 공역을 각각 $x \\in X, y \\in Y$ 라고 했을 때, 구간 $[x,a]$ 에서 $x$ 의 변화 $\\Delta x$ 에 따른 $y$ 의 평균적인 변화폭 $\\Delta y / \\Delta x$\\[\\begin{aligned}  \\frac{\\Delta y}{\\Delta x}  = \\frac{f(x)-f(a)}{x-a}  = \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}  \\end{aligned}\\]        순간변화율: $x \\to a$ 일 때 구간 $[x,a]$ 에서 $x$ 의 변화 $\\Delta x$ 에 따른 $y$ 의 평균적인 변화폭 $\\Delta y / \\Delta x$ 으로서, 즉, $\\Delta x \\to 0$ 일 때 $y$ 의 평균변화율\\[\\begin{aligned}  \\frac{\\mathrm{d}y}{\\mathrm{d}x}  = \\lim_{x \\to a}{\\frac{f(x) - f(a)}{x-a}}  =\\lim_{\\Delta x \\to 0}{\\frac{f(x + \\Delta x) - f(x)}{\\Delta x}}  \\end{aligned}\\]        미분(Differentiation): 함수 $f:X \\to Y$ 의 정의역과 공역을 각각 $x \\in X, y \\in Y$ 라고 했을 때, $x \\in X$ 의 변화에 따른 $y \\in Y$ 의 순간변화율을 구하는 연산자\\[\\begin{aligned}  f^{\\prime}(x)  &amp;= \\lim_{\\Delta x \\to 0}{\\frac{f(x + \\Delta x) - f(x)}{\\Delta x}}  \\end{aligned}\\]    연산 규칙:          $\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}\\alpha=0$      $\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}\\alpha f(x)=\\alpha \\cdot \\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)$      $\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}x^{n}=n \\cdot x^{n-1}$      $\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}[f(x)+g(x)]=\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)+\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}g(x)$      $\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}[f(x)g(x)]=g(x) \\cdot \\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)+f(x)\\cdot\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}x}g(x)$            연쇄 법칙(Chain Rule): 합성함수의 미분법으로서, $y=f(u),u=g(x)$ 가 각각 $u \\in U,x \\in X$ 전체에 대하여 미분 가능한 경우 다음이 성립함\\[\\begin{aligned}  \\frac{\\mathrm{d}y}{\\mathrm{d}x}  = \\frac{\\mathrm{d}y}{\\mathrm{d}u} \\times \\frac{\\mathrm{d}u}{\\mathrm{d}x}  \\end{aligned}\\]  Natural Logarithm      자연로그의 미분법:\\[\\begin{aligned}  \\ln{x}  &amp;=\\int_{t=1}^{t=x}{\\frac{1}{t}\\mathrm{d}t}\\\\  \\therefore \\frac{\\mathrm{d}}{\\mathrm{d}x}\\ln(x)  &amp;= \\frac{\\mathrm{d}}{\\mathrm{d}x}\\int_{t=1}^{t=x}{\\frac{1}{t}\\mathrm{d}t}=\\frac{1}{x}  \\end{aligned}\\]        상수 $e$ 에 대한 지수함수의 미분법:\\[\\begin{aligned}  \\frac{\\mathrm{d}}{\\mathrm{d}x}e^{x}  &amp;= e^{x}  \\end{aligned}\\]                  임의의 상수 $a$ 에 대하여 정의된 지수함수 $f(x)=a^{x}$ 의 순간변화율:\\[\\begin{aligned}  \\frac{\\mathrm{d}}{\\mathrm{d}x}a^{x}  &amp;= \\lim_{\\Delta x \\to 0}{\\frac{a^{x}(a^{\\Delta x}-1)}{\\Delta x}}\\\\  &amp;= a^{x}  \\end{aligned}\\]                    좌변에서 $\\lim_{\\Delta x \\to 0}{a^{x}}$ 를 소거하면:\\[\\begin{aligned}  \\lim_{\\Delta x \\to 0}{\\frac{a^{x}(a^{\\Delta x}-1)}{\\Delta x}}  &amp;= a^{x}\\\\  \\lim_{\\Delta x \\to 0}{a^{x}} \\times \\lim_{\\Delta x \\to 0}{\\frac{a^{\\Delta x}-1}{\\Delta x}}  &amp;= a^{x}\\\\  a^{x} \\times \\lim_{\\Delta x \\to 0}{\\frac{a^{\\Delta x}-1}{\\Delta x}}  &amp;= a^{x}\\\\  \\therefore \\lim_{\\Delta x \\to 0}{\\frac{a^{\\Delta x}-1}{\\Delta x}}  &amp;= 1  \\end{aligned}\\]                    좌변에서 $\\lim_{\\Delta x \\to 0}{1/\\Delta x}$ 를 소거하면:\\[\\begin{aligned}  \\lim_{\\Delta x \\to 0}{\\frac{a^{\\Delta x}-1}{\\Delta x}}  &amp;= 1\\\\  \\frac{\\lim_{\\Delta x \\to 0}{(a^{\\Delta x}-1)}}{\\lim_{\\Delta x \\to 0}{\\Delta x}}  &amp;= 1\\\\  \\lim_{\\Delta x \\to 0}{(a^{\\Delta x}-1)}  &amp;= \\lim_{\\Delta x \\to 0}{\\Delta x}  \\end{aligned}\\]                    좌변에서 $\\lim_{\\Delta x \\to 0}{1}$ 을 소거하면:\\[\\begin{aligned}  \\lim_{\\Delta x \\to 0}{(a^{\\Delta x}-1)}  &amp;= \\lim_{\\Delta x \\to 0}{\\Delta x}\\\\  \\lim_{\\Delta x \\to 0}{a^{\\Delta x}}-\\lim_{\\Delta x \\to 0}{1}  &amp;= \\lim_{\\Delta x \\to 0}{\\Delta x}\\\\  \\lim_{\\Delta x \\to 0}{a^{\\Delta x}}  &amp;= \\lim_{\\Delta x \\to 0}{1} + \\lim_{\\Delta x \\to 0}{\\Delta x}\\\\  \\therefore \\lim_{\\Delta x \\to 0}{a^{\\Delta x}}  &amp;= \\lim_{\\Delta x \\to 0}{(1 + \\Delta x)}  \\end{aligned}\\]                    양변을 $1/\\Delta x$ 제곱하면:\\[\\begin{aligned}  \\lim_{\\Delta x \\to 0}{a^{\\Delta x}}  &amp;= \\lim_{\\Delta x \\to 0}{(1 + \\Delta x)}\\\\  \\lim_{\\Delta x \\to 0}{a}  &amp;= \\lim_{\\Delta x \\to 0}{(1 + \\Delta x)^{1/\\Delta x}}\\\\  \\therefore a  &amp;= \\lim_{\\Delta x \\to 0}{(1 + \\Delta x)^{1/\\Delta x}}  \\end{aligned}\\]                    $\\Delta x$ 를 $1/n$ 으로 치환하면:\\[\\begin{aligned}  a  &amp;= \\lim_{\\Delta x \\to 0}{(1 + \\Delta x)^{1/\\Delta x}}\\\\  &amp;= \\lim_{n \\to \\infty}{\\left(1 + \\frac{1}{n}\\right)^{n}}\\\\  &amp;= e  \\end{aligned}\\]            "
  },
  
  {
    "title": "Limit and Continuity",
    "url": "/posts/limit_continuity/",
    "categories": "1.MATHEMATICAL TECHS, 2.calculus",
    "tags": "mathematics, calculus",
    "date": "2022-07-11 00:00:00 +0900",
    





    
    "snippet": "Limit &amp; Continuity      극한(Limit): 함수 $f:X \\to Y$ 에 대하여 $x \\ne a$ 이면서 $x$ 가 $a$ 에 한없이 가까워질 때 $y$ 가 일정한 값 $z$ 에 가까워지는 경우, $y$ 가 $x \\to a$ 일 때 $z$ 에 수렴한다(Converge)고 하고, $L$ 을 $x \\to a$ 에서 $f$ 의 극...",
    "content": "Limit &amp; Continuity      극한(Limit): 함수 $f:X \\to Y$ 에 대하여 $x \\ne a$ 이면서 $x$ 가 $a$ 에 한없이 가까워질 때 $y$ 가 일정한 값 $z$ 에 가까워지는 경우, $y$ 가 $x \\to a$ 일 때 $z$ 에 수렴한다(Converge)고 하고, $L$ 을 $x \\to a$ 에서 $f$ 의 극한(Limit)이라고 함\\[\\begin{aligned}  \\lim_{x  \\to a}{f(x)}=z  \\Rightarrow  \\underbrace{\\lim_{x  \\to a-0}{f(x)}}_{\\text{left-hand limit}}  =\\underbrace{\\lim_{x  \\to a+0}{f(x)}}_{\\text{right-hand limit}}  =z  \\end{aligned}\\]          $\\lim_{x  \\to a}{\\alpha f(x)}=\\alpha \\lim_{x  \\to a}{f(x)}$      $\\lim_{x  \\to a}{[f(x)+g(x)]}=\\lim_{x  \\to a}{f(x)}+\\lim_{x  \\to a}{g(x)}$      $\\lim_{x  \\to a}{[f(x)g(x)]}=\\lim_{x  \\to a}{f(x)}\\lim_{x  \\to a}{g(x)}$      $\\lim_{x  \\to a}{[f(x)/g(x)]}=\\lim_{x  \\to a}{f(x)}/\\lim_{x  \\to a}{g(x)} \\quad (\\text{s.t.}\\ \\lim_{x  \\to a}{g(x)} \\ne 0)$            연속(Continuity): 함수 $f:X \\to Y$ 에 대하여 $f$ 가 $x=a$ 에서 함수값 $y=f(x)$ 과 극한값 $z=\\lim_{x \\to a}{f(x)}$ 이 모두 존재하고 $y=z$ 일 때 $f$ 는 $x=a$ 에서 연속임  \\[\\begin{aligned}f(a)=\\lim_{x \\to a}{f(x)}\\end{aligned}\\]  연속 함수(Continuous Function): 함수 $f:X \\to Y$ 가 정의역 $a \\in \\mathcal{X}$ 전체에서 연속이면 $f$ 는 연속 함수임\\[\\begin{aligned}f(a)=\\lim_{x \\to a}{f(x)}, \\quad \\forall a \\in \\mathcal{X}\\end{aligned}\\]Natural Logarithm      자연로그(Natural Logarithm): 함수 \\(g(x)=1/x\\) 의 면적(정적분)에 관한 함수\\[\\begin{aligned}  f(x)  =\\ln{x}  =\\int_{t=1}^{t=x}{\\frac{1}{t}\\text{d}t}  \\end{aligned}\\]        상수 $e$: 자연로그 값이 $1$ 일 때의 $x$ 값\\[\\begin{aligned}  e  = \\lim_{n \\to \\infty}{\\left(1 + \\frac{1}{n}\\right)^{n}}  = 2.71828\\cdots, \\quad n \\in \\mathbb{R}  \\end{aligned}\\]        example $\\lim_{x \\to 0}{(1+3x)^{1/x}}$\\[\\begin{aligned}  \\lim_{x \\to 0}{(1+3x)^{n}}  &amp;= \\lim_{x \\to 0}{\\left(1+\\frac{3}{n}\\right)^{n}}\\\\  &amp;= \\lim_{x \\to 0}{\\left(1+\\frac{3}{n/3}\\right)^{n/3 \\times 3}}\\\\  &amp;= e^{3}  \\end{aligned}\\]        연속 복리(Continuous Compounding): 가장 짧은 시간 간격으로 취하는 복리                  원금 $a$ 를 연이율 $r$ 로 $n$ 년간 복리예금 시 원리금\\[\\begin{aligned}  S  &amp;= a(1+r)^{n}  \\end{aligned}\\]                    $n$ 년간 이자를 $k$ 번 계산하는 경우 원리금\\[\\begin{aligned}  S  &amp;= a\\left[\\left(1+r/k\\right)^{k}\\right]^{n}  \\end{aligned}\\]                    $k \\to \\infty$ 일 때 원리금\\[\\begin{aligned}  \\lim_{k \\to \\infty}{S}  &amp;= \\lim_{k \\to \\infty}{a\\left[\\left(1+r/k\\right)^{k}\\right]^{n}}\\\\  &amp;= \\lim_{k \\to \\infty}{a\\left[\\left(1+\\frac{1}{k/r}\\right)^{k/r \\times r}\\right]^{n}}\\\\  &amp;= a \\times e^{r \\times n}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Matrix Decomposition",
    "url": "/posts/matrix_decomposition/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-09 00:00:00 +0900",
    





    
    "snippet": "Matrix Decomposition  행렬 분해(Matrix Decomposition): 고차원 행렬을 특정한 구조를 가진 저차원 행렬들의 합과 곱으로 근사하는 기법          스펙트럼 분해(Spectral Decomposition): 대칭행렬에 대한 분해    \\[\\begin{aligned}  \\mathbf{A} \\approx \\mathbf{...",
    "content": "Matrix Decomposition  행렬 분해(Matrix Decomposition): 고차원 행렬을 특정한 구조를 가진 저차원 행렬들의 합과 곱으로 근사하는 기법          스펙트럼 분해(Spectral Decomposition): 대칭행렬에 대한 분해    \\[\\begin{aligned}  \\mathbf{A} \\approx \\mathbf{P}\\Lambda\\mathbf{P}^{T}, \\quad \\mathbf{A}=\\mathbf{A}^{T}  \\end{aligned}\\]          특이값 분해(Singular Value Decomposition): 비대칭 행렬에 대한 분해    \\[\\begin{aligned}  \\mathbf{A} \\approx \\mathbf{U}\\Sigma\\mathbf{V}^{T}  \\end{aligned}\\]  Spectral Decomposition  대칭행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 에 대하여, 그 차원이 \\(N \\times N\\)  이라면 \\(N\\) 개의 고유벡터 \\(\\mathbf{v}_{i}\\) 와 고유값 \\(\\lambda_{i}\\) 이 존재함\\[\\begin{aligned}\\mathbf{A}\\mathbf{v}_{i}=\\lambda_{i}\\mathbf{v}_{i},\\quad i=1,2,\\cdots,N\\end{aligned}\\]  대칭행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 의 고유벡터들은 모두 직교함\\[\\begin{aligned}\\mathbf{v}_{1} \\perp \\mathbf{v}_{2} \\perp \\cdots \\perp \\mathbf{v}_{N}\\end{aligned}\\]  따라서 대칭행렬 \\(\\mathbf{A}\\) 는 항상 직교 대각화(orthogonal diagonalization) 가능함\\[\\begin{aligned}\\mathbf{P}^{T}\\mathbf{A}\\mathbf{P}&amp;=\\Lambda, \\quad \\mathbf{P}^{T}=\\mathbf{P}^{-1}\\end{aligned}\\]  이로부터 대칭행렬 \\(\\mathbf{A}\\) 를 대각화 행렬 \\(\\mathbf{P}=\\begin{bmatrix}\\mathbf{v}_{1} &amp; \\mathbf{v}_{2} &amp; \\cdots &amp; \\mathbf{v}_{N}\\end{bmatrix}\\) 와 고유값 대각 행렬 \\(\\Lambda=\\mathrm{diag}(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{N})\\) 의 곱으로 근사할 수 있음\\[\\begin{aligned}\\mathbf{P}^{T}\\mathbf{A}\\mathbf{P}&amp;=\\Lambda\\\\(\\mathbf{P}\\mathbf{P}^{T})\\mathbf{A}(\\mathbf{P}\\mathbf{P}^{T})&amp;=\\mathbf{P}\\Lambda\\mathbf{P}^{T}\\\\\\mathbf{I}\\mathbf{A}\\mathbf{I}&amp;=\\mathbf{P}\\Lambda\\mathbf{P}^{T},\\quad (\\because \\mathbf{P}^{T}=\\mathbf{P}^{-1})\\\\\\therefore \\mathbf{A}&amp;= \\mathbf{P}\\Lambda\\mathbf{P}^{T}\\end{aligned}\\]Singular Value Decomposition      비대칭행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{M \\times N}\\) 에 대하여 다음을 정의하자\\[\\begin{aligned}  \\mathbf{P}  &amp;= \\mathbf{A}\\mathbf{A}^{T} \\in \\mathbb{R}^{M \\times M}\\\\  \\mathbf{Q}  &amp;= \\mathbf{A}^{T}\\mathbf{A} \\in \\mathbb{R}^{N \\times N}  \\end{aligned}\\]        왼쪽 특이벡터 행렬 \\(\\mathbf{U}\\) 과 오른쪽 특이벡터 행렬 \\(\\mathbf{V}\\) 을 각각 다음과 같이 구성하자\\[\\begin{aligned}  \\mathbf{U}  &amp;= \\begin{bmatrix}\\mathbf{u}_{1} &amp; \\mathbf{u}_{2} &amp; \\cdots &amp; \\mathbf{u}_{K}\\end{bmatrix}\\\\  \\mathbf{V}  &amp;= \\begin{bmatrix}\\mathbf{v}_{1} &amp; \\mathbf{v}_{2} &amp; \\cdots &amp; \\mathbf{v}_{K}\\end{bmatrix}  \\end{aligned}, \\quad  K=\\mathrm{rank}(\\mathbf{A})\\]                  \\(\\mathbf{u}\\): 왼쪽 특이벡터(Left Singular Vector)\\[\\forall \\mathbf{u}:\\mathbf{P}\\mathbf{u}=\\lambda\\mathbf{u}\\]                    \\(\\mathbf{v}\\): 오른쪽 특이벡터(Right Singular Vector)\\[\\forall \\mathbf{v}:\\mathbf{Q}\\mathbf{v}=\\lambda\\mathbf{v}\\]                  \\(\\mathbf{P}\\) 와 \\(\\mathbf{Q}\\) 는 전치 관계이므로 그 고유값이 동일하며, 이때 고유값 \\(\\lambda_{i}\\) 의 제곱근을 특이값(Singular Value)이라 함\\[\\begin{aligned}  \\sqrt{\\lambda_{i}}  \\end{aligned}\\]        특이값 대각 행렬 \\(\\Sigma\\) 는 특이값 \\(\\sqrt{\\lambda_{i}}\\) 을 대각 원소로 가지는 대각행렬임\\[\\begin{aligned}  \\Sigma  &amp;= \\mathrm{diag}(\\sqrt{\\lambda_{1}},\\sqrt{\\lambda_{2}},\\cdots,\\sqrt{\\lambda_{K}})  \\end{aligned}\\]        비대칭행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{M \\times N}\\) 은 다음과 같이 근사될 수 있음\\[\\begin{aligned}  \\mathbf{A}  &amp;\\approx \\mathbf{U}\\Sigma\\mathbf{V}^{T}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Eigen",
    "url": "/posts/eigen/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-08 00:00:00 +0900",
    





    
    "snippet": "Eigen      정방행렬 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 로 선형 변환하였을 때 그 방향은 변하지 않고 길이만 변하는 벡터를 $\\mathbf{A}$ 의 고유벡터(Eigen Vector), 이때 길이의 변화량을 고유값(Eigen Value)이라고 정의함    \\[\\begin{gathered}  \\mathbf{...",
    "content": "Eigen      정방행렬 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 로 선형 변환하였을 때 그 방향은 변하지 않고 길이만 변하는 벡터를 $\\mathbf{A}$ 의 고유벡터(Eigen Vector), 이때 길이의 변화량을 고유값(Eigen Value)이라고 정의함    \\[\\begin{gathered}  \\mathbf{A}\\mathbf{v}  = \\lambda\\mathbf{v},\\quad \\mathbf{v}\\ne\\mathbf{0}\\\\  \\Updownarrow \\\\  \\begin{bmatrix}  a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,N}\\\\  a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,N}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  a_{N,1} &amp; a_{N,2} &amp; \\cdots &amp; a_{N,N}\\\\  \\end{bmatrix}  \\begin{bmatrix}  v_{1}\\\\  v_{2}\\\\  \\vdots\\\\  v_{N}\\\\  \\end{bmatrix}  = \\lambda \\begin{bmatrix}  v_{1}\\\\  v_{2}\\\\  \\vdots\\\\  v_{N}\\\\  \\end{bmatrix}  \\end{gathered}\\]    연산 규칙:          $\\mathrm{tr}(\\mathbf{A})=\\sum_{i=1}^{N}{\\lambda_{i}}$      $\\mathrm{det}(\\mathbf{A})=\\prod_{i=1}^{N}{\\lambda_{i}}$      $\\mathbf{A}\\mathbf{v}=\\lambda\\mathbf{v} \\quad \\text{and} \\quad \\mathbf{A}^{T}\\mathbf{w}=\\lambda\\mathbf{w}$      $\\lambda_{i}=0 \\Rightarrow \\nexists \\mathbf{A}^{-1}$      \\(\\lambda_{i} \\ne \\lambda_{j} \\Rightarrow \\alpha_{i}\\mathbf{v}_{i} + \\alpha_{j}\\mathbf{v}_{j} \\ne 0,\\forall \\alpha \\ne 0\\) \\(\\quad\\)            특성 방정식(Characteristic Equation):\\[\\begin{aligned}  (\\mathbf{A} - \\lambda \\mathbf{I})\\mathbf{v}  &amp;=\\mathbf{0},\\quad \\mathbf{v}\\ne\\mathbf{0}  \\end{aligned}\\]          정해: \\(\\nexists (\\mathbf{A}-\\lambda \\mathbf{I})^{-1} \\Leftrightarrow \\exists \\mathbf{v},\\lambda\\)      불능: \\(\\exists (\\mathbf{A}-\\lambda \\mathbf{I})^{-1} \\Leftrightarrow \\nexists \\mathbf{v},\\lambda\\)      Diagonalization      행렬의 대각화(Diagonalization): 정방행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 에 대하여 \\(\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}\\) 가 대각행렬 \\(\\Lambda=\\mathrm{diag}(\\lambda_{1},\\cdots,\\lambda_{N})\\) 이 되도록 만드는 정방행렬 \\(\\mathbf{P}(\\ne \\mathbf{0})\\) 이 이 존재하는 경우\\[\\begin{aligned}  \\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}  &amp;= \\Lambda \\\\  &amp;= \\mathrm{diag}(\\lambda_{1},\\cdots,\\lambda_{N})  \\end{aligned}\\]          \\(\\mathbf{P}\\): 고유벡터 행렬 혹은 대각화 행렬      \\(\\Lambda\\): 고유값 대각 행렬            대칭행렬의 직교 대각화          대칭행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 에 대하여 그 고유값이 \\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\) 이고, 고유벡터가 \\(\\mathbf{v}_{1},\\mathbf{v}_{2},\\cdots,\\mathbf{v}_{N}\\) 이라고 하자    \\[\\begin{aligned}  \\mathbf{A}\\mathbf{v}_{i}  &amp;= \\lambda_{i}\\mathbf{v}_{i}, \\quad i=1,2,\\cdots,N  \\end{aligned}\\]                  \\(\\mathbf{A}\\) 의 고유벡터 \\(\\mathbf{v}_{1},\\mathbf{v}_{2},\\cdots, \\mathbf{v}_{N}\\) 는 항상 직교함\\[\\begin{aligned}  \\mathbf{v}_{1} \\perp \\mathbf{v}_{2} \\perp \\cdots \\perp \\mathbf{v}_{N}  \\end{aligned}\\]                    \\(\\mathbf{A}\\) 의 고유벡터들로 구성된 대각화 행렬 \\(\\mathbf{P}=\\begin{bmatrix}\\mathbf{v}_{1}&amp;\\mathbf{v}_{2}&amp;\\cdots&amp;\\mathbf{v}_{N}\\end{bmatrix}\\) 은 항상 직교행렬임\\[\\begin{aligned}  \\mathbf{P}^{T}  &amp;=\\mathbf{P}^{-1}  \\end{aligned}\\]                    직교행렬 \\(\\mathbf{P}=\\begin{bmatrix}\\mathbf{v}_{1}&amp;\\mathbf{v}_{2}&amp;\\cdots&amp;\\mathbf{v}_{N}\\end{bmatrix}\\) 은 \\(\\mathbf{A}\\) 를 그 고유값 \\(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{N}\\) 으로 구성된 대각행렬 \\(\\Lambda\\) 로 대각화시킴\\[\\begin{aligned}  \\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}  &amp;= \\Lambda \\\\  &amp;= \\mathrm{diag}(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)  \\end{aligned}\\]            "
  },
  
  {
    "title": "Linear Transformation",
    "url": "/posts/linear_transformation/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-07 00:00:00 +0900",
    





    
    "snippet": "Linear Transformation      선형 변환(Linear Transformation): 행렬 $\\mathbf{A} \\in \\mathbb{R}^{N \\times P}$ 은 벡터 공간 $\\mathbb{R}^{P}$ 에서 $\\mathbb{R}^{N}$ 으로의 선형 사상자(Linear Map)임\\[L: \\mathbb{R}^{P} \\to \\mat...",
    "content": "Linear Transformation      선형 변환(Linear Transformation): 행렬 $\\mathbf{A} \\in \\mathbb{R}^{N \\times P}$ 은 벡터 공간 $\\mathbb{R}^{P}$ 에서 $\\mathbb{R}^{N}$ 으로의 선형 사상자(Linear Map)임\\[L: \\mathbb{R}^{P} \\to \\mathbb{R}^{N},  \\quad  L(\\mathbf{x}):= \\mathbf{A}\\mathbf{x}\\]          $L(\\mathbf{v}+\\mathbf{w})=L(\\mathbf{v})+L(\\mathbf{w})$      $L(\\alpha \\mathbf{v})=\\alpha L(\\mathbf{v})$      Example      단위 행렬 \\(\\mathbf{I} \\in \\mathbb{R}^{2}\\) 는 벡터 공간의 기저 벡터 \\(\\mathbf{e}_{1},\\mathbf{e}_{2}\\) 들의 집합임\\[\\begin{aligned}  \\mathbf{I}  = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}  = \\begin{bmatrix} \\mathbf{e}_{1} &amp; \\mathbf{e}_{2} \\end{bmatrix}  \\end{aligned}\\]        벡터 \\(\\mathbf{x} \\in \\mathbb{R}^{2}\\) 는 \\(\\begin{bmatrix}1 \\\\0\\end{bmatrix}\\) 를 \\(X\\) 축 기저로, \\(\\begin{bmatrix}0 \\\\1\\end{bmatrix}\\) \\(Y\\) 축 기저로 취하는 좌표계에서 원점으로부터 \\(X\\) 축으로 \\(x_{1}\\) 단위, \\(Y\\) 축으로 \\(x_{2}\\) 단위 만큼 이동한 좌표임\\[\\begin{aligned}  \\mathbf{x}  &amp;=\\begin{bmatrix}1 \\\\ 1\\end{bmatrix}  =\\begin{bmatrix}1 &amp; 0\\\\ 0 &amp;1\\end{bmatrix} \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}  =\\begin{bmatrix}1 \\\\ 0\\end{bmatrix} \\cdot 1 + \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} \\cdot 1  \\end{aligned}\\]        행렬 $\\mathbf{A}$ 는 \\(X\\) 축 기저 벡터를 \\(\\mathbf{a}_{1}\\) 로, \\(Y\\) 축 기저 벡터를 \\(\\mathbf{a}_{2}\\) 로 변환함\\[\\mathbf{A}  =\\begin{bmatrix}2 &amp; -3\\\\ 1 &amp; 1\\end{bmatrix}  =\\begin{bmatrix}\\mathbf{a}_{1} &amp; \\mathbf{a}_{2}\\end{bmatrix},  \\quad  \\begin{aligned}  \\mathbf{a}_{1}  &amp;=\\begin{bmatrix}2 &amp; 1 \\end{bmatrix}^{T},\\\\  \\mathbf{a}_{2}  &amp;=\\begin{bmatrix}-3 &amp; 1 \\end{bmatrix}^{T}  \\end{aligned}\\]        선형 변환 \\(\\mathbf{A}\\mathbf{x}\\) 는 벡터 \\(\\mathbf{x}\\) 를 \\(\\mathbf{e}_{1},\\mathbf{e}_{2}\\) 를 기저로 취하는 죄표계에서 \\(\\mathbf{a}_{1},\\mathbf{a}_{2}\\) 를 기저로 취하는 좌표계로 사상함\\[\\begin{aligned}  \\mathbf{A}\\mathbf{x}  &amp;= \\begin{bmatrix}2 &amp; -3\\\\ 1 &amp; 1\\end{bmatrix} \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}  =\\begin{bmatrix}2 \\\\ 1\\end{bmatrix} \\cdot 1 + \\begin{bmatrix}-3 \\\\ 1\\end{bmatrix} \\cdot 1  \\end{aligned}\\]  Special Transformation      회전 변환 행렬(Rotation Matrix): 반시계 방향으로 $\\theta^{\\circ}$ 회전하는 선형 변환\\[\\begin{bmatrix}  \\cos \\theta &amp; -\\sin \\theta \\\\  \\sin \\theta &amp; \\cos \\theta  \\end{bmatrix}\\]        크기 변환 행렬(Scaling Matrix): $X$ 축 단위를 $\\alpha$ 배, $Y$ 축 단위를 $\\beta$ 배 늘리는 선형 변환\\[\\begin{bmatrix}  \\alpha &amp; 0 \\\\  0 &amp; \\beta  \\end{bmatrix}\\]        전단 변환 행렬(Shearing Matrix): 각 축의 기저 벡터를 변형시키는 선형 변환                  Horizontal Shearing: \\(X\\) 축의 기저 벡터는 그대로, \\(Y\\) 축의 기저 벡터는 \\(\\begin{bmatrix} \\beta \\\\1 \\end{bmatrix}\\) 으로 변형함\\[\\begin{bmatrix}  1 &amp; \\beta\\\\  0 &amp; 1  \\end{bmatrix}\\]                    Vertical Shearing: \\(Y\\) 축의 기저 벡터는 그대로, \\(X\\) 축의 기저 벡터는 \\(\\begin{bmatrix} 1\\\\ \\beta \\end{bmatrix}\\) 으로 변형함\\[\\begin{pmatrix} 1&amp;0\\\\s&amp;1 \\end{pmatrix}\\]                    Arbitrary Shearing: \\(X\\) 축의 기저 벡터는 \\(\\begin{bmatrix} 1 \\\\ \\alpha \\end{bmatrix}\\) 으로, \\(Y\\) 축의 기저 벡터는 \\(\\begin{bmatrix} \\beta \\\\ 1 \\end{bmatrix}\\) 으로 변형함\\[\\begin{bmatrix}  1 &amp; \\beta\\\\  \\alpha &amp; 1  \\end{bmatrix}\\]            Determinant      행렬식(Determinant): 정방행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 으로 선형 변환함에 따른 좌표계 단위 면적(혹은 부피)의 변화량    \\[\\begin{aligned}  \\vert\\mathrm{det}(\\mathbf{A}) \\vert  &amp;= \\Vert\\mathbf{a}_{1}\\Vert \\cdot \\Vert\\mathbf{a}_{2}\\Vert \\cdot \\sin{\\theta}  \\end{aligned}\\]    연산 규칙:          $\\mathrm{det}(\\alpha)=\\alpha$      $\\mathrm{det}(\\alpha \\mathbf{A})=\\alpha^{n} \\cdot \\mathrm{det}(\\mathbf{A})$      $\\mathrm{det}(\\mathbf{I})=1$      $\\mathrm{det}(\\mathbf{A})=\\mathrm{det}(\\mathbf{A}^{T})$      $\\mathrm{det}(\\mathbf{A}^{-1})=\\mathrm{det}(\\mathbf{A})^{-1}$      $\\mathrm{det}(\\mathbf{AB})=\\mathrm{det}(\\mathbf{A}) \\cdot \\mathrm{det}(\\mathbf{B})$      \\(\\mathrm{det}(\\begin{bmatrix}\\mathbf{a}_{i} &amp; \\mathbf{a}_{j}\\end{bmatrix}) = - \\mathrm{det}(\\begin{bmatrix}\\mathbf{a}_{j} &amp; \\mathbf{a}_{i}\\end{bmatrix})\\) \\(\\quad\\)      \\(\\mathrm{det}\\left(\\begin{bmatrix}\\alpha \\mathbf{a}_{i} \\\\ \\mathbf{a}_{j}\\end{bmatrix}\\right)=\\alpha  \\cdot \\mathrm{det}\\left(\\begin{bmatrix}\\mathbf{a}_{i} \\\\ \\mathbf{a}_{j}\\end{bmatrix}\\right)\\) \\(\\quad\\)        $\\mathrm{det}(\\mathbf{A})=0, \\quad \\mathbf{A} \\in \\mathbb{R}^{N \\times N}$:          $\\mathrm{rank}(\\mathbf{A}) &lt; N$      \\(\\mathrm{span}(\\{\\mathbf{a}_{1},\\cdots,\\mathbf{a}_{N}\\}) \\ne \\mathbb{R}^{N}\\) \\(\\quad\\)      $\\nexists \\mathbf{A}^{-1}$        $\\mathrm{det}(\\mathbf{A}) \\ne 0, \\quad \\mathbf{A} \\in \\mathbb{R}^{N \\times N}$:          $\\mathrm{rank}(\\mathbf{A}) = N$      \\(\\mathrm{span}(\\{\\mathbf{a}_{1},\\cdots,\\mathbf{a}_{N}\\}) = \\mathbb{R}^{N}\\) \\(\\quad\\)      $\\exists \\mathbf{A}^{-1}$      Sourse  https://angeloyeo.github.io/2019/07/15/Matrix_as_Linear_Transformation.html"
  },
  
  {
    "title": "Linear Equation",
    "url": "/posts/linear_equation/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-06 00:00:00 +0900",
    





    
    "snippet": "Linear Equation      선형방정식(Linear Equation): 최고차항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  a_{1}x_{1} + a_{2}x_{2} + \\cdots + a_{P}x_{P}  &amp;= b  \\end{aligned}\\]        선형연립방정식(Linea...",
    "content": "Linear Equation      선형방정식(Linear Equation): 최고차항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  a_{1}x_{1} + a_{2}x_{2} + \\cdots + a_{P}x_{P}  &amp;= b  \\end{aligned}\\]        선형연립방정식(Linear Simultaneous Equation): 둘 이상의 선형방정식의 집합\\[\\begin{gathered}  \\begin{matrix}  a_{1,1}x_{1} &amp; + &amp; a_{1,2}x_{2} &amp; + &amp; \\cdots &amp; + &amp; a_{1,P}x_{P} &amp; = &amp; b_1 \\\\  a_{2,1}x_{1} &amp; + &amp; a_{2,2}x_{2} &amp; + &amp; \\cdots &amp; + &amp; a_{2,P}x_{P} &amp; = &amp; b_{2} \\\\  \\vdots &amp; + &amp; \\vdots &amp; + &amp; \\ddots &amp; + &amp; \\vdots &amp; = &amp; \\vdots \\\\  a_{N,1}x_{1} &amp; + &amp; a_{N,2}x_{2} &amp; + &amp; \\cdots &amp; + &amp; a_{N,P}x_{P} &amp; = &amp; b_{P}  \\end{matrix}  \\end{gathered}\\]  Coefficient Matrix      Vector representation of Linear Equation:\\[\\begin{gathered}  \\mathbf{A}\\mathbf{x}=\\mathbf{b}  \\\\  \\Updownarrow\\\\  \\begin{bmatrix}  a_{1,1}&amp;a_{1,2}&amp;\\cdots&amp;a_{1,P}\\\\  a_{2,1}&amp;a_{2,2}&amp;\\cdots&amp;a_{2,P}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{N,1}&amp;a_{N,2}&amp;\\cdots&amp;a_{N,P}  \\end{bmatrix}  \\begin{bmatrix}  x_{1}\\\\  x_{2}\\\\  \\vdots\\\\  x_{P}  \\end{bmatrix}      = \\begin{bmatrix}  b_{1}\\\\  b_{2}\\\\  \\vdots\\\\  b_{P}  \\end{bmatrix}  \\end{gathered}\\]          $\\mathbf{A}$: 계수 행렬      $\\mathbf{x}$: 미지수 벡터 혹은 해 벡터      $\\mathbf{b}$: 상수 벡터            계수 행렬(Coefficient Matrix): 선형연립방정식 계수들의 집합으로서 벡터 $\\mathbf{x}$ 를 선형변환하는 행렬\\[\\begin{aligned}  \\mathbf{A}  &amp;=\\begin{bmatrix}  a_{1,1}&amp;a_{1,2}&amp;\\cdots&amp;a_{1,P}\\\\  a_{2,1}&amp;a_{2,2}&amp;\\cdots&amp;a_{2,P}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{N,1}&amp;a_{N,2}&amp;\\cdots&amp;a_{N,P}  \\end{bmatrix}  \\end{aligned}\\]        계수 행렬 \\(\\mathbf{A}\\) 은 \\(\\mathbf{e}_{1},\\mathbf{e}_{2},\\cdots,\\mathbf{e}_{P}\\) 를 기저로 사용하는 좌표계에서 \\(\\mathbf{a}_{1},\\mathbf{a}_{2},\\cdots,\\mathbf{a}_{P}\\) 를 기저로 사용하는 좌표계로 벡터 \\(\\mathbf{x}\\) 를 선형변환함:\\[\\begin{aligned}  \\mathbf{x}  &amp;=\\begin{bmatrix}1 \\\\ 0 \\\\ \\vdots \\\\ 0\\end{bmatrix} x_{1} + \\begin{bmatrix}0 \\\\ 1 \\\\ \\vdots \\\\ 0\\end{bmatrix} x_{2} + \\cdots + \\begin{bmatrix}0 \\\\ 0 \\\\ \\vdots \\\\ 1\\end{bmatrix} x_{P}  \\\\  \\mathbf{A}\\mathbf{x}  &amp;= \\begin{bmatrix}a_{1,1} \\\\ a_{2,1} \\\\ \\vdots \\\\ a_{N,1}\\end{bmatrix} x_{1} + \\begin{bmatrix}a_{1,2} \\\\ a_{2,2} \\\\ \\vdots \\\\ a_{N,2}\\end{bmatrix} x_{2} + \\cdots + \\begin{bmatrix}a_{1,P} \\\\ a_{2,P} \\\\ \\vdots \\\\ a_{N,P}\\end{bmatrix} x_{P}  \\end{aligned}\\]  Solution of the Equation      정해(uniquely determined): 선형연립방정식의 계수 행렬 \\(\\mathbf{A} \\in \\mathbb{R}^{N \\times N}\\) 에 대하여 그 역행렬이 존재하면 단 하나의 해가 존재함    \\[\\begin{aligned}  \\exists \\mathbf{A}^{-1} \\Leftrightarrow \\forall \\mathbf{b} \\in \\mathbb{R}^{P}, \\exists ! \\mathbf{x} \\in \\mathbb{R}^{P} : \\mathbf{A}\\mathbf{x}=\\mathbf{b}  \\end{aligned}\\]          $\\mathrm{rank}(\\mathbf{A})=P$      $\\mathrm{det}(\\mathbf{A}) \\ne 0$      $\\sum_{i=1}^{P}{\\alpha_{i}\\mathbf{a}_{i}} \\ne 0, \\quad \\forall \\alpha \\ne 0$      $\\mathrm{span}(S)=\\mathbb{R}^{P}, \\quad S={\\mathbf{a}{1},\\cdots,\\mathbf{a}{P}}$            불능(inconsistent): 해를 구할 수 없는 상태로서, 계수 행렬 \\(\\mathbf{A}=\\begin{bmatrix}\\mathbf{a}_{1} &amp; \\mathbf{a}_{2} &amp; \\cdots &amp; \\mathbf{a}_{P}\\end{bmatrix}^{T}\\) 가 선형 종속이고, 동시에 \\(\\mathbf{b}\\) 가 선형 독립인 경우    \\[\\begin{gathered}  \\mathrm{rank}(\\mathbf{A})&lt;P  \\ \\text{and} \\  \\mathbf{b} \\notin \\mathrm{span}(\\{\\mathbf{a}_{1},\\cdots,\\mathbf{a}_{P}\\})  \\Rightarrow \\nexists \\mathbf{x} \\in \\mathbb{R}^{P}:\\mathbf{A}\\mathbf{x}=\\mathbf{b}  \\end{gathered}\\]        부정(indeterminate): 해가 무수히 많아 하나로 정할 수 없는 상태로서, 계수 행렬 \\(\\mathbf{A}=\\begin{bmatrix}\\mathbf{a}_{1} &amp; \\mathbf{a}_{2} &amp; \\cdots &amp; \\mathbf{a}_{P}\\end{bmatrix}^{T}\\) 가 선형 종속이고, 동시에 \\(\\mathbf{b}\\) 도 선형 종속인 경우    \\[\\begin{gathered}  \\mathrm{rank}(\\mathbf{A})&lt;P  \\ \\text{and} \\  \\mathbf{b} \\in \\mathrm{span}(\\{\\mathbf{a}_{1},\\cdots,\\mathbf{a}_{P}\\})  \\Rightarrow \\exists^{\\infty} \\mathbf{x} \\in \\mathbb{R}^{P}:\\mathbf{A}\\mathbf{x}=\\mathbf{b}  \\end{gathered}\\]  "
  },
  
  {
    "title": "Matrix",
    "url": "/posts/matrix/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-05 00:00:00 +0900",
    





    
    "snippet": "Matrix      행렬(Matrix):\\[\\begin{aligned}  \\mathbf{X}  &amp;=\\begin{bmatrix}  x_{1,1}&amp;x_{1,2}&amp;\\cdots&amp;x_{1,P}\\\\  x_{2,1}&amp;x_{2,2}&amp;\\cdots&amp;x_{2,P}\\\\  \\vdots&amp;\\vdots&amp;\\ddots...",
    "content": "Matrix      행렬(Matrix):\\[\\begin{aligned}  \\mathbf{X}  &amp;=\\begin{bmatrix}  x_{1,1}&amp;x_{1,2}&amp;\\cdots&amp;x_{1,P}\\\\  x_{2,1}&amp;x_{2,2}&amp;\\cdots&amp;x_{2,P}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  x_{N,1}&amp;x_{N,2}&amp;\\cdots&amp;x_{N,P}  \\end{bmatrix}  \\end{aligned}\\]                  행(row)과 열(column)로 구분된 직사각 모양의 배열\\[\\mathbf{X}  = [x_{i,j}] \\in \\mathbb{R}^{N \\times P}, \\quad  \\begin{aligned}  i&amp;=1,2,\\cdots,N\\\\  j&amp;=1,2,\\cdots,P  \\end{aligned}\\]                    벡터들의 집합:\\[\\begin{aligned}  \\mathbf{X}  &amp;=\\begin{bmatrix}  \\mathbf{x}_{1}&amp;\\mathbf{x}_{2}&amp;\\cdots &amp; \\mathbf{x}_{P}  \\end{bmatrix},\\quad \\forall \\mathbf{x} \\in \\mathbb{R}^{N}  \\end{aligned}\\]                  계수(Rank) : 임의의 행렬을 구성하는 벡터 중 선형 독립인 벡터의 갯수\\[\\begin{aligned}  \\mathrm{rank}(\\mathbf{X}) \\le \\min{(N,P)}, \\quad \\mathbf{X} \\in \\mathbb{R}^{N \\times P}  \\end{aligned}\\]          Full-Rank: 어떤 행렬에 대하여 그 계수가 될 수 있는 가장 큰 값      정방행렬 \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times N}\\) 의 계수가 Full-Rank 인 경우, 그 구성 벡터 \\(\\mathbf{x}_{1},\\mathbf{x}_{2},\\cdots,\\mathbf{x}_{N}\\) 는 모두 선형 독립임      정방행렬 \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times N}\\) 의 계수가 Full-Rank 인 경우, 그 구성 벡터들의 집합 \\(S=\\{\\mathbf{x}_{1},\\mathbf{x}_{2},\\cdots,\\mathbf{x}_{N}\\}\\) 에 대하여 \\(\\mathrm{span}(S)=\\mathbb{R}^{N}\\) 임      정방행렬 \\(\\mathbf{X}\\) 의 계수가 Full-Rank 인 경우, 그 역행렬 \\(\\mathbf{X}^{-1}\\) 이 존재함      정방행렬 \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times N}\\) 의 계수가 Full-Rank 인 경우, 그 행렬식 \\(\\mathrm{det}(\\mathbf{X}) \\ne 0\\) 임      Special Matrices      정방행렬(Square Matrix): 행과 열의 갯수가 동일한 행렬\\[\\begin{aligned}  \\mathbf{X}  \\in \\mathbb{R}^{N \\times N}  \\end{aligned}\\]        영행렬(Zero-Matrix): 원소가 모두 $0$ 인 행렬\\[\\begin{aligned}  \\mathbf{0}  &amp;=\\begin{bmatrix}  0&amp;0&amp;0\\\\  0&amp;0&amp;0\\\\  0&amp;0&amp;0  \\end{bmatrix}  \\end{aligned}\\]        항등행렬(Identify Matrix): 대각항 원소는 모두 $1$ 이고, 비대각항 원소는 모두 $0$ 인 정방행렬로서, 각 차원에 대하여 그 단위 벡터들의 모임\\[\\begin{aligned}  \\mathbf{I}_{N}  &amp;=\\begin{bmatrix}  1&amp;0&amp;\\cdots&amp;0\\\\  0&amp;1&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  0&amp;0&amp;\\cdots&amp;1  \\end{bmatrix}  =\\begin{bmatrix}  \\mathbf{e}_{1}&amp; \\mathbf{e}_{2}&amp; \\cdots&amp; \\mathbf{e}_{N}  \\end{bmatrix}  \\end{aligned}\\]        대각행렬(Diagonal Matrix): 대각항을 제외한 모든 원소가 $0$ 인 정방행렬\\[\\begin{aligned}  \\mathrm{diag}(1, 2, 3)  &amp;=\\begin{bmatrix}  1&amp;0&amp;0\\\\  0&amp;2&amp;0\\\\  0&amp;0&amp;3  \\end{bmatrix}  \\end{aligned}\\]        삼각행렬(Triangular Matrix): 대각항을 기준으로 그 아래 혹은 위에 위치한 원소가 모두 0인 정방행렬\\[\\begin{aligned}  \\begin{bmatrix}  1&amp;4&amp;5\\\\  0&amp;2&amp;6\\\\  0&amp;0&amp;3  \\end{bmatrix},  \\quad  \\begin{bmatrix}  1&amp;0&amp;0\\\\  4&amp;2&amp;0\\\\  5&amp;6&amp;3  \\end{bmatrix}  \\end{aligned}\\]        대칭행렬(Symmetric Matrix): 그 전치행렬이 자기 자신이 되는 정방행렬\\[\\begin{aligned}  \\mathbf{X}^{T}  &amp;=\\mathbf{X}  \\end{aligned}\\]        직교행렬(Orthogonal Matrix): 모든 행벡터 혹은 열벡터가 직교정규벡터로 구성된 행렬\\[\\begin{aligned}  \\mathbf{x}_{1}\\perp\\cdots\\perp\\mathbf{x}_{n},  \\quad  \\mathbf{x}_{i} = \\mathbf{X}_{:,i}  \\end{aligned}\\]  Matrix Operation      전치(Transpose): 행렬의 전치는 그 행과 열의 위치를 바꾸는 연산으로 정의함\\[\\begin{aligned}  [x_{i,j}]^{T}  &amp;= [x_{j,i}]  \\end{aligned}\\]          $\\alpha^T=\\alpha$      $(\\mathbf{A}+\\mathbf{B})^{T}=\\mathbf{A}^{T}+\\mathbf{B}^{T}$      $(\\mathbf{AB})^{T}=\\mathbf{B}^{T}\\mathbf{A}^{T}$            덧셈과 뺄셈: 크기가 $N \\times P$ 로 동일한 두 행렬의 덧셈과 뺄셈을 대응 원소의 합과 차로 정의함\\[\\begin{aligned}  \\mathbf{X}+\\mathbf{Y}  &amp;= [x_{i,j} + y_{i,j}]  \\end{aligned}\\]          $\\mathbf{X} \\pm \\mathbf{0} = \\mathbf{X}$            스칼라-행렬 곱셈: 스칼라와 행렬의 곱셈을 행렬의 모든 원소에 대한 스칼라 곱으로 정의함\\[\\begin{aligned}  \\alpha \\cdot \\mathbf{X}  &amp;= [\\alpha \\times x_{i,j}]  \\end{aligned}\\]        행렬 곱셈: 적합성 조건(Conformability Condition)을 만족하는 행렬 \\(\\mathbf{X} \\in \\mathbb{R}^{M \\times P}, \\mathbf{Y} \\in \\mathbb{R}^{P \\times N}\\) 을 곱한 결과 \\(\\mathbf{XY} \\in \\mathbb{R}^{M \\times N}\\) 는 전항의 \\(i=1,2,\\cdots,M\\) 번째 행벡터와 후항의 \\(j=1,2,\\cdots,N\\) 번째 열벡터 간 내적의 집합임\\[\\begin{aligned}  \\mathbf{X}^{T}  &amp;=\\begin{bmatrix}\\mathbf{x}_{1}&amp;\\mathbf{x}_{2}&amp;\\cdots&amp;\\mathbf{x}_{M}\\end{bmatrix},\\quad \\mathbf{x}_{i} \\in \\mathbb{R}^{P}\\\\  \\mathbf{Y}  &amp;=\\begin{bmatrix}\\mathbf{y}_{1}&amp;\\mathbf{y}_{2}&amp;\\cdots&amp;\\mathbf{y}_{N}\\end{bmatrix},\\quad \\mathbf{y}_{j} \\in \\mathbb{R}^{P}\\\\  \\mathbf{XY}  &amp;=\\begin{bmatrix}  \\left&lt;\\mathbf{x}_{1},\\mathbf{y}_{1}\\right&gt; &amp; \\left&lt;\\mathbf{x}_{1},\\mathbf{y}_{2}\\right&gt; &amp; \\cdots &amp; \\left&lt;\\mathbf{x}_{1},\\mathbf{y}_{N}\\right&gt;\\\\  \\left&lt;\\mathbf{x}_{2},\\mathbf{y}_{1}\\right&gt; &amp; \\left&lt;\\mathbf{x}_{2},\\mathbf{y}_{2}\\right&gt; &amp; \\cdots &amp; \\left&lt;\\mathbf{x}_{2},\\mathbf{y}_{N}\\right&gt;\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\left&lt;\\mathbf{x}_{M},\\mathbf{y}_{1}\\right&gt; &amp; \\left&lt;\\mathbf{x}_{M},\\mathbf{y}_{2}\\right&gt; &amp; \\cdots &amp; \\left&lt;\\mathbf{x}_{M},\\mathbf{y}_{N}\\right&gt;\\\\  \\end{bmatrix}  \\end{aligned}\\]          $\\mathbf{XY} \\ne \\mathbf{YX}$      $\\mathbf{X}\\mathbf{I} = \\mathbf{X}$      Inverse Matrix      역행렬(Inverse Matrix): 정방행렬 $\\mathbf{X},\\mathbf{Y} \\in \\mathbb{R}^{N \\times N}$ 에 대하여 다음을 만족하는 경우, 양자는 서로 역행렬 관계에 있음\\[\\begin{aligned}  \\mathbf{X}\\mathbf{Y}  =\\mathbf{Y}\\mathbf{X}  =\\mathbf{I}  \\end{aligned}\\]        가역성(Inverible): 그 역을 계산할 수 있는 성질\\[\\begin{aligned}  \\exists \\mathbf{X}^{-1} \\quad \\text{such that} \\quad \\mathrm{rank}(\\mathbf{X}_{N \\times N}) = N  \\end{aligned}\\]          정칙행렬(Non-Singular Matrix): 가역성을 가지는 행렬      특이행렬(Singular Matrix): 가역성을 갖지 않는 행렬            연산 규칙:          $\\mathbf{I}^{-1}=\\mathbf{I}$      $(\\alpha\\mathbf{X})^{-1}=\\alpha^{-1}\\mathbf{X}^{-1}$      $(\\mathbf{X}^{T})^{-1}=(\\mathbf{X}^{-1})^{T}$      $(\\mathbf{XY})^{-1}=\\mathbf{Y}^{-1}\\mathbf{X}^{-1}$      $\\mathrm{diag}(a_{i})^{-1}=\\mathrm{diag}(1/a_{i})$      \\(\\mathbf{x}_{1}\\perp\\cdots\\perp\\mathbf{x}_{n} \\Rightarrow \\mathbf{X}^{-1}=\\mathbf{X}^{T}\\) \\(\\quad\\)      $\\mathbf{X}^{T}=\\mathbf{X} \\Rightarrow (\\mathbf{X}^{-1})^{T}=\\mathbf{X}^{-1}$      "
  },
  
  {
    "title": "Vector",
    "url": "/posts/vector/",
    "categories": "1.MATHEMATICAL TECHS, 1.linear algebra",
    "tags": "mathematics, linear algebra",
    "date": "2022-07-04 00:00:00 +0900",
    





    
    "snippet": "Vector      벡터(Vector): 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량\\[\\begin{aligned}  \\mathbf{x}  &amp;=\\begin{bmatrix}  x_{1}\\\\  x_{2}\\\\  \\vdots\\\\  x_{N}  \\end{bmatrix}  \\end{aligned}\\]                  원소...",
    "content": "Vector      벡터(Vector): 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량\\[\\begin{aligned}  \\mathbf{x}  &amp;=\\begin{bmatrix}  x_{1}\\\\  x_{2}\\\\  \\vdots\\\\  x_{N}  \\end{bmatrix}  \\end{aligned}\\]                  원소(Element): 벡터를 구성하는 요소\\[\\begin{aligned}  x_{1},x_{2},\\cdots,x_{N}  \\end{aligned}\\]                    차원(Dimension): 원소의 갯수\\[\\begin{aligned}  \\mathbf{x} \\in \\mathbb{R}^{N}  \\end{aligned}\\]                  특수한 벡터                  영벡터(Zero Vector): 벡터 공간에서의 덧셈에 대한 항등원이 되는 벡터\\[\\begin{aligned}  \\mathbf{0}  &amp;=\\begin{bmatrix}  0\\\\  0\\\\  \\vdots\\\\  0  \\end{bmatrix}  \\end{aligned}\\]                    단위 벡터(Unit Vector): 길이가 $1$ 인 벡터로서 정규 벡터(Normal Vector)라고도 함\\[\\begin{gathered}  (\\mathbf{e}_{i})_{j}  =\\begin{cases}  1,\\quad \\text{if} \\ j=i\\\\  0,\\quad \\text{if} \\ j \\ne i  \\end{cases}\\\\  \\\\  \\mathbf{e}_{1}  =\\begin{bmatrix}  1\\\\  0\\\\  0\\\\  \\vdots\\\\  0  \\end{bmatrix},   \\mathbf{e}_{2}  =\\begin{bmatrix}  0\\\\  1\\\\  0\\\\  \\vdots\\\\  0   \\end{bmatrix},   \\mathbf{e}_{3}  =\\begin{bmatrix}  0\\\\  0\\\\  1\\\\  \\vdots\\\\  0  \\end{bmatrix}  \\end{gathered}\\]            Norm      유클리디안 노름(L-2 Norm): 벡터의 규모(Magnitude) 혹은 원점 $\\mathbf{0}$ 으로부터의 길이(Length)를 측정하는 연산자\\[\\begin{aligned}  \\Vert \\mathbf{x} \\Vert  &amp;=\\sqrt{\\mathbf{x}^T\\mathbf{x}}  \\end{aligned}\\]          $\\Vert \\mathbf{x} \\Vert \\ge 0$      $\\Vert \\mathbf{x} \\Vert = 0 \\Rightarrow \\mathbf{x} = \\mathbf{0}$      $\\Vert \\beta \\cdot \\mathbf{x} \\Vert =\\vert \\beta \\vert \\cdot \\Vert \\mathbf{x} \\Vert$      $\\Vert\\mathbf{x}+\\mathbf{y}\\Vert \\le \\Vert\\mathbf{x}\\Vert+\\Vert\\mathbf{y}\\Vert$            내적(Inner Product): 두 벡터 사이의 유사성 또는 정렬 정도를 측정하는 연산자로서, 그 결과값은 두 벡터가 원점을 기준으로 얼마나 같은 방향을 향하고 있는지를 나타냄\\[\\begin{aligned}  \\left&lt;\\mathbf{x},\\mathbf{y}\\right&gt;  &amp;=\\mathbf{x}^{T}\\mathbf{y}  \\end{aligned}\\]        코사인 유사도(Cosine Similarity): 두 벡터의 사이각 $\\theta$ 의 코사인 값을 이용하여 측정한 벡터 간 유사도\\[\\begin{aligned}  \\cos{\\theta}=\\frac{\\left&lt;\\mathbf{x},\\mathbf{y}\\right&gt;}{\\Vert\\mathbf{x}\\Vert\\cdot\\Vert\\mathbf{y}\\Vert}  \\end{aligned}\\]          $-1\\le \\cos{\\theta} \\le 1$      $\\cos{\\theta} = -1$: 음의 유사도를 가진다고 볼 수 있으며 기하학적으로 상반된 방향성을 가짐      $\\cos{\\theta} = 1$: 양의 유사도를 가진다고 볼 수 있으며 기하학적으로 동일한 방향성을 가짐      $\\cos{\\theta} = 0$: 유사하다고 볼 수 없으며 기하학적으로 직교함            직교 정규 벡터(Orthonomal Vector): 임의의 벡터에 대하여 해당 벡터와 직교하는 정규 벡터                      정규 벡터(Normal Vector): 노름이 $1$ 인 벡터로서 단위 벡터\\[\\begin{aligned}  \\Vert \\mathbf{x} \\Vert  &amp;= 1  \\end{aligned}\\]                    상호 직교(Mutually Orthonal): 두 벡터가 서로 수직 관계에 있어 내적값이 $0$ 이 됨\\[\\begin{aligned}  \\mathbf{x} \\perp \\mathbf{y}  \\Leftrightarrow \\frac{\\left&lt;\\mathbf{x},\\mathbf{y}\\right&gt;}{\\Vert \\mathbf{x} \\Vert \\cdot \\Vert \\mathbf{y} \\Vert} = \\cos{90^{\\circ}}  \\end{aligned}\\]            Linear Combination      스칼라-벡터 곱셈: 벡터의 모든 원소에 대한 스칼라 곱으로서, 벡터의 노름을 스칼라 비율로 확대 혹은 축소하는 연산으로 해석 가능함\\[\\begin{aligned}  \\alpha \\times \\mathbf{x}  &amp;=\\begin{bmatrix}  \\alpha \\times x_{1}\\\\  \\alpha \\times x_{2}\\\\  \\vdots\\\\  \\alpha \\times x_{N}  \\end{bmatrix}  \\end{aligned}\\]        덧셈과 뺄셈: 동차원 원소 간 합 혹은 차로서, 벡터 $\\mathbf{x}$ 를 방향 $\\mathbf{y}$ 으로 폭 $\\Vert \\mathbf{y} \\Vert$ 만큼 평행이동하는 연산으로 해석 가능함\\[\\begin{aligned}  \\begin{bmatrix}  x_{1}\\\\  x_{2}\\\\  \\vdots\\\\  x_{N}  \\end{bmatrix} + \\begin{bmatrix}  y_{1}\\\\  y_{2}\\\\  \\vdots\\\\  y_{N}  \\end{bmatrix} = \\begin{bmatrix}  x_{1}+y_{1}\\\\  x_{2}+y_{2}\\\\  \\vdots\\\\  x_{N}+y_{N}  \\end{bmatrix}  \\end{aligned}\\]        선형 결합(Linear Combination): 차원이 $n$ 으로 동일한 임의의 벡터와 스칼라에 대하여, 각 항에 스칼라를 곱하거나 상호 더함으로써 일련의 항으로 구성하는 작업\\[\\begin{aligned}  \\beta_{1}\\mathbf{x}_{1} + \\beta_{2}\\mathbf{x}_{2} + \\cdots + \\beta_{p}\\mathbf{x}_{p}  \\end{aligned}\\]        선형 종속(Linearly Dependent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현 가능한 경우    \\[\\begin{aligned}  \\beta_{1}\\mathbf{x}_{1} + \\beta_{2}\\mathbf{x}_{2} + \\cdots + \\beta_{p}\\mathbf{x}_{p}  &amp;=0,  \\quad \\forall \\beta \\ne 0  \\end{aligned}\\]        선형 독립(Linearly Independent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현될 수 없는 경우    \\[\\begin{aligned}  \\beta_{1}\\mathbf{x}_{1} + \\beta_{2}\\mathbf{x}_{2} + \\cdots + \\beta_{p}\\mathbf{x}_{p}  &amp;\\ne 0,  \\quad \\forall \\beta \\ne 0  \\end{aligned}\\]        \\(\\mathrm{span}\\): 벡터 공간 \\(V\\) 에서 선형 독립인 벡터들의 집합 \\(S=\\{\\mathbf{v}_{1},\\mathbf{v}_{2},\\cdots,\\mathbf{v}_{k}\\}\\) 이 주어졌을 때, 모든 가능한 선형 결합의 집합으로서, \\(\\forall \\mathbf{v} \\in S\\) 가 생성 가능한 선형 공간, 혹은 이를 반환하는 생성자\\[\\begin{aligned}  \\mathrm{span}(S)  &amp;= \\left\\{\\sum_{i=1}^{k}{\\alpha_{i}\\mathbf{v}_{i}} \\mid \\alpha_{i} \\in \\mathbb{F}\\right\\}  \\end{aligned}\\]        기저(Basis): 부분 벡터 공간을 생성하는 직교 정규 벡터들의 집합으로서, $n$ 차원 벡터 공간을 총 $n$ 개의 직교 정규 벡터들을 $\\mathrm{span}$ 하여 생성되며, 이때 기저들은 해당 벡터 공간의 축(axis)이 됨\\[\\begin{aligned}  \\begin{bmatrix}  3\\\\  2  \\end{bmatrix}  &amp;= 3 \\times \\mathbf{e}_{1} + 2 \\times \\mathbf{e}_{2}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Welfare Economics (2) Social Choice",
    "url": "/posts/welfare_economics_2/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, welfare economics, pareto efficiency, pareto, efficiency, social welfare, welfare, equity, social choice",
    "date": "2019-07-23 00:00:00 +0900",
    





    
    "snippet": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : ...",
    "content": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : 사회후생함수(Social Welfare Function)      What? Pareto Efficiency      파레토 효율성(Pareto Efficiency) : 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 어떤 경제주체의 효용수준도 개선할 수 없을 정도로 자원이 배분되었음        예시                            자원 배분 방법          부존자원량          총배분자원량          $A$          $B$          잉여자원량                                      배분1          100          100          30          70          0                          배분2          100          100          70          30          0                          배분3          100          100          50          50          0                          배분4          100          80          20          60          20                          배분5          100          80          60          20          20                          배분6          100          80          40          40          20                            $\\text{배분1},\\text{배분2},\\text{배분3}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서는 다른 경제주체의 자원 보유량을 개선할 수 없는 상태로서 파레토 최적인 상태임(Pareto Optimal)      $\\text{배분4},\\text{배분5},\\text{배분6}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서도 잉여자원 $20$ 으로써 다른 경제주체의 자원 보유량을 개선할 수 있는 상태로서 파레토 개선 가능한 상태임(Pareto Improvement)      따라서 $\\text{배분1},\\text{배분2},\\text{배분3}$ 은 $\\text{배분4},\\text{배분5},\\text{배분6}$ 보다 파레토 우월함(Pareto Superiority)      Condition      생산의 효율성(Productive Efficiency) : 사용 가능한 생산요소 제약 하 경제 전반의 재화 생산량을 극대화하여, 임의의 재화의 생산량을 몇 단위 포기하지 않고서는 다른 재화의 생산량을 개선하지 못하는 상태를 이룸\\[MRTS^{(X)}_{L,K}=\\frac{w}{v}=MRTS^{(Y)}_{L,K}\\]                생산요소 $L,K$ 제약 하 재화 $X,Y$ 에 대한 생산의 계약곡선                  상품 공간 상에 표현된 재화 $X,Y$ 에 대한 생산의 계약곡선으로서생산가능경계(Production Possibility Frontier; PPF)          교환의 효율성(Allocative Efficiency) : 배분 가능한 부존자원 제약 하 경제 전반의 효용을 극대화하여, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 다른 경제주체의 효용수준을 개선하지 못하는 상태를 이룸\\[MRS^{(A)}_{X,Y}=\\frac{P_X}{P_Y}=MRS^{(B)}_{X,Y}\\]                부존자원 $X,Y$ 제약 하 경제주체 $A,B$ 에 대한 교환의 계약곡선          총체적 효율성(Overall Efficiency) : 사용 가능한 생산요소 제약 하 극대화된 재화 생산량을 경제주체들에게 모두 배분하여 경제 전반의 효용수준을 극대화한 상태를 이룸\\[MRPT_{X,Y}=MRS_{X,Y}\\]                총체적 효율성 하에서는 재화 간 한계생산변환율과 경제주체별 재화 간 한계대체율이 일치함                  주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합으로서효용가능경계(Utility Possibility Frontier; UPF)    Social Welfare Function      사회후생함수(Social Welfare Function) : 사회 구성원들의 효용수준($X$)과 사회후생수준($Y$) 간 상관관계를 나타내는 함수\\[SW=F\\left(U_{A},U_{B}\\right)\\]          효율성의 정의가 파레토 효율성으로써 합의된 데 반해, 형평성은 윤리적 관점에 따라 그 해석이 다양함. 이에 따라 파레토 최적 상태 하 형평성 달성도를 나타내는 사회후생함수 역시 어느 하나로 합의되지 않고 다양한 형태를 띰.            (초기) 공리주의 사회후생함수(Utilitarian Social Welfare Function) : 최대 다수의 최대 행복          비록 효용이 주관적 개념이긴 하나, 개인 간에 질적으로는 차이가 없고, 오로지 양적으로만 차이가 있음. 따라서 사회 전체의 효용수준은 그저 그 사회 구성원들이 누리는 효용의 총합에 불과함.    \\[SW=U_{A}+U_{B}\\]            롤스 사회후생함수(Rawlsian Social Welfare Function) : 최소 수혜자의 최대 이익          사회 구성원들에게 무지의 베일을 씌운 원초적 상황 하에서 민주적으로 자원 배분 정책을 수립한다고 하자. 타인의 이익에 무관심하고 오로지 자신의 이익에만 관심이 있음에도 불구하고, 사회 구성원들은 자신이 최악의 상황에 처할 가능성을 고려하여 최소극대화 원칙에 근거한 배분 정책을 수립할 것임.    \\[SW=\\min{\\left[U_{A},U_{B}\\right]}\\]            (실질적) 평등주의 사회후생함수(Egalitarian Social Welfare Function) : 한계효용의 평등          빈자에게 있어서 1원과 부자의 그것이 가지는 실질적 가치가 같다고 볼 수 없음. 따라서 사회 전체의 효용수준을 논함에 있어서 개인의 사정을 고려해야 함.    \\[SW=\\left(U_A\\right)^{\\alpha} \\cdot \\left(U_B\\right)^{1-\\alpha}\\]      Impossibility Theorem  합리성의 공리와 민주성의 공리는 상호위배된다. 따라서 사회후생수준을 평가할 수 있는, 합리적인 동시에 민주적인 사회선호체계란 존재할 수 없다. (케네스 애로우)  합리적 사회선호체계의 공리                  완비성(Completeness); 사회선호체계가 모든 사회적 상태를 비교하고 평가할 수 있어야 한다.\\[X \\neq Y \\implies X \\succeq Y \\;\\text{or}\\; Y \\succeq X \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]                    이행성(Transitivity); 사회적 상태 $X, Y, Z$ 에 대하여 사회선호체계가 $X$ 를 $Y$ 보다 선호하고 $Y$ 를 $Z$ 보다 선호하면 $X$ 를 $Z$ 보다 선호해야 한다.\\[X \\succeq Y \\;\\text{and}\\; Y \\succeq Z \\implies X \\succeq Z \\quad\\text{for}\\quad X, Y, Z \\in \\mathcal{S}\\]                    파레토 원칙(Pareto Principle); 임의의 사회적 상태에 대하여 모든 사회 구성원들이 해당 사회적 상태를 다른 사회적 상태보다 선호한다면, 사회선호체계 역시 해당 사회적 상태를 다른 사회적 상태보다 선호해야 한다.\\[\\begin{aligned} X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ i^{\\forall} &amp;\\in N \\end{aligned}\\]                    독립성(Independence); 사회선호체계가 두 가지 사회적 상태의 선호관계를 평가함에 있어서 이들과 무관한 것으로부터 영향을 받지 말아야 한다.\\[\\begin{aligned} X \\succ Y \\implies X \\succ^{\\prime} Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ Z &amp;\\in \\mathcal{S} \\setminus \\{X, Y\\} \\end{aligned}\\]              민주적 사회선호체계의 공리                  비독재성(Non-dictatorship); 사회선호체계가 사회 구성원 소수의 선호체계에 좌우되지 말아야 한다.\\[\\nexists i \\in N \\; \\text{such that} \\; X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]              이행성과 민주성의 동시 성립 불가능성                  사회 구성원 $A,B,C$ 가 사회적 상태 $X,Y,Z$ 에 대하여 각각 다음과 같이 평가한다고 하자\\[\\begin{aligned}  A:\\quad &amp;X \\succ_A Y \\; \\text{and} \\; Y \\succ_A Z\\\\  B:\\quad &amp;Y \\succ_B Z \\; \\text{and} \\; Z \\succ_B X\\\\  C:\\quad &amp;Z \\succ_C X \\; \\text{and} \\; X \\succ_C Y  \\end{aligned}\\]                    사회선호체계는 파레토 원칙 및 비독재성에 의해 사회적 상태를 다음과 같이 평가함\\[\\begin{aligned}  \\mathcal{S}: X \\succ Y \\; \\text{and} \\; Y \\succ Z \\; \\text{and} \\; Z \\succ X  \\end{aligned}\\]                    따라서 민주성의 공리에 기초하여 도출한 사회선호체계는 이행성을 보장하지 못함            "
  },
  
  {
    "title": "Welfare Economics (1) Theorems of Welfare Economics",
    "url": "/posts/welfare_economics_1/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, welfare Economics",
    "date": "2019-07-22 00:00:00 +0900",
    





    
    "snippet": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자...",
    "content": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자원 $X,Y$ 을 보유하고 있고, 두 명의 경제주체 $A,B$ 가 활동하는 가상의 경제를 상정함      Walras Equilibrium  시장에서 모든 경제주체가 동시에 자신의 최적화 문제를 해결하고, 모든 시장이 동시에 균형을 이루는 상태로서, 모든 부존자원에 대하여 모든 경제주체의 주관적 교환 비율과 객관적 교환 비율이 일치하는 상태.Initial Endowment Point      초기부존자원점(Initial Endowment Point)              자원 $X$ 의 부존량 $X=\\overline{X}_A+\\overline{X}_B$      자원 $Y$ 의 부존량 $Y=\\overline{Y}_A+\\overline{Y}_B$            초기부존자원 하 효용 수준              초기부존자원 하 경제주체의 효용 수준을 초기부존자원점에서 서로 교차하는 경제주체 각각의 무차별곡선으로 나타낼 수 있음. 위 그래프는 각각의 무차별곡선이 교차하되 접하지는 않는 상태임. 이때 어느 한 무차별곡선을 원점 가까이 조정하지 않고서도 다른 무차별곡선을 원점에서 더 멀리 이동시킬 수 있음. 즉, 어느 경제주체의 효용 수준을 낮추지 않고서도 다른 경제주체의 효용 수준을 개선할 여지가 있음. 따라서 위 초기부존자원은 이상적인 자원 배분이 아님.      Walras Dis-Equilibrium      교환하기 위한 가격체계 설정              교환(Exchange) : 시장경제체제에서 경제주체들이 각자 효용을 극대화하는 자원조합을 구성하기 위해 상호간에 초기부존자원을 거래하는 행위      가격체계(Price System) : 두 재화 간 객관적 교환 비율로서, (위 그래프의 경우) 부존자원 $X,Y$ 에 대하여 $X$ 의 $Y$ 에 대한 상대가격            가격체계 하 효용 극대화 지점 도출\\[MRS_{X,Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}\\]                $A$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량                  $B$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량          왈라스 불균형\\[MRS^{(A)}_{X,Y} \\ne MRS^{(B)}_{X,Y}\\]                현재 가격체계 하에서는 두 경제주체 간 이해관계가 맞아떨어지지 않음                  $A$ 의 효용 극대점에서 거래를 강제하는 경우$B$ 의 효용수준이 낮아짐                  $B$ 의 효용 극대점에서 거래를 강제하는 경우$A$ 의 효용수준이 낮아짐          왈라스 불균형 하 수요량과 공급량의 불일치        Walras Equilibrium      모색 과정 : 왈라스 균형에 도달하기 위해 가격체계를 조정하는 과정            왈라스 균형\\[MRS^{(A)}_{X,Y} = \\frac{P_X}{P_Y} = MRS^{(B)}_{X,Y}\\]            왈라스 균형 하 수요량과 공급량의 일치            계약곡선(Contract Curve) : 두 경제주체가 교환을 통해 효용을 극대화하는(왈라스 균형을 실현하는) 배분점의 집합      Theorems of Welfare EconomicsThe First Fundamental Theorem  모든 경제주체의 선호체계가 강단조성을 갖고, 하나의 경제에 외부성이 존재하지 않으면, 왈라스 균형 하에서의 배분은 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없을 정도로 자원이 효율적으로 배분된 상태를 실현한다(파레토 최적이다).해석: 경제주체들은 이기적으로 행동함에도 불구하고, 시장에서 보이지 않는 손에 의해 경제주체 간 상충하는 욕망이 조정되어, 사익과 공익이 조화를 이루게 된다.The Second Fundamental Theorem  초기부존지원이 적절하게 분배된 상태에서 모든 경제주체의 선호체계가 연속성, 강단조성, 볼록성을 가진다면, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없는 상태를 실현하는(파레토 효율적인) 배분은 왈라스 균형이 된다.해석: 초기부존자원을 적절한 가격체계 위에 설정한다면, 이상적인(파레토 효율적인) 배분을 왈라스 균형 하 배분으로 만드는 가격체계가 실현될 수 있다."
  },
  
  {
    "title": "Competition Theory",
    "url": "/posts/competition_theory/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, equilibrium, competition theory, perfect competition theory",
    "date": "2019-07-21 00:00:00 +0900",
    





    
    "snippet": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별...",
    "content": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별생산자는 가격 수용자이다.      하나의 시장에서 거래되는 상품은 모두 동질적이다.      개별생산자는 시장에 자유롭게 진입하거나 퇴출할 수 있다.      시장에 관한 모든 정보는 모든 시장 참여자들에게 있어서 주지사실이다.        시장실패(Market Failure) : 완전 경쟁의 네 가지 조건이 동시에 충족되지 못하여 사회적 후생이 극대화되지 못함          산업조직론(Industrial Organization) : 불완전 경쟁으로 인한 시장실패 현상을 분석함      공공경제학(Public Economics) : 공공재 및 외부효과로 인한 시장실패 현상을 분석함      정보경제학(Information Economics) : 정보의 비대칭성으로 인한 시장실패 현상을 분석함      법경제학(Law and Economics) : 정부의 과도한 경제 간섭과 규제로 인한 시장실패 현상을 분석함      Demand &amp; Supply under Perfect Competition      완전탄력적 수요곡선(Perfectly Elastic Demand Curve) : 개별생산자가 단독으로 직면하는 시장수요곡선              소비자는 가격 수용자로서, 가격의 특정 수준에 대하여 수요량을 조절함으로써 영향력을 행사할 수 없음. 따라서 개별생산자가 단독으로 직면하는 시장수요곡선은 균형가격에서 수평선(완전탄력적인 곡선)이 됨.            평균비용곡선의 극소점을 상회하는 수준의 한계비용곡선(Marginal Cost Curve above the Minimum Point of the Average Cost Curve) : 개별공급곡선              생산자는 가격 수용자로서, 주어진 가격 하 양의 이윤을 보장받을 수 있는 상태에서 이윤을 극대화하는 생산량을 공급함. 따라서 생산자들의 개별공급곡선은 한계비용곡선 중 평균비용곡선의 극소점을 상회하는 수준이 됨.                      주어진 가격 하 양의 이윤을 보장받을 수 있는 생산량 $Q^{*}$\\[\\pi(Q^{*}) \\ge 0 \\Leftrightarrow Q^{*} \\bigg\\vert AR(Q) \\ge AC(Q)\\]                    주어진 가격 하 이윤을 극대화하는 생산량 $Q^{*}$\\[\\max{\\pi(Q^{*})} \\Leftrightarrow Q^{*} \\bigg\\vert MR(Q)=MC(Q)\\]                    주어진 가격 하 평균수익($AR$)과 한계수익($MR$)\\[\\begin{aligned}  TR(Q)&amp;= P \\cdot Q\\\\\\\\  AR(Q)&amp;= \\frac{TR(Q)}{Q}\\\\&amp;= P\\\\\\\\  MR(Q)&amp;= \\frac{\\Delta TR(Q)}{\\Delta Q}\\\\&amp;= P  \\end{aligned}\\]                    종합\\[Q^{*} \\bigg\\vert P=MC(Q) \\quad \\&amp; \\quad P &gt; AC(Q)\\]            Short-Term$P &gt; AC \\Rightarrow \\pi &gt; 0$  균형가격이 평균비용곡선의 극소점을 상회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_A$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_A$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_A)$ 과 균형공급량 $Q_A$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_A)$ 에서 총비용 $TC(Q_A)$ 을 뺀 값임.총수익이 총비용보다 크므로($TR(Q_A)&gt;TC(Q_A)$) 양의 이윤이 발생함($\\pi(Q_A)&gt;0$).        $TR(Q_A)=P \\times Q_A$        $TC(Q_A)=AC(Q_A) \\times Q_A$        $\\pi(Q_A)=TR(Q_A)-TC(Q_A)&gt;0$$P &lt; AC \\Rightarrow \\pi &lt; 0$  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_B$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_B$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_B)$ 과 균형공급량 $Q_B$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_B)$ 에서 총비용 $TC(Q_B)$ 을 뺀 값임.총수익이 총비용보다 작으므로($TR(Q_B)&lt;TC(Q_B)$) 음의 이윤이 발생함($\\pi(Q_B)&lt;0$).        $TR(Q_B)=P \\times Q_B$        $TC(Q_B)=AC(Q_B) \\times Q_B$        $\\pi(Q_B)=TR(Q_B)-TC(Q_B)&lt;0$Negative Profit Analysis  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되어 음의 이윤이 발생하는 경우, 생산을 중단하여 비용을 없애는 것이 합리적인 의사결정임. 그러나 단기에는 공급을 중단하더라도 고정비용이 발생함. 따라서 생산중단을 결정하기 전에 생산을 지속함으로써 고정비용을 회수할 수 있는지 여부를 검토할 필요가 있음.$P&lt;AFC(Q)$  균형가격이 평균고정비용곡선의 극소점을 하회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 작으므로($TR(Q_C)&lt;TFC(Q_C)$) 생산을 지속해도 총고정비용을 회수할 수 없음.따라서 균형가격이 평균고정비용곡선의 극소점을 하회하는 수준에서 형성되는 경우($P&lt;AFC(Q)$) 생산을 중단하는 것이 유리함.        $TR(Q_C)=P \\times Q_C$        $TC(Q_C)=TVC(Q_C)+TFC(Q_C)$        $TR(Q_C)&lt;TFC(Q_C)$$AFC(Q)&lt;P&lt;AVC(Q)$  균형가격이 평균고정비용곡선의 극소점을 상회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 크므로($TR(Q_C)&gt;TFC(Q_C)$) 생산을 지속하면 총고정비용을 회수할 수 있음.따라서 균형가격이 평균고정비용곡선의 극소점을 상회하는 수준에서 형성되는 경우($P&gt;AFC(Q)$) 생산을 중단하는 것이 불리함.        $TR(Q_D)=P \\times Q_D$        $TC(Q_D)=TVC(Q_D)+TFC(Q_D)$        $TR(Q_D)&gt;TFC(Q_D)$Long-Term시장수요곡선의 장기화      $P&gt;\\min{AC} \\Rightarrow \\pi&gt;0$ : 잠재적 생산자가 시장에 진입하여 시장공급곡선이 우측으로 이동함에 따라 균형가격이 하락함            $P&lt;\\min{AC} \\Rightarrow \\pi&lt;0$ : 시장에 진입해 있는 생산자가 퇴출되어 시장공급곡선이 좌측으로 이동함에 따라 균형가격이 상승함            $P=\\min{AC} \\Rightarrow \\pi=0$ : 균형가격은 생산자 진입 및 퇴출에 따라 등락을 반복하다가 점차 이윤이 발생하지 않는 수준으로 수렴함      개별공급곡선의 장기화      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합    \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합    \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]        장기개별공급곡선(Long-Term Individual Supply Curve) : 장기평균비용곡선의 극소점을 상회하는 수준의 장기한계비용곡선      장기 균형      $P(=AR)=LAC \\Rightarrow \\pi=0$          개별생산자의 평균수익 $AR$ 과 장기평균비용 $LAC$ 이 일치함에 따라 이윤 $\\pi$ 이 발생하지 않음. 따라서 잠재적 생산자의 시장 진입 혹은 진입해 있는 생산자의 시장 퇴출 가능성이 제거됨. 즉, 외부교란요인이 발생할 여지가 없음.            $P(=MR)=LMC \\Rightarrow \\max{\\pi}$          개별생산자의 한계수익 $MR$ 과 장기한계비용 $LMC$ 이 일치함에 따라 이윤 $\\pi$ 가 극대화됨.      "
  },
  
  {
    "title": "Producer Theory (3) Joint Production",
    "url": "/posts/producer_theory_3/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, producer theory",
    "date": "2019-07-20 00:00:00 +0900",
    





    
    "snippet": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합  ...",
    "content": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합            한계생산변환율(Marginal Rate of Product Transformation; MRPT) : 재화 $X,Y$ 에 대하여, 동일한 비용 수준에서 특정 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta x \\cdot MC_X + \\Delta y \\cdot MC_Y = 0\\]\\[\\therefore MRPT_{X,Y}:= -\\frac{\\Delta y}{\\Delta x} = \\frac{MC_X}{MC_Y}\\]          $MC_X = \\displaystyle\\frac{\\partial z}{\\partial x}$ : 재화 $X$ 에 대한 한계비용      $MC_Y = \\displaystyle\\frac{\\partial z}{\\partial y}$ : 재화 $Y$ 에 대한 한계비용            한계생산변환율 체증의 법칙 : 특정 재화의 생산량이 증가할수록 동일한 비용 수준에서 해당 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분이 증가하는 현상\\[\\frac{\\partial MRPT_{X,Y}}{\\partial X} \\succ 0\\]  Revenue Constraint      한계수익불변 하 등수익곡선(Iso-Revenue Curve subject to Constant Marginal Revenue) : 공급 시 동일한 수익을 얻을 수 있는 상품묶음의 조합\\[X \\cdot P_X + Y \\cdot P_Y \\le R\\]                  한계수익불변(Constant Marginal Revenue) : 한계수익이 특정 재화의 공급량 변화에 반응하지 아니하고 일정함\\[\\frac{\\partial R}{\\partial X}=\\overline{\\alpha},\\frac{\\partial R}{\\partial Y}=\\overline{\\beta}\\]                  상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 수익 수준에서 특정 재화를 한 단위 추가 공급하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Cost Minimization under Revenue Constraint\\[\\min{Z} \\quad \\text{s.t.} \\; X \\cdot P_{X} + Y \\cdot P_{Y} \\le R\\]      생산변환곡선의 접선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 한계생산변환율 $MRPT_{X,Y}$\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{MC_X}{MC_Y}\\]        등수익곡선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 상대가격\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{P_X}{P_Y}\\]        생산변환곡선과 등수익곡선의 접점 : 수익 제약 하 비용을 최소화하는 상품묶음\\[\\begin{aligned}  \\frac{MC_X}{MC_Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MC_{X}}{P_X}$ 와 $\\displaystyle\\frac{MC_{Y}}{P_Y}$ 가 일치함\\[\\frac{MC_{X}}{MC_{Y}}=\\frac{P_X}{P_Y} \\Leftrightarrow \\frac{MC_{X}}{P_X}=\\frac{MC_{Y}}{P_Y}\\]          $\\displaystyle\\frac{MC_{X}}{P_X}$ : 화폐 단위당 취득 가능한 $X$ 단위의 한계비용      $\\displaystyle\\frac{MC_{Y}}{P_Y}$ : 화폐 단위당 취득 가능한 $Y$ 단위의 한계비용      "
  },
  
  {
    "title": "Producer Theory (2) Profit Maximization",
    "url": "/posts/producer_theory_2/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, producer theory",
    "date": "2019-07-19 00:00:00 +0900",
    





    
    "snippet": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{align...",
    "content": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{aligned}\\]          $P=\\alpha - \\beta \\cdot Q$ : 단위당 시장가격      $Q$ : 총 공급량            평균수익(Average Revenue; AR) : 개별생산자가 재화 단위당 취득할 수 있는 수익\\[\\begin{aligned}  AR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{TR(Q \\vert \\alpha, \\beta)}{Q}\\\\  &amp;= P  \\end{aligned}\\]        한계수익(Marginal Revenue; MR) : 개별생산자가 재화를 한 단위 추가 공급했을 때 추가 취득할 수 있는 수익\\[\\begin{aligned}  MR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}\\\\  &amp;= \\alpha - 2 \\beta \\cdot Q  \\end{aligned}\\]  $\\max{TR}$\\[\\begin{aligned}\\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}&amp;= MR(Q)\\\\&amp;= P \\cdot \\left(1 + \\frac{Q / \\Delta Q}{P / \\Delta P}\\right)\\\\&amp;= P \\cdot \\left(1 - \\frac{1}{\\varepsilon_{P}} \\right)\\\\&amp;= 0\\end{aligned}\\]\\[\\therefore \\hat{Q} = \\text{arg}\\max{TR(Q \\vert \\alpha, \\beta)} \\quad \\text{for} \\; \\varepsilon_{P}=1\\]CostShort-Term Cost      단기총비용(Short-Term Total Cost; STC) : 개별생산자가 재화를 총 $Q$ 단위 공급하기 위해 지불해야 하는 비용\\[\\begin{aligned}  STC(Q \\vert K) &amp;= STVC(Q) + STFC\\\\  STVC(Q) &amp;= L \\cdot w\\\\  STFC &amp;= \\overline{K} \\cdot v  \\end{aligned}\\]        단기평균비용(Short-Term Average Cost; SAC) : 개별생산자가 재화 단위당 지불해야 하는 비용\\[\\begin{aligned}  SAC(Q \\vert K)  &amp;= \\frac{STC(Q \\vert K)}{Q}\\\\  &amp;= \\frac{STVC(Q)}{Q} + \\frac{STFC}{Q}  \\end{aligned}\\]        단기한계비용(Short-Term Marginal Cost; SMC) : 개별생산자가 재화 단위를 추가할 때 추가 지불해야 하는 비용\\[\\begin{aligned}  SMC(Q \\vert K)  &amp;= \\frac{\\partial STC(Q \\vert K)}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} + \\frac{\\partial STFC}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} \\quad \\left(\\because \\frac{\\partial STFC}{\\partial Q} = 0 \\right)  \\end{aligned}\\]  Long-Term Cost      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합      \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합      \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]  Profit Maximization      양의 이윤을 극대화하는 생산량 도출\\[Q_{S}^{*}= \\text{arg} \\max{\\pi(Q)}\\]        이윤 함수(Profit Function)\\[\\pi(Q) = TR(Q) - TC(Q)\\]        일계 조건\\[\\begin{aligned}  \\frac{\\partial \\pi(Q)}{\\partial Q}  &amp;= \\frac{\\partial TR(Q)}{\\partial Q} - \\frac{\\partial TC(Q)}{\\partial Q}\\\\  &amp;= MR(Q) - MC(Q)\\\\  &amp;=0\\\\\\\\  \\therefore MR(Q)&amp;=MC(Q)  \\end{aligned}\\]        이계 조건\\[\\begin{aligned}  \\frac{\\partial^2 \\pi(Q)}{\\partial Q^2}  &amp;= \\frac{\\partial}{\\partial Q} \\frac{\\partial \\pi(Q)}{\\partial Q}\\\\  &amp;= \\frac{\\partial MR(Q)}{\\partial Q} - \\frac{\\partial MC(Q)}{\\partial Q}\\\\  &amp;&lt; 0\\\\\\\\  \\therefore \\frac{\\partial MR(Q)}{\\partial Q} &amp;&lt; \\frac{\\partial MC(Q)}{\\partial Q}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Producer Theory (1) Output Maximization under Cost Constraint",
    "url": "/posts/producer_theory_1/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, producer theory",
    "date": "2019-07-18 00:00:00 +0900",
    





    
    "snippet": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat...",
    "content": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat{K}\\right)$ 도출\\[\\hat{L}, \\hat{K}=\\text{arg} \\min{L \\cdot w + K \\cdot v} \\quad \\text{s.t.} \\; Q^{*}_{S}=F(L,K)\\]            Production      생산 함수(Production Function) : 단기 콥-더글라스 생산 함수임을 가정          가정 : 생산 기간은 단기로 간주하고, 투입되는 생산요소를 노동($L$)과 자본($K$)으로 제한하자. 단기에는 고정투입요소의 투입량을 유동적으로 조정할 수 없으며($\\overline{K}$), 생산기술이 일정한 수준으로 유지된다($\\overline{H}$).    \\[\\begin{aligned}  Q_S  &amp;= F\\left(L,\\overline{K}\\right)\\\\  &amp;= \\overline{H} \\cdot L^{\\alpha} \\cdot \\overline{K}^{\\beta}  \\end{aligned}\\]          $Q_S$ : 개별생산량      $L$ : 노동으로서 가변투입요소      $\\overline{K}$ : 자본으로서 고정투입요소      $\\overline{H}$ : 생산기술            등량 곡선(Isoquant Curve) : 노동 투입량을 X축으로, 자본 투입량을 Y축으로 하는 좌표평면 위에 생산량이 무차별한 요소조합을 이은 곡선    \\[Q_K = F(L, K)\\]          동일한 생산함수의 상이한 생산량수준을 나타내는 두 개의 등량곡선은 교차하지 않는다.      원점에서 비교적 먼 등량곡선은 비교적 높은 생산량수준을 나타낸다.      등량곡선은 우하향한다.      제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 등량곡선이 하나 존재한다.      등량곡선은 원점에 대하여 볼록한 모양을 가진다.      Productivity of Factors of Production      생산요소의 생산력                      노동의 총생산(Total Production of Labor; $TP_L$) : 노동을 $L$ 단위 투입했을 때 가능한 생산량\\[TP_L = f(L,\\overline{K})\\]                    노동의 평균생산(Average Production of Labor; $AP_L$) : 노동 단위당 가능한 생산량\\[AP_L = \\frac{TP_L}{L}\\]                    노동의 한계생산(Marginal Production of Labor; $MP_L$) : 노동 단위 추가 투입 시 가능한 추가 생산량\\[MP_L = \\frac{\\partial TP_L}{\\partial L}\\]                  한계기술대체율(Marginal Rate of Technical Substitution; MRTS) : 동일한 생산량 수준에서 특정 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소 단위\\[\\Delta L \\cdot MP_L + \\Delta K \\cdot MP_K = 0\\]\\[\\therefore MRTS_{L,K}:= -\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        한계기술대체율 체감의 법칙 : 특정 생산요소의 투입량이 증가할수록 동일한 생산량 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분이 감소하는 현상\\[\\frac{\\partial MRTS_{L,K}}{\\partial L} \\prec 0\\]  Cost Constraint      등비용곡선(Iso-Cost Curve) : 주어진 비용($C$)과 요소가격 상황($P_L=w,P_K=v$)에 맞게 취득할 수 있는 요소조합의 집합\\[(L,K) \\quad \\text{s.t.} \\; L \\cdot w + K \\cdot v \\le C\\]        상대가격(Relative Price) : 특정 생산요소에 대하여, 동일한 비용 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분\\[\\Delta L \\cdot w + \\Delta K \\cdot v = 0\\]\\[\\therefore - \\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]  Output Maximization under Cost Constraint\\[\\max{Q_S} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      등량곡선의 접선의 기울기 : 노동의 자본에 대한 한계기술대체율 $MRTS_{L,K}$\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        등비용곡선의 기울기 : 노동의 자본에 대한 상대가격\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]        등비용곡선과 등량곡선의 접점 : 비용 제약 하 생산량을 극대화하는 요소조합\\[\\begin{aligned}  \\frac{MP_L}{MP_K}=-\\frac{\\Delta K}{\\Delta L}=\\frac{w}{v}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MP_{L}}{w}$ 과 $\\displaystyle\\frac{MP_{K}}{v}$ 이 일치함\\[\\frac{MP_{L}}{MP_{K}}=\\frac{w}{v} \\Leftrightarrow \\frac{MP_{L}}{w}=\\frac{MP_{K}}{v}\\]          $\\displaystyle\\frac{MP_{L}}{w}$ : 화폐 단위당 취득 가능한 노동 단위의 한계생산      $\\displaystyle\\frac{MP_{K}}{v}$ : 화폐 단위당 취득 가능한 자본 단위의 한계생산      "
  },
  
  {
    "title": "Consumer Theory (2) Demand Response to Changes in Market Demend Determinants",
    "url": "/posts/consumer_theory_2/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, consumer theory",
    "date": "2019-07-17 00:00:00 +0900",
    





    
    "snippet": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른...",
    "content": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면        소득-수량 평면(Income-Quantity Plane) : 임의의 재화 $X$ 에 대하여 소득수준(혹은 예산제약) $M$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면  Price Changes  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 재 시장가격 $P_{Y}$ 와 소득수준 $M$ 이 일정한 상황에서 $X$ 재 시장가격 $P_{X}$ 는 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $\\displaystyle\\frac{P_{X}}{P_{Y}}$ 이 감소함      예산선의 기울기가 점차 완만해짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Q_{X}^{*}$ 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격소비곡선(Price Consumption Curve; PCC) : 상품 공간에서 시장가격의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            개별수요곡선(Individual Demand Curve) : 가격-수량 평면에서 시장가격의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      개별수요곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta P_X}{\\Delta Q_X}\\right)$ 와 개별수요의 가격 탄력성 $\\varepsilon_{P}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{P}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta P_X/P_X}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta P_X} \\cdot \\frac{P_X}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta P_{X}}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{P_X}{Q_X}  \\end{aligned}\\]            Income Changes  가정 : 정상재 $X,Y$ 에 대하여, 그 시장가격 $P_{X},P_{Y}$ 이 일정한 상황에서 소득수준 $M$ 이 지속적으로 상승하는 추세에 있다.            현상      상품 공간 상의 표현                  예산규모 $M$ 이 증가함      예산선이 원점에서 점차 멀어짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Y$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{Y}}$ 이 증가함      예산선의 $Y$ 절편이 점차 원점에서 멀어짐              \\(Q_{X}^{*}, Q_{Y}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 우상향함            소득소비곡선(Income Consumption Curve; ICC) : 상품 공간에서 소득수준의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            엥겔곡선(Engel Curve; EC) : 소득-수량 평면에서 소득수준의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      엥겔곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta M}{\\Delta Q_X}\\right)$ 와 개별수요의 소득 탄력성 $\\varepsilon_{M}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{M}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta M/M}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta M} \\cdot \\frac{M}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta M}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{M}{Q_X}  \\end{aligned}\\]            Price Effect  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 의 시장가격 $P_Y$ 가 일정한 상태에서 $X$ 의 시장가격 $P_{X}$ 이 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함      예산선의 기울기가 점차 완만해짐              \\(Q_{X}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격 효과(Price Effect) : 특정 재화의 가격 변동이 해당 재화의 수요량에 미치는 총 효과            $\\text{Price Effect} = \\text{Substitution Effect} + \\text{Income Effect}$                      $E_1 \\rightarrow E_3$ : 대체 효과                  대체 관계에 있는 재화 $X,Y$ 에 대하여, 동일한 효용수준을 유지하는 경우, $Y$ 에 대한 $X$ 의 상대가격 $-\\displaystyle\\frac{\\Delta Y}{\\Delta X}=\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함에 따라 $Y$ 단위당 기회비용이 증가하므로 $Y$ 의 개별수요량 $Q_Y$ 일부가 $X$ 의 개별수요량 $Q_X$ 으로 대체될 수 있음                            $E_3 \\rightarrow E_2$ : 소득 효과                  정상재 $X$ 에 대하여, $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함에 따라 $X$ 의 개별수요량 $Q_X$ 이 증가할 수 있음                    Price Effect Analysis      대체 효과(Substitution Effect; $E_1 \\rightarrow E_3$) : 특정 재화의 가격이 감소했을 때, 동일한 효용 수준을 유지하면서 상대적으로 더 저렴해진 재화를 더 많이 소비하고, 더 비싸진 재화를 덜 소비하는 효과              동일한 효용 수준을 유지하므로 무차별곡선에 변화가 없음      상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하므로 예산선의 기울기가 완만해짐      최적 선택 하 $Q_Y$ 일부가 $Q_X$ 으로 대체되므로 예산선과 무차별곡선의 접점이 우하향함            소득 효과(Income Effect; $E_3 \\rightarrow E_2$) : 특정 재화의 가격이 감소했을 때, 소비자가 동일한 예산 제약 하에서 취득 가능한 수량(구매력)이 증가하여 효용 수준이 변화하는 효과              상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 대체 효과 이후와 동일하므로 예산선은 대체 효과로 인해 완만해진 예산선과 평행함      실질 소득 수준이 증가하므로 예산선은 원점에서 멀어짐                  $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하므로 $X$ 절편이 우측으로 이동함          $Y$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_Y}$ 에는 변화가 없으므로 $Y$ 절편은 대체 효과 이전으로 회귀함                    VariationCompensating Variation      보상 변화(Compensating Variation; CV) : 특정 재화의 가격이 변화했을 때, 이전과 동일한 효용 수준을 누리기 위해 보상 받아야 하는 추가 소득              $P_X$ 가 감소함에 따라 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하였음. 가격체계를 임의로 조정할 수 없는 상태에서 이전과 동일한 효용 수준으로 회귀하기 위해서는, 가격 변화 이전에 누렸던 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기가 완만해진 상태에서 기울기를 임의로 조정할 수 없는 경우, 가격 변화 이전의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 보상 변화가 됨.            보상수요곡선(Compensated Demand Curve) : 가격 효과를 반영한 개별수요곡선에서 소득 효과를 제외한 대체 효과, 혹은 보상 변화만을 반영한 개별수요곡선      Equivalent Variation      대등 변화(Equivalent Variation; EV) : 특정 재화의 가격이 변화했다고 가정했을 때 누릴 수 있는 효용 수준과 대등한 효용 수준을 누리기 위해 필요한 추가 소득              $P_X$ 가 감소한다고 가정한다면, 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가할 것임. 이에 따라 누릴 수 있는 효용 수준이 상승할 것임. 실제로는 가격체계에 변함이 없는 상태에서 가정과 대등한 효용 수준을 누리기 위해서는, 가격 변화 이후 누릴 수 있는 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기에 변함이 없는 경우, 가격 변화 이후의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 대등 변화가 됨.      "
  },
  
  {
    "title": "Consumer Theory (1) Utility Maximization under Budget Constraint",
    "url": "/posts/consumer_theory_1/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, consumer theory",
    "date": "2019-07-16 00:00:00 +0900",
    





    
    "snippet": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Pr...",
    "content": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Preference Relation) : 임의의 상품묶음과 다른 상품묶음 간 선호의 우열관계\\[(x,y) \\succ (x', y')\\]              선호체계의 공리                  완비성(Completeness); 동일한 품목의 수량을 나타내는 상품묶음 사이의 선호관계를 비교할 수 있다.\\[A \\succ B \\; \\text{or} \\; B \\succ A \\; \\text{or} \\; A \\sim B \\quad \\text{for}\\;(A, B)^{\\forall} \\in X\\]                    이행성(Transitivity); 동일한 품목의 수량을 나타내는 상품묶음 A, B, C에 대하여 A보다 B를 선호하고, B보다 C를 선호하면 A보다 C를 선호한다.\\[A \\succ B \\; \\text{and} \\; B \\succ C \\implies A \\succ C \\quad \\text{for}\\; (A, B, C)^{\\forall} \\in X\\]                    강단조성(Strong Monotonicity); 상품묶음이 나타내는 두 가지 재화 중에서 임의의 재화에 대하여 다른 재화의 수량이 일정하다면 해당 상품의 수량이 더 높은 상품묶음을 선호한다.\\[x_i \\ge y_i \\; \\text{for all} \\; i \\; \\text{and} \\; x_i &gt; y_i \\; \\text{for some} \\; i \\implies A \\succ B \\quad \\text{for} \\; (A, B)^{\\forall} \\in X\\]                    연속성(Continuity); 두 상품묶음에 대한 선호도의 차이는 두 상품묶음이 나타내는 수량의 차이에 비례한다.\\[A \\succ B \\; \\text{and} \\; C \\approx A \\implies C \\succ B \\quad \\text{for}\\;(A, B, C)^{\\forall} \\in X\\]                    볼록성(Convexity); 극단적인 수량의 조합을 나타내는 상품묶음보다는 두 가지 재화의 수량이 고루 섞여 있는 상품묶음을 선호한다.\\[\\begin{aligned} \\lambda A + (1 - \\lambda)B \\succ A \\quad \\text{for} \\quad &amp;\\lambda^{\\forall} \\in (0, 1)\\\\ &amp;(A, B)^{\\forall} \\in X \\end{aligned}\\]            Utility      효용함수(Utility Function) : 상품묶음과 선호도 값 사이의 상관관계를 나타내는 함수\\[\\begin{aligned}  U^{(1)}:&amp; \\quad U(A)=10, U(B)=20, U(C)=30\\\\  U^{(2)}:&amp; \\quad U(A)=40, U(B)=60, U(C)=80  \\end{aligned}\\]          $U^{(1)}$ 과 $U^{(2)}$ 는 재화에 대하여 선호도 값을 다르게 매겼으나, 선호관계를 동일하게 평가하였음. 따라서 두 효용함수는 실질적으로는 무차별함. 이처럼 효용함수는 선호도 값의 기수성이 아니라 서수성이 중요함.            무차별곡선(Indifference curve) : 재화 $X,Y$ 에 대하여, 동일한(무차별한) 효용 수준을 누릴 수 있는 상품묶음 $(X, Y)$ 의 집합    \\[U(x,y)=u_{i}\\]          완비성(Completeness); 동일한 효용함수의 상이한 효용수준을 나타내는 두 개의 무차별곡선은 교차하지 않는다.      이행성(Transitivity); 무차별곡선은 원점에서 멀수록 더 높은 효용수준을 나타낸다.      강단조성(Strong Monotonicity); 무차별곡선은 우하향한다.      연속성(Continuity); 제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 무차별곡선이 하나 존재한다.      볼록성(Convexity); 무차별곡선은 원점에 대하여 볼록한 모양을 가진다.      Subjective Rate of Substitution      한계효용(Marginal Utility; MU) : 임의의 재화를 한 단위 추가 소비함으로써 추가로 누릴 수 있는 효용 수준\\[MU_{X}:= \\frac{\\partial U}{\\partial X}\\]        한계대체율(Marginal Rate of Substitution; MRS) : 재화 $X,Y$ 에 대하여, 동일한 효용 수준에서 해당 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot MU_{X} + \\Delta Y \\cdot MU_{Y} = 0\\]\\[\\therefore MRS_{X,Y}:= -\\frac{\\Delta Y}{\\Delta X} = \\frac{MU_{X}}{MU_{Y}}\\]        한계대체율 체감의 법칙 : 임의의 상품에 대하여, 해당 상품의 보유량이 증가할수록 동일한 효용수준에서 해당 상품을 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분이 감소하는 현상\\[\\frac{\\partial MRS_{X,Y}}{\\partial X} \\prec 0\\]  Budget Constraint      예산선(Budget Line) : 주어진 예산($M$)과 가격 상황($P_{X}, P_{Y}$)에 맞게 취득할 수 있는 상품묶음들의 집합\\[\\begin{aligned}  (x,y) \\quad \\text{s.t.}\\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M  \\end{aligned}\\]        상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 예산 수준에서 특정 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Utility Maximization under Budget Constraint\\[\\max{U(x,y)} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      무차별곡선의 접선의 기울기 : X재의 Y재에 대한 주관적 교환비율로서 한계대체율\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{MU_{X}}{MU_{Y}}\\]        예산선의 기울기 : X재의 Y재에 대한 객관적 교환비율로서 상대가격\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}\\]        예산선과 무차별곡선의 접점 : 예산 제약 하 효용을 극대화하는 상품묶음\\[\\begin{aligned}  \\frac{MU_{X}}{MU_{Y}}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MU_{X}}{P_{X}}$ 과 $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ 이 일치함\\[\\frac{MU_{X}}{MU_{Y}}=\\frac{P_{X}}{P_{Y}} \\Leftrightarrow \\frac{MU_{X}}{P_{X}}=\\frac{MU_{Y}}{P_{Y}}\\]          $\\displaystyle\\frac{MU_{X}}{P_{X}}$ : 화폐 단위당 취득 가능한 X재 단위의 한계효용      $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ : 화폐 단위당 취득 가능한 Y재 단위의 한계효용      Sourse  https://enotesworld.com/price-budget-line-or-budget-constraint/"
  },
  
  {
    "title": "What? Microeconomics",
    "url": "/posts/what_micro/",
    "categories": "7.ECONOMICS, 2.microeconomics",
    "tags": "economics, microeconomics, optimization, equilibrium",
    "date": "2019-07-15 00:00:00 +0900",
    





    
    "snippet": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원...",
    "content": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득할 수 있도록 마련한 절차          시장경제체제(Market Economy) : 한 사회의 자원 배분이 그 구성원들의 경제 활동으로써(혹은 시장 수요와 공급에 의해) 결정되는 제도      계획경제체제(Command Economy) : 한 사회의 자원 배분 및 그 구성원들의 경제 활동이 정부에 의해 결정되는 제도        시장경제체제의 운용 원리          모든 선택에는 대가가 있다.      선택의 대가는 그것을 얻기 위해 포기한 것이다.      합리적 판단은 한계적으로 이루어진다.      경제주체는 경제적 유인에 반응한다.      자유거래는 모든 경제주체를 이롭게 한다.      일반적으로 시장이 경제활동을 조직하는 좋은 수단이다.      경우에 따라 정부가 시장의 성과를 개선할 수 있다.      한 나라의 생활수준은 그 나라의 생산 능력에 달려 있다.      통화량이 지나치게 증가하면 물가는 상승한다.      단기적으로는 인플레이션과 실업 사이에 상충관계가 있다.      Equilibrium      보이지 않는 손(Invisible Hand)          시장 참여자들이 자신의 이익을 추구하는 과정에서 가격 메커니즘을 통해 사회 전체의 자원 배분이 효율적으로 이루어지는 현상, 혹은 이러한 현상을 가능케 하는 메커니즘              교환(Exchange) : 이상적인 자원 조합을 구성하기 위해 상대가격이 낮은 자원을 지불하여 상대가격이 높은 자원을 구입하는 행위      상대가격(Relative Price) : 다른 자원의 단위로 측정한 어떤 자원의 가치로서, 시장 참여자 상호간에 합의된 자원 간 상대적 교환 비율      가격(Price) : 화폐로써 수량화된 자원의 가치로서, 화폐 단위당 자원의 절대적 교환 비율            최적화(Optimization) : 시장 참여자들이 제약 하에서 목표를 최대화하거나 최소화하는 과정으로서, 경제 활동 혹은 경제 활동의 결과 실현된 상태    수요자의 최적 의사결정          쾌락의 최대화 : 동일한 가치를 지불함으로써 취득 가능한 자원 단위를 최대화함      고통의 최소화 : 동일한 자원 단위를 취득하기 위해 지불해야 하는 가치를 최소화함      최대지불의사(Willingness to Pay; WTP) : 어떤 시장 참여자가 특정 자원을 취득하기 위해 포기할 수 있는 최대 가치        공급자의 최적 의사결정          쾌락의 극대화 : 동일한 자원 단위를 지불함으로써 취득 가능한 가치를 최대화함      고통의 최소화 : 동일한 가치를 취득하기 위해 교환해야 하는 자원 단위를 최소화함      유보가격(Reservation Price) : 어떤 시장 참여자가 특정 자원을 포기하는 대신 취득하고자 하는 최소 가치            균형(Equilibrium) : 자원의 교환 가치를 낮추려는 힘과 높이려는 힘이 맞아떨어져서 외부 교란 요인이 없는 한 유지되는 상태              존재성 : 균형이 존재하는 성질      유용성 : 균형이 적을수록 유용한 성질      안정성 : 다수의 균형이 존재하는 경우 안정적인 균형이 선호되는 성질      Market DemandDeterminants      시장수요결정변수(Market Demand Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장수요($Y$)를 결정하는 요인($X$)\\[f_{D}:P;M,P_{R},N \\rightarrow Q_{D}\\]        가격(Price; $P$) : 수요자가 자원을 취득하기 위해 지불해야 할 가치                  수요의 법칙(Law of Demand; LOD) : 가격과 수요량 간 음의 상관관계\\[\\frac{\\Delta Q_{D}}{\\Delta P} &lt; 0\\]                  소득수준(Income; $M$) : 수요자가 자원을 취득하기 위해 지불 가능한 예산 규모        관련재의 가격(Prices of Substitutes and Complements; $P_{R}$)        수요자 수(Population; $N$)  Elasticity  수요의 탄력성(Elasticity of Demand) : 시장수요결정변수의 변화에 따른 시장수요의 변동성          $\\varepsilon &gt; 1$ : 시장수요결정변수에 대하여 탄력적      $\\varepsilon = 1$ : 시장수요결정변수에 대하여 단위탄력적      $\\varepsilon &lt; 1$ : 시장수요결정변수에 대하여 비탄력적            수요량의 가격 탄력성(Price Elasticity of Demand; PED) : 가격의 단위 변화에 따른 시장수요량의 변동성\\[\\varepsilon_{P}:= -\\frac{\\Delta Q_{D}/Q_D}{\\Delta P/P} \\quad (\\because \\text{LOD})\\]        수요의 소득 탄력성(Income Elasticity of Demand; IED) : 소득수준의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{M}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta M/M}\\]                  정상재(Normal Goods) : 소득수준의 변동성과 시장수요의 변동성이 비례하는 자원\\[\\varepsilon_{M} &gt; 0\\]                              사치재(Luxury Goods) : 소득수준의 단위 변화에 따른 수요의 변동성이 탄력적인 자원\\[\\varepsilon_{M} &gt; 1\\]                                필수재(Necessities) : 소득수준의 단위 변화에 따른 수요의 변동성이 비탄력적인 자원\\[0 &lt; \\varepsilon_{M} &lt; 1\\]                                      열등재(Inferior Goods) : 소득수준의 변동성과 시장수요의 변동성이 반비례하는 자원\\[\\varepsilon_{M} &lt; 0\\]                  수요의 교차 탄력성(Cross-Price Elasticity of Demand; XED) : 관련재 가격의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{C}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta P_{R}/P_R}\\]                  대체재(Substitutes) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 증가하는 경우\\[\\varepsilon_{C} &gt; 0\\]                    보완재(Complements) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 감소하는 경우\\[\\varepsilon_{C} &lt; 0\\]                    독립재(Unrelated Goods) : 어떤 자원의 가격 변동성이 다른 자원의 시장수요 변동성에 영향을 미치지 않는 경우\\[\\varepsilon_{C} = 0\\]            Market SupplyDeterminants      시장공급결정변수(Market Supply Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장공급($Y$)을 결정하는 요인($X$)\\[f_{S}:P;w,v,H,C \\rightarrow Q_{D}\\]        가격(Price; $P$) : 공급자가 자원 단위를 공급함으로써 취득하는 가치                  공급의 법칙(Law of Supply; LOS) : 가격과 공급량 간 양의 상관관계\\[\\frac{\\Delta Q_{S}}{\\Delta P} &gt; 0\\]              자원 생산 시 투입되는 생산요소의 단위당 가격          임금(Wage; $w$) : 노동의 단위당 가격      임대료(Rent; $v$) : 자본의 단위당 가격            기술수준(Hechnics; $H$)    공급자 수(Population; $C$)Elasticity  공급의 탄력성(Elasticity of Supply) : 시장공급결정변수의 변화에 따른 시장공급의 변동성          $\\epsilon &gt; 1$ : 시장공급결정변수에 대하여 탄력적      $\\epsilon = 1$ : 시장공급결정변수에 대하여 단위탄력적      $\\epsilon &lt; 1$ : 시장공급결정변수에 대하여 비탄력적            공급량의 가격 탄력성(Price Elasticity of Supply) : 가격의 단위 변화에 따른 시장공급량의 변동성\\[\\epsilon_{P}:= \\frac{\\Delta Q_{S}/Q_S}{\\Delta P/P} \\quad (\\because \\text{LOS})\\]  Sourse  https://policonomics.com/supply-and-demand/  https://thismatter.com/economics/supply.htm"
  }
  
]


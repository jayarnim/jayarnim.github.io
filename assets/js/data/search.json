[
  
  {
    "title": "Hierarchical Clustering",
    "url": "/posts/Hierarchical_Clustering/",
    "categories": "DATA MINING TECHS, 3.multivariate statistical analysis",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2025-01-09 00:00:00 +0900",
    





    
    "snippet": "Hierarchical Clustering      계층적 군집화(Hierarchical Clustering): 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram): 결합 혹은 분할하는 순서를 나타내는 계층적 ...",
    "content": "Hierarchical Clustering      계층적 군집화(Hierarchical Clustering): 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram): 결합 혹은 분할하는 순서를 나타내는 계층적 트리모형            종류              상향식 군집화(Agglomerative Clustering) : 개별 개체들을 유사한 개체/군집과 계층적으로 통합해가는 방식      하향식 군집화(Divisive Clustering) : 표본을 유의미하게 구분되는 지점마다 계층적으로 분할해가는 방식      How to Agglomerative Clustering      모든 개체를 개별 군집으로서 정의함\\[C_{i} = \\{\\overrightarrow{x}_{i}\\} \\quad \\text{for} \\quad i=1,2,\\cdots, n\\]        군집 간 거리 행렬을 계산함\\[\\mathbf{D}_{i,j}=d(C_{i},C_{j})\\]        가장 가까운 두 개의 군집을 하나의 군집으로 통합함\\[\\begin{aligned} C_{k}&amp;=\\hat{C}_{i} \\cup \\hat{C}_{j}\\\\ \\hat{C}_{i},\\hat{C}_{j}&amp;=\\text{arg} \\min_{C_{i},C_{j}}{d(C_{i},C_{j})} \\end{aligned}\\]        군집 간 거리 행렬을 갱신함\\[\\mathbf{D}_{N} = \\mathbf{D}_{N-1} \\quad \\text{Recalculate} \\quad d(C_{i^{\\forall} \\ne k},C_{k})\\]        모든 개체가 하나의 군집으로 통합될 때까지 ③, ④의 과정을 반복함  How to Calculate Distance      Single Linkage(Minimum Distance) : 각 군집에 속한 개체들 사이 거리 최소값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\min_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Complete Linkage(Maximum Distance) : 각 군집에 속한 개체들 사이 거리 최대값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\max_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Average Linkage(Mean Distance) : 각 군집에 속한 개체들 사이 거리 평균\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{a} \\in \\mathbf{A}}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Centroid Linkage(Distance Between Centroids) : 각 군집 중심 간 거리\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= d(\\overrightarrow{\\mu}_{A},\\overrightarrow{\\mu}_{B})\\\\  \\overrightarrow{\\mu}_{A}  &amp;= \\frac{1}{\\vert\\mathbf{A}\\vert}\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{\\overrightarrow{a}}\\\\  \\overrightarrow{\\mu}_{B}  &amp;= \\frac{1}{\\vert\\mathbf{B}\\vert}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{\\overrightarrow{b}}  \\end{aligned}\\]        Ward’s Method : 병합 후 SSE와 병합 전 개별 군집의 SSE의 합의 차\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{c} \\in \\mathbf{C}}{d(\\overrightarrow{c},\\overrightarrow{\\mu}_{C})} - \\Big[\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{d(\\overrightarrow{a},\\overrightarrow{\\mu}_{A})} + \\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{b},\\overrightarrow{\\mu}_{B})}\\Big]\\\\  \\mathbf{C}  &amp;= \\mathbf{A} \\cup \\mathbf{B}  \\end{aligned}\\]  Sourse  https://towardsdatascience.com/hierarchical-clustering-explained-e59b13846da8  https://harshsharma1091996.medium.com/hierarchical-clustering-996745fe656b"
  },
  
  {
    "title": "Linear Discriminant Analysis",
    "url": "/posts/LDA/",
    "categories": "DATA MINING TECHS, 3.multivariate statistical analysis",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2025-01-06 00:00:00 +0900",
    





    
    "snippet": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &...",
    "content": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &amp;= \\frac{(\\overrightarrow{a}-p\\overrightarrow{b})^{T}\\overrightarrow{b}}{\\Vert \\overrightarrow{a}\\Vert \\cdot \\Vert\\overrightarrow{b}\\Vert}\\\\  &amp;= 0\\\\  \\therefore \\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})  &amp;= p\\overrightarrow{b}\\\\  &amp;= \\left(\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{\\Vert\\overrightarrow{b}\\Vert^{2}}\\right)\\overrightarrow{b}  \\end{aligned}\\]          $p=\\displaystyle\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{\\Vert\\overrightarrow{b}\\Vert^{2}}$ : 정사영 벡터의 크기      $\\overrightarrow{b}$ : 정사영 벡터의 방향      Covariance Matrix      공분산(Covariance) : 두 확률변수의 선형관계를 나타내는 지표로서, 두 확률변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]        공분산행렬(Covariance Matrix) : $n$ 개 변수들 간 공분산을 나열한 $n \\times n$ 정방행렬\\[\\Sigma=  \\begin{matrix}  &amp; \\overrightarrow{A} &amp; \\overrightarrow{B} &amp; \\overrightarrow{C} \\\\  \\overrightarrow{A} &amp; \\sigma_{A}^2 &amp; \\sigma_{AB} &amp; \\sigma_{AC} \\\\  \\overrightarrow{B} &amp; \\sigma_{BA} &amp; \\sigma_{B}^2 &amp; \\sigma_{BC} \\\\  \\overrightarrow{C} &amp; \\sigma_{CA} &amp; \\sigma_{CB} &amp; \\sigma_{C}^2  \\end{matrix}\\]  Linear Transformation      행렬 $\\mathbf{X}$ 을 통한 선형변환은 어떤 좌표를 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계에서 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계로 변환하는 것을 의미함\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix} \\overrightarrow{x}_{1}&amp;\\overrightarrow{x}_{2} \\end{pmatrix}  \\end{aligned}\\]        벡터 $\\overrightarrow{v}$ 는 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 를 나타냄\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= -1\\begin{pmatrix}1\\\\0\\end{pmatrix} + 2\\begin{pmatrix}0\\\\1\\end{pmatrix}\\\\  \\end{aligned}\\]        $\\mathbf{X}$ 를 통한 선형 변환 결과 \\(\\overrightarrow{v}\\) 는 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 로 변환되었음\\[\\begin{aligned}  \\mathbf{X}\\cdot\\overrightarrow{v}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\cdot \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix}-5\\\\2\\end{pmatrix}\\\\  &amp;= -1\\overrightarrow{x}_{1} + 2\\overrightarrow{x}_{2}  \\end{aligned}\\]  Eigen-Vector      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A_n$ 으로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 $\\overrightarrow{0}$ 이 아닌 벡터\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]        고유값(Eigen-Value; $\\lambda$) : 고유벡터의 선형변환 전 크기 대비 선형변환 후 크기의 비율  Linear Discriminant Analysis      선형 판별 분석(Linear Discriminant Analysis; LDA) : 고차원 데이터에 대하여, 주어진 클래스를 가장 잘 구분할 수 있는 새로운 저차원 직교 좌표(선형 판별 함수)를 찾는 기법            방법 : 클래스 간 분산은 최대화하는 동시에 클래스 내 관측치 간 분산은 최소화하는 성분들을 추출함\\[\\hat{\\overrightarrow{w}}  =\\text{arg} \\max_{\\overrightarrow{w}}{\\frac{\\Sigma^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}}  \\quad \\text{s.t.} \\quad  \\overrightarrow{w}^{T}\\overrightarrow{w}=1\\]          $\\Sigma^{2}$ : 정사영 후 클래스 간 분산      $\\sigma_{i}^{2}$ : 정사영 후 $i$ 번째 클래스 내 관측치 간 분산      How to Extract      정사영 후 범주 간 분산 $\\Sigma^{2}$\\[\\begin{aligned}  \\Sigma^{2}  &amp;= (\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})(\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})^{T}\\\\  &amp;= (\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})(\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})^{T}\\quad(\\because \\overrightarrow{\\mu}_{i}=\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})\\\\  &amp;= \\overrightarrow{w}^{T}(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}  \\end{aligned}\\]          \\(\\overrightarrow{m}_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 중심점 벡터      \\(\\overrightarrow{\\mu}_{i}=\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{m}_{i})\\) : \\(\\overrightarrow{m}_{i}\\) 의 정사영 벡터      \\(\\mathbf{S}_{B}\\) : 범주 \\(C_{i},C_{j}\\) 간 편차      \\(\\Sigma\\) : 정사영 후 범주 \\(C_{i},C_{j}\\) 간 편차            정사영 후 범주 내 분산 $\\sigma_{i}^{2}$\\[\\begin{aligned}  \\sigma_{i}^{2}  &amp;= \\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})^{T}}\\quad(\\overrightarrow{x}_{j} \\in C_{i})\\\\  &amp;= \\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})^{T}}\\quad(\\because \\overrightarrow{y}_{j}=\\overrightarrow{w}^{T}\\overrightarrow{x}_{j})\\\\  &amp;= \\overrightarrow{w}^{T}\\left[\\sum_{j=1}^{ \\vert C_{i} \\vert }{(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})^{T}}\\right]\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{i}\\overrightarrow{w}  \\end{aligned}\\]          \\(\\overrightarrow{x}_{j} \\in C_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 \\(j\\) 번째 관측치 벡터      \\(\\overrightarrow{y}_{j}=\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{x}_{j})\\) : \\(\\overrightarrow{x}_{j}\\) 의 정사영 벡터      \\(S_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차      \\(\\sigma_{i}\\) : 정사영 후 \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차            목적 함수 재정의\\[\\begin{aligned}  \\hat{\\overrightarrow{w}}  =\\text{arg} \\max_{\\overrightarrow{w}}{\\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}}  \\quad \\text{s.t.} \\quad   \\overrightarrow{w}^{T}\\overrightarrow{w}=1  \\end{aligned}\\]        라그랑주 승수법을 통한 최적화 문제 풀이\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\partial \\overrightarrow{w}}  &amp;= 0\\\\  \\therefore \\left[\\mathbf{S}_{B}^{-1}(\\mathbf{S}_{1}+\\mathbf{S}_{2})-\\lambda\\mathbf{I}\\right]\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]  "
  },
  
  {
    "title": "Principal Component Analysis",
    "url": "/posts/PCA/",
    "categories": "DATA MINING TECHS, 3.multivariate statistical analysis",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2025-01-05 00:00:00 +0900",
    





    
    "snippet": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &...",
    "content": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &amp;= \\frac{(\\overrightarrow{a}-p\\overrightarrow{b})^{T}\\overrightarrow{b}}{\\Vert \\overrightarrow{a}\\Vert \\cdot \\Vert\\overrightarrow{b}\\Vert}\\\\  &amp;= 0\\\\  \\therefore \\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})  &amp;= p\\overrightarrow{b}\\\\  &amp;= \\left(\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{\\Vert\\overrightarrow{b}\\Vert^{2}}\\right)\\overrightarrow{b}  \\end{aligned}\\]          $p=\\displaystyle\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{\\Vert\\overrightarrow{b}\\Vert^{2}}$ : 정사영 벡터의 크기      $\\overrightarrow{b}$ : 정사영 벡터의 방향      Covariance Matrix      공분산(Covariance) : 두 확률변수의 선형관계를 나타내는 지표로서, 두 확률변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]        공분산행렬(Covariance Matrix) : $n$ 개 변수들 간 공분산을 나열한 $n \\times n$ 정방행렬\\[\\Sigma=  \\begin{matrix}  &amp; \\overrightarrow{A} &amp; \\overrightarrow{B} &amp; \\overrightarrow{C} \\\\  \\overrightarrow{A} &amp; \\sigma_{A}^2 &amp; \\sigma_{AB} &amp; \\sigma_{AC} \\\\  \\overrightarrow{B} &amp; \\sigma_{BA} &amp; \\sigma_{B}^2 &amp; \\sigma_{BC} \\\\  \\overrightarrow{C} &amp; \\sigma_{CA} &amp; \\sigma_{CB} &amp; \\sigma_{C}^2  \\end{matrix}\\]  Linear Transformation      행렬 $\\mathbf{X}$ 을 통한 선형변환은 어떤 좌표를 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계에서 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계로 변환하는 것을 의미함\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix} \\overrightarrow{x}_{1}&amp;\\overrightarrow{x}_{2} \\end{pmatrix}  \\end{aligned}\\]        벡터 $\\overrightarrow{v}$ 는 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 를 나타냄\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= -1\\begin{pmatrix}1\\\\0\\end{pmatrix} + 2\\begin{pmatrix}0\\\\1\\end{pmatrix}\\\\  \\end{aligned}\\]        $\\mathbf{X}$ 를 통한 선형 변환 결과 \\(\\overrightarrow{v}\\) 는 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 로 변환되었음\\[\\begin{aligned}  \\mathbf{X}\\cdot\\overrightarrow{v}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\cdot \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix}-5\\\\2\\end{pmatrix}\\\\  &amp;= -1\\overrightarrow{x}_{1} + 2\\overrightarrow{x}_{2}  \\end{aligned}\\]  Eigen-Vector      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A_n$ 으로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 $\\overrightarrow{0}$ 이 아닌 벡터\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]        고유값(Eigen-Value; $\\lambda$) : 고유벡터의 선형변환 전 크기 대비 선형변환 후 크기의 비율  Principal Component Analysis      주성분 분석(Principal Component Analysis; PCA) : 고차원 데이터에 대하여, X의 방향적 분포를 가장 잘 설명하는 새로운 저차원 직교 좌표를 학습하는 기법              주성분(Principal Component; PC) : 새로운 저차원 직교 좌표            방법 : 관측치 간 상대적 특성을 잘 보존하는 성분들을 추출함              $\\text{component}$ : 주성분 벡터 $\\overrightarrow{w}$      $\\text{datapoint}$ : 관측치 벡터 $\\overrightarrow{x}\\in \\mathbf{X}$      $\\text{projected data}$ : 주성분 벡터에 대한 관측치 벡터의 정사영 벡터 $\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{x})$      $D_{1}$ : 관측치 벡터에 대하여 보존하는 정보로서 분산      $D_{2}$ : 관측치 벡터에 대하여 유실하는 정보      $D_{3}$ : 관측치 벡터의 본래 정보      How to Extract      관측치 행렬 $X_{N \\times P}$ 를 단위벡터 $\\overrightarrow{w}$ 에 정사영한다고 하자\\[\\begin{aligned}  proj_{\\overrightarrow{w}}(\\mathbf{X})  &amp;= \\frac{&lt;\\mathbf{X},\\overrightarrow{w}&gt;}{\\Vert w \\Vert ^2}\\cdot\\overrightarrow{w}\\\\  &amp;= (\\overrightarrow{w}^{T}\\mathbf{X})\\cdot\\overrightarrow{w} \\quad (\\because \\Vert w \\Vert=1)  \\end{aligned}\\]          $\\overrightarrow{w}$ : 정사영 벡터의 방향      $\\overrightarrow{w}^{T}\\mathbf{X}$ : 정사영 벡터의 크기            $\\overrightarrow{w}$ 에 정사영된 관측치들의 분산 $\\mathbf{V}$ 은 다음과 같음\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w})\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}  \\end{aligned}\\]          $\\Sigma=\\displaystyle\\frac{1}{n}\\mathbf{X}\\mathbf{X}^{T}$ : 관측치 행렬 $X$ 의 공분산 행렬            $\\mathbf{V}$ 을 최대화하는 $\\overrightarrow{w}$ 를 채택한다고 하자\\[\\hat{\\overrightarrow{w}}  = \\text{arg} \\max_{\\overrightarrow{w}}{\\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}}  \\quad \\text{s.t.} \\quad  \\overrightarrow{w}^{T}\\overrightarrow{w}=1\\]        라그랑주 승수법에 기초하여 $\\hat{\\overrightarrow{w}}$ 도출\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\overrightarrow{w}}  &amp;= 0\\\\  \\therefore (\\Sigma-\\lambda\\mathbf{I})\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]        $\\mathbf{V}$ 를 최대화하는 주성분 $\\overrightarrow{w}$ 은 $\\mathbf{X}$ 의 공분산 행렬 $\\Sigma$ 의 고유벡터임\\[\\begin{aligned}  \\Sigma  &amp;= \\mathbb{V}\\mathbb{\\Lambda}\\mathbb{V}^{-1},\\\\  \\mathbb{V}  &amp;= \\begin{pmatrix}\\overrightarrow{w}_{1}&amp;\\overrightarrow{w}_{2}&amp;\\cdots&amp;\\overrightarrow{w}_{p}\\end{pmatrix}\\\\  \\mathbb{\\Lambda}  &amp;= \\text{diag}(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{p})  \\end{aligned}\\]  Explanatory Power      주성분 벡터의 고유값 : 관측치 행렬 $\\mathbf{X}$ 에 대하여 주성분 벡터에 대한 정사영 벡터 간 분산\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}\\\\  &amp;= \\hat{\\overrightarrow{w}}^{T}\\lambda\\hat{\\overrightarrow{w}} \\quad (\\because \\Sigma\\hat{\\overrightarrow{w}}-\\lambda\\hat{\\overrightarrow{w}}=0)\\\\  &amp;= \\lambda \\quad (\\because \\overrightarrow{w}^{T}\\overrightarrow{w}=1)  \\end{aligned}\\]        주성분 벡터의 설명력 : 관측치 행렬 $\\mathbf{X}_{N \\times P}$ 에 대하여 생성 가능한 $P$ 개의 주성분 벡터 고유값 합계 대비 해당 주성분 벡터 고유값 비율\\[\\frac{\\lambda_{k}}{\\sum_{i=1}^{p}{\\lambda_{i}}}\\]  Sourse  http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/"
  },
  
  {
    "title": "Bayesian Attention Modules",
    "url": "/posts/BAM/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, Deep Learning, Attention Mechanism, Variational Inference",
    "date": "2024-09-19 00:00:00 +0900",
    





    
    "snippet": "Prerequisite  Attention MechanismBayesian Attention Modules      Bayesian Attention Modules : Attention Mechanism 에 실증적 베이지안 접근법을 적용하여 Attention Weight 의 불확실성을 반영하되, Probabilic Attention Mechanism ...",
    "content": "Prerequisite  Attention MechanismBayesian Attention Modules      Bayesian Attention Modules : Attention Mechanism 에 실증적 베이지안 접근법을 적용하여 Attention Weight 의 불확실성을 반영하되, Probabilic Attention Mechanism 선행연구의 한계점을 보완하는 근사 분포를 적용하는 방법론    Probabilic Attention Mechanism 선행 연구의 한계점          Hard Attention : 사후 분포의 근사 분포를 이산 확률 분포로 설정하는데, 이는 재매개변수화가 불가능하여 역전파 알고리즘을 통한 최적화 효율성을 도모할 수 없음      Soft Attention : 사후 분포의 근사 분포를 디리클레 분포, 정규 분포 등으로 설정하는데, 디리클레 분포는 마찬가지로 재매개변수가 불가능하고, 정규 분포는 확률변수의 범위를 양수로 제한하지 않아 샘플링된 Attention Weight 를 확률적으로 해석할 수 없음        Bayesian Attention Modules 의 해법 : 재매개변수화 가능하고 확률변수의 범위를 양수로 제한하는 확률 분포를 근사 분포로 설정함으로써 샘플링된 Attention Weight 의 역전파 학습 및 확률적 해석을 도모함Approx. Prob. Dist.      와이블 분포(Weibull Distribution) : 특정 사건이 발생하기까지의 대기 시간에 관한 확률 분포\\[\\begin{aligned}  \\mathcal{A} \\sim \\text{Weibull}\\left(k, \\lambda\\right) \\quad \\text{for} \\quad \\mathcal{A} &gt; 0  \\end{aligned}\\]          Shape Parameter($k$) : 사건 발생 대기 시간에 따른 사건 발생 가능성의 증가 혹은 감소 패턴      Scale Parameter($\\lambda$) : 사건 발생 대기 시간의 범위            로그 정규 분포(Log Normal Distribution) : 로그 값이 정규 분포를 따르는 확률변수에 관한 분포\\[\\begin{aligned}  \\mathcal{A} \\sim \\text{Log-Normal}\\left(\\mu, \\sigma^{2}\\right) \\quad \\text{for} \\quad \\mathcal{A} &gt; 0  \\end{aligned}\\]          Shape Parameter($\\mu$)      Scale Parameter($\\sigma^{2}$)      Bayesian Framework      Empirical Prior Dist. for Attention Score\\[\\begin{aligned}  \\mathcal{A}  &amp;\\sim \\pi\\left(\\Theta, \\eta\\right)  \\end{aligned}\\]                  $\\Theta$ : Shape Parameter is Trained by $\\mathbf{K}$\\[\\begin{aligned}  \\overrightarrow{\\Theta}_{N \\times 1} \\mid \\mathbf{K}_{N \\times d_{K}}  &amp;= \\text{Softmax}\\left[\\mathcal{F}^{(2)}\\left(\\text{ReLU}\\left[\\mathcal{F}^{(1)}\\left(\\mathbf{K}_{N \\times d_{K}}\\right)\\right]\\right)\\right]  \\end{aligned}\\]                  선택지 \\(\\overrightarrow{\\mathbf{v}}_{j} \\in \\mathbf{V}_{N \\times D}\\) 의 중요성을 질문 \\(\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbf{Q}_{M \\times d_{K}}\\) 마다 맞춤으로 갱신하기 전, 질문과 비교 가능한, 선택지에 대한 정보 \\(\\overrightarrow{\\mathbf{k}}_{j} \\in \\mathbf{K}_{N \\times d_{K}}\\) 만을 활용하여 선택지의 전반적인 중요성을 사전 평가함                            $\\eta$ : Scale Parameter is Global Hyper Parameter                  Liklehood\\[\\mathcal{L}\\left(\\mathbf{Y} \\mid \\mathcal{A}, \\mathbf{Q},\\cdots\\right)\\]        Posterior Dist. Estimation\\[\\begin{aligned}  p\\left(\\mathcal{A} \\mid \\mathbf{Y}, \\mathbf{Q}, \\cdots\\right)  \\propto \\mathcal{L}\\left(\\mathbf{Y} \\mid \\mathcal{A}, \\mathbf{Q}, \\cdots\\right) \\cdot \\pi\\left(\\mathcal{A} ; \\Theta, \\eta \\right)  \\end{aligned}\\]        Attention weights are derived using simplex projection, not softmax\\[\\begin{aligned}  W  &amp;= \\frac{\\mathcal{A}}{\\sum_{j}{\\mathcal{A}_{j}}}  \\end{aligned}\\]  Approx. Dist. Determination      Approx. Dist. of $\\mathcal{A} \\mid \\mathbf{Y}, \\mathbf{Q}, \\cdots \\sim P$\\[\\mathcal{A} \\sim \\mathcal{Q}\\left(\\Phi\\right)\\]          $\\Phi = \\mathcal{F}\\left(\\mathbf{Q} \\oplus \\mathbf{K}\\right)$      Weibull Dist.      If Approx. Dist. $\\mathcal{A} \\sim \\mathcal{Q}\\left(\\Phi\\right)$ is set to $\\text{Weibull}\\left(k,\\lambda\\right)$\\[\\begin{aligned}  \\mathcal{Q}\\left(\\Phi\\right) = \\text{Weibull}\\left(k, \\lambda\\right)  \\end{aligned}\\]        Reparameterization Trick\\[\\begin{aligned}  \\mathcal{A}  &amp;= \\mathcal{G}(\\epsilon ; k, \\lambda)\\\\  &amp;= \\lambda\\left(\\log{\\frac{1}{1-\\epsilon}}\\right)^{1/k}, \\quad \\epsilon \\sim \\text{Uniform}\\left(0,1\\right)  \\end{aligned}\\]        Prior Dist. $\\mathcal{A} \\sim \\pi\\left(\\Theta,\\eta\\right)$ is set to $\\text{Gamma}\\left(\\alpha, \\beta\\right)$ because of Analytical Expression\\[\\begin{aligned}  &amp;D_{KL}\\Big[\\text{Weibull}\\left(k,\\lambda\\right) \\parallel \\text{Gamma}\\left(\\alpha,\\beta\\right)\\Big]\\\\  &amp;= \\gamma \\cdot \\alpha \\cdot \\frac{1}{k} - \\alpha \\cdot \\log{\\lambda} + \\log{k} + \\beta \\cdot \\lambda \\cdot \\Gamma\\left(1 + \\frac{1}{k}\\right) - \\gamma - 1 - \\alpha \\cdot \\log{\\beta} + \\log{\\Gamma\\left(\\alpha\\right)}  \\end{aligned}\\]          $\\gamma$ : Euler–Mascheroni constant      Log-Normal Dist.      If Approx. Dist. $\\mathcal{A} \\sim \\mathcal{Q}\\left(\\Phi\\right)$ is set to $\\text{Log-Normal}\\left(\\mu, \\sigma^{2}\\right)$\\[\\begin{aligned}  \\mathcal{Q}\\left(\\Phi\\right) = \\text{Log-Normal}\\left(\\mu, \\sigma^{2}\\right)  \\end{aligned}\\]        Reparameterization Trick\\[\\begin{aligned}  \\mathcal{A}  &amp;= \\mathcal{G}(\\mathcal{Z} ; \\mu, \\sigma)\\\\  &amp;= \\exp{\\Big[\\mu + \\sigma \\cdot \\mathcal{Z} \\Big]}, \\quad \\mathcal{Z} \\sim \\mathcal{N}\\left(0,1\\right)  \\end{aligned}\\]        Prior Dist. $\\mathcal{A} \\sim \\pi\\left(\\Theta,\\eta\\right)$ is set to $\\text{Log-Normal}\\left(\\mu,\\sigma^{2}\\right)$ because of Analytical Expression\\[\\begin{aligned}  &amp;D_{KL}\\Big[\\text{Log-Normal}\\left(\\mu_{\\text{Approx}},\\sigma^{2}_{\\text{Approx}}\\right) \\parallel \\text{Log-Normal}\\left(\\mu_{\\text{Prior}},\\sigma^{2}_{\\text{Prior}}\\right)\\Big]\\\\  &amp;= \\frac{\\sigma_{\\text{Approx}}}{\\sigma_{\\text{Prior}}} + \\frac{\\left(\\mu_{\\text{Approx}} - \\mu_{\\text{Prior}}\\right)^{2}}{2 \\cdot \\sigma^{2}_{\\text{Prior}}} - \\frac{1}{2} + \\log{\\frac{\\sigma_{\\text{Prior}}}{\\sigma_{\\text{Approx}}}}  \\end{aligned}\\]  Variational Inference      ELBO\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\mathbb{E}_{\\mathcal{A} \\sim \\mathcal{Q}\\left(\\Phi\\right)}\\Big[\\log{\\mathcal{L}\\left(\\mathbf{Y} \\mid \\mathcal{A}, \\mathbf{Q}, \\cdots\\right)}\\Big]  - D_{KL}\\Big[q\\left(\\mathcal{A};\\Phi\\right) \\parallel \\pi\\left(\\mathcal{A};\\Theta,\\eta\\right)\\Big]  \\end{aligned}\\]        Gaussian Negative Log-Likelihood                  if \\(y \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}\\right)\\)\\[\\begin{aligned}  p\\left(y \\mid \\mu, \\sigma^{2}\\right)  &amp;= \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\exp{\\left[\\frac{(y - \\mu)^{2}}{2\\sigma^{2}}\\right]}\\\\  \\log{p\\left(y \\mid \\mu, \\sigma^{2}\\right)}  &amp;= -\\frac{1}{2}\\log{2\\pi \\sigma^{2}} - \\frac{(y - \\mu)^{2}}{2\\sigma^{2}}\\\\  &amp;\\approx \\cancel{-\\frac{1}{2}\\log{2\\pi}} -\\frac{1}{2}\\log{\\sigma^{2}} - \\frac{(y - \\mu)^{2}}{2\\sigma^{2}}  \\end{aligned}\\]                    Negative Log-Likelihood\\[\\begin{aligned}  \\text{NLL}  &amp;= -\\log{p\\left(y \\mid \\mu, \\sigma^{2}\\right)}\\\\  &amp;\\approx \\frac{1}{2}\\log{\\sigma^{2}} + \\frac{(y - \\mu)^{2}}{2\\sigma^{2}}  \\end{aligned}\\]                    if $\\sigma^{2}_{\\forall} = \\sigma^{2}$\\[\\begin{aligned}  \\text{NLL}  \\approx \\text{MSE}  \\end{aligned}\\]                  Optimization\\[\\begin{aligned}  \\mathcal{A},\\Theta,\\Phi \\mid \\eta,\\cdots  = \\text{arg}\\min{-\\text{ELBO}}  \\end{aligned}\\]  "
  },
  
  {
    "title": "CLiMF",
    "url": "/posts/CLiMF/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF, Ranking Prediction, Objective Function, Listwise Learning, MRR",
    "date": "2024-09-05 00:00:00 +0900",
    





    
    "snippet": "CLiMF      CLiMF(Collaborative Less-is-More Filtering) : Probabilistc Pointwise Ranking Prediction          선행 연구들은 명시적 피드백 하 선호 점수를 예측하는 것에 초점을 맞추었음. 이러한 연구 경향은 친구 추천, 팔로우 추천 등 이진 피드백이 활용되는 사례에 적합...",
    "content": "CLiMF      CLiMF(Collaborative Less-is-More Filtering) : Probabilistc Pointwise Ranking Prediction          선행 연구들은 명시적 피드백 하 선호 점수를 예측하는 것에 초점을 맞추었음. 이러한 연구 경향은 친구 추천, 팔로우 추천 등 이진 피드백이 활용되는 사례에 적합하지 않음. 순위 기반 최적화 및 Top-k 추천 품질에 관한 논의가 필요함. BPR 이 순위 기반 최적화를 시도하였으나, AUC 최적화는 Top-k 추천 품질 개선에 미흡함. 순위가 더 높이 제안될수록 더 큰 영향을 가지도록 유도하는 MRR 최적화가 필요함.      MRR Optimization      RR(Reciprocal Rank) : 사용자 $u$ 에 대하여 정답 아이템이 처음 등장하는 순번의 역수\\[\\begin{aligned}  \\text{RR}  &amp;= \\frac{1}{\\text{Rank of 1st Relevent Item}}  \\end{aligned}\\]        MRR(Mean Reciprocal Rank) : 모든 사용자에 대하여 정답 아이템이 처음 등장하는 평균적인 순번\\[\\begin{aligned}  \\text{MRR}  &amp;= \\frac{1}{\\vert U \\vert}\\sum_{u \\in U}{\\text{RR}_{u}}  \\end{aligned}\\]  How to Modeling      Smoothing Trick\\[\\begin{aligned}  \\sigma(x)  &amp;= \\frac{1}{1 + \\exp{-x}}  \\end{aligned}\\]        Rank : 사용자 벡터 \\(\\overrightarrow{\\mathbf{p}}_{u}\\) 와 아이템 벡터 \\(\\overrightarrow{\\mathbf{q}}_{i}\\) 의 내적값이 클수록 해당 아이템이 상위에 랭크될 가능성이 높다는 뜻으로 이해할 수 있음\\[\\begin{aligned}  \\frac{1}{\\text{Rank}(u,i)}  &amp;\\approx \\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right]  \\end{aligned}\\]                            Dot Product          Sigmoid Function                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to +\\infty\\)          \\(\\sigma \\to 1\\)                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to 0\\)          \\(\\sigma \\to 0.5\\)                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} \\to -\\infty\\)          \\(\\sigma \\to 0\\)                          Indicator Function : 순위는 다른 아이템과의 상대적 위치이므로, 아이템 간 선호의 우열을 다루는 항목이 필요하며, 이때 사용자 $u$ 와 아이템 $i$ 의 내적값이 $j$ 보다 더 클 가능성이 높을수록 순위가 더 높다는 뜻으로 이해할 수 있음                  Original(Rank Comparison):\\[\\begin{aligned}  \\mathbb{I}(\\text{Rank}(u,i) &lt; \\text{Rank}(u,j))  = \\begin{cases}  1 \\quad &amp;\\text{If $i$ is Higher than $j$}\\\\  0 \\quad &amp;\\text{Otherwise}  \\end{cases}  \\end{aligned}\\]                    Convert(Dot Product Comparison):\\[\\begin{aligned}  \\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\right]  \\end{aligned}\\]                                            Dot Product              Sigmoid Function                                                          \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} &gt; \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 1\\)                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} = \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 0.5\\)                                      \\(\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} &lt; \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\)              \\(\\sigma \\to 0\\)                                                Objective Function\\[\\begin{aligned}  \\mathcal{J}  &amp;= \\sum_{u \\in U} \\sum_{i \\in I_{u}^{+}}{\\left(\\ln{\\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right]} + \\sum_{j \\in I \\setminus I_{u}^{+}}{\\ln{\\sigma\\left[\\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}\\right]}}\\right)} - \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}  \\end{aligned}\\]  "
  },
  
  {
    "title": "LambdaRank",
    "url": "/posts/LambdaRank/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF, Ranking Prediction, Objective Function, Listwise Learning, NDCG",
    "date": "2024-08-28 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Variational AutoEncoder",
    "url": "/posts/VAE/",
    "categories": "DATA MINING TECHS, 6.image analytics",
    "tags": "AI Application, CV, Generative Model, Autoencoder, Bayesian, Variational Inference",
    "date": "2024-08-19 00:00:00 +0900",
    





    
    "snippet": "AutoEncoder      오토인코더(AutoEncoder; AE) : 입력 데이터를 압축시켜 저차원 특징 공간으로 축소한 후, 이를 다시 확장하여 원본으로 복원하는 인공신경망 아키텍처            Encoder:\\[\\begin{aligned}  \\mathbf{z} = F\\left(\\mathbf{x} \\mid \\Theta \\right)  \\...",
    "content": "AutoEncoder      오토인코더(AutoEncoder; AE) : 입력 데이터를 압축시켜 저차원 특징 공간으로 축소한 후, 이를 다시 확장하여 원본으로 복원하는 인공신경망 아키텍처            Encoder:\\[\\begin{aligned}  \\mathbf{z} = F\\left(\\mathbf{x} \\mid \\Theta \\right)  \\end{aligned}\\]          \\(F_{\\Theta}\\) : Encoder Layer      \\(\\mathbf{x}\\) : Input Data      \\(\\mathbf{z}\\) : Latent Space            Decoder:\\[\\begin{aligned}  \\hat{\\mathbf{x}} = G\\left(\\mathbf{z} \\mid \\Phi \\right)  \\end{aligned}\\]          \\(G_{\\Phi}\\) : Encoder Layer      \\(\\mathbf{z}\\) : Latent Space      \\(\\hat{\\mathbf{x}}\\) : Output Data            Optimization:\\[\\begin{aligned}  \\hat{\\mathbf{z}}, \\hat{\\Theta}, \\hat{\\Phi} &amp;= \\text{arg}\\min{\\mathcal{L}\\left(\\mathbf{x}, \\hat{\\mathbf{x}}\\right)}  \\end{aligned}\\]  Variations      적층 오토인코더(Stacked AutoEncoder or Deep AutoEncoder) : 입력층과 잠재공간, 잠재공간과 출력층 사이에 여러 장의 은닉층을 추가함으로써 기본 오토인코더보다 복잡하고 비선형적인 데이터 패턴을 잘 포착하도록 함            희소 오토인코더(Sparse AutoEncoder; SAE) : 입력 데이터를 고차원으로 확장했다가 본래 차원으로 축소하는 과정을 통해 저차원에서는 발견하기 어려운 잠재 정보나 패턴을 포착하도록 함                      희소성 제약(Sparse Constraint) : 특히 Sparse AutoEncoder 에서, 데이터 과적합을 방지하고 핵심 정보만 선택적으로 학습하기 위하여 은닉층 뉴런 중 일부만 활성화되도록 강제하는 기법\\[\\begin{aligned}  \\mathcal{L}=\\frac{1}{N}\\sum_{i=1}^{N}{\\Vert \\mathbf{x}_{i} - \\hat{\\mathbf{x}}_{i} \\Vert^{2}} + \\beta \\cdot \\underbrace{\\Omega(\\overrightarrow{\\mathbf{h}} \\mid m, \\rho)}_{\\begin{array}{c} \\text{Sparse} \\\\ \\text{Penalty} \\end{array}}  \\end{aligned}\\]                    Sparse Penalty Function : 은닉층 뉴런들이 평균적으로 목표 희소성 비율에 가깝게 활성화되도록 하기 위함으로, 대개 쿨백 라이블러 발산(Kullback–Leibler Divergence)을 활용함\\[\\begin{aligned}  \\Omega(\\overrightarrow{\\mathbf{h}} \\mid m, \\rho)  &amp;= \\sum_{j=1}^{m}{D_{KL}\\left[\\rho \\parallel \\hat{\\rho}_{j}\\right]}\\\\  &amp;= \\sum_{j=1}^{m}{\\rho \\cdot \\log{\\frac{\\rho}{\\hat{\\rho}_{j}}} + (1-\\rho) \\cdot \\log{\\frac{1-\\rho}{1-\\hat{\\rho}_{j}}}}  \\end{aligned}\\]                  $m$ : 은닉층 뉴런 수          $\\rho$ : 목표 희소성 비율          \\(\\hat{\\rho}_{j}=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}{h_{j}^{(i)}}\\) : 은닉층 뉴런 $j$ 의 평균 출력값                          잡음 제거 오토인코더(Denoising AutoEncoder; DAE) : 원본 데이터에 잡음을 추가하여 입력한 후, 원본을 복원함으로써 잡음에 대한 강건성을 확보하고 데이터의 본질적인 특징에 집중할 수 있도록 함                      How to Generate Noise\\[\\begin{aligned}  \\tilde{\\mathbf{x}} &amp;= g(\\mathbf{x} \\mid \\theta)  \\end{aligned}\\]                              Gaussian Noise:\\[\\begin{aligned}  g(\\mathbf{x} \\mid \\sigma)= \\mathbf{x} + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,\\sigma^2)  \\end{aligned}\\]                                Salt and Pepper Noise:\\[g(\\mathbf{x} \\mid p)=\\begin{cases}\\begin{aligned}  \\mathbf{x} \\quad &amp; 1-p\\\\  \\mathbf{v}_{\\text{min}} \\quad &amp; \\frac{p}{2}\\\\  \\mathbf{v}_{\\text{max}} \\quad &amp; \\frac{p}{2}  \\end{aligned}\\end{cases}\\]                                Masking Noise:\\[\\begin{aligned}  g(\\mathbf{x} \\mid p)= \\mathbf{x} \\cdot m, \\quad m \\sim \\text{Bernouli}(1-p)  \\end{aligned}\\]                              Variational AutoEncoder  변분 오토인코더(Variational AutoEncoder; VAE) : 입력 데이터의 확률 분포를 탐색하고(Encoder), 그 파라미터(Latent Space)에 기초하여 데이터를 확률적으로 생성하는(Decoder), 오토인코더 기반 생성 모형(Generative Model)How to Modeling      관측치 $\\overrightarrow{\\mathbf{x}}$ 가 파라미터 $\\overrightarrow{\\mathbf{z}}$ 에서 생성되었다고 가정하자. $\\overrightarrow{\\mathbf{x}}$ 의 우도 함수:\\[\\overrightarrow{\\mathbf{x}} \\mid \\overrightarrow{\\mathbf{z}} \\sim \\mathcal{L}\\left(\\Theta \\right)\\]        파라미터 $\\overrightarrow{\\mathbf{z}}$ 의 사전 확률 분포 결정:\\[\\overrightarrow{\\mathbf{z}} \\sim \\mathcal{N}\\left(0, \\mathbf{I}_{K}\\right)\\]        파라미터 $\\overrightarrow{\\mathbf{z}}$ 의 사후 확률 분포 추정:\\[p\\left(\\overrightarrow{\\mathbf{z}} \\mid \\overrightarrow{\\mathbf{x}} ; \\Theta\\right) \\propto \\mathcal{L}\\left(\\overrightarrow{\\mathbf{x}} \\mid \\overrightarrow{\\mathbf{z}} ; \\Theta \\right) \\cdot \\pi\\left(\\overrightarrow{\\mathbf{z}}\\right)\\]        $\\overrightarrow{\\mathbf{z}} \\mid \\overrightarrow{\\mathbf{x}} \\sim P(\\Theta)$ 의 근사 분포 $\\overrightarrow{\\mathbf{z}} \\sim Q(\\Phi)$ 정의:\\[\\begin{aligned}  q\\left(\\overrightarrow{\\mathbf{z}} ; \\Phi\\right)  &amp;= \\mathcal{N}\\left(\\mu(\\overrightarrow{\\mathbf{x}} ; \\Phi), \\text{diag}[\\sigma^2(\\overrightarrow{\\mathbf{x}} ; \\Phi)]\\right)\\\\  &amp;\\approx \\mu(\\overrightarrow{\\mathbf{x}} ; \\Phi) + \\sigma(\\overrightarrow{\\mathbf{x}} ; \\Phi) \\odot \\epsilon \\quad \\text{for} \\quad \\epsilon \\sim \\mathcal{N}\\left(0, \\mathbf{I}_{K}\\right)  \\end{aligned}\\]        ELBO:\\[\\text{ELBO}  = \\underbrace{\\mathbb{E}_{\\mathbf{z} \\sim Q(\\Phi)}\\Big[\\log{\\mathcal{L}\\left(\\overrightarrow{\\mathbf{x}} \\mid \\overrightarrow{\\mathbf{z}} ; \\Theta \\right)}\\Big]}_{-\\text{Reconstruction Loss}} - \\beta \\cdot \\underbrace{D_{KL}\\Big[q\\left(\\overrightarrow{\\mathbf{z}} ; \\Phi\\right) \\parallel \\pi\\left(\\overrightarrow{\\mathbf{z}}\\right)\\Big]}_{\\text{KL Divergence}}\\]        Optimization:\\[\\hat{\\Theta},\\hat{\\Phi} \\mid K, \\beta  = \\text{arg}\\max_{\\Theta,\\Phi}{\\text{ELBO}}\\]          $K$ : Dimension of Latent Space      $0 \\le \\beta \\le 1$ : KL Annealing Param      Architecture      Encoder : Posterior Probability Distribution Estimatior\\[q\\left(\\overrightarrow{\\mathbf{z}} ; \\Phi\\right)\\]        Latent Space : Posterior Probability Distribution\\[\\overrightarrow{\\mathbf{z}} \\mid \\overrightarrow{\\mathbf{x}}\\]        Decoder : Data Generator\\[\\mathcal{L}\\left(\\overrightarrow{\\mathbf{x}} \\mid \\overrightarrow{\\mathbf{z}} ; \\Theta \\right)\\]  Source  https://velog.io/@jochedda/%EB%94%A5%EB%9F%AC%EB%8B%9D-Autoencoder-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EC%A2%85%EB%A5%98"
  },
  
  {
    "title": "GPT",
    "url": "/posts/GPT/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Generative Model, Attention Mechanism",
    "date": "2024-08-16 00:00:00 +0900",
    





    
    "snippet": "GPT      지피티(Generative Pre-trained Transformer; GPT) : 트랜스포머의 디코더 아키텍처를 기반으로 하여 다양한 텍스트 데이터로 사전 훈련된 자기회귀모형(Auto-Regressive Model)                  자기회귀모형(Auto-Regressive Model; AR) : 이전 출력값들을 참고하여...",
    "content": "GPT      지피티(Generative Pre-trained Transformer; GPT) : 트랜스포머의 디코더 아키텍처를 기반으로 하여 다양한 텍스트 데이터로 사전 훈련된 자기회귀모형(Auto-Regressive Model)                  자기회귀모형(Auto-Regressive Model; AR) : 이전 출력값들을 참고하여 다음 출력값을 예측하는 모형\\[\\begin{aligned}  X_{t}  &amp;= \\beta + \\sum_{i=1}^{p}{\\alpha_{i} \\cdot X_{t-i}} + \\epsilon_{t}  \\end{aligned}\\]                  \\(X_{t}\\) : 현재 시점 출력값          \\(X_{t-i}\\) : 이전 시점 출력값          \\(\\alpha_{i}\\) : 각 시점에 대한 가중치          \\(\\beta\\) : 편향          \\(\\epsilon_{t}\\) : 노이즈                          vs. BERT                                           BERT          GPT                                      Type          Masked Language Model          Auto-Regressive Model                          Task          Natural Language Understanding          Natural Language Generation                          Object          Predict Masked Word          Predict Next Word                          Direction          Bidirectional          Unidirectional                          Transformer          Encoder          Decoder                          Version                                           GPT-1          GPT-2          GPT-3                                      Year          2018          2019          2020                          Embedding Dimension          768          1,024          12,288                          Decoder Layers          12          48          96                          Attention Heads          12          16          96                          Total Parameters          117M          1.5B~15B          175B                          Traning Data          BooksCorpus          OpenWebText          Common Crawl  WebText2  Wikipedia  BooksCorpus                    Word Representation      Unique(or Max) Number of Vector                            VECTOR          GPT-1          GPT-2          GPT-3                                      Unique Tokens          40,000          50,257          50,257                          Max Seq          512          1,024          2,048                      Tokenization Method : BPE(Byte-Pair Encoding)                  단어를 문자(Byte) 단위로 쪼갠 후 가장 많이 등장하는 문자 쌍(Pair)을 병합하는 과정을 반복하여 최종 내부 단어(Sub-Word) 단위 토큰을 생성함                    Split a Word into Bytes                                            Word              Bytes                                                          low              [l, o, w]                                      lower              [l, o, w, e, r]                                      newest              [n, e, w, e, s, t]                                      widest              [w, i, d, e, s, t]                                                  Merge Pairs                                            Pair              Count              Merge                                                          (l, o)              2              lo                                      (o, w)              2              ow                                      (e, s)              2              es                                      (s, t)              2              st                                      $\\vdots$              $\\vdots$              $\\vdots$                                                  Result                                            Word              Sub-Word Tokens                                                          low              [lo, w]                                      lower              [lo, w, er]                                      newest              [ne, w, est]                                      widest              [wi, d, est]                                                Embedding\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{i}  &amp;= \\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{TOKEN}} + \\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{POS}}  \\end{aligned}\\]                  \\(\\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{TOKEN}}\\) : Token Embedding                    \\(\\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{POS}}\\) : Position Embedding, Not Fixed But Learnable            Single Layer\\[\\begin{aligned}\\mathcal{X}^{(0)}&amp;=\\text{Embeddings}\\left(\\text{Tokens}\\right)\\\\\\mathcal{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right) + \\mathcal{X}^{(k)}\\Big]\\\\\\mathcal{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathcal{H}^{(k)}\\right) + \\mathcal{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathcal{X}$ is Input Data of Single Layer, $\\mathcal{Y}$ is Output Data of Single Layer          \\(\\mathcal{X}^{(k+1)}=\\mathcal{Y}^{(k)}\\) : Input Data of $k+1$ Decoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathcal{X}^{(0)}\\) is Sum of Token Embedding &amp; Position Embedding Vector      Output Data of Final Layer \\(\\mathcal{Z}=\\mathcal{Y}^{(K)}\\) is Output of Decoder Module            \\(\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right)\\) : Multi-Head Masked Self Attention          $\\mathcal{M}$ : Causal Mask(Upper-triangular mask)            \\(\\text{FFN}\\left(\\mathcal{H}^{(k)}\\right)\\) : Feed-Forward Networks\\[\\begin{aligned}  \\text{FFN}\\left(\\mathcal{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathcal{H}^{(k)} + \\overrightarrow{\\mathbf{b}}^{(k)}_{1}\\right]\\right) + \\overrightarrow{\\mathbf{b}}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Sourse  https://wikidocs.net/184363"
  },
  
  {
    "title": "BERT",
    "url": "/posts/BERT/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Language Model, Attention Mechanism",
    "date": "2024-08-15 00:00:00 +0900",
    





    
    "snippet": "BERT      버트(Bidirectional Encoder Representations from Transformers; BERT) : 트랜스포머의 인코더 아키텍처를 기반으로 하여 위키피디아(25억 단어), BooksCorpus(8억 단어) 등 레이블 없는 텍스트 데이터로 사전 훈련된 대형 언어 모형(Pre-trained Large Language...",
    "content": "BERT      버트(Bidirectional Encoder Representations from Transformers; BERT) : 트랜스포머의 인코더 아키텍처를 기반으로 하여 위키피디아(25억 단어), BooksCorpus(8억 단어) 등 레이블 없는 텍스트 데이터로 사전 훈련된 대형 언어 모형(Pre-trained Large Language Model)            Version Comparison                                       BASE          LARGE                                      Embedding Dimension          768          1024                          Encoder Layers          12          24                          Attention Heads          12          16                          Total Parameter          110M          340M                    Word Representation      Unique(or Max) Number of Vector                            VECTOR          NUM                                      Unique Tokens          30,522                          Max Seq          512                          Max Sentence          2                          Each observation can contain up to two sequences          CLS my dog is cute SEP he likes play ##ing SEP              CLS : 입력 정보를 종합하여 대표하는 벡터      SEP : 문장 구분자        Tokenization Method : Word-Piece Encoding          단어 사전에 존재하는 단어들로 쪼개고, 이때 내부 단어(Sub-Word)는 앞에 ## 을 표기하여 온전한 단어가 아님을 나타냄      Here is the sentence I want embeddings for.      [here, is, the, sentence, i, want, em, ##bed, ##ding, ##s, for, .]            Embedding    \\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{i}  &amp;= \\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{TOKEN}} + \\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{POS}} + \\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{SEG}}  \\end{aligned}\\]                  \\(\\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{TOKEN}}\\) : Token Embedding                    \\(\\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{POS}}\\) : Position Embedding, Not Fixed But Learnable                    \\(\\overrightarrow{\\mathbf{x}}^{(i)}_{\\text{SEG}}\\) : Segment Embedding                                            Token              Segment Embedding                                                          CLS              First Sequence Vector                                      Tokens @ First Sequence              First Sequence Vector                                      SEP              First Sequence Vector                                      Tokens @ Second Sequence              Second Sequence Vector                                      SEP              Second Sequence Vector                                          Single Layer\\[\\begin{aligned}\\mathbf{X}^{(0)}&amp;=\\text{Embeddings}\\left(\\text{Tokens}\\right)\\\\\\mathbf{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right) + \\mathbf{X}^{(k)}\\Big]\\\\\\mathbf{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right) + \\mathbf{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathbf{X}$ is Input Data of Single Layer, $\\mathbf{Y}$ is Output Data of Single Layer          \\(\\mathbf{X}^{(k+1)}=\\mathbf{Y}^{(k)}\\) : Input Data of $k+1$ Encoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathbf{X}^{(0)}\\) is Sum of Token Embedding &amp; Position Embedding &amp; Segment Embedding Vector      Output Data of Final Layer \\(\\mathbf{Z}=\\mathbf{Y}^{(K)}\\) is Output of BERT Module            \\(\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right)\\) : Multi-Head Self Attention        \\(\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)\\) : Feed-Forward Networks\\[\\begin{aligned}  \\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathbf{H}^{(k)} + \\overrightarrow{\\mathbf{b}}^{(k)}_{1}\\right]\\right) + \\overrightarrow{\\mathbf{b}}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Pre-Training for Transfer Learning      MLM(Masked Language Model) : 입력 문장에서 일부는 MASK 로 가리고, 일부는 다른 단어로 무작위 변경한 후(10%), 원래 단어를 예측하도록 양방향 학습함으로써 일반화된 언어 패턴을 학습하고 문맥을 이해하는 능력을 강화함                      Bidirection : 트랜스포머 디코더가 단방향 예측($t-1$ 시점까지 정보를 기반으로 $t$ 시점을 예측)을 수행했던 것과 달리, 버트는 양방향 예측(이전 시점과 이후 시점의 정보를 종합하여 $t$ 시점을 예측)을 수행하므로, 문맥 벡터 생성 시 미래 순번 정보를 모두 마스킹 처리하지 않음                    How to Process Target                                            역할              처리 방법              비중                                                          CONTEXT              변경하지 않음              85%                                      PREDICTION              MASK              12%                                      PREDICTION              무작위 변경              1.5%                                      PREDICTION              변경하지 않음              1.5%                                                NSP(Next Sentence Prediction) : CLS 토큰을 기반으로 두 문장이 연속된 문장인지 아닌지 예측하도록 학습함으로써 문장 간 관계를 학습함      Sourse  https://pub.towardsai.net/demystifying-bert-efe9ac3c1c74  https://www.sbert.net/examples/unsupervised_learning/MLM/README.html  https://wikidocs.net/115055"
  },
  
  {
    "title": "ListMLE",
    "url": "/posts/ListMLE/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF, Ranking Prediction, Objective Function, Listwise Learning",
    "date": "2024-08-14 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Transformer",
    "url": "/posts/Transformer/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Machine Translation, Attention Mechanism",
    "date": "2024-08-14 00:00:00 +0900",
    





    
    "snippet": "Attention is all you need      트랜스포머(Transformer) : 시계열 데이터를 순차 입력 받는 RNN 계열 레이어를 배제하고 어텐션 메커니즘을 전적으로 활용하여 시계열 데이터의 병렬 처리를 도모하는 기계 번역 아키텍처        TOTAL ARCHITECTURE : SEQ2SEQ 의 ENCODER-DECODER 구조를 ...",
    "content": "Attention is all you need      트랜스포머(Transformer) : 시계열 데이터를 순차 입력 받는 RNN 계열 레이어를 배제하고 어텐션 메커니즘을 전적으로 활용하여 시계열 데이터의 병렬 처리를 도모하는 기계 번역 아키텍처        TOTAL ARCHITECTURE : SEQ2SEQ 의 ENCODER-DECODER 구조를 따름              ENCODER : Natural Language Understanding &amp; Feature Extraction      DECODER : Natural Language Generation            Transformer Application              BERT(Bidirectional Encoder Representations from Transformers) : LLM, Transformer Encoder Application      GPT(Generative Pre-Training) : GM, Transformer Decoder Application      Core Techs      Token Embedding : 입력 문장 내 단어들 각각의 정보를 표현하는 벡터를 생성함        Positional Encoding : 입력 문장 내 단어들의 위치 정보를 표현하는 벡터를 생성함        Multi-Head Self Attention @ Encoder : 인코더에서 입력 문장 내 단어들 간 관계를 학습하여 각 단어가 문장에서 어떤 역할을 하는지를 반영하는 문맥 벡터를 생성함        Multi-Head Masked Self Attention @ Decoder : 디코더에서 출력 문장 내 단어들 간 관계를 학습하여 각 단어의 문맥 벡터를 생성하되, 이전 순번까지의 단어만 참고하도록 마스킹하여 다음 순번에 관한 정보가 유출되는 것을 방지함        Multi-Head Cross Attention @ Decoder : 출력 문장의 각 단어가 인코더의 출력들과 맺는 관계를 학습하여 출력 문장 생성 시 개별 순번마다 입력 문장에서 어떤 부분이 중요한지 반영하는 문맥 벡터를 생성함  Positional EncodingCondition  주기성(Periodicity) : 벡터는 단어 간 상대적 위치를 표현할 수 있어야 함          단어의 절대적 위치가 아니라 단어 간 상대적 위치에 따른 관계 패턴이 문장의 의미를 결정함      어텐션 메커니즘은 각 단어가 서로를 참조하는 방식으로 정보를 처리함      주기성을 띠는 함수가 관계 패턴을 결정짓는 상대적 위치를 표현하기에 효율적임        연속성(Continuity) : 벡터는 연속적인 값을 가져야 함          임의의 두 단어 순번 간 거리가 일정하다면, 벡터 간 거리도 일정해야 함      임의의 두 단어 순번 간 위치가 비슷하다면, 벡터 값도 유사해야 함      불연속적인 값이 존재하면 모형이 상대적 위치에 따른 관계 패턴을 학습하기 어려움        일반화(Generalization) : 벡터는 특정 모형 구조나 훈련 데이터에 종속되지 않고, 모든 상황에서 일정한 방식으로 사용할 수 있어야 함          벡터는 모형 설계 방식과 상관없이 일정한 방식으로 위치 정보를 제공해야 함      벡터는 시퀀스 길이에 상관없이 일정한 정보 해상도를 가져야 함        단어 임베딩과의 균형(Balance with Word Embedding) : 벡터의 원소값은 단어의 의미 정보와 위치 정보가 균형을 이룰 수 있는 범위 내에 존재해야 함          원소값이 너무 크면 단어의 의미가 왜곡될 수 있음      원소값이 너무 작으면 위치 정보가 무시될 수 있음      Positional Encoding\\[\\begin{aligned}\\overrightarrow{\\mathbf{e}}_{\\text{POS}}&amp;=\\begin{pmatrix}\\sin{\\frac{POS}{10000^{0}}} \\\\\\cos{\\frac{POS}{10000^{0}}} \\\\\\sin{\\frac{POS}{10000^{2/8}}} \\\\\\cos{\\frac{POS}{10000^{2/8}}} \\\\\\sin{\\frac{POS}{10000^{4/8}}} \\\\\\cos{\\frac{POS}{10000^{4/8}}} \\\\\\sin{\\frac{POS}{10000^{6/8}}} \\\\\\cos{\\frac{POS}{10000^{6/8}}}\\end{pmatrix},\\quad \\text{where} \\quad d=8\\end{aligned}\\]      FUNCTION    \\[\\begin{aligned}  PE(POS,2i)&amp;=\\sin{\\frac{POS}{10000^{2i/d}}}\\\\  PE(POS,2i+1)&amp;=\\cos{\\frac{POS}{10000^{2i/d}}}  \\end{aligned}\\]          $POS$ : 문장 내 단어 순번      $d$ : 단어 임베딩 벡터 차원      $i=0,1,\\cdots,\\displaystyle\\frac{d}{2}-1$ : 포지셔널 인코딩 벡터의 차원 인덱스            PERIODICITY    \\[\\begin{aligned}  \\begin{pmatrix}\\sin{\\frac{POS+K}{10000^{2i/d}}} \\\\ \\cos{\\frac{POS+K}{10000^{2i/d}}}\\end{pmatrix}  = \\begin{pmatrix}\\cos{\\frac{K}{10000^{2i/d}}} &amp; \\sin{\\frac{K}{10000^{2i/d}}} \\\\ -\\sin{\\frac{K}{10000^{2i/d}}} &amp; \\cos{\\frac{K}{10000^{2i/d}}}\\end{pmatrix}  \\cdot \\begin{pmatrix}\\sin{\\frac{POS}{10000^{2i/d}}} \\\\ \\cos{\\frac{POS}{10000^{2i/d}}}\\end{pmatrix}  \\end{aligned}\\]          \\(\\displaystyle\\begin{pmatrix}\\cos{\\frac{K}{10000^{2i/d}}} &amp; \\sin{\\frac{K}{10000^{2i/d}}} \\\\ -\\sin{\\frac{K}{10000^{2i/d}}} &amp; \\cos{\\frac{K}{10000^{2i/d}}}\\end{pmatrix}\\) : $2 \\times 2$ Rotation Matrix      즉, 임베딩 차원 $d=2$ 일 때, 위치가 $K$ 만큼 이동하게 되면 벡터 공간 상에서 특정한 크기 \\(\\displaystyle\\frac{K}{10000^{2i/d}}\\) 만큼의 회전 변환이 이루어짐      요컨대 포지셔널 인코딩 벡터는 위치 간 관계(혹은 위치의 변화)를 부드러운(연속적인) 회전 변환 형태로 표현함      Single LayersEncoder Layer\\[\\begin{aligned}\\mathbf{X}^{(0)}&amp;=\\text{Token-Embedding}\\left(\\text{Tokens}\\right) + \\text{Positional-Encoding}\\left(\\text{Tokens}\\right)\\\\\\mathbf{H}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right) + \\mathbf{X}^{(k)}\\Big]\\\\\\mathbf{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right) + \\mathbf{H}^{(k)}\\Big]\\end{aligned}\\]  $\\mathbf{X}$ is Input Data of Single Layer, $\\mathbf{Y}$ is Output Data of Single Layer          \\(\\mathbf{X}^{(k+1)}=\\mathbf{Y}^{(k)}\\) : Input Data of $k+1$ Encoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathbf{X}^{(0)}\\) is Sum of Token Embedding &amp; Positional Encoding Vector      Output Data of Final Layer \\(\\mathbf{Z}=\\mathbf{Y}^{(K)}\\) is Output of Encoder Module            \\(\\text{Multi-Head}\\left(\\mathbf{X}^{(k)}\\right)\\) : Multi-Head Self Attention @ Encoder        \\(\\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)\\) : Feed-Forward Networks @ Encoder\\[\\begin{aligned}  \\text{FFN}\\left(\\mathbf{H}^{(k)}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathbf{H}^{(k)} + \\overrightarrow{\\mathbf{b}}^{(k)}_{1}\\right]\\right) + \\overrightarrow{\\mathbf{b}}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Decoder Layer\\[\\begin{aligned}\\mathcal{X}^{(0)}&amp;=\\text{Token-Embedding}\\left(\\text{Tokens}\\right) + \\text{Positional-Encoding}\\left(\\text{Tokens}\\right)\\\\\\mathcal{H}^{(k)}_{1}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right) + \\mathcal{X}^{(k)}\\Big]\\\\\\mathcal{H}^{(k)}_{2}&amp;=\\text{Layer-Norm}\\Big[\\text{Multi-Head}\\left(\\mathcal{H}^{(k)}_{1},\\mathbf{Z},\\mathbf{Z}\\right) + \\mathcal{H}^{(k)}_{1}\\Big]\\\\\\mathcal{Y}^{(k)}&amp;=\\text{Layer-Norm}\\Big[\\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right) + \\mathcal{H}^{(k)}_{2}\\Big]\\end{aligned}\\]  $\\mathcal{X}$ is Input Data of Single Layer, $\\mathcal{Y}$ is Output Data of Single Layer          \\(\\mathcal{X}^{(k+1)}=\\mathcal{Y}^{(k)}\\) : Input Data of $k+1$ Decoder Layer is Output Data of $k$      Input Data of Initial Layer \\(\\mathcal{X}^{(0)}\\) is Sum of Token Embedding &amp; Positional Encoding Vector      Output Data of Final Layer \\(\\mathcal{Z}=\\mathcal{Y}^{(K)}\\) is Output of Decoder Module            \\(\\text{Multi-Head}\\left(\\mathcal{X}^{(k)};\\mathcal{M}\\right)\\) : Multi-Head Masked Self Attention @ Decoder          $\\mathcal{M}$ : Causal Mask(Upper-triangular mask)            \\(\\text{Multi-Head}\\left(\\mathcal{H}^{(k)}_{1},\\mathbf{Z},\\mathbf{Z}\\right)\\) : Multi-Head Cross Attention @ Decoder          \\(\\mathbf{Z}\\) : Output of Encoder Module            \\(\\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right)\\) : Feed-Forward Networks @ Decoder\\[\\begin{aligned}  \\text{FFN}\\left(\\mathcal{H}^{(k)}_{2}\\right)  &amp;=\\mathbf{W}^{(k)}_{2} \\cdot \\left(\\text{ReLU}\\left[\\mathbf{W}^{(k)}_{1} \\cdot \\mathcal{H}^{(k)}_{2} + \\overrightarrow{\\mathbf{b}}^{(k)}_{1}\\right]\\right) + \\overrightarrow{\\mathbf{b}}^{(k)}_{2}  \\end{aligned}\\]          $\\mathbf{W}^{(k)}_{1} \\in \\mathbb{R}^{M \\times 4d}$ : Dimension Expansion to four times the Dimension of the Embedding Vector      $\\mathbf{W}^{(k)}_{2} \\in \\mathbb{R}^{M \\times d}$ : Dimension Reduction to Embedding Vector Dimension      Sourse  https://zeuskwon-ds.tistory.com/88  https://bongholee.com/transformer-yoyag-jeongri-2/  https://wikidocs.net/162096"
  },
  
  {
    "title": "Attention Mechanism",
    "url": "/posts/ATTN/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Machine Translation, Attention Mechanism",
    "date": "2024-08-13 00:00:00 +0900",
    





    
    "snippet": "Attention Mechanism  어텐션 메커니즘(Attention Mechanism) : 질의와 선택지가 주어진 상황에서, 특정 질의가 입력되었을 때 각 선택지가 해당 질의에 대한 대답으로서 출력되기에 적합한 정도를 계산해 가중치를 부여하고, 이를 기반으로 개별 질의에 특화된 문맥 정보를 생성하는 메커니즘          교차 어텐션(Cross ...",
    "content": "Attention Mechanism  어텐션 메커니즘(Attention Mechanism) : 질의와 선택지가 주어진 상황에서, 특정 질의가 입력되었을 때 각 선택지가 해당 질의에 대한 대답으로서 출력되기에 적합한 정도를 계산해 가중치를 부여하고, 이를 기반으로 개별 질의에 특화된 문맥 정보를 생성하는 메커니즘          교차 어텐션(Cross Attention) : 입력값과 반환할 값이 다른 경우      셀프 어텐션(Self Attention) : 입력값과 반환할 값이 같은 경우            Framework    \\[\\begin{aligned}  \\text{ATTN}\\left(\\mathcal{Q},\\mathcal{K},\\mathcal{V}\\right)  = \\text{Softmax}\\left[f(\\mathcal{Q},\\mathcal{K})\\right] \\cdot \\mathcal{V}  = \\mathcal{C}  \\end{aligned}\\]          INPUT                  \\(\\mathcal{Q} \\in \\mathbb{R}^{M \\times D}\\) : 입력값에 대하여 정보를 얻고자 하는 기준점으로서 질의(Query)          \\(\\mathcal{K} \\in \\mathbb{R}^{N \\times D}\\) : 질의와 매칭하여 관련성을 평가할 기준으로서 키(Key)          \\(\\mathcal{V} \\in \\mathbb{R}^{N \\times D_{V}}\\) : 관련성을 기반으로 반환할 값으로서 선택지(Value)                    OUTPUT                  \\(\\mathcal{A}=f(\\mathcal{Q},\\mathcal{K}) \\in \\mathbb{R}^{M \\times N}\\) : 질의와 키 간 유사도 행렬                          \\(\\alpha_{m,n} \\in \\mathcal{A}\\) : 어텐션 점수(Attention Score)                                \\(\\mathcal{W}=\\text{Softmax}\\left[\\mathcal{A}\\right] \\in \\mathbb{R}^{M \\times N}\\) : 유사도 정규화 행렬로서 어텐션 맵(Attention Map)                          \\(\\overrightarrow{\\omega} \\in \\mathcal{W}\\) : 어텐션 분포(Attention Distribution)              \\(\\omega_{m,n} \\in \\overrightarrow{\\omega} \\in \\mathcal{W}\\) : 어텐션 가중치(Attention Weight)                                \\(\\mathcal{C}=\\mathcal{W} \\cdot \\mathcal{V} \\in \\mathbb{R}^{M \\times D_{V}}\\) : 문맥 행렬(Context Matrix)                          \\(\\overrightarrow{\\sigma} \\in \\mathcal{C}\\) : 문맥 벡터(Context Vector)                                                Attention Score Function                            Name          Function          Defined by                                      Dot Product          \\(f(\\overrightarrow{\\mathbf{q}}, \\mathbf{K}) = \\overrightarrow{\\mathbf{q}} \\cdot \\mathbf{K}\\)          Luong et al. (2015)                          Learnable Weighted Attention          \\(f(\\overrightarrow{\\mathbf{q}}, \\mathbf{K}) = \\overrightarrow{\\mathbf{q}}^{T} \\cdot \\mathbf{W} \\cdot \\mathbf{K}\\)          Luong et al. (2015)                          Additive Attention          \\(f(\\overrightarrow{\\mathbf{q}}, \\mathbf{K}) = \\mathbf{W}^{T}_{A} \\cdot \\text{tanh}\\left[\\mathbf{W}_{B} \\cdot (\\overrightarrow{\\mathbf{q}} \\oplus \\mathbf{K})\\right]\\)          Bahdanau et al. (2015)                          Concatenation          \\(f(\\overrightarrow{\\mathbf{q}}, \\mathbf{K}) = \\mathbf{W}^{T}_{A} \\cdot \\text{tanh}\\left[\\mathbf{W}_{B} \\cdot \\overrightarrow{\\mathbf{q}} + \\mathbf{W}_{C} \\cdot \\mathbf{K}\\right]\\)          Bahdanau et al. (2015)                          Scaled Dot Product          \\(f(\\overrightarrow{\\mathbf{q}}, \\mathbf{K}) = \\displaystyle\\frac{\\overrightarrow{\\mathbf{q}}^{T} \\cdot \\mathbf{K}}{\\sqrt{n}}\\)          Vaswani et al. (2017)                    Adaptive Weight      적응형 가중치 할당(Adaptive Weight Allocation) : 표현력을 강화하기 위하여 학습 가능한 가중치 행렬 $\\mathbf{W}$ 을 활용하여 $\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$ 를 선형 변환하고, 이를 기반으로 유사도를 계산하여 입력 간 상호작용 정보를 동적으로 학습하는 기법                            WHAT          INPUT DATA          LEARNABLE WEIGHT          TOTAL                                      \\(\\mathcal{Q}\\)          \\(\\mathbf{Q} \\in \\mathbb{R}^{M \\times D_{Q}}\\)          \\(\\mathbf{W}_{Q} \\in \\mathbb{R}^{D_{Q} \\times D}\\)          \\(\\mathbf{Q} \\cdot \\mathbf{W}_{Q} \\in \\mathbb{R}^{M \\times D}\\)                          \\(\\mathcal{K}\\)          \\(\\mathbf{K} \\in \\mathbb{R}^{N \\times D_{K}}\\)          \\(\\mathbf{W}_{K} \\in \\mathbb{R}^{D_{K} \\times D}\\)          \\(\\mathbf{K} \\cdot \\mathbf{W}_{K} \\in \\mathbb{R}^{N \\times D}\\)                          \\(\\mathcal{V}\\)          \\(\\mathbf{V} \\in \\mathbb{R}^{N \\times D_{V}}\\)          \\(\\mathbf{W}_{V} \\in \\mathbb{R}^{D_{V} \\times D}\\)          \\(\\mathbf{V} \\cdot \\mathbf{W}_{V} \\in \\mathbb{R}^{N \\times D}\\)                          WHY? NECESSITY          $\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$ 간 차원 보정이 필요한 경우                  $\\mathcal{Q}$ 와 $\\mathcal{K}$ 가 서로 다른 특징 차원을 가지고 있는 경우($D_{Q} \\ne D_{K} \\ne D_{V}$)          $\\mathcal{Q}$ 와 $\\mathcal{K}$ 가 서로 같은 특징 차원을 공유하고 있으나 상황에 따라 유사도가 중요도에 작용하는 방향(선호/비선호)이 다를 경우                    상호작용 정보를 포착함에 있어서 유사도 이상의 복잡한 관계를 조명하고자 하는 경우                  셀프 어텐션에서, 입력값과 반환할 값은 동일하나 역할($\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$)에 따라 서로 다른 정보 처리를 수행해야 하는 경우          멀티 헤드 어텐션에서, 헤드마다 상호작용 정보를 다각도로 포착하고자 하는 경우                    Variations      멀티 헤드 어텐션(Multi-Head Attention) : 입력 데이터를 여러 독립적인 적응형 가중 어텐션 메커니즘(헤드)으로 병렬 처리하여, 데이터 간 관계와 패턴을 다각도로 학습하는 기법                      하나의 헤드는 독립적인 적응형 가중 어텐션으로 이루어짐\\[\\begin{aligned}  \\text{HEAD}^{(h)}  &amp;= \\text{ATTN}^{(h)}\\left(\\mathbf{Q} \\cdot \\mathbf{W}_{\\mathcal{Q}}^{(h)}, \\mathbf{K} \\cdot \\mathbf{W}_{\\mathcal{K}}^{(h)}, \\mathbf{V} \\cdot \\mathbf{W}_{\\mathcal{V}}^{(h)}\\right)  \\end{aligned}\\]                    멀티 헤드 어텐션의 결과값은 헤드별 결과값의 벡터 결합을 선형 변환한 값임\\[\\begin{aligned}  \\text{Multi-Head}\\left(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}\\right)  &amp;= \\left[\\cdots \\oplus \\text{HEAD}^{(h)} \\oplus \\cdots \\right] \\cdot \\mathbf{W}_{\\mathcal{O}}  \\end{aligned}\\]                  셀프 어텐션(Self-Attention) : 입력값과 반환할 값이 같은 경우로서, 통상 역할($\\mathcal{Q}, \\mathcal{K}, \\mathcal{V}$)에 따라 서로 다른 정보 처리를 수행하도록 적응형 가중 어텐션과 결합되어 활용됨    \\[\\begin{aligned}  \\mathcal{Q}=\\mathbf{X} \\cdot \\mathbf{W}^{(Q)}, \\quad \\mathcal{K}=\\mathbf{X} \\cdot \\mathbf{W}^{(K)}, \\quad \\mathcal{Q}=\\mathbf{V} \\cdot \\mathbf{W}^{(V)}  \\end{aligned}\\]        마스크 행렬(Mask Matrix) : 특정 위치에 대한 가중치를 차단하거나 조정함으로써 예측해야 하는 정보가 유출되거나 불필요한 정보가 참조되는 것을 방지함    \\[\\begin{aligned}  f\\left(\\mathcal{Q}_{M \\times D}, \\mathcal{K}_{N \\times D}\\right) + \\mathbf{M}_{M \\times N}  \\end{aligned}\\]          셀프 어텐션은 입력 데이터의 모든 위치가 서로 영향을 주고받는 구조이나, 시퀀스 생성 모형은 현재 순번 데이터로만 다음 순번을 예측해야 하므로, 미래 위치에 대한 주의 점수를 $-\\infty$ 로 처리하여 모형이 해당 정보를 참조하지 못하도록 강제함      Application to SEQ2SEQ      SEQ2SEQ 적용 목적 : RNN 계열 레이어의 초기 순번 정보 유실 문제 및 기울기 소실 문제를 보완하기 위함으로서, 문맥 벡터를 최종 은닉 상태로 획일화하여 사용하지 않고, 인코더 각 순번 은닉 상태와 디코더 현재 시점 간 관련성을 고려하여, 디코더의 각 시점에 특화된 문맥 벡터를 생성함        루옹 어텐션(Luong Attention) : 디코더의 현재 시점 은닉 상태를 활용하여 문맥 벡터를 생성하고, 이를 현재 시점 은닉 상태에 적용하는 어텐션 기법                      Attention Mechanism\\[\\overrightarrow{\\sigma}^{(t)}  = \\text{ATTN}\\left(\\eta_{t}, \\mathbf{H}, \\mathbf{H}\\right)\\]                  \\(\\mathcal{Q} = \\eta_{t}\\) : 디코더의 $t$ 시점 은닉 상태          \\(\\mathcal{K} = \\mathcal{V} = \\mathbf{H}\\) : 인코더의 각 순번 은닉 상태 행렬          \\(\\overrightarrow{\\sigma}^{(t)}\\) : 디코더의 $t$ 시점 문맥 벡터(Context Vector)                            Combining information on the context vector at $t$ and the hidden state at $t$\\[\\overrightarrow{\\mathbf{z}}_{t}  = \\text{F}_{\\text{tanh}}\\left[\\overrightarrow{\\sigma}^{(t)} \\oplus \\eta_{t}\\right]\\]                  바다나우 어텐션(Bahdanau Attention) : 디코더의 이전 시점 은닉 상태를 활용하여 문맥 벡터를 생성하고, 이를 현재 시점 입력값에 적용하는 어텐션 기법                      Attention Mechanism\\[\\overrightarrow{\\sigma}^{(t)}  = \\text{ATTN}\\left(\\eta_{t-1}, \\mathbf{H}, \\mathbf{H}\\right)\\]                  \\(\\mathcal{Q} = \\eta_{t-1}\\) : 디코더의 $t-1$ 시점 은닉 상태          \\(\\mathcal{K} = \\mathcal{V} = \\mathbf{H}\\) : 인코더의 각 순번 은닉 상태 행렬          \\(\\overrightarrow{\\sigma}^{(t)}\\) : 디코더의 $t$ 시점 문맥 벡터(Context Vector)                            Combining information on the context vector at $t$ and the input vector at $t$\\[\\overrightarrow{\\mathbf{z}}_{t}  = \\overrightarrow{\\sigma}^{(t)} \\oplus \\hat{\\mathbf{y}}_{t-1}\\]            Sourse  https://www.linkedin.com/pulse/what-self-attention-impact-large-language-models-llm-nikhil-goel-srpbc  https://newsletter.theaiedge.io/p/the-multi-head-attention-mechanism  https://krypticmouse.hashnode.dev/attention-is-all-you-need  https://wikidocs.net/22893  https://wikidocs.net/73161"
  },
  
  {
    "title": "SEQ2SEQ",
    "url": "/posts/SEQ2SEQ/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Machine Translation, Metric",
    "date": "2024-08-12 00:00:00 +0900",
    





    
    "snippet": "Machine Translation      기계 번역(Machine Translation) : 특정 언어로 표현된 텍스트를 다른 언어로 된 텍스트로 변환하는 과정              NLU(Natural Language Understanding) : 특정 언어로 된 텍스트를 이해하는 과정으로서, 해당 텍스트를 벡터 공간에 사상(Projection...",
    "content": "Machine Translation      기계 번역(Machine Translation) : 특정 언어로 표현된 텍스트를 다른 언어로 된 텍스트로 변환하는 과정              NLU(Natural Language Understanding) : 특정 언어로 된 텍스트를 이해하는 과정으로서, 해당 텍스트를 벡터 공간에 사상(Projection)하는 절차(Many to One)      NLG(Natural Language Generation) : 다른 언어로 된 텍스트를 생성하는 과정으로서, 사상된 벡터를 목표 언어로 변환하는 절차(Many to Many)            Brief History          RBMT(Rule-based Machine Translation) : 규칙 기반 기계 번역      SMT(Statistical Machine Translation) : 통계적 기계 번역      NMT(Neural Networks based Machine Translation) : 신경망 기반 기계 번역                  Word Embedding          End-to-End Model                    SEQ2SEQ      시퀀스 투 시퀀스(SEQ2SEQ) : RNN 계열 레이어 기반 기계 번역 알고리즘\\[\\begin{aligned}  P(y_{1}, y_{2}, \\cdots, y_{T^{\\prime}} \\mid x_{1}, x_{2}, \\cdots, x_{T})  = \\prod_{t=1}^{T^{\\prime}}{P(y_{t} \\mid z, y_{1}, y_{2}, \\cdots, y_{t-1})}  \\end{aligned}\\]        Architecture                      인코더(Encoder) : 입력 문장의 모든 단어들을 순차로 입력 받아 하나의 문맥 벡터(Context Vector)로 변환하는 모듈(NLU Process)\\[\\begin{aligned}  h_{t}, c_{t}  &amp;= \\text{LSTM}\\left[\\overrightarrow{\\mathbf{x}}_{t}, h_{t-1}, c_{t-1}\\right]  \\end{aligned}\\]                  \\(h_{t}\\) : $t$ 시점 은닉 상태          \\(c_{t}\\) : $t$ 시점 셀 상태          \\(\\overrightarrow{\\mathbf{x}}_{t}\\) : $t$ 번째 단어 임베딩 벡터          \\(\\overrightarrow{\\mathbf{z}}=h_{T}\\) : 마지막 시점 은닉 상태로서 문맥 벡터(Context Vector)                            디코더(Decoder) : 문맥 벡터를 참조하여 목표 언어의 단어들을 순차로 출력하는 모듈(NLG Process)\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\hat{\\mathbf{v}}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]                  \\(\\eta_{t}\\) : $t$ 시점 은닉 상태                          \\(\\eta_{0}=\\overrightarrow{\\mathbf{z}}\\) : 초기 은닉 상태는 문맥 벡터를 할당함                                \\(\\sigma_{t}\\) : $t$ 시점 셀 상태          \\(\\hat{\\mathbf{y}}_{t}=\\text{arg} \\max{\\text{F}_{\\text{Softmax}}\\left[\\eta_{t}\\right]}\\) : 목표 언어의 $t$ 시점에서 발생 확률이 가장 높은 단어의 임베딩 벡터                          \\(\\hat{\\mathbf{y}}_{0}\\) : 초기 입력값은 &lt;SOS&gt; 토큰을 활용함              \\(\\hat{\\mathbf{y}}_{T}\\) : 마지막 출력값은 &lt;EOS&gt; 토큰을 활용함                                                교사 강요(Teacher Forcing) : 디코더 학습 과정에서, 다음 시점의 입력으로서 이전 시점에서 생성한 출력값 대신 정답 시퀀스를 사용하는 기법                      Training Phase : 정답 시퀀스 \\(\\overrightarrow{\\mathbf{y}}_{t-1}\\) 를 입력값으로 사용함\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\overrightarrow{\\mathbf{y}}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]                    Inference Phase : 이전 시점에서 생성한 출력값 \\(\\hat{\\mathbf{y}}_{t-1}\\) 를 입력값으로 사용함\\[\\begin{aligned}  \\eta_{t}, \\sigma_{t}  &amp;= \\text{LSTM}\\left[\\hat{\\mathbf{y}}_{t-1}, \\eta_{t-1}, \\sigma_{t-1}\\right]  \\end{aligned}\\]            Metric      BLEU Score(Bi-Lingual Evaluation Understudy Score) : 기계 번역 및 자연어 생성에서 기계 번역 결과와 기준 텍스트 간의 유사성을 정량화하는 성능 평가 지표\\[\\begin{aligned}  \\text{BLEU}  &amp;= \\text{BP} \\cdot \\exp{\\left[\\sum_{n=1}^{N}{w_{n}\\cdot\\log{P_{n}}}\\right]}  \\end{aligned}\\]        $\\text{BP}$ : 길이 패널티(Brevity Penalty)로서, 생성된 문장(Hypothesis)이 참조 문장(Reference)보다 지나치게 짧을 경우 패널티를 부여함\\[\\begin{aligned}  \\text{BP}  = \\begin{cases}  1 \\quad &amp; h &gt; r\\\\  \\exp{\\left[1-\\displaystyle\\frac{r}{h}\\right]} \\quad &amp; h \\le r  \\end{cases}  \\end{aligned}\\]          $h$ : 생성된 문장(Hypothesis)의 길이      $r$ : 참조 문장(Reference)의 길이            $P_{n}$ : $n-\\text{gram}$ 정밀도로서, 생성된 문장(Hypothesis)과 참조 문장(Reference) 간 $n-\\text{gram}$ 중복 비율\\[\\begin{aligned}  P_{n}  &amp;= \\frac{\\sum_{n-\\text{gram} \\in \\text{Hypothesis}}{\\min{\\Big[\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram}), \\text{Count}_{\\text{Reference}}(n-\\text{gram})\\Big]}}}{\\sum_{n-\\text{gram} \\in \\text{Hypothesis}}{\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram})}}  \\end{aligned}\\]          Why not intersection?  생성된 문장을 기준으로(분모로) 하는 정밀도 특성 상, 참조 문장과의 교집합에 해당하는 특정 유니그램이 반복 생성되었을 때 성능이 과대평가되는 것을 방지하기 위하여 참조 문장에서 등장하는 최대 횟수까지만 매칭을 인정함              \\(\\text{Count}_{\\text{Hypothesis}}(n-\\text{gram})\\) : 생성된 문장(Hypothesis)의 유니그램 중 특정 $n-\\text{gram}$ 등장 횟수      \\(\\text{Count}_{\\text{Reference}}(n-\\text{gram})\\) : 참조 문장(Reference)의 유니그램 중 특정 $n-\\text{gram}$ 등장 횟수            \\(\\sum_{n=1}^{N}{w_{n}\\cdot\\log{P_{n}}}\\) : $n-\\text{gram}$ 정밀도 가중 평균          통상 가중치 $w_{n}$ 은 균등하게 분배함      Sourse  https://yjjo.tistory.com/35"
  },
  
  {
    "title": "Topic Model",
    "url": "/posts/Topic_Model/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Topic Model",
    "date": "2024-08-11 00:00:00 +0900",
    





    
    "snippet": "Topic Model  토픽 모형(Topic Model) : 관측 가능한 단어(Word) 및 문서(Document)로부터 말뭉치(Corpus)에 내재되어 있는(Latent) 토픽(Topic)을 탐색하는 방법          문서(Document)는 토픽(Topic)으로 어떻게 표현할 수 있을까?      단어(Word)는 토픽(Topic) 별로 어떻게...",
    "content": "Topic Model  토픽 모형(Topic Model) : 관측 가능한 단어(Word) 및 문서(Document)로부터 말뭉치(Corpus)에 내재되어 있는(Latent) 토픽(Topic)을 탐색하는 방법          문서(Document)는 토픽(Topic)으로 어떻게 표현할 수 있을까?      단어(Word)는 토픽(Topic) 별로 어떻게 등장하는가?      탐색된 Something(Topic)의 정체를 무엇이라 정의하면 좋을까?      LSA      잠재 의미 분석(Latent Semantic Analysis; LSA) : 특이값 분해(Singular Value Decomposition; SVD)를 활용하여 Document-Term Matrix 를 분해하는 방법\\[\\mathbb{A}_{n \\times d} \\approx \\mathbb{U}_{n \\times k} \\cdot \\Sigma_{k \\times k} \\cdot \\mathbb{V}^{T}_{d \\times k}\\]                            Dimension          Interpretation                                                 $n$          Number of Document                                     $d$          Number of Term                                     $k$          Number of Topic          Hyper-Parameter                            $\\mathbb{A}_{n \\times d}$ : Document-Term Matrix      \\(\\mathbb{U}_{n \\times k} \\cdot \\Sigma_{k \\times k}\\) : Document-Topic Matrix      $\\Sigma_{k \\times k} \\cdot \\mathbb{V}_{d \\times k}^{T}$ : Term-Topic Matrix      SVD      특이값 분해(Singular Value Decomposition; SVD) : 차원의 크기가 $n \\times d$ 인 임의의 행렬 $\\mathbb{A}$ 를 세 개의 행렬의 곱으로 분해하는 방법        $\\mathbb{U}_{n \\times k}$ : 직교 정규 행렬(Ortho-normal Matrix)                  열벡터 $\\overrightarrow{u}_{i} \\in \\mathbb{U}$ 는 행렬 $\\mathbb{A} \\cdot \\mathbb{A}^{T}$ 의 고유벡터(Eigen Vector)임\\[\\mathbb{A}\\mathbb{A}^{T} \\cdot \\overrightarrow{u}_i = \\lambda_i \\overrightarrow{u}_i\\]                    열벡터 $\\overrightarrow{u}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\overrightarrow{u}_{i} \\Vert = 1\\]                    열벡터 \\(\\overrightarrow{u}_{i}, \\overrightarrow{u}_{j}\\) 은 직교함\\[\\overrightarrow{u}_{i} \\perp \\overrightarrow{u}_{j} \\Leftrightarrow \\langle \\overrightarrow{u}_{i}, \\overrightarrow{u}_{j} \\rangle = 0\\]              $\\mathbb{V}_{d \\times k}^{T}$ : 직교 정규 행렬(Ortho-normal Matrix)                  열벡터 $\\overrightarrow{v}_{i} \\in \\mathbb{V}$ 는 행렬 $\\mathbb{A}^{T} \\cdot \\mathbb{A}$ 의 고유벡터(Eigen Vector)임\\[\\mathbb{A}^{T}\\mathbb{A} \\cdot \\overrightarrow{v}_i = \\lambda_i \\overrightarrow{v}_i\\]                    열벡터 $\\overrightarrow{v}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\overrightarrow{v}_{i} \\Vert = 1\\]                    열벡터 \\(\\overrightarrow{v}_{i}, \\overrightarrow{v}_{j}\\) 은 직교함\\[\\overrightarrow{v}_{i} \\perp \\overrightarrow{v}_{j} \\Leftrightarrow \\langle \\overrightarrow{v}_{i}, \\overrightarrow{v}_{j} \\rangle = 0\\]                  $\\Sigma_{k \\times k}$ : 대각 행렬(Diagonal Matrix)\\[\\Sigma_{k \\times k}  = \\begin{pmatrix}  \\sigma_{1} &amp; 0 &amp; \\cdots &amp; 0 \\\\  0 &amp; \\sigma_{2} &amp; \\cdots &amp; 0 \\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\  0 &amp; 0 &amp; \\cdots &amp; \\sigma_{k}  \\end{pmatrix}\\]                  대각항의 원소 $\\sigma_{i}$ 는 행렬 $\\mathbb{A} \\cdot \\mathbb{A}^{T}$ 혹은 $\\mathbb{A}^{T} \\cdot \\mathbb{A}$ 의 고유값(Eigen Value) $\\lambda_{i}$ 의 자승근임\\[\\sigma_{i} = \\sqrt{\\lambda_i}\\]            LDA      잠재 디리클레 할당(Latent Dirichlet Allocation; LDA) : 베이지안 프레임워크를 활용하여 문서에 내재된 잠재적인 토픽 구조를 탐색하는 방법\\[\\begin{aligned}  &amp;\\hat{\\theta}, \\hat{\\psi}\\\\  &amp;=\\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d \\mid z(d,n)) \\times P(\\psi_{z(d,n)} \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{\\underbrace{P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)}_{\\begin{array}{c} \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\begin{array}{c} \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}}}}  \\end{aligned}\\]          $P(\\theta_d \\mid z(d,n)) \\propto P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)$ : Posterior Probability of Document-Topic Allocation      $P(\\psi_{z(d,n)} \\mid w(d,n)) \\propto P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})$ : Posterior Probability of Topic-Word Allocation      Posterior Probability  각 문서는 여러 토픽의 혼합으로 구성되어 있고, 각 토픽은 특정 단어들의 혼합으로 구성되어 있다고 가정하자. 특정 문서를 구성하고 있는 단어들로부터, 해당 단어들을 발생시킨 토픽들의 비중을 추론할 수 있음.      문서 $d$ 에는 여러 토픽들이 담겨 있으며, 각 토픽 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} k \\mid \\theta_d &amp;\\sim \\text{Multinomial}(\\theta_{d})\\\\ \\theta_{d} &amp;\\sim \\text{Dirichlet}(\\alpha) \\end{aligned}\\]          $k \\mid \\theta_d$ : 문서 $d$ 에서 토픽 $k$ 가 발생할 확률      $\\theta_d$ : $d$ 번째 문서에서 각 토픽들이 발생할 확률            토픽 $k$ 에서는 여러 단어들이 발생할 수 있으며, 각 단어 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} w \\mid \\psi_{k} &amp;\\sim \\text{Multinomial}(\\psi_{k})\\\\ \\psi_{k} &amp;\\sim \\text{Dirichlet}(\\beta) \\end{aligned}\\]          $w \\mid \\psi_{k}$ : 토픽 $k$ 에서 단어 $w$ 가 발생할 확률      $\\psi_{k}$ : 토픽 $k$ 에서 각 단어들이 발생할 확률            따라서 단어 $w(d,n)$ 이 발생했을 때, $\\theta_d$ 및 $\\psi_{z(d,n)}$ 의 사후 확률 분포는 다음과 같음\\[\\begin{aligned} &amp;P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))\\\\ &amp;\\propto \\underbrace{P(\\theta_d \\mid z(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)} \\mid w(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}\\\\ &amp;\\propto \\left[\\underbrace{P(\\theta_d)}_{\\text{Prior}} \\cdot \\underbrace{P(z(d,n) \\mid \\theta_d)}_{\\text{Likelihood}}\\right] \\times \\left[\\underbrace{P(\\psi_{z(d,n)})}_{\\text{Prior}} \\cdot \\underbrace{P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\text{Likelihood}}\\right] \\end{aligned}\\]          $w(d,n)$ : 문서 $d$ 의 $n$ 번째 단어      $z(d,n)$ : 단어 $w(d,n)$ 에 대하여 해당 단어가 할당된 토픽      $\\theta_d$ : 문서 $d$ 의 토픽 분포      $\\psi_{z(d,n)}$ : 토픽 $z(d,n)$ 의 단어 분포      Sourse  https://intoli.com/blog/pca-and-svd/"
  },
  
  {
    "title": "Language Model",
    "url": "/posts/Langauge_Model/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Language Model, Metric",
    "date": "2024-08-10 00:00:00 +0900",
    





    
    "snippet": "Language Model  언어 모형(Language Model) : Word Sequence(문장)에 확률을 할당하여 가장 자연스러운 문장을 탐색하는 모형Statistical Language ModelSLM      SLM(Statistical Language Model) : 조건부 확률을 활용하여 Word Sequence 발생 확률을 부여하는 모...",
    "content": "Language Model  언어 모형(Language Model) : Word Sequence(문장)에 확률을 할당하여 가장 자연스러운 문장을 탐색하는 모형Statistical Language ModelSLM      SLM(Statistical Language Model) : 조건부 확률을 활용하여 Word Sequence 발생 확률을 부여하는 모형\\[\\begin{aligned}  P(W)  &amp;= P(w_1, w_2, \\cdots, w_n)\\\\  &amp;= \\cancel{P(w_1)} \\cdot \\frac{\\cancel{P(w_1,w_2)}}{\\cancel{P(w_1)}} \\cdot \\frac{\\cancel{P(w_1, w_2, w_3)}}{\\cancel{P(w_1, w_2)}} \\cdots \\frac{P(w_1, w_2, \\cdots, w_n)}{\\cancel{P(w_1, w_2, \\cdots, w_{n-1})}}\\\\  &amp;= P(w_1) \\cdot P(w_2 \\mid w_1) \\cdot P(w_3 \\mid w_1, w_2) \\cdots P(w_n \\mid w_1, w_2, \\cdots, w_{n-1})\\\\  &amp;= \\prod_{i=1}^{n}{P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]        확률 부여 방법\\[\\begin{aligned}  P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})  &amp;= \\frac{\\text{Count}(w_1, w_2, \\cdots, w_i)}{\\text{Count}(w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]          $\\text{Count}(w_1, w_2, \\cdots, w_i)$ : 말뭉치에서 Word Sequence $(w_1, w_2, \\cdots, w_i)$ 가 등장한 횟수      n-Gram      n-Gram : $i$ 번째 단어를 예측함에 있어 $N-1$ 개의 단어만을 활용하는 방법\\[\\begin{aligned}  P(W)  &amp;= \\prod_{i=1}^{n}{P(w_{i} \\mid w_{i-(n-1)}, w_{i-(n-2)}, \\cdots, w_{i-1})}  \\end{aligned}\\]        How to Select $n$ : 통상 $n \\le 5$ 권장                            Problem          Small $n$          Large $n$                                      Sparsity Problem          $\\downarrow$          $\\uparrow$                          Long-term Dependency          $\\uparrow$          $\\downarrow$                            희소성 문제(Sparsity Problem) : 충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제      장기 의존성 문제(Long-term Dependency) : 문맥 내에서 멀리 떨어져 있는 단어들 간의 관계를 처리하는 문제      Neural Networks based Langauge Model  통계적 방법론의 한계점과 그 대안          NNLM(Neural Networks Langauge Model) : 임베딩을 활용한 희소성 문제 보완      RNNLM(Recurrent Neural Networks Langauge Model) : RNN 계열 레이어를 활용한 장기 의존성 문제 보완            How to Generate a Context Vector for $w_{t+1}$              NNLM : $t$ 번째까지 등장한 단어 벡터들의 결합(Concatenation)으로 생성      RNNLM : $t$ 번째까지 등장한 단어 벡터들을 RNN 계열 레이어에 순차 입력하여 생성      NNLM  INPUT → PROJECTION          Projection : \\(\\overrightarrow{\\mathbf{w}}_{i} = \\overrightarrow{\\mathbf{x}}_{i} \\cdot \\mathbf{W}\\)      Concatenation : \\(\\overrightarrow{\\mathbf{z}}_{t} = \\overrightarrow{\\mathbf{w}}_{t-n+1} \\oplus \\overrightarrow{\\mathbf{w}}_{t-n+2} \\oplus \\cdots \\oplus \\overrightarrow{\\mathbf{w}}_{t}\\)            PRJECTION → HIDDEN\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}_{t}  &amp;= \\text{F}_{\\text{ReLU}}\\left[\\overrightarrow{\\mathbf{z}}_{t}\\right]  \\end{aligned}\\]        HIDDEN → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{t+1}  &amp;= \\text{F}_{\\text{Softmax}}\\left[\\overrightarrow{\\mathbf{h}}_{t}\\right]  \\end{aligned}\\]  RNNLM      INPUT → PROJECTION\\[\\overrightarrow{\\mathbf{w}}_{i}  = \\overrightarrow{\\mathbf{x}}_{i} \\cdot \\mathbf{W}\\]        PRJECTION → HIDDEN\\[\\begin{aligned}  h_{t}, c_{t}  &amp;= \\text{LSTM}\\left(\\overrightarrow{\\mathbf{w}}_{t}, h_{t-1}, c_{t-1}\\right)  \\end{aligned}\\]        HIDDEN → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{t+1}  &amp;= \\text{F}_{\\text{Softmax}}\\left[h_{t}\\right]  \\end{aligned}\\]  Metric      PPL(PerPLexity) : 언어 모형의 성능 평가 지표\\[\\begin{aligned}  PPL(W)  &amp;= P(W)^{-\\frac{1}{N}}\\\\  &amp;= P(w_1, w_2, \\cdots, w_N)^{-\\frac{1}{N}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{P(w_1, w_2, \\cdots, w_N)}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  \\end{aligned}\\]        해석 : 선택 가능한 경우의 수를 의미하는 분기 계수(Branching Factor)로서, 특정 시점마다 평균적으로 고민하는 선택지 수\\[\\begin{aligned}  PPL(W)  &amp;=10\\\\  \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  &amp;= 10\\\\  \\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}\\\\  \\underset{\\frac{1}{10}}{P(w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_2 \\mid w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_3 \\mid w_1, w_2)} \\cdots \\underset{\\frac{1}{10}}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Docs Representation",
    "url": "/posts/Docs_Representation/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Document Representation, Embedding",
    "date": "2024-08-09 00:00:00 +0900",
    





    
    "snippet": "Traditional Method      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법            DTM(Document Term Matrix) : 여러 개의 문서를 BoW 로 표현하는 방법            TF-IDF(Term Frequency-Inverse Document Frequency) : DTM 내 ...",
    "content": "Traditional Method      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법            DTM(Document Term Matrix) : 여러 개의 문서를 BoW 로 표현하는 방법            TF-IDF(Term Frequency-Inverse Document Frequency) : DTM 내 단어들에 대하여 각 단어의 중요도에 따라 가중치를 부여하여 표현하는 방법\\[\\text{TF-IDF}(d,t)=\\text{TF}(d,t) \\cdot \\text{IDF}(t)\\]                  TF(Term Frequency) : 문서 $d$ 에서 단어 $t$ 가 등장하는 횟수\\[\\text{TF}(d,t)\\]                    IDF(Inverse Document Frequency) : 단어 $t$ 가 등장하는 문서의 수에 반비례하는 수\\[\\text{IDF}(t)=\\ln{\\frac{n}{1+\\text{DF}(t)}}\\]                  $n$ : 문서의 수          $\\text{DF}(t)$ : 단어 $t$ 가 등장하는 문서의 수                    DOC2VEC      도큐먼트 투 벡터(DOC2VEC) : WORD2VEC 을 활용하여 문서의 밀집 표현을 학습하는 방법론            PV-DM(Paragraph Vector-Distributed Memory) : WORD2VEC 의 CBOW 와 유사한 학습 방법으로서, 도큐먼트 벡터와 주변 단어 벡터들이 주어졌을 때 발생 가능한 중심 단어 벡터를 추론하는 과정에서 도큐먼트 벡터 표현을 학습함\\[\\begin{aligned}  P\\left(w_{t} \\mid d, w_{t-\\omega}, \\cdots, w_{t-1}, w_{t+1}, \\cdots, w_{t+\\omega}\\right)  &amp;= \\text{Softmax}\\left(\\overrightarrow{\\mathbf{d}} + \\sum_{i \\in \\text{Context}}{\\overrightarrow{\\mathbf{w}}_{i}}\\right)  \\end{aligned}\\]        PV-DBOW(Paragraph Vector-Distributed Bag Of Words) : WORD2VEC 의 Skip-Gram 과 유사한 학습 방법으로서, 도큐먼트 벡터가 주어졌을 때 단어들의 발생 확률 분포 벡터를 추론하는 과정에서 도큐먼트 벡터 표현을 학습함\\[\\begin{aligned}  P\\left(\\cdots \\mid d\\right)  &amp;= \\text{Softmax}\\left(\\overrightarrow{\\mathbf{d}} \\cdot \\mathbf{W}\\right)  \\end{aligned}\\]  "
  },
  
  {
    "title": "WORD2VEC Improvements",
    "url": "/posts/WORD2VEC_Improvements/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Word Representation, Embedding",
    "date": "2024-08-08 00:00:00 +0900",
    





    
    "snippet": "Fast-Text      Fast-Text : 내부 단어(Sub-word)를 고려한 임베딩 학습 방법론          EAT vs. EATING              WORD2VEC 의 한계점 : 단어의 형태학적 특성을 고려하지 않으므로, 비슷한 문맥에서 사용되지 않았다면 동일한 어근에서 파생된 단어들의 의미상 유사도를 반영할 수 없음      ...",
    "content": "Fast-Text      Fast-Text : 내부 단어(Sub-word)를 고려한 임베딩 학습 방법론          EAT vs. EATING              WORD2VEC 의 한계점 : 단어의 형태학적 특성을 고려하지 않으므로, 비슷한 문맥에서 사용되지 않았다면 동일한 어근에서 파생된 단어들의 의미상 유사도를 반영할 수 없음      Fast-Text 의 해법 : 단어를 철자(Character) 단위의 n-gram 으로 간주하고, 단어 자체가 아니라 내부 단어들의 임베딩을 학습함                  통상 $3 \\le n \\le 6$ 으로 설정함                          EXAMPLE “eating”                      Character $n$-grams of eating                                            word              $n$              n-grams(sub-word)                                                          eating              3-gram              &lt;ea, eat, ati, tin, ing, ng&gt;                                      eating              4-gram              &lt;eat, eati, atin, ting, ing&gt;                                      eating              5-gram              &lt;eati, eatin, ating, ting&gt;                                      eating              6-gram              &lt;eatin, eating, ating&gt;                                      eating              Full              eating                                                  Embedding Vector of eating\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}  &amp;= \\text{Embedding}\\left(\\text{eating}\\right) + \\sum_{n}{\\text{Embedding}\\left(n\\text{-grams}\\right)}  \\end{aligned}\\]            GloVe  WORD2VEC, Fast-Text 의 한계점 : 말뭉치 내 Global Context 를 활용하지 못함Co-occurrence Matrix based Method      Co-occurrence Matrix : 말뭉치에서 각 단어가 윈도우 내에 다른 단어와 함께 등장하는 횟수를 측정한 행렬                            Counts          I          like          enjoy          deep          learning          NLP          flying          .                                      I          0                                                                                                       like                     0                                                                                            enjoy                                0                                                                                 deep                                           0                                                                      learning                                                      0                                                           NLP                                                                 0                                                flying                                                                            0                                     .                                                                                       0                            $X_{i,j} \\in \\mathbf{X}_{N \\times N}$ : $i$ 번째 단어를 중심으로 했을 때 윈도우 내에 $j$ 번째 단어가 등장한 횟수            PMI(Point Mutual Information) : 단순 횟수 측정 시 발생하는 고빈도 단어에 대한 잘못된 표현을 정정하기 위하여 고안된 측정 지표로서, 단어 $x$ 와 $y$ 가 동시에 발생할 확률을, 각각이 발생할 확률로 나눈 값\\[\\begin{aligned}  PMI(A,B)  &amp;= \\log{\\frac{P(A,B)}{P(A)P(B)}}\\\\  &amp;= \\log{N} + \\log{\\text{Count}(A,B)} - \\log{\\text{Count}(A)} - \\log{\\text{Count}(B)}  \\end{aligned}\\]        PPMI(Positive Point Mutual Information) : 두 단어의 동시 발생 횟수가 $0$ 일 때 발생하는 음의 무한대로의 발산 문제를 해결한 측정 지표\\[\\begin{aligned}  PPMI(A,B)  &amp;=\\max\\left(0, PMI(A,B)\\right)  \\end{aligned}\\]        SVD 를 활용하여 고차원 문제 보완    \\[\\begin{aligned}  \\mathbf{X}_{N \\times N}  \\approx \\underbrace{\\mathbf{U}_{N \\times N} \\cdot \\Sigma_{N \\times D}}_{\\text{Vector Representation}} \\cdot \\mathbf{V}^{T}_{N \\times D}  \\end{aligned}\\]  GloVe  Co-occurrence Matrix based Method 의 한계점          단어 간 유사도가 반영된 벡터 표현을 도출하지 못함      고차원 행렬이기 때문에 SVD 등 차원 축소 기법을 추가로 활용해야 함            GloVe(Global Vectors for Word Representation) : 단어 간 전역적 통계 정보를 활용하여 단어를 임베딩하는 방법론                      중심 단어 $i$ 와 주변 단어 $j$ 간 임베딩 벡터의 내적값이 동시 발생 확률이 되도록 학습함\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}   \\approx \\log{P(w_{j} \\mid w_{i})}  = \\log{\\frac{X_{i,j}}{\\sum_{k}{X_{i,k}}}}  \\end{aligned}\\]                  $\\overrightarrow{\\mathbf{w}}_{i} \\in \\mathbf{W}$ : 단어 $i$ 가 중심 단어일 때의 임베딩 벡터          $\\overrightarrow{\\mathbf{v}}_{j} \\in \\mathbf{V}$ : 단어 $j$ 가 주변 단어일 때의 임베딩 벡터          $P(w_{j} \\mid w_{i})$ : 중심 단어 $i$ 발생 조건부 $j$ 발생 확률          $\\log{P(w_{j} \\mid w_{i})}$ : 스케일 조정을 위하여 공동 발생 확률 자체가 아니라 공동 발생 확률의 로그값에 수렴하도록 학습함                            동시 발생 확률 $P(w_{j} \\mid w_{i})$ 대신 동시 발생 횟수 $X_{i,j}$ 를 활용함\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}   \\approx \\log{X_{i,j}}  \\end{aligned}\\]                  내적 값과 확률 값의 직접 대응이 어렵기 때문임($\\because \\sum_{j}{P(w_{j} \\mid w_{i})}=1$)                          Loss Function\\[\\begin{aligned}  \\mathcal{L}  &amp;= \\sum_{i,j}{f(X_{i,j})\\left(\\overrightarrow{\\mathbf{w}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j} + (b_{i} + \\beta_{j}) - \\log{X_{i,j}}\\right)^{2}}  \\end{aligned}\\]          \\(f(X_{i,j})=\\min{\\left[1, \\left(\\displaystyle\\frac{X_{i,j}}{X_{\\text{max}}}\\right)^{3/4}\\right]}\\) : 학습 중 고빈도 단어 영향력 조정 함수      ELMo      FFNN 에 기반한 기존 방법론의 한계점 : 문장 전체의 문맥을 반영하지 못하여 동의어, 다형어에 대한 표현이 제대로 이루어지지 못함        ELMo(Embeddings from Language Model) : 방대한 텍스트 데이터로 사전 훈련된 LSTM 기반 언어 모형 BiLM 을 활용하는 단어 임베딩 방법론            BiLM(Bidirectional Language Model) : 문장 시퀀스를 순방향, 역방향으로 각각 학습하는 LSTM 기반 언어 모형            Forward Path                      Multi-Layer LSTM\\[\\begin{aligned} h^{(k)}_{t}, c^{(k)}_{t} &amp;= \\text{LSTM}^{(k)}\\left(h^{(k-1)}_{t}, h^{(k)}_{t-1}, c^{(k)}_{t-1}\\right) \\end{aligned}\\]                  $h^{(k)}_{t}$ : $k$ 번째 LSTM Layer 의 $t$ 시점 은닉 값                          첫 번째 LSTM Layer 의 $t$ 시점 입력값 \\(h^{(0)}_{t}\\) 은 $t$ 시점 단어 $w_{t}$ 의 임베딩 벡터임                                $c^{(k)}_{t}$ : $k$ 번째 LSTM Layer 의 $t$ 시점 셀 상태 값                            Output Layer\\[\\begin{aligned} \\hat{\\mathbf{y}} &amp;= \\text{F}_{\\text{Softmax}}\\left[h^{(K)}_{T}\\right] \\end{aligned}\\]                  ELMo Representation    \\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}_{t}  &amp;= \\sum_{k}{\\gamma^{(k)}\\left(h^{(k)}_{t} \\oplus \\eta^{(k)}_{t}\\right)}  \\end{aligned}\\]  Sourse  https://intoli.com/blog/pca-and-svd/  https://github.com/dvgodoy/dl-visuals/  https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782  https://wikidocs.net/33930"
  },
  
  {
    "title": "Word Representation",
    "url": "/posts/Word_Representation/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP, Word Representation, Embedding",
    "date": "2024-08-07 00:00:00 +0900",
    





    
    "snippet": "Representation MethodsSparse Representation      희소 표현(Sparse Representation) : 하나의 단어를 하나의 차원으로 하는 $n$ 차원 공간에 단어를 표현하는 방법    \\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &a...",
    "content": "Representation MethodsSparse Representation      희소 표현(Sparse Representation) : 하나의 단어를 하나의 차원으로 하는 $n$ 차원 공간에 단어를 표현하는 방법    \\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots \\end{pmatrix}\\\\  \\text{Puppy}&amp;=\\begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\cdots \\end{pmatrix}  \\end{aligned}\\]          Dimensionality Curse Problem in Sparse Vector      Semantic/Structural Disjointness Problem      Dense Representation      단어 임베딩(Word Embedding) : 희소 표현의 한계점을 보완한 방법으로서, 분포 가설에 근거하여 단어를 밀집된 형태로 표현하는 방법          Embedding  An embedding is a mapping of a discrete - categorical - variable to a vector of continuous numbers.  In the context of machine learning, an embedding is a low-dimensional, learned continuous vector representation of discrete variables into which you can translate high-dimensional vectors.            밀집 표현(Dense Representation) : 연구자가 설정한 $k \\le n$ 차원 공간에 단어를 표현하는 방법\\[\\begin{aligned}  \\text{Dog}&amp;=\\begin{pmatrix} 0.1 &amp; 0.3 &amp; -0.2 \\end{pmatrix}\\\\  \\text{Puppy}&amp;=\\begin{pmatrix} 0.1 &amp; 0.3 &amp; -0.3 \\end{pmatrix}  \\end{aligned}\\]        분산 표현(Distributed Representation) : 분포 가설에 근거하여 단어의 의미 를 다차원 공간에 표현하는 방법                  분포 가설(Distributional Hypothesis) : 비슷한 문맥에서 등장하는, 다시 말해 비슷하게 분포되어 있는 단어들은 비슷한 의미를 가짐\\[\\begin{aligned}  &amp;\\text{My dog is cute. Sometimes my dog braks at me.}\\\\  &amp;\\text{My puppy is cute. Sometimes my puppy braks at me.}  \\end{aligned}\\]            WORD2VEC  워드 투 벡터(WORD2VEC) : 단어 임베딩 학습 방법론          CBOW(Continuous Bag of Words) : 주변 단어들로부터 중심 단어를 예측하는 과정에서 단어의 벡터 표현을 학습하는 방법론      Skip-Gram : 중심 단어로부터 주변 단어들을 예측하는 과정에서 단어의 벡터 표현을 학습하는 방법론      SGNS(Skip-Gram with Negative Sampling) : Skip-Gram 에 Negative Sampling 을 적용함으로써 단어 예측 문제의 유형을 전환하는 방법론                  Skip-Gram : 중심 단어가 등장했을 때 전체 단어가 발생할 확률 분포 학습 문제          SGNS : 중심 단어가 등장했을 때 특정 주변 단어 발생 여부 판별 문제                          EXAMPLE “The fat cat sat on the mat” (Where Window Size is 2)        Annotation          $\\omega$ : Context Window Size      $i$ : Target Word      $j = 1,2,\\cdots,\\omega,\\cdots,2\\omega$ : Context Words      $N$ : Number of Words      $D$ : Embedding Size      $\\mathbf{X} \\in \\mathbb{R}^{N \\times N}$ : One-Hot Encoded Matrix      $\\mathbf{W} \\in \\mathbb{R}^{N \\times D}$ : Embedding Matrix      CBOW      INPUT → PROJECTION\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{i}  &amp;= \\frac{1}{2 \\omega} \\sum_{j}{\\overrightarrow{\\mathbf{x}}_{j} \\cdot \\mathbf{W}}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{w}}_{j} = \\overrightarrow{\\mathbf{x}}_{j} \\cdot \\mathbf{W} \\in \\mathbb{R}^{D}\\) : Embedding Vector of Context Word $j$            PROJECTION → OUTPUT\\[\\begin{aligned}  \\hat{\\mathbf{x}}_{i}  &amp;= \\text{Softmax}\\left[\\overrightarrow{\\mathbf{z}}_{i} \\cdot \\mathbf{W}^{T}\\right]  \\end{aligned}\\]        Optimization\\[\\begin{aligned}  \\hat{\\mathbf{W}}  &amp;= \\text{arg} \\min{\\sum_{i}{\\text{Cross-Entropy}\\left[\\overrightarrow{\\mathbf{x}}_{i}, \\hat{\\mathbf{x}}_{i}\\right]}}  \\end{aligned}\\]  Skip-Gram      INPUT → PROJECTION\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}_{i}  &amp;=\\overrightarrow{\\mathbf{x}}_{i} \\cdot \\mathbf{W}  \\end{aligned}\\]        PROJECTION → OUTPUT\\[\\begin{aligned}  \\overrightarrow{\\mathbf{y}}_{i}  &amp;= \\text{Softmax}\\left[\\overrightarrow{\\mathbf{w}}_{i} \\cdot \\mathbf{W}^{T}\\right]  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{y}}_{i} \\in \\mathbb{R}^{N}\\) : Context Probability Distribution Vector for Target Word $i$            Optimization\\[\\begin{aligned}  \\hat{\\mathbf{W}}  &amp;= \\text{arg} \\min{\\sum_{i,j}{\\text{Cross-Entropy}\\left[\\overrightarrow{\\mathbf{x}}_{j}, \\overrightarrow{\\mathbf{y}}_{i}\\right]}}  \\end{aligned}\\]  SGNS      이진 분류 문제로 전환하기 위한 입력과 레이블 변화            Negative Sampling                      $k$ 번째 단어가 샘플링될 확률\\[\\begin{aligned}  P\\left(w_{k} \\mid \\alpha \\right)  &amp;= \\frac{f\\left(w_{k}\\right)^{\\alpha}}{\\sum_{l=1}^{N}{f\\left(w_{l}\\right)^{\\alpha}}}  \\end{aligned}\\]                  $\\alpha=0.75$ : 샘플링 확률 조정 파라미터로서 고빈도 단어가 샘플링될 확률을 할인함          $f\\left(w_{k}\\right)$ : 통상 단어 빈도수로 설정함                          Optimization    \\[\\begin{aligned}  \\hat{\\mathbf{W}}, \\hat{\\mathbf{V}}  &amp;= \\text{arg} \\min{-\\sum_{i,j}{y_{i,j} \\log{\\sigma\\left[\\mathbf{W}_{i} \\cdot \\mathbf{V}_{j}\\right]} + \\left(1-y_{i,j}\\right) \\log{\\sigma\\left[-\\mathbf{W}_{i} \\cdot \\mathbf{V}_{j}\\right]}}}  \\end{aligned}\\]          $\\mathbf{W} \\in \\mathbb{R}^{N \\times D}$ : Target Embedding Matrix      $\\mathbf{V} \\in \\mathbb{R}^{N \\times D}$ : Target Embedding Matrix      $\\sigma\\left[\\cdot\\right]$ : Sigmoid Function            What? Final Embedding Matrix          Target Embedding Matrix $\\mathbf{W}$      Concatenation $\\mathbf{W} \\oplus \\mathbf{V}$      Mean, Plus, etc.      Sourse  https://velog.io/@growthmindset/%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9One-Hot-Encoding  https://wikidocs.net/22660  https://wikidocs.net/69141"
  },
  
  {
    "title": "Text Data Preprocessing",
    "url": "/posts/Text_Data_Preprocessing/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP",
    "date": "2024-08-06 00:00:00 +0900",
    





    
    "snippet": "Text Analytics      텍스트 애널리틱스(Text Analytics) : 텍스트로부터 정보를 추출하는 과정          Text mining, text data mining(TDM) or text analytics is the process of deriving high-quality information from text. It in...",
    "content": "Text Analytics      텍스트 애널리틱스(Text Analytics) : 텍스트로부터 정보를 추출하는 과정          Text mining, text data mining(TDM) or text analytics is the process of deriving high-quality information from text. It involves “the discovery by computer of new, previously unknown information, by automatically extracting inofrmation from different written resources. (Wikipedia)            사례                                       규칙 기반 방법론          통계적 방법론          신경망 기반 방법론          RNN          Attention                                      단어 표현          One-Hot Encoding          -          Word2Vec          ELMo          -                          문서 표현          DTM          -          Doc2Vec          -          -                          언어 모형          -          SLM          NNLM          RNNLM          BERT                          토픽 모형          -          LSA, LDA          -          -          BERTopic                          기계 번역          RBMT          SMT          -          SEQ2SEQ          Transformer                          생성 모형          -          -          -          -          GPT                    Process      문제 정의(Problem Definition)          어떤 문제를 해결할 것인가? 이를 위해 필요한 데이터는 무엇인가?        텍스트 데이터 획득(Text Data Collection)          크롤링(Crawling)      스크래이핑(Scraping) 등        텍스트 데이터 전처리(Text Data Preprocessing) : 자연어를 특정 단위로 분할하고, 유용하지 않은 데이터를 제거하고, 동일한 의미를 가진 데이터를 획일화하는 작업          토큰화(Tokenization)      정제(Cleansing)      정규화(Normalization) 등        벡터 표현(Vector Representation) : 자연어를 컴퓨터가 이해할 수 있는 형식으로 표현하는 작업          원-핫 인코딩(One-Hot Encoding)      워드 투 벡터(Word2Vec) 등        모델링(Modeling)          Summarization      Visualization      Topic Model      Docs Classification      Docs Clustering      NLU(Natural Language Understanding)      NLG(Natural Language Generation)      Text Data Preprocessing  순서          토큰화(Tokenization)      정제(Cleansing)      정규화(Normalization)      Tokenization  자연어(Natural Language) : 사람들이 일상적으로 쓰는 언어를 인공적인 언어인 인공어와 구분하여 부르는 개념(Wikipedia)          형태상으로는 문자(Character)로, 의미상으로는 단어(Word)로 구성된 시계열 데이터(Sequence Data)      자연어를 컴퓨터가 이해할 수 있는 형식으로 변환함에 있어, 그 의미가 반영될 수 있어야 함        토큰화(Tokenization) : 주어진 말뭉치를 토큰 단위로 나누는 작업          말뭉치(Corpus) : 자연어 처리 목적으로 수집된 텍스트 데이터      토큰(Token) : 문장이나 단어 등 의미의 최소 단위        POS(Part of Speech) Tagging : (특히 동음이의어를 구분하기 위하여) 토큰에 그 앞, 뒤 문맥상 적합한 품사를 태깅하는 작업Cleansing  정제(Cleansing) : 말뭉치에서 노이즈를 제거하는 작업          등장 빈도가 적은 토큰 제거      (특히 영어에서) 길이가 짧은 토큰 제거      불용어(Stopwords) 제거      오탈자, 띄어쓰기 교정 등      Normalization      정규화(Normalization) : 다른 형태를 취하나 의미가 같은 단어들을 하나로 통합하여 동일한 표현으로 만드는 작업    표제어 추출(Lemmatization) : 대상 토큰의 품사에 알맞은 표제어를 추출하는 행위          표제어(Lemma) : 기본 사전형 단어        어간 추출(Stemming) : 단어의 변형된 형태를 제거하거나 치환하여 어간을 추출하는 행위로서, 형태학적 파싱보다는 정해진 규칙에 따라 접사를 잘라내는 작업에 가까움          형태학(Morphology) : 형태소로부터 단어가 형성되는 과정을 분석하는 학문      형태소(Morpheme) : 의미가 있는, 가장 작은 말의 단위                  어간(Stem) : 단어의 의미를 담고 있는 부분          접사(Affix) : 단어에 추가적인 의미를 부여하는 부분                    Agglutinative Language      교착어(Agglutinative Language) : 한국어 등 어간에 문법적으로 기능하는 형태소가 결합하여 문법적 기능이 부여되는 언어    자립형태소 : 자립하여 사용할 수 있는 형태소          체언(명사, 대명사, 수사)      수식언(관형사, 부사)      감탄사 등        의존형태소 : 다른 형태소와 결합하여 사용되는 형태소          어미 : 동사, 형용사의 어간에 결합하여 문법적 기능을 부여하는 형태소      조사 : 체언에 결합하여 문법적 기능을 부여하는 형태소      "
  },
  
  {
    "title": "Regular Expression",
    "url": "/posts/Regular-Expression/",
    "categories": "DATA MINING TECHS, 5.text analytics",
    "tags": "AI Application, NLP",
    "date": "2024-08-05 00:00:00 +0900",
    





    
    "snippet": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                   ...",
    "content": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                      .          개행 문자(\\n) 를 제외하고 공백을 포함한 모든 문자                          \\s          탭(\\t), 개행 문자(\\n)                          \\d          숫자                          \\D          \\d 의 검사 범위를 제외한 모든 문자                          \\w          알파벳 대소문자와 언더바(_)                          \\W          \\w 의 검사 범위를 제외한 모든 문자                          검사 범위 수동 지정                            패턴          설명                                      [xyz]          x, y, z 중 하나                          [^xyz]          x, y, z 를 제외한 모든 문자 중 하나                          (xyz)          xyz 매칭                          (?:xyz)          xyz 매칭                          x|yz          x 또는 yz                          검사 위치 지정                            패턴          설명                                      ^          첫 번째 줄의 시작                          $          마지막 줄의 끝                          \\b          경계 문자                          \\B          경계 문자                          (?=)          긍정형 전방 탐색                          (?!)          부정형 전방 탐색                          (?&lt;=)          긍정형 후방 탐색                          (?&lt;!)          부정형 후방 탐색                          수량 지정                            패턴          설명                                      *          $0$ 개 이상                          +          $1$ 개 이상                          ?          $0$ 또는 $1$                          {n}          $n$ 개                          {n,}          $n$ 개 이상                          {,n}          $n$ 개 이하                          {m,n}          $m$ 개 이상 $n$ 개 이하                    Python Package re      re.compile(pattern)      import re  pattern = ...  p = re.compile(pattern, option)              option                  None          re.DOTALL : 개행 문자(\\n)를 무시하고 매칭함          re.IGNORECASE : 대소문자 구분 없이 매칭함          re.MULTILINE : 문자열의 각 줄마다 매칭함                          p.match(my_str) : 문자열 처음부터 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.match(my_str)              result.group() : 매칭된 문자열을 반환함      result.start() : 매칭된 문자열의 시작 위치를 반환함      result.end() : 매칭된 문자열의 끝 위치를 반환함      result.span() : 매칭된 문자열의 (시작 위치, 끝 위치) 를 튜플로 반환함            p.search(my_str) : 문자열 전체를 탐색하여 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.search(my_str)            p.findall(my_str) : 정규표현식과 매칭되는 모든 문자열을 반환함      my_str = ...  result = p.findall(my_str)            p.finditer(my_str) : 정규표현식과 매칭되는 모든 문자열을 반복 가능한 객체(iterator)로 반환함      my_str = ...  result = p.finditer(my_str)            p.sub(re_str, my_str) : 정규표현식과 매칭되는 모든 문자열을 다른 문자열로 수정함      my_str = ...  re_str = ...  result = p.sub(re_str, my_str)      Matching Rule of PythonForward Orderpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            1efG 매칭            추가 매칭되는 문자열 없음      Excluding the Prior Matchedpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efCefGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            먼저 매칭된 문자열을 제외하고 탐색하므로 CefG 는 포함되지 않음      Greedypattern = '[a-zA-Z0-9]+ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      If Python is not Greedy            But Python is Greedy      Exploration      긍정형 전방 탐색 B(?=A) : Pattern A 의 시작점 이전 지점에서 Pattern B 를 탐색함      pattern = '[a-zA-Z0-9]+(?=efg)'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                긍정형 후방 탐색 (?&lt;=A)B : Pattern A 의 끝점 이후 지점에서 Pattern B 를 탐색함      pattern = '(?&lt;=efg)[a-zA-Z0-9]+'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                부정형 전방 탐색 B(?!A) : Pattern A 의 시작점을 제외한 지점에서 Pattern B 를 탐색함      pattern = '[a-zA-Z0-9]+(?!efg)'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)                부정형 후방 탐색 (?&lt;!A)B : Pattern A 의 끝점을 제외한 지점에서 Pattern B 를 탐색함      pattern = '(?&lt;!efg)[a-zA-Z0-9]+'  p = re.complile(pattern)  my_str = \"ABCDefgHIJefgK\"  results = p.finditer(my_str)  for result in results:      print(result)          Sourse  https://zephyrus1111.tistory.com/310"
  },
  
  {
    "title": "Gaussian Process",
    "url": "/posts/GP/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, Stochastic Process, Nonparametric Estimation, Gaussian Process",
    "date": "2024-08-01 00:00:00 +0900",
    





    
    "snippet": "Stochastic Process      확률적 과정(Stochastic Process)          어떤 시점 혹은 위치 지표 $t$ 에 대하여 확률변수들의 집합 \\(\\{X_{t} \\mid t \\in T\\}\\) 이 주어졌을 때 이를 확률적 과정이라고 한다. 즉, 확률적 과정은 시간 또는 공간을 따라 변화하는 확률변수들의 집합으로서, 특정한 시점...",
    "content": "Stochastic Process      확률적 과정(Stochastic Process)          어떤 시점 혹은 위치 지표 $t$ 에 대하여 확률변수들의 집합 \\(\\{X_{t} \\mid t \\in T\\}\\) 이 주어졌을 때 이를 확률적 과정이라고 한다. 즉, 확률적 과정은 시간 또는 공간을 따라 변화하는 확률변수들의 집합으로서, 특정한 시점 또는 위치에서 확률변수가 결정된다. 이때 시간 또는 공간을 따라 확률변수가 변하는 양상은 특정한 확률적 패턴을 가질 수 있다.            Stochastic Patterns                  독립 확률 과정(Independent Stochastic Process) : 각 포인트에서의 확률변수 $X_{t}$ 가 서로 독립인 확률 과정\\[\\begin{aligned}  P\\left(X_{t} \\mid X_{t-1}, X_{t-2}, \\cdots, X_{0}\\right) = P\\left(X_{t}\\right)  \\end{aligned}\\]                    마코프 과정(Markov Process) : 현재 상태 $X_{t}$ 가 주어졌을 때, 미래 상태 $X_{t+1}$ 는 과거 상태들과 독립이고 오직 현재 상태에만 의존하는 과정\\[\\begin{aligned}  P\\left(X_{t+1} \\mid X_{t}, X_{t-1}, X_{t-2}, \\cdots, X_{0}\\right) = P\\left(X_{t+1} \\mid X_{t}\\right)  \\end{aligned}\\]                    정상 과정(Stationary Process) : 시간 혹은 공간에 따라 확률적으로 변화하는 패턴이 일정한 성질을 유지하는 과정\\[\\begin{aligned}  X_{t} = \\alpha \\cdot X_{t-1} + \\epsilon_{t}, \\quad \\epsilon_{t} \\sim \\mathcal{N}\\left(0, \\sigma^{2}\\right)  \\end{aligned}\\]                              확률변수 \\(X_{t}\\) 의 기대값이 일정함\\[\\text{E}\\left[X_{t^{\\forall}}\\right]=\\mu\\]                                확률변수 \\(X_{t}\\) 의 변동성이 일정함\\[\\text{Var}\\left[X_{t^{\\forall}}\\right]=\\text{E}\\left[\\left(X_{t^{\\forall}}-\\mu\\right)\\right]=\\sigma^{2}\\]                                $X_{t}$ 와 $X_{t+h}$ 의 관계가 시점 $t$ 자체가 아니라 시간 차이 $h$ 에만 의존함\\[\\text{Cov}\\left[X_{t},X_{t+h}\\right]=\\text{E}\\left[\\left(X_{t}-\\mu\\right)\\left(X_{t+h}-\\mu\\right)\\right]=\\gamma\\left(h\\right)\\]                              Non-Parametric Density EstimationNon-Parametric Method      밀도(Density) : 데이터가 특정 구간에 존재할 확률        모수 추정(Parametric Estimation) : 데이터가 모수로써 정의되는 특정한 형태로 분포되었다고 가정하고, 소수의 모수를 추정함으로써 데이터 분포를 추정하는 방법                  EXAMPLE Probability Density Estimation  확률변수 $X$ 는 평균을 $\\mu$, 분산을 $\\sigma^{2}$ 으로 하는 가우시안 분포에 따라 분포되어 있음\\[\\begin{aligned}  X \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}\\right)  \\end{aligned}\\]                    EXAMPLE Regression Analysis  한국인 남성의 키($Y$)는 몸무게($X$)와 선형 관계에 있음\\[\\begin{aligned}  Y = \\alpha \\cdot X + \\beta  \\end{aligned}\\]                  비모수 추정(Non-Parametric Estimation) : 데이터가 특정한 형태로 분포되었다고 가정하지 않고, 주어진 데이터를 토대로 직접 추정하는 방법          Histogram Density Estimation      Kernel Density Estimation      k-Nearest Neighbors Density Estimation      Maximum Entropy Density Estimation      Regression-Based Density Estimation      KDE      커널 밀도 추정(Kernel Density Estimation; KDE) : 각 데이터 주변에서 작은 확률 분포(Kernel)를 만든 후, 이를 합산하여 전체 밀도를 추정하는 방법            확률 밀도 함수(Probability Density Function)\\[\\begin{aligned}  f(x)  &amp;= \\frac{1}{h} \\cdot \\frac{1}{n} \\cdot \\sum_{i=1}^{n}{\\mathcal{K}\\left(\\frac{x-x_{i}}{h}\\right)}  \\end{aligned}\\]          $n$ : 데이터 포인트 갯수      $x_{i}$ : 개별 데이터 포인트      $h$ : 밴드위스(Bandwidth)      $\\mathcal{K}\\left(\\cdot\\right)$ : 커널 함수(Kernel Function)            밴드위스(Bandwidth) : 커널의 너비를 조절하는 하이퍼파라미터로서, 값이 클수록 전역적 패턴을, 작을수록 국소적 패턴을 포착함            커널 함수(Kernel Function) : 특정 데이터 포인트 주변의 밀도를 조절하는 함수                            Name          Function                                      Gaussian          \\(\\mathcal{K}(u) = \\displaystyle\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\displaystyle\\frac{u^2}{2}\\right)\\)                          Epanechnikov          \\(\\begin{aligned}\\mathcal{K}(u)=\\begin{cases}\\displaystyle\\frac{3}{4}(1-u^{2}), \\quad &amp;\\text{if} \\quad \\vert u \\vert \\le 1 \\\\0, \\quad &amp;\\text{otherwise}\\end{cases}\\end{aligned}\\)                          Tophat          \\(\\begin{aligned}\\mathcal{K}(u) = \\begin{cases}\\displaystyle\\frac{1}{2}, \\quad &amp; \\text{if} \\quad \\vert u \\vert \\le 1 \\\\0, \\quad &amp; \\text{otherwise}\\end{cases}\\end{aligned}\\)                          Logistic          \\(\\mathcal{K}(u) = \\displaystyle\\frac{1}{e^{u} + e^{-u} + 2}\\)                          Silverman          \\(\\mathcal{K}(u) = \\displaystyle\\frac{1}{2} \\cdot \\exp\\left(-\\displaystyle\\frac{\\vert u \\vert}{\\sqrt{2}}\\right) \\cdot \\cos\\left(\\displaystyle\\frac{\\vert u \\vert}{\\sqrt{2}}\\right)\\)                          Laplacian          \\(\\mathcal{K}(u) = \\displaystyle\\frac{1}{2} \\cdot \\exp(-\\vert u \\vert)\\)                    MVNMulti-Variate Gaussian Distribution      다변량 가우시안 분포(Multi-Variate Gaussian/Normal Distribution; MVN) : 유한 차원의 상관된 가우시안 확률변수 벡터에 대해 정의되는 가우시안 분포            Definition\\[\\begin{aligned}  \\mathbf{X} \\sim \\mathcal{N}\\left(\\mu, \\Sigma\\right)  \\end{aligned}\\]                  \\(\\mathbf{X}= \\begin{pmatrix}X_{1} &amp; X_{2} &amp; \\cdots &amp; X_{N}\\end{pmatrix}^{T}\\) : Multi-Variable                  \\(X_{i} \\sim \\mathcal{N}\\left(\\mu_{i}, \\sigma_{i}^{2}\\right)\\) : The elements are random variables that follow individual Gaussian dist.                    \\(\\mu=\\begin{pmatrix}\\mu_{1} &amp; \\mu_{2} &amp; \\cdots &amp; \\mu_{N}\\end{pmatrix}^{T}\\) : Mean Vector      \\(\\Sigma=\\begin{pmatrix}\\Sigma_{11} &amp; \\Sigma_{12} &amp; \\cdots &amp; \\Sigma_{1N}\\\\ \\Sigma_{21} &amp; \\Sigma_{22} &amp; \\cdots &amp; \\Sigma_{2N}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\Sigma_{N1} &amp; \\Sigma_{N2} &amp; \\cdots &amp; \\Sigma_{NN} \\end{pmatrix}\\) : Covariance Matrix            Probability Density Function\\[\\begin{aligned}  f(\\mathbf{X})  &amp;= \\frac{1}{(2\\pi)^{n/2} \\vert \\Sigma \\vert^{1/2}} \\exp{\\left[-\\frac{1}{2}\\underbrace{(\\mathbf{X}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{X}-\\mu)}_{\\text{Mahalanobis Distance}}\\right]}  \\end{aligned}\\]                  마할라노비스 거리(Mahalanobis Distance) : 상관관계가 존재하는 다변량 데이터에서, 하나의 데이터 포인트가 특정 분포 혹은 군집에서 얼마나 떨어져 있는지를 측정하는 개념으로서, 단순 좌표 상의 거리뿐만 아니라 데이터 분포(분산-공분산 구조)를 반영하여 측정함\\[\\begin{aligned}  D_{M}(x)  &amp;= \\sqrt{(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu)}  \\end{aligned}\\]                  $\\sqrt{(x-\\mu)^{T}(x-\\mu)}$ : 데이터 포인트와 특정 분포 중심점 간 편차로서 유클리드 거리          $\\Sigma$ : 특정 분포의 공분산 행렬로서 데이터의 분산과 변수 간 상관관계를 포함하며, 이를 반영하여 방향성과 크기에 따라 거리를 조정함                    Conditional Probability\\[\\begin{aligned}Z_{2} \\mid Z_{1} \\sim \\mathcal{N}\\left(\\mu_{2} + \\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1}), \\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)\\end{aligned}\\]      Multi-Variate Gaussian Dist.\\[\\begin{aligned}  \\mathbf{Z}=\\begin{bmatrix}Z_{1} \\\\ Z_{2}\\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix}\\mu_{1} \\\\ \\mu_{2}\\end{bmatrix}, \\begin{bmatrix}\\Sigma_{11} &amp; \\Sigma_{12}\\\\ \\Sigma_{21} &amp; \\Sigma_{22}\\end{bmatrix}\\right)  \\end{aligned}\\]        Probability Density Function\\[\\begin{aligned}  f(\\mathbf{Z})  &amp;= \\frac{1}{(2\\pi)^{n/2} \\vert \\Sigma \\vert^{1/2}} \\exp{\\left[-\\frac{1}{2}\\underbrace{(\\mathbf{Z}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mu)}_{\\text{Mahalanobis Distance}}\\right]}  \\end{aligned}\\]        Inv-Covariance Matrix\\[\\begin{aligned}  \\Sigma^{-1}  &amp;= \\begin{bmatrix}  \\Sigma_{11}^{-1}+\\Sigma_{11}^{-1}\\Sigma_{12} \\cdot \\mathbf{M} \\cdot \\Sigma_{12}\\Sigma_{11}^{-1} &amp; -\\Sigma_{11}^{-1}\\Sigma_{12}\\mathbf{M}\\\\  -\\mathbf{M}\\Sigma_{21}\\Sigma_{11}^{-1} &amp; \\mathbf{M}  \\end{bmatrix}  \\end{aligned}\\]          \\(\\mathbf{M}=\\left(\\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\\right)^{-1}\\) : Schur Complement            Exponent Formula Expansion\\[\\begin{aligned}  (\\mathbf{Z}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mu)  &amp;= \\underbrace{(Z_{1}-\\mu_{1})^{T}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})}_{\\text{Mahalanobis Distance of } Z_{1}}\\\\  &amp;\\quad + \\underbrace{\\Bigg[Z_{2}-\\bigg\\{\\mu_{2}+\\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\bigg\\}\\Bigg]^{T}\\mathbf{M}\\Bigg[Z_{2}-\\bigg\\{\\mu_{2}+\\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\bigg\\}\\Bigg]}_{\\text{Conditional Mahalanobis Distance of }Z_{2} \\mid Z_{1}}  \\end{aligned}\\]        Therefore,\\[\\begin{aligned}  \\text{E}\\left[Z_{2} \\mid Z_{1}\\right]  &amp;= \\mu_{2} + \\Sigma_{21}\\Sigma_{11}^{-1}(Z_{1}-\\mu_{1})\\\\  \\text{Var}\\left[Z_{2} \\mid Z_{1}\\right]  &amp;= \\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}  \\end{aligned}\\]  Gaussian ProcessGaussian Process      가우시안 프로세스(Gaussian Process; GP) : 무한 차원의 다변량 가우시안 분포를 가정하는 비모수 확률적 과정(Non-Parametric Stochastic Process)            Definition          함수 분포(Function Distribution)  가우시안 프로세스는 각 입력값에 대한 관측치를 개별적인 확률변수로 간주하고 이를 무한 차원으로 확장함으로써 다변량 가우시안 분포의 개념을 함수 공간으로 확장함. 즉, 함수(설명변수와 반응변수 간 관계식)를 선험적으로 정의하지 않고 데이터를 통해 전체 함수 형태를 확률적으로 예측한다는 점에서, 가우시안 프로세스는 함수 자체를 하나의 확률변수로써 다루고, 이를 비모수 추정한다고 볼 수 있음.    \\[\\begin{aligned}  \\mathcal{F} \\sim \\mathcal{GP}\\left(\\mu(X), \\mathcal{K}(X, X^{\\prime})\\right)  \\end{aligned}\\]          \\(\\mu(X)\\) : 평균 함수(Mean Function)      \\(\\mathcal{K}(X, X^{\\prime})\\) : 공분산 함수(Covariance Function)            커널 함수(Kernel Function) : 두 입력 벡터 간 유사도 측정 함수로서 공분산 행렬을 구성함                            Name          Function                                      Linear          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = X \\cdot X^{\\prime}\\)                          Polynomial          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\left(X \\cdot X^{\\prime} + \\beta\\right)^{d}\\)                          RBF          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\displaystyle\\frac{\\Vert X-X^{\\prime} \\Vert^{2}}{2\\ell^{2}}\\right]}\\)                          Sigmoid          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\text{tanh}\\left(\\alpha \\cdot X \\cdot X^{\\prime} + \\beta\\right)\\)                          Laplacian          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\gamma \\Vert X-X^{\\prime} \\Vert_{1}\\right]}\\)                          Exponential          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\gamma \\Vert X-X^{\\prime} \\Vert_{2}\\right]}\\)                          Matern          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\displaystyle\\frac{2^{1-\\nu}}{\\Gamma\\left(\\nu\\right)} \\cdot \\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)^{\\nu} \\cdot K_{\\nu}\\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)\\)                          Periodic          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp\\left[-2 \\sin^2\\left( \\displaystyle\\frac{\\pi \\vert X-X^{\\prime} \\vert}{p} \\right) \\Bigg/ \\ell^2 \\right]\\)                          Rational Quadratic          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\left( 1 + \\displaystyle\\frac{\\vert X-X^{\\prime} \\vert^2}{2 \\alpha \\ell^2} \\right)^{-\\alpha}\\)                                    대칭성(Symmetry)\\[\\mathcal{K}\\left(x,x^{\\prime}\\right)=\\mathcal{K}\\left(x^{\\prime},x\\right)\\]                    양의 반정치성(Positive Semi-Definiteness, PSD)\\[\\sum_{i}\\sum_{j}{\\alpha_{i} \\cdot \\alpha_{j} \\cdot \\mathcal{K}\\left(x_{i},x_{j}\\right)} \\ge 0\\]            Bayesian Framework      SUMMARY : 베이지안 프레임워크로써 이해했을 때 가우시안 프로세스는 기존 데이터 \\((X,Y)\\) 를 통해 새로운 입력 \\(X^{*}\\) 에 대한 함수 \\(\\mathcal{F}^{*}\\) 를 사후확률로 갱신하는 과정으로 볼 수 있음\\[\\begin{aligned}  p\\left(\\mathcal{F}^{*} \\mid X, Y, X^{*}\\right)  &amp;= \\frac{p\\left(Y \\mid \\mathcal{F}, X\\right) \\cdot p\\left(\\mathcal{F}^{*} \\mid X^{*}\\right)}{p\\left(Y \\mid X\\right)}  \\end{aligned}\\]          \\(\\mathcal{F}\\) : Function Variable      \\(\\mathcal{F}^{*}\\) : Function Variable Updated by New Observations      \\(X,Y\\) : Existing Observations      \\(X^{*}\\) : New Observations            Prior Dist. : 새로운 입력을 관측하지 않은 상태에서 함수가 가질 수 있는 형태에 대한 정보는 기존에 관측되었던 값들로써 추론됨\\[\\begin{aligned}  \\mathcal{F}^{*} \\mid X^{*} \\sim \\mathcal{GP}\\left(\\mu(X), \\mathcal{K}(X, X^{\\prime})\\right)  \\end{aligned}\\]        Likelihood Function : 함수가 특정 형태일 때($\\mathcal{F}$), 기존에 관측되었던 값은 함수 값을 중심으로 가우시안 분포 형태로 분포함\\[\\begin{aligned}  Y  &amp;= \\mathcal{F}\\left(X\\right) + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}\\left(0, \\sigma_{N}^{2}\\mathbf{I}\\right)\\\\  &amp;\\Updownarrow\\\\  Y \\mid \\mathcal{F}, X  &amp;\\sim \\mathcal{N}\\left(\\mathcal{F}(X), \\sigma_{N}^{2}\\mathbf{I}\\right)  \\end{aligned}\\]        Evidence : 기존에 관측되었던 값은 다변량 가우시안 분포를 따름\\[\\begin{aligned}  Y \\mid X  \\sim \\mathcal{N}\\left(\\mu\\left(X\\right), \\mathbf{K}_{N} + \\sigma_{N}^{2}\\mathbf{I}\\right)  \\end{aligned}\\]  Posterior Estimation      MVN(Multi-Variate Normal Distribution) : 기존 데이터와 신규 데이터를 하나의 결합 가우시안 분포로 표현할 수 있음\\[\\begin{aligned}  \\begin{bmatrix}Y \\\\ \\mathcal{F}^{*}\\end{bmatrix}  \\sim \\mathcal{N} \\left(\\begin{bmatrix}\\mu(X) \\\\ \\mu(X^{*})\\end{bmatrix},\\begin{bmatrix}\\mathbf{K}_{N} + \\sigma^{2}_{N}\\mathbf{I} &amp; \\overrightarrow{\\mathbf{k}}_{N}^{*} \\\\ \\left(\\overrightarrow{\\mathbf{k}}_{N}^{*}\\right)^{T} &amp; \\mathcal{K}(X^{*}, X^{*})\\end{bmatrix}\\right)  \\end{aligned}\\]                  Covariance vector between old and new:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{k}}_{n}^{*}  = \\begin{bmatrix}\\mathcal{K}(X^{*},X_{1}) &amp; \\mathcal{K}(X^{*},X_{2}) &amp; \\cdots &amp; \\mathcal{K}(X^{*},X_{N})\\end{bmatrix}^{T}  \\end{aligned}\\]                  Posterior Dist. : 신규 데이터에 의해 갱신된 함수는 다시 가우시안 프로세스를 따름\\[\\begin{aligned}  \\mathcal{F}^{*} \\mid X, Y, X^{*} \\sim \\mathcal{N}(\\mu^{*}, (\\sigma^{*})^{2})  \\end{aligned}\\]                  Posterior Mean:\\[\\begin{aligned}  \\mu^{*}=\\mu(X^{*}) + \\overrightarrow{\\mathbf{k}}_{N}^{*}(\\mathbf{K}_{N}+\\sigma^{2}_{N}\\mathbf{I})^{-1}(Y-\\mu(X))  \\end{aligned}\\]                    Posterior Var.:\\[\\begin{aligned}  (\\sigma^{*})^{2}  =\\mathcal{K}(X^{*},X^{*})-\\overrightarrow{\\mathbf{k}}_{N}^{*}(\\mathbf{K}_{N}+\\sigma^{2}_{N}\\mathbf{I})^{-1}\\left(\\overrightarrow{\\mathbf{k}}_{N}^{*}\\right)^{T}  \\end{aligned}\\]            "
  },
  
  {
    "title": "BPR",
    "url": "/posts/BPR/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF, Ranking Prediction, Objective Function, Pairewise Learning, AUC, Bayesian",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "BPR      BPR(Bayesian Personalized Ranking) : Probabilistc Pairwise Ranking Prediction          선행 연구들은 대체로 평점 예측에 집중하는 경향을 보였으며, 이는 명시적 피드백 환경에 적합함. 하지만 실제에서는 주로 암묵적 피드백이 사용되며, 때문에 개별 아이템의 평점을 정확히...",
    "content": "BPR      BPR(Bayesian Personalized Ranking) : Probabilistc Pairwise Ranking Prediction          선행 연구들은 대체로 평점 예측에 집중하는 경향을 보였으며, 이는 명시적 피드백 환경에 적합함. 하지만 실제에서는 주로 암묵적 피드백이 사용되며, 때문에 개별 아이템의 평점을 정확히 맞추는 것보다는 중요한 상호작용 정보과 중요하지 않은 상호작용 정보 간 차등을 두는 (아이템 간 선호 순위를 맞추는) 목적 함수가 요구됨.      AUC Optimization      ROC(Receiver Operating Characteristic) is the set of $(x, y)$ pairs for all threshold $t$ values:\\[\\begin{aligned}  \\text{ROC}  &amp;=\\left\\{(x,y) \\mid t \\in [0,1]\\right\\}  \\end{aligned}\\]                  $x$ is FPR(False Positive Rate):\\[\\begin{aligned}  x  &amp;=f(t)\\\\  &amp;=p\\left(\\hat{z} &gt; t\\mid z=\\text{NEG}\\right)  \\end{aligned}\\]                    $y$ is TPR(True Positive Rate):\\[\\begin{aligned}  y  &amp;=g(t)\\\\  &amp;=p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right)  \\end{aligned}\\]                  AUC(Area Under the Curve) is the area under the ROC curve:\\[\\begin{aligned}  \\text{AUC}  &amp;=\\int_{0}^{1}{g \\circ f^{-1}\\left(x\\right)\\text{d}x}  \\end{aligned}\\]        Convert to Probability                  $f(t), g(t)$ is related to CDF(Cumulative Distribution Function):\\[\\begin{aligned}  f(t)  &amp;= p\\left(\\hat{z} &gt; t\\mid z=\\text{NEG}\\right)\\\\  &amp;= 1 - \\underbrace{p\\left(\\hat{z} \\le t\\mid z=\\text{NEG}\\right)}_{\\text{CDF}}\\\\  \\\\  g(t)  &amp;= p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right)\\\\  &amp;= 1 - \\underbrace{p\\left(\\hat{z} \\le t\\mid z=\\text{POS}\\right)}_{\\text{CDF}}  \\end{aligned}\\]                    Change of Variables:\\[\\begin{aligned}  \\frac{\\text{d}x}{\\text{d}t}  &amp;= \\frac{\\text{d}f(t)}{\\text{d}t}\\\\  &amp;= -\\underbrace{p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)}_{\\text{PDF}}\\\\  \\\\  \\therefore \\text{d}x  &amp;= -p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t  \\end{aligned}\\]                    Therefore:\\[\\begin{aligned}  \\text{AUC}  &amp;=\\int_{x=0}^{x=1}{g \\circ f^{-1}\\left(x\\right)\\text{d}x}\\\\  &amp;= \\int_{t=1}^{t=0}{g(t) \\frac{\\text{d}f(t)}{\\text{d}t} \\text{d}t}\\\\  &amp;= -\\int_{t=0}^{t=1}{g(t) \\frac{\\text{d}f(t)}{\\text{d}t} \\text{d}t}\\\\  &amp;= \\int_{t=0}^{t=1}{p\\left(\\hat{z} &gt; t\\mid z=\\text{POS}\\right) p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t}\\\\  &amp;= \\int_{t=0}^{t=1}\\int_{\\tau&gt;t}{p\\left(\\hat{z} = \\tau\\mid z=\\text{POS}\\right) p\\left(\\hat{z}=t \\mid z=\\text{NEG}\\right)\\text{d}t}\\\\  &amp;= p(\\hat{z}_{\\text{POS}} &gt; \\hat{z}_{\\text{NEG}})  \\end{aligned}\\]            Data Set  학습 데이터 : 개별 사용자 $u$ 의 선호체계 $&gt;_{u}$                  비교 가능성(Totality)\\[\\forall i,j \\in I:\\quad i \\ne j \\quad \\Rightarrow \\quad \\left(i &gt;_{u} j\\right) \\vee \\left(j &gt;_{u} i\\right)\\]                    반대칭성(Anti-Symmetry)\\[\\forall i,j \\in I:\\quad \\left(i &gt;_{u} j\\right) \\wedge \\left(j &gt;_{u} i\\right) \\quad \\Rightarrow \\quad i = j\\]                    이행성(Transitivity)\\[\\forall i,j,k \\in I:\\quad \\left(i &gt;_{u} j\\right) \\wedge \\left(j &gt;_{u} k\\right) \\quad \\Rightarrow \\quad \\left(i &gt;_{u} k\\right)\\]                  Pair-wise Preference Data Set\\[\\Omega  = \\Big\\{(u,i,j) \\mid i \\in I_{u} \\wedge j \\in I \\setminus I_{u}\\Big\\}\\]          $I$ : 아이템 집합      $I_{u} \\subset I$ : 사용자 $u$ 가 상호작용한 아이템 집합      $i \\in I_{u}$ : 사용자 $u$ 가 상호작용한 아이템      $j \\in I \\setminus I_{u}$ : 사용자 $u$ 가 상호작용하지 아니한 아이템            Single Data Point Definition\\[x_{u,i,j}:=r_{u,i} - r_{u,j}\\]  How to ModelingPosterior Estimation\\[\\underbrace{\\ln{P(\\Theta \\mid \\mathcal{D})}}_{\\begin{array}{c} \\text{Objective Function} \\\\ \\text{(Log Posterior)} \\end{array}} \\propto \\underbrace{\\ln{P(\\mathcal{D} \\mid \\Theta)}}_{\\text{Log Likelihood}} + \\underbrace{\\ln{P(\\Theta)}}_{\\text{Log Prior}}\\]      Log Likelihood                  Likelihood of Single Data Point\\[\\begin{aligned}  P(i &gt;_{u} j \\mid \\Theta)  &amp;= \\sigma\\left(\\hat{x}_{u,i,j}\\right)  \\end{aligned}\\]                    Likelihood of Data Set\\[\\begin{aligned}  P(\\mathcal{D} \\mid \\Theta)  &amp;= \\prod_{(u,i,j)\\in\\Omega}{P(i &gt;_{u} j \\mid \\Theta)}\\\\  &amp;= \\prod_{(u,i,j)\\in\\Omega}{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}  \\end{aligned}\\]                    Log Likelihood\\[\\begin{aligned}  \\ln{P(\\mathcal{D} \\mid \\Theta)}  &amp;= \\ln{\\prod_{(u,i,j)\\in\\Omega}{P(i &gt;_{u} j \\mid \\Theta)}}\\\\  &amp;= \\sum_{(u,i,j)\\in\\Omega}{\\ln{P(i &gt;_{u} j \\mid \\Theta)}}\\\\  &amp;= \\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}}  \\end{aligned}\\]                  Prior Determination; $\\Theta \\sim \\mathcal{N}\\left(0, \\lambda_{\\Theta}^{-1}\\mathbf{I}\\right)$\\[\\begin{aligned}  P\\left(\\Theta\\right)  &amp;= \\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}} \\cdot \\exp \\left[-\\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\right]\\\\  \\\\  \\ln{P\\left(\\Theta\\right)}  &amp;= \\ln{\\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}} \\cdot \\exp \\left[-\\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\right]}\\\\  &amp;= \\ln{\\frac{1}{(2\\pi)^{d/2} \\cdot \\lambda_{\\Theta}^{d/2}}} - \\frac{\\lambda_{\\Theta}}{2}\\Vert \\Theta \\Vert^{2}\\\\  &amp;\\propto -\\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}  \\end{aligned}\\]        Posterior Estimation\\[\\begin{aligned}  P(\\Theta \\mid \\mathcal{D})  &amp;\\propto P(\\mathcal{D} \\mid \\Theta) \\cdot P(\\Theta)\\\\  \\\\  \\ln{P(\\Theta \\mid \\mathcal{D})}  &amp;\\propto \\ln{P(\\mathcal{D} \\mid \\Theta)} + \\ln{P(\\Theta)}\\\\  &amp;\\propto \\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} -\\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}  \\end{aligned}\\]  Optimization      Objective Function\\[\\text{BPR-OPT} = \\ln{P(\\Theta \\mid \\mathcal{D})}\\]        Optimization\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max_{\\Theta}{\\ln{P(\\Theta \\mid \\mathcal{D})}}\\\\  &amp;= \\text{arg} \\max_{\\Theta}{\\sum_{(u,i,j)\\in\\Omega}{\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} - \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}\\\\  &amp;= \\text{arg} \\min_{\\Theta}{\\sum_{(u,i,j)\\in\\Omega}{-\\ln{\\sigma\\left(\\hat{x}_{u,i,j}\\right)}} + \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}  \\end{aligned}\\]          $\\hat{\\Theta}$ is MAP(Maximum a Posteriori) Estimator      "
  },
  
  {
    "title": "Bayesian Regression",
    "url": "/posts/Bayesian_Regression/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, Regression",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "        Bayesian Regression ModelFrequentist Estimation      다중선형회귀모형(Multiple Linear Regression Model)\\[\\begin{aligned}  \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\beta} + \\overrightarr...",
    "content": "        Bayesian Regression ModelFrequentist Estimation      다중선형회귀모형(Multiple Linear Regression Model)\\[\\begin{aligned}  \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\beta} + \\overrightarrow{\\varepsilon}  \\quad \\text{for} \\quad \\overrightarrow{\\varepsilon} \\sim N(0, \\sigma^2\\mathbf{I})\\\\  \\therefore \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\hat{\\beta}}  \\end{aligned}\\]  MLE      최우추정법(Maximum Liklihood Estimation; MLE) : 우도를 최대화하는 회귀계수를 탐색하는 방법\\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}_{MLE}  &amp;= \\text{arg}\\max{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}  \\end{aligned}\\]        우도(Liklihood) : 파라미터 $\\theta$ 가 주어졌을 때, 관측치 $y$ 가 발생할 확률\\[\\begin{aligned}  \\overrightarrow{y}  &amp;\\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}) \\quad (\\because \\overrightarrow{\\varepsilon} \\sim N(0, \\sigma^2\\mathbf{I}))\\\\  \\\\  \\therefore \\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)  &amp;= P(\\overrightarrow{y} \\,\\mid\\, \\overrightarrow{\\beta}, \\sigma^2)\\\\  &amp;= \\frac{1}{(2\\pi\\sigma^2)^{n/2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\right]}  \\end{aligned}\\]  OLS      최소자승법(Least Square Estimation; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 탐색하는 방법\\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}_{OLS}  &amp;= \\text{arg}\\min_{\\beta}{RSS}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]        Residual Sum of Square(RSS) : 잔차 자승의 합\\[\\begin{aligned}  RSS  &amp;= \\sum_{i}{(y_{i}-\\hat{y}_{i})^2}\\\\  &amp;= \\mid \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\mid^{2}\\\\  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})  \\end{aligned}\\]  \\(\\hat{\\beta}_{MLE}=\\hat{\\beta}_{OLS}\\)      우도 $\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)$ 는 잔차 $RSS$ 에 반비례함\\[\\begin{aligned}  \\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)  &amp;\\propto \\log{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}\\\\  &amp;= -\\frac{n}{2}\\cdot\\log{2\\pi\\sigma^2}-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\propto -\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\propto -(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;= -RSS  \\end{aligned}\\]        따라서 \\(\\hat{\\beta}_{MLE}\\) 과 \\(\\hat{\\beta}_{OLS}\\) 는 동일함\\[\\begin{aligned}  \\therefore \\text{arg}\\max_{\\beta}{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}  &amp;= \\text{arg}\\max_{\\beta}{\\log{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}}\\\\  &amp;= \\text{arg}\\max_{\\beta}{-(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})}\\\\  &amp;= \\text{arg}\\min_{\\beta}{(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})}\\\\  &amp;= \\text{arg}\\min_{\\beta}{RSS}  \\end{aligned}\\]          \\(\\hat{\\beta}_{MLE}\\) : 최우추정량으로서 우도를 최대화하는 모수      \\(\\hat{\\beta}_{OLS}\\) : 최소자승추정량으로서 잔차를 최소화하는 모수      Non-informative Prior DeterminationLiklihood Function Transformation      다중선형회귀모형의 우도 함수\\[\\begin{aligned}  \\mathcal{L}(\\beta, \\sigma^2)  &amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]} \\quad (\\because \\overrightarrow{y} \\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}))\\\\  &amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}  \\end{aligned}\\]        $(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})$ 변형\\[\\begin{aligned}  (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= \\left[(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\right]^{T}\\left[(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\right]\\\\  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\\\  &amp;\\quad + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\quad + 2 \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  \\\\  (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\\\  2 \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;=0\\\\  \\\\  \\therefore (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\\\  \\end{aligned}\\]        우도 함수에 대입\\[\\begin{aligned}  \\mathcal{L}(\\beta, \\sigma^2)  &amp;\\propto (\\sigma^2)^{-n/2}\\\\  &amp;\\quad \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\right]}\\\\  &amp;\\quad \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\  \\end{aligned}\\]        잔차 분산 및 자유도 정의\\[\\begin{aligned}  s^{2}  &amp;= \\frac{1}{\\nu} \\cdot RSS\\\\  &amp;= \\frac{1}{\\nu} \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\\\  \\nu  &amp;= n-k  \\end{aligned}\\]        우도 함수에 대입\\[\\begin{aligned}  \\therefore \\mathcal{L}(\\beta, \\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\  &amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}  \\end{aligned}\\]  Prior Determination of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2)&amp;= P(\\beta ; \\sigma^2) \\cdot P(\\sigma^2)\\\\&amp;= P(\\beta) \\cdot P(\\sigma^2) \\quad (\\because \\text{i.i.d})\\\\&amp;= 1 \\times \\frac{1}{\\sigma^2}\\end{aligned}\\]      Jacobian Change of $\\sigma^2$ for Relaxing Range Constraints\\[\\begin{aligned}  \\psi  &amp;= \\log{\\sigma^2}\\\\  \\therefore P(\\sigma^2)  &amp;= P(\\psi) \\cdot \\frac{1}{\\sigma^2}  \\end{aligned}\\]        Non-informative Prior Determination of $\\beta, \\psi$\\[\\beta, \\psi \\sim \\text{Uniform}(0,1)\\]        Jeffreys Prior of $\\sigma^2$\\[\\begin{aligned}  P(\\sigma^2)  &amp;= P(\\psi) \\cdot \\frac{1}{\\sigma^2}\\\\  &amp;= \\frac{1}{\\sigma^2}  \\end{aligned}\\]  Posterior Estimation of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2 \\mid \\mathcal{D})&amp;\\propto P(\\mathcal{D} \\mid \\beta, \\sigma^2) \\cdot P(\\beta, \\sigma^2)\\\\\\\\&amp;\\propto (\\sigma^2)^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2} \\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\&amp;\\quad \\times \\frac{1}{\\sigma^2}\\\\\\\\&amp;= (\\sigma^2)^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2} \\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\end{aligned}\\]      Marginal Posterior of $\\sigma^2$ is Inverse Chi-Squared Distribution\\[\\begin{aligned}  f(\\sigma^2 \\mid \\nu,s^2)  &amp;=(\\sigma^2)^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\  \\therefore \\sigma^2 \\mid \\mathcal{D}  &amp;\\sim \\text{Inv-}\\chi^2(\\nu,s^2)  \\end{aligned}\\]        Conditional Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  f(\\beta \\mid \\hat{\\beta}, \\mathbf{V}_{\\beta})  &amp;= (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\  \\therefore \\beta ; \\sigma^2 \\mid \\mathcal{D}  &amp;\\sim N(\\overrightarrow{\\hat{\\beta}}, \\sigma^2\\mathbf{V}_{\\beta})  \\end{aligned}\\]          $\\overrightarrow{\\hat{\\beta}}=(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}$ : $\\overrightarrow{\\beta}$ 의 최우추정량      $\\sigma^2\\mathbf{V}_{\\beta}=\\sigma^2(\\mathbf{X}^{T}\\mathbf{X})^{-1}$ : $\\overrightarrow{\\beta}$ 의 공분산 행렬      Informative Prior DeterminationLiklihood Function\\[\\begin{aligned}\\mathcal{L}(\\beta, \\sigma^2)&amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]} \\quad (\\because \\overrightarrow{y} \\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}))\\\\&amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}\\end{aligned}\\]Setting Conjugate Prior of $\\beta, \\sigma^2$\\[P(\\beta, \\sigma^2) = P(\\beta ; \\sigma^2) \\cdot P(\\sigma^2)\\]      Conjugate Prior of $\\sigma^2$ is Scaled Inverse Chi-Squared Distribution\\[\\begin{aligned}  P(\\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\nu_{0}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu_{0} s_{0}^{2}\\right]}\\\\  &amp;\\propto \\text{Scaled Inv-}\\chi^2(\\nu_{0}, s_{0}^{2})  \\end{aligned}\\]          $\\nu_{0}$ : 사전 자유도      $s_{0}^{2}$ : 사전 잔차 분산            Conjugate Prior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  P(\\beta;\\sigma^2)  &amp;\\propto (\\sigma^2)^{-(n-\\nu_0)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_0)^{T}\\Lambda_{0}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_0)\\right]}\\\\  &amp;\\propto N(\\overrightarrow{\\mu}_0, \\sigma^2\\Lambda_{0}^{-1})  \\end{aligned}\\]          $\\overrightarrow{\\mu}_0$ : $\\overrightarrow{\\beta}$ 의 사전 평균      $\\sigma^2\\Lambda_{0}^{-1}$ : $\\overrightarrow{\\beta}$ 의 사전 공분산 행렬      Posterior Estimation of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2 \\mid \\mathcal{D})&amp;\\propto P(\\mathcal{D} \\mid \\beta, \\sigma^2) \\cdot P(\\beta, \\sigma^2)\\\\\\\\&amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\nu_{n}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu_{n} s_{n}^{2}\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\\\\\\\&amp;= (\\sigma^2)^{-\\frac{n+\\nu_n}{2}-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\left(\\nu_n s^{2}_{n} + (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right)\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\end{aligned}\\]      Posterior of $\\sigma^2$ is Inverse-Gamma Distribution\\[\\begin{aligned}  P(\\sigma^2 \\mid \\mathcal{D})  &amp;\\propto (\\sigma^2)^{-\\frac{n+\\nu_n}{2}-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\left(\\nu_n s^{2}_{n} + (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right)\\right]}\\\\  &amp;\\propto \\text{Inv-Gamma}\\left(\\frac{n + \\nu_n}{2}, \\frac{1}{2} \\left[\\nu_n s_n^2 + (\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})\\right]\\right)  \\end{aligned}\\]          $\\nu_{n}$ : 사후 자유도      $s_{n}^{2}$ : 사후 잔차 분산            Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  P(\\beta;\\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\\\  &amp;\\propto N(\\overrightarrow{\\mu}_n, \\sigma^2\\Lambda_{n}^{-1})  \\end{aligned}\\]          $\\overrightarrow{\\mu}_n$ : $\\overrightarrow{\\beta}$ 의 사후 평균      $\\sigma^2\\Lambda_{n}^{-1}$ : $\\overrightarrow{\\beta}$ 의 사후 공분산 행렬      "
  },
  
  {
    "title": "Naive Bayes",
    "url": "/posts/Naive_Bayes/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, Classification",
    "date": "2024-07-30 00:00:00 +0900",
    





    
    "snippet": "Naive Bayes      나이브 베이즈(Naive Bayes): 베이즈 정리에 기초하여 관측치의 범주를 판별하는 알고리즘            Class Conditional Independent Assumption:\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)  &amp;= P(X_{1} \\mid...",
    "content": "Naive Bayes      나이브 베이즈(Naive Bayes): 베이즈 정리에 기초하여 관측치의 범주를 판별하는 알고리즘            Class Conditional Independent Assumption:\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)  &amp;= P(X_{1} \\mid Y) \\times P(X_{2} \\mid Y) \\times \\cdots \\times P(X_{n} \\mid Y)  \\end{aligned}\\]  Decision Function      problem definition:\\[\\begin{aligned}  \\hat{Y}  &amp;= f(\\overrightarrow{\\mathbf{x}})\\\\  &amp;= \\text{arg} \\max_{Y}{P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}\\) 의 범주 \\(\\hat{Y}\\) 는 \\(\\overrightarrow{\\mathbf{x}}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 로 주어졌을 때, 범주 \\(Y\\) 가 \\(i=1,2,\\cdots\\) 일 확률이 최대인 \\(i\\) 임            By Bayes’ theorem:\\[\\begin{aligned}  &amp;P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          \\(P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 범주에 대한 사후 확률로서, 관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}=(x_{1},x_{2},\\cdots,x_{n})\\) 가 주어졌을 때, 해당 관측치의 범주 \\(Y\\) 가 $i$ 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i)\\) : 관측치 범주에 대한 우도로서, 범주 \\(Y=i\\) 가 주어졌을 때, 관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률      \\(P(Y=i)\\) : 관측치 범주에 대한 사전 확률로서, 범주 \\(Y\\) 가 \\(i\\) 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 범주에 대한 주장의 근거로서, 관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률            Multivariate conditional probability can be converted to univariate conditional probability under class conditional independence assumption:\\[\\begin{aligned}  &amp;P(X_{1},X_{2},\\cdots,X_{n} \\mid Y)\\\\  &amp;= P(X_{1} \\mid Y) \\times P(X_{2} \\mid Y) \\times \\cdots \\times P(X_{n} \\mid Y)  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  &amp;P(Y=i \\mid X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=i) \\cdot P(Y=i)}{\\sum_{j}P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\mid Y=j)}\\\\  &amp;= \\frac{\\prod_{k=1}^{n}{P(X_{k}=x_{k} \\mid Y=i)} \\cdot P(Y=i)}{\\sum_{j}{\\prod_{k=1}^{n}{P(X_{k}=x_{k} \\mid Y=j)}}}  \\end{aligned}\\]  Laplace Smoothing      라플라스 평활화(Laplace Smoothing): 훈련 데이터 세트에 존재하지 않는 사례 \\(\\overrightarrow{\\mathbf{x}}_{k}\\) 에 대한 확률을 \\(0\\) 으로 부여하는 것을 방지하기 위한 기법\\[P(\\overrightarrow{\\mathbf{x}}_{k} \\mid Y)  = \\frac{\\text{Count}(\\overrightarrow{\\mathbf{x}}_{k},Y)+\\alpha}{\\text{Count}(Y)+2\\alpha}\\]          \\(P(\\overrightarrow{\\mathbf{x}}_{k} \\mid Y)\\) : 관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}_{k}\\) 가 범주 \\(Y\\) 에 속할 조건부 확률      \\(\\text{Count}(\\overrightarrow{\\mathbf{x}}_{k},Y)\\) : 관측치 벡터 \\(\\overrightarrow{\\mathbf{x}}_{k}\\) 와 범주 \\(Y\\) 의 동시 출현 빈도      \\(\\text{Count}(Y)\\) : 범주 \\(Y\\) 의 출현 빈도      \\(\\alpha\\) : 라플라스 평활화 강도      Sourse  https://www.linkedin.com/pulse/naive-bayes-theorem-machine-learning-rohit-bele/"
  },
  
  {
    "title": "Multi Armed Bandits",
    "url": "/posts/Multi_Armed_Bandits/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, Multi Armed Bandits",
    "date": "2024-07-29 00:00:00 +0900",
    





    
    "snippet": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. ...",
    "content": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. 단, 슬롯 머신의 보상 확률은 알려져 있지 않다. 어떤 슬롯 머신을 고르는 것이 이득일까?            A/B Test vs. MAB                      A/B Test : 탐색 후 그 결과를 100% 활용하는 불연속적인(Discrete) 방법                  $n$ 개의 집단에 $n$ 개의 선택지를 노출하여 순수하게 새로운 가능성을 탐색(Exploration)한 후, 의사결정이 완료된 후에는 채택된 선택지를 모든 집단에 노출하여 활용함(Exploitation)                            MAB : 탐색과 활용을 동시에 수행하는 연속적인(Continuous) 방법                  고객의 피드백을 실시간으로 반영하며 각 선택지의 보상 확률을 갱신함으로써 열등한 선택지는 비교적 적게 노출하고 우월한 선택지는 비교적 많이 노출함                          Selection Issue : Exploration-Exploitation Trade-off              만약 적당히 좋은 결과를 돌려주는 슬롯 머신을 찾아냈다면, 그 결과를 유지하기 위해 그 슬롯 머신을 활용할 것인가(Exploitation) 아니면 더 좋은 결과를 얻을 수 있다는 희망으로 다른 슬롯 머신을 탐색할 것인가(Exploration)?              탐색(Exploration) : 다양한 슬롯 머신들을 선택하면서 보상이 어느 정도 도출되는지 탐색하는 과정      활용(Exploitation) : 수집된 정보를 바탕으로 보상 확률이 높은 슬롯 머신을 선택하는 과정      Selection Algorithms      Loss Function for MAB is Total Regret\\[\\begin{aligned}  \\mathcal{R}(T)  &amp;= \\sum_{t=1}^{T}{\\left[\\theta_{opt}-\\theta_{B(t)}\\right]}\\\\  &amp;= T \\cdot \\theta_{opt} - \\sum_{t=1}^{T}{\\theta_{B(t)}}  \\end{aligned}\\]          $B(t)$ : $t$ 번째 시점에서 선택한 슬롯 머신      $P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률 분포      $\\theta_{B(t)} \\sim P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률      $\\theta_{opt}$ : 최적 슬롯 머신의 보상 확률      Bayes Selection; Thompson Sampling      모든 슬롯 머신의 보상 확률에 대하여 사전 확률 분포 설정\\[\\begin{aligned} X \\mid \\theta &amp;\\sim \\text{Bin}(n,\\theta)\\\\ \\therefore \\theta &amp;\\sim \\text{Beta}(\\alpha_0,\\beta_0) \\end{aligned}\\]        보상 확률이 가장 높은 슬롯 머신 선택\\[B(t)=\\text{arg}\\max_{a}{\\theta_{a}}\\]        보상 관찰 후 해당 슬롯 머신의 사후 확률 분포 갱신\\[\\begin{aligned} \\theta_{B(t)} \\mid X &amp;\\sim \\text{Beta}(\\alpha, \\beta)\\\\ \\alpha &amp;= \\alpha_0 + X\\\\ \\beta &amp;= \\beta_0 - n + X \\end{aligned}\\]  Extra Selection Algorithms      Greedy : $t-1$ 번째 시점까지 탐색한 정보를 토대로 기대 보상이 가장 큰 슬롯 머신만을 활용하는 전략\\[\\begin{aligned}  B(t)  &amp;= \\text{arg}\\max_{a}{Q(a;t)}\\\\  &amp;= \\text{arg}\\max_{a}{\\frac{\\sum_{i=1}^{t-1}{\\tau_{i} \\cdot \\mathbb{I}\\left[B(i)=a\\right]}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}  \\end{aligned}\\]          $\\tau_{i}$ : $i$ 번째 시점에서 받은 보상      $\\mathbb{I}\\left[B(i)=a\\right]$ : Indicate Function            $\\varepsilon$-Greedy : $\\varepsilon$ 의 확률로 새로운 슬롯 머신을 탐색하는 전략\\[B(t)  = \\begin{cases}\\begin{aligned}  Q(a;t) \\quad &amp; \\text{with probability} \\; 1-\\varepsilon\\\\  \\text{random} \\quad &amp; \\text{with probability} \\; \\varepsilon  \\end{aligned}\\end{cases}\\]          $Q(a;t)$ : Exploitation Term      $\\text{random}$ : Exploration Term            UCB(Upper Confidence Bound) : 승률이 높은 슬롯 머신을 활용하면서, 승률의 불확실성이 높은 슬롯 머신을 탐색하는 전략\\[B(t)  =\\text{arg}\\max_{a}{\\left[Q(a;t) + c \\cdot \\sqrt{\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}\\right]}\\]          $Q(a;t)$ : Exploitation Term      $\\sqrt{\\displaystyle\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}$ : Exploration Term      $c$ : Exploration Constant      Source  https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/  https://link.springer.com/article/10.1007/s10489-023-04955-0?fromPaywallRec=false"
  },
  
  {
    "title": "Bayesian A/B Test",
    "url": "/posts/Bayesian_A_B_Test/",
    "categories": "BAYES, 3.bayes applications",
    "tags": "Bayesian, A/B Test",
    "date": "2024-07-28 00:00:00 +0900",
    





    
    "snippet": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 ...",
    "content": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 기록하였다. $A,B$ 전환율 간에 유의한 차이가 있다고 볼 수 있는가? (단, \\(\\sigma^2_{A}=\\sigma^2_{B}\\) 임이 알려져 있다고 가정한다.)            디자인      방문자 수      전환 수                  A      1,300      120              B      1,275      125      Frequentist A/B Test  Point Estimator          Interest Parameter : $\\pi_A-\\pi_B$      Point Estimator : $p_A-p_B$        Hypothesis          $H_{0}:\\quad p_A-p_B = D_{0}$      $H_{1}:\\quad p_A-p_B \\ne D_{0}$            Parametric Test Assumptions\\[\\begin{aligned}  n_A \\cdot p_A &amp;\\ge 5\\\\  n_A \\cdot (1-p_A) &amp;\\ge 5\\\\  n_B \\cdot p_B &amp;\\ge 5\\\\  n_B \\cdot (1-p_B) &amp;\\ge 5  \\end{aligned}\\]        Test Statistic\\[\\begin{aligned}  Z  &amp;= \\frac{(p_A-p_B) - D_0}{\\sqrt{s^2_p(1-s^2_p)\\left(\\displaystyle\\frac{1}{n_A}+\\displaystyle\\frac{1}{n_B}\\right)}}  \\sim N(0,1)  \\end{aligned}\\]                  $s^{2}_p$ : Pooled Estimator\\[s^{2}_p = \\frac{n_A \\cdot p_A + n_B \\cdot p_B }{n_A + n_B}\\]            Bayesian A/B Test      Prior of $\\pi$ Determination                  전환율 $\\pi$ 은 $n$ 번의 실험에 따른 성공 횟수 $X \\mid \\pi$ 에 대한 성공 확률임\\[X \\mid \\pi \\sim \\text{Bin}(n,\\pi)\\]                    Binomial Dist. 의 성공 확률 $\\pi$ 에 대한 Conjugate Prior Dist. 로서 Beta Dist. 가 적합함\\[\\pi \\sim \\text{Beta}(\\alpha_0,\\beta_0)\\]                  Posterior of $\\pi \\mid X$ Estimation\\[\\pi \\mid X \\sim \\text{Beta}(\\alpha_0 + X, \\beta_0 + n - X)\\]        Beyes Action\\[\\hat{p} = \\text{arg}\\min{\\mathcal{R}(p)}\\]                  $\\mathcal{R}(p)$ : Bayes Risk\\[\\begin{aligned}  \\mathcal{R}(p)  &amp;= \\mathbb{E}_{\\pi \\mid X}\\left[\\text{Loss}(\\pi, p)\\right]\\\\  &amp;\\approx \\frac{1}{k}\\sum_{i=1}^{k}{\\text{Loss}(p^{(i)}, p)}  \\end{aligned}\\]                  Compare $\\hat{p}_A$ and $\\hat{p}_B$  "
  },
  
  {
    "title": "Stein Variational Gradient Descent",
    "url": "/posts/SVGD/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Stein's Method, Nonparametric Estimation",
    "date": "2024-07-27 00:00:00 +0900",
    





    
    "snippet": "SVGD      SVGD(Stein Variational Gradient Descent) : Stein Discrepancy 를 활용하여 제안 분포 $W \\sim Q$ 를 목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에 근사하는 비모수 방법론(Non-Parametric Method)        Vector Optimization v...",
    "content": "SVGD      SVGD(Stein Variational Gradient Descent) : Stein Discrepancy 를 활용하여 제안 분포 $W \\sim Q$ 를 목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에 근사하는 비모수 방법론(Non-Parametric Method)        Vector Optimization vs. Distribution Optimization through Gradient Descent                                       Euclidean Gradient          Wasserstein Gradient                                      Space          Euclidean          Measure                          Distance          Euclidean          Wasserstein                          Target          $x$          $q(x)$                          Loss Function          $\\mathcal{L}(x)$          $D(q \\parallel p)$                          Gradient          $\\partial \\mathcal{L}(x) / \\partial x$          $\\delta D(q \\parallel p) / \\delta q$                          Update          $x \\to x^{*}$          $q \\to p$                          Distribution Optimization $\\to$ Particle Optimization          Stein Variational Gradient Descent 는 파라미터의 분포를 직접 모델링하지 않고 개별 입자들을 모델링함. 즉, 제안 분포와 목표 분포 간 차이를 줄임으로써 분포 전체를 직접 최적화하는 방식이 아니라(변분 미분), 제안 분포에서 샘플링된 개별 입자들의 위치가 목표 분포를 따르도록 조정하는 방식으로 학습이 진행됨(편미분).  입자가 이동해야 하는 최적 방향을 제공하는 지표는 분포 간 차이를 나타내는 \\(D_{\\text{STEIN}}(q \\parallel p)\\) 에 개별 입자의 위치를 편미분한 값 \\(\\phi(x_{i})=\\displaystyle\\frac{\\partial}{\\partial x_{i}}D_{\\text{STEIN}}(q \\parallel p)\\) 으로, 이는 RKHS에서 유도된 최적의 함수와 동일함.            Stein Gradient:\\[\\begin{aligned}  \\phi(w_{i})  &amp;= \\mathbb{E}_{w_{j} \\sim q}[\\mathcal{K}(w_{i}, w_{j}) \\cdot \\nabla_{w_{j}}\\log{p(w_{j} \\mid \\mathcal{D})}+\\nabla_{w_{j}}\\mathcal{K}(w_{i}, w_{j})]\\\\  &amp;= \\frac{1}{M}\\sum_{j=1}^{M}{\\underbrace{\\mathcal{K}(w_{i}, w_{j})}_{\\text{kernel}} \\cdot \\underbrace{\\nabla_{w_{j}}\\log{p(w_{j} \\mid \\mathcal{D})}}_{\\text{score function}}+\\underbrace{\\nabla_{w_{j}}\\mathcal{K}(w_{i}, w_{j})}_{\\text{repulsion effect}}}  \\end{aligned}\\]                  스코어 함수(Score Function) : 입자 $w_{i} \\sim q$ 가 확률 분포 $p$ 를 따라 움직이도록 유도함\\[\\begin{aligned}  \\underbrace{\\log{p(w_{j} \\mid \\mathcal{D})}}_{\\text{posterior}}  &amp;= \\underbrace{\\log{p(\\mathcal{D} \\mid w_{j})}}_{\\text{likelihood}} + \\underbrace{\\log{p(w_{j})}}_{\\text{prior}} - \\underbrace{\\log{p(\\mathcal{D})}}_{\\text{evidence}}\\\\  \\therefore \\underbrace{\\nabla_{w_{j}}\\log{p(w_{j} \\mid \\mathcal{D})}}_{\\text{score function}}  &amp;= \\underbrace{\\nabla_{w_{j}}\\log{p(\\mathcal{D} \\mid w_{j})}}_{\\text{likelihood gradient}} + \\underbrace{\\nabla_{w_{j}}\\log{p(w_{j})}}_{\\text{prior gradient}}  \\end{aligned}\\]                    반발 효과(Repulsion Effect) : 입자들이 서로 퍼지도록 함으로써 입자 간 분포를 유지함                  Update:\\[\\begin{aligned}  w_{i} \\gets w_{i} + \\epsilon \\cdot \\phi(w_{i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Stein's Method",
    "url": "/posts/Stein/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Stein's Method, Nonparametric Estimation",
    "date": "2024-07-26 00:00:00 +0900",
    





    
    "snippet": "Stein’s MethodStein Operator  테스트 함수 $f(x)$ 를 확률 분포 $p(x)$ 의 구조가 반영된 형태로 변환하는 연산자로서, $x$ 의 변화에 따른 $f(x)$ 의 변화율를 측정하고, 그 변화를 $x$ 가 발생할 가능성이 반영된 형태로 조정하는 방식으로 동작함\\[\\begin{aligned}\\mathcal{T}_{p}f(x)&...",
    "content": "Stein’s MethodStein Operator  테스트 함수 $f(x)$ 를 확률 분포 $p(x)$ 의 구조가 반영된 형태로 변환하는 연산자로서, $x$ 의 변화에 따른 $f(x)$ 의 변화율를 측정하고, 그 변화를 $x$ 가 발생할 가능성이 반영된 형태로 조정하는 방식으로 동작함\\[\\begin{aligned}\\mathcal{T}_{p}f(x)&amp;= \\nabla_{x}f(x) + f(x)\\cdot\\nabla_{x}\\log{p(x)}\\end{aligned}\\]  \\(\\nabla_{x}f(x)\\) : $x$ 에 대한 $f(x)$ 의 변화율  \\(\\nabla_{x}\\log{p(x)}=\\displaystyle\\frac{p^{\\prime}(x)}{p(x)}\\) : 스코어 함수(Score Function)로서 $x$ 에 대한 $\\log{p(x)}$ 의 변화율Stein Class  Stein Operator 을 통해 변화율 조정 가능한 테스트 함수 $f(x)$ 는 확률 분포 $p(x)$ 의 정의역 경계에서 $0$ 으로 수렴해야 하고(Boundary Condition), 정의역에서 미분 가능해야 함(Differentiability Condition)      Boundary Condition\\[\\begin{aligned}  \\lim_{x \\to \\text{boundary}}{f(x)p(x)}=0  \\end{aligned}\\]        Differentiability Condition\\[\\begin{aligned}  \\forall x \\in \\mathbb{R}, \\quad \\exists \\nabla_{x}f(x) = \\lim_{h \\to 0}{\\frac{f(x+h)-f(x)}{h}}  \\end{aligned}\\]  Stein’s Identity  $x$ 의 변화에 따른 테스트 함수 \\(f(x)\\) 의 변화 양상을 \\(x\\) 발생 확률 분포로써 조정했을 때(Stein Operator) 조정된 변화율의 기대값이 $0$ 이 되는 성질로서, 특정한 형태의 연산(Stein Operator)을 거친 테스트 함수 \\(f(x)\\) 가 특정 확률 분포 \\(p(x)\\) 에서 평균적으로 변화가 없음을 보장하는 정리\\[\\begin{aligned}\\mathbb{E}_{x \\sim p}\\left[\\mathcal{T}_{p}f(x)\\right]&amp;= \\int{p(x) \\cdot \\mathcal{T}_{p}f(x)\\text{d}x}\\\\&amp;= \\int{p(x)\\cdot\\Big(f^{\\prime}(x) + f(x) \\cdot \\nabla_{x}\\log{p(x)} \\Big)\\text{d}x}\\\\&amp;= \\int{\\Big[p(x) \\cdot f^{\\prime}(x) + p(x) \\cdot f(x) \\cdot \\nabla_{x}\\log{p(x)} \\Big]\\text{d}x}\\\\&amp;= \\int{p(x) \\cdot f^{\\prime}(x)\\text{d}x} + \\int{p(x) \\cdot f(x) \\cdot \\nabla_{x}\\log{p(x)}\\text{d}x}\\\\&amp;= 0\\end{aligned}\\]      부정적분:\\[\\begin{aligned}  \\int_{a}^{b}{u(x) \\cdot v^{\\prime}(x)\\text{d}x}  &amp;= \\Big[u(x) \\cdot v(x)\\Big]_{a}^{b} - \\int_{a}^{b}{u^{\\prime}(x) \\cdot v(x)\\text{d}x}  \\end{aligned}\\]        대입:\\[\\begin{aligned}  \\int_{-\\infty}^{\\infty}{f(x) \\cdot p^{\\prime}(x)\\text{d}x}  &amp;= \\Big[f(x) \\cdot p(x)\\Big]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty}{f^{\\prime}(x) \\cdot p(x)\\text{d}x}  \\end{aligned}\\]        \\(p(x)\\) 가 확률 밀도 함수이고, \\(f(x)\\) 가 Bounded Function 이라고 하자.\\(x \\to \\pm\\infty\\) 이면 \\(p(x) \\to 0\\) 이므로,\\[\\begin{aligned}  \\Big[f(x) \\cdot p(x)\\Big]_{-\\infty}^{\\infty}  &amp;=0  \\end{aligned}\\]        따라서:\\[\\begin{aligned}  \\int_{-\\infty}^{\\infty}{f^{\\prime}(x) \\cdot p(x)\\text{d}x}  &amp;= -\\int_{-\\infty}^{\\infty}{f(x) \\cdot p^{\\prime}(x)\\text{d}x}\\\\  &amp;= \\int_{-\\infty}^{\\infty}{-f(x) \\cdot p^{\\prime}(x)\\text{d}x}  \\end{aligned}\\]        로그함수의 미분:\\[\\begin{aligned}  \\nabla_{x}\\log{p(x)}  = \\frac{\\text{d}}{\\text{d}x}\\log{p(x)}  = \\frac{p^{\\prime}(x)}{p(x)}  \\end{aligned}\\]        따라서:\\[\\begin{aligned}  p(x) \\cdot f(x) \\cdot \\nabla_{x}\\log{p(x)}  &amp;= \\cancel{p(x)} \\cdot f(x) \\cdot \\frac{p^{\\prime}(x)}{\\cancel{p(x)}}\\\\  &amp;= f(x) \\cdot p^{\\prime}(x)  \\end{aligned}\\]  KSDRKHS      RKHS(Reproducing Kernel Hilbert Space) : 특정한 재생 커널(Reproducing Kernel)에 의해 정의된 힐베르트 공간으로서, 이 함수 공간에서 모든 함수는 커널 함수의 선형 조합으로 표현됨\\[\\begin{aligned}  f(x)  &amp;= \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})}  \\end{aligned}\\]                  힐베르트 공간(Hilbert Space) : 유클리드 공간을 일반화한 개념으로서, 내적과 거리가 정의된 완비 공간\\[\\begin{aligned}  \\langle f, g \\rangle _{\\mathcal{H}}:=\\sum_{i=1}^{n}\\sum_{j=1}^{m}{\\alpha_{i}\\beta_{j}\\mathcal{K}(x_{i}, x_{j})}, \\quad \\Vert f \\Vert _{\\mathcal{H}} := \\sqrt{\\langle f, f \\rangle _{\\mathcal{H}}}  \\end{aligned}\\]                  $f(x)=\\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})}$          $g(x)=\\sum_{j=1}^{m}{\\beta_{j} \\cdot \\mathcal{K}(x, x_{j})}$                            재생(Reproducing) : 모든 함수 $f(x)$ 가 커널 함수의 선형 조합으로 표현됨에 따라 $f(x)$ 를 직접 계산하지 않고도 커널 함수를 통해 함수 값을 재생할 수 있는 성질\\[\\begin{aligned}  f(x)  = \\langle f, \\mathcal{K}(\\cdot, x) \\rangle _{\\mathcal{H}}  = \\left\\langle \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(\\cdot, x_{i})}, \\mathcal{K}(\\cdot, x) \\right\\rangle _{\\mathcal{H}}  = \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})}  \\end{aligned}\\]                  재생 커널(Reproducing Kernel)                            Name          Function                                      Linear          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = X \\cdot X^{\\prime}\\)                          Polynomial          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\left(X \\cdot X^{\\prime} + \\beta\\right)^{d}\\)                          RBF          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\displaystyle\\frac{\\Vert X-X^{\\prime} \\Vert^{2}}{2\\ell^{2}}\\right]}\\)                          Matern          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\displaystyle\\frac{2^{1-\\nu}}{\\Gamma\\left(\\nu\\right)} \\cdot \\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)^{\\nu} \\cdot K_{\\nu}\\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)\\)                                    대칭성(Symmetry):\\[\\begin{aligned}  \\mathcal{K}(x, x^{\\prime})  &amp;= \\mathcal{K}(x^{\\prime}, x)  \\end{aligned}\\]                    양의 정부호성(Positive Definiteness):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}^{T} \\mathbf{K} \\overrightarrow{\\mathbf{v}} &gt; 0, \\quad \\forall \\overrightarrow{\\mathbf{v}} \\in \\mathbb{R}^{N}\\setminus \\{0\\}  \\end{aligned}\\]                              \\(\\mathbf{K}\\) is Kernel Matrix\\[\\begin{aligned}  \\mathbf{K}  = \\begin{pmatrix}  \\mathcal{K}(x_{1}, x_{1}) &amp; \\mathcal{K}(x_{1}, x_{2}) &amp; \\cdots &amp; \\mathcal{K}(x_{1}, x_{N})\\\\  \\mathcal{K}(x_{2}, x_{1}) &amp; \\mathcal{K}(x_{2}, x_{2}) &amp; \\cdots &amp; \\mathcal{K}(x_{2}, x_{N})\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\mathcal{K}(x_{N}, x_{1}) &amp; \\mathcal{K}(x_{N}, x_{2}) &amp; \\cdots &amp; \\mathcal{K}(x_{N}, x_{N})\\\\  \\end{pmatrix}  \\end{aligned}\\]                              KSD      Stein’s Identity Application                  if $q(x)=p(x)$:\\[\\begin{aligned}  \\mathbb{E}_{x \\sim q}\\left[\\mathcal{T}_{p}f(x)\\right]  = \\begin{cases}\\int{q(x) \\cdot \\mathcal{T}_{p}f(x)\\text{d}x}\\\\  \\sum{q(x) \\cdot \\mathcal{T}_{p}f(x)}  \\end{cases}  = 0  \\end{aligned}\\]                    else:\\[\\begin{aligned}  \\mathbb{E}_{x \\sim q}\\left[\\mathcal{T}_{p}f(x)\\right]  = \\begin{cases}\\int{q(x) \\cdot \\mathcal{T}_{p}f(x)\\text{d}x}\\\\  \\sum{q(x) \\cdot \\mathcal{T}_{p}f(x)}  \\end{cases}  \\ne 0  \\end{aligned}\\]                  KSD(Kernelized Stein Discrepancy) : Stein’s Identity 를 활용하여 두 확률 분포 간 차이를 측정함에 있어, RKHS 의 커널 함수를 이용하는 기법                  Stein Discrepancy:\\[\\begin{aligned}  D_{\\text{STEIN}}(q \\parallel p)  &amp;= \\sup_{f \\in \\mathcal{F}}{\\mathbb{E}_{x \\sim q}\\left[\\mathcal{T}_{p}f(x)\\right]}  \\end{aligned}\\]                    If Test Function is defined in RKHS:\\[\\begin{aligned}  f(x)  = \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})},\\quad f \\in \\mathcal{H}_{K}  \\end{aligned}\\]                    Argument of Supremum is:\\[\\begin{aligned}  f^{*}(x)  &amp;= \\text{arg} \\sup_{f \\in \\mathcal{F}}{\\mathbb{E}_{x \\sim q}\\left[\\mathcal{T}_{p}f(x)\\right]}\\\\  &amp;= \\mathbb{E}_{x^{\\prime} \\sim q}[\\mathcal{K}(x, x^{\\prime}) \\cdot \\nabla_{x^{\\prime}}\\log{p(x^{\\prime})}+\\nabla_{x^{\\prime}}\\mathcal{K}(x, x^{\\prime})]  \\end{aligned}\\]                    Therefore:\\[\\begin{aligned}  D_{\\text{STEIN}}(q \\parallel p)  &amp;= \\mathbb{E}_{x,x^{\\prime}\\sim q}\\left[\\nabla_{x}\\log{p(x)}^{T} \\cdot \\mathcal{K}(x,x^{\\prime}) \\cdot \\nabla_{x^{\\prime}}\\log{p(x^{\\prime})} + \\nabla_{x}\\nabla_{x^{\\prime}}\\mathcal{K}(x,x^{\\prime})\\right]  \\end{aligned}\\]            "
  },
  
  {
    "title": "Monte Carlo Dropout",
    "url": "/posts/MC_Dropout/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Variational Inference",
    "date": "2024-07-25 00:00:00 +0900",
    





    
    "snippet": "Monte Carlo Dropout  MC Dropout(Monte Carlo Dropout) : 드롭아웃의 확률적 성질을 변분 추론 관점에서 해석하여 사후 확률 분포를 근사하는 모수 방법론으로서, 평가 과정에서도 드롭아웃을 유지하고 여러 번 샘플링한 결과값에 평균을 내어 최종 결론을 도출함How to Interpret      Original ELB...",
    "content": "Monte Carlo Dropout  MC Dropout(Monte Carlo Dropout) : 드롭아웃의 확률적 성질을 변분 추론 관점에서 해석하여 사후 확률 분포를 근사하는 모수 방법론으로서, 평가 과정에서도 드롭아웃을 유지하고 여러 번 샘플링한 결과값에 평균을 내어 최종 결론을 도출함How to Interpret      Original ELBO\\[\\begin{aligned}  \\text{ELBO}  = \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - D_{KL}\\big[Q(W) \\parallel P(W)\\big]  \\end{aligned}\\]          $P(W)$ : Prior Dist.      $Q(W)$ : Approx. Dist.      \\(\\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right]\\) : Likelihood            Prior Dist. : Normality Assumption\\[\\begin{aligned}  \\mathcal{W} \\sim \\mathcal{N}\\left(0, \\sigma^{2}_{p}\\mathbf{I}\\right)  \\end{aligned}\\]        Approx. Dist.                  Dropout is a process of applying Bernoulli sampling to weights,  so each weight has stochastic properties:\\[\\begin{aligned}  \\mathcal{W} \\mid \\mathbf{M} &amp;\\sim Q  \\end{aligned}\\]                  $\\mathcal{W} = \\mathbf{W} \\odot \\mathbf{M}$          $M_{i,j} \\sim \\text{Bernoulli}(p)$                            According to the CLS,  the mean and variance of multiple samplings converge to a normal dist.\\[\\begin{aligned}  q(\\mathcal{\\omega}) \\approx \\mathcal{N}\\left(0, \\sigma^{2}_{q}\\mathbf{I}\\right)  \\end{aligned}\\]                  KL Divergence from Approx. to Prior\\[\\begin{aligned}  D_{KL}(q \\parallel p)  &amp;= \\frac{1}{2}\\sum_{i}\\left(\\frac{\\sigma_{q}^{2}}{\\sigma_{p}^{2}} + \\frac{\\sigma_{p}^{2}}{\\sigma_{q}^{2}} - 1\\right)  \\end{aligned}\\]                  If $\\sigma_{p}^{2} \\approx \\sigma_{q}^{2}$:\\[\\begin{aligned}  D_{KL}(q \\parallel p)  &amp;= \\frac{1}{2\\sigma^{2}}\\Vert \\mathcal{W} \\Vert^{2}  \\end{aligned}\\]                  Likelihood  Approximated by averaging the results of multiple samplings\\[\\begin{aligned}  \\mathbb{E}_{\\omega \\sim q}[\\log{p(\\mathcal{D} \\mid \\omega)}]  \\approx \\frac{1}{T}\\sum_{t=1}^{T}{\\log{p(\\mathcal{D} \\mid \\omega_{t})}}  \\end{aligned}\\]        Therefore:\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\frac{1}{T}\\sum_{t=1}^{T}{\\log{p(\\mathcal{D} \\mid \\omega_{t})}} - \\frac{1}{2\\sigma^{2}}\\Vert \\mathcal{W} \\Vert^{2}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Random Fourier Features Gaussian Process",
    "url": "/posts/RFF_GP/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Variational Inference, Gaussian Process, Fourier",
    "date": "2024-07-24 00:00:00 +0900",
    





    
    "snippet": "GP      가우시안 프로세스(Gaussian Process): 순차 입력 $x_{1},x_{2},\\cdots \\in \\ell^{2}$ 에 대한 출력 $f(x_{1}),f(x_{2}),\\cdots \\in \\ell^{2}$ 이 입력 공간 $\\ell^{2}$ 전체에 대하여 확률 분포를 가지는 확률 과정으로서, 함수 자체를 확률변수로 취하는 함수 분포\\[...",
    "content": "GP      가우시안 프로세스(Gaussian Process): 순차 입력 $x_{1},x_{2},\\cdots \\in \\ell^{2}$ 에 대한 출력 $f(x_{1}),f(x_{2}),\\cdots \\in \\ell^{2}$ 이 입력 공간 $\\ell^{2}$ 전체에 대하여 확률 분포를 가지는 확률 과정으로서, 함수 자체를 확률변수로 취하는 함수 분포\\[\\begin{aligned}  f(\\cdot) \\sim \\mathcal{GP}(\\mu(\\cdot), \\mathcal{K}(\\cdot, \\cdot))  \\end{aligned}\\]        $f(x) \\sim \\mathcal{N}(\\mu(x),\\mathcal{K}(x,x))$: 입력값 $x$ 에 대한 출력값\\[\\begin{aligned}  f(x) \\in \\ell^{2}  \\end{aligned}\\]        $\\mathbf{f} \\sim \\mathcal{N}(\\mu,\\Sigma)$: 입력값 $x_{1},x_{2},\\cdots$ 에 대한 출력값 $f(x_{1}),f(x_{2}),\\cdots$ 벡터\\[\\begin{aligned}  \\mathbf{f}  := \\begin{bmatrix}  f(x_{1})\\\\  f(x_{2})\\\\  \\vdots  \\end{bmatrix}  \\in \\ell^{2}  \\end{aligned}\\]                  $\\mu$: 입력값 $x_{1},x_{2},\\cdots$ 에 대한 출력값 $f(x_{1}),f(x_{2}),\\cdots$ 의 평균 벡터\\[\\begin{aligned}  \\mu  =\\begin{bmatrix}  \\mu(x_{1}) \\\\  \\mu(x_{2}) \\\\  \\vdots  \\end{bmatrix}  \\end{aligned}\\]                    $\\Sigma$: 입력값 $x_{1},x_{2},\\cdots$ 에 대한 출력값 $f(x_{1}),f(x_{2}),\\cdots$ 의 공분산 행렬\\[\\begin{aligned}  \\Sigma  &amp;=\\begin{bmatrix}  \\mathcal{K}(x_{1},x_{1}) &amp; \\mathcal{K}(x_{1},x_{2}) &amp; \\cdots \\\\  \\mathcal{K}(x_{2},x_{1}) &amp; \\mathcal{K}(x_{2},x_{2}) &amp; \\cdots \\\\  \\vdots &amp; \\vdots &amp; \\ddots  \\end{bmatrix}  \\end{aligned}\\]                  $f(\\cdot) \\sim \\mathcal{GP}(\\mu(\\cdot), \\mathcal{K}(\\cdot, \\cdot))$: $\\forall x$ 에 대하여 $f(\\forall x)$ 를 정의하는 규칙\\[\\begin{aligned}  f(\\cdot) \\in \\mathcal{H}_{\\mathcal{K}}  \\end{aligned}\\]  RKHS      RKHS(Reproducing Kernel Hilbert Space) : 특정한 재생 커널(Reproducing Kernel)에 의해 정의된 힐베르트 공간으로서, 이 함수 공간에서 모든 함수는 커널 함수의 선형 조합으로 표현됨\\[\\begin{aligned}  f(x)  &amp;= \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})}  \\end{aligned}\\]        힐베르트 공간(Hilbert Space) : 유클리드 공간을 일반화한 개념으로서, 내적과 거리가 정의된 완비 공간\\[\\begin{aligned}  \\langle f, g \\rangle _{\\mathcal{H}}:=\\sum_{i=1}^{n}\\sum_{j=1}^{m}{\\alpha_{i}\\beta_{j}\\mathcal{K}(x_{i}, x_{j})}, \\quad \\Vert f \\Vert _{\\mathcal{H}} := \\sqrt{\\langle f, f \\rangle _{\\mathcal{H}}}  \\end{aligned}\\]          $f(x)=\\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x, x_{i})}$      $g(x)=\\sum_{j=1}^{m}{\\beta_{j} \\cdot \\mathcal{K}(x, x_{j})}$            재생(Reproducing) : 모든 함수 $f(x)$ 가 커널 함수의 선형 조합으로 표현됨에 따라 $f(x)$ 를 직접 계산하지 않고도 커널 함수를 통해 함수 값을 재생할 수 있는 성질\\[\\begin{aligned}  f(x)  = \\langle f, \\mathcal{K}(\\cdot, x) \\rangle _{\\mathcal{H}}  = \\left\\langle \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(\\cdot, x_{i})}, \\mathcal{K}(\\cdot, x) \\right\\rangle _{\\mathcal{H}}  \\end{aligned}\\]  RFF      Random Fourier Features:          임의의 조건을 만족하는 커널은 푸리에 변환을 통해 어떤 확률 밀도 함수의 기대값으로 표현 가능하다. 그리고 이 커널에 의해 정의되는 무한 차원의 함수 공간 $RKHS$ 는 해당 커널의 스펙트럼 밀도 $p(w)$ 로부터 샘플링된 $w$ 에 대하여 정의되는 유한 개 무작위 기저 함수 $\\phi_{W \\sim P}(x) \\in RKHS$ 들의 선형 결합(혹은 내적)의 기대값으로써 근사될 수 있다.    \\[\\begin{aligned}  \\mathcal{K}(x,x^{\\prime})  &amp;= \\left&lt;\\mathcal{K}(\\cdot, x), \\mathcal{K}(\\cdot, x^{\\prime})\\right&gt;_{\\mathcal{H}}\\\\  &amp;\\approx \\left&lt;\\phi(x), \\phi(x^{\\prime})\\right&gt;_{\\mathbb{R}^{K}}\\\\  &amp;= \\mathbb{E}_{W \\sim P}\\left[\\phi_{w}(x) \\cdot \\phi_{w}(x^{\\prime})\\right]  \\end{aligned}\\]          $\\phi(x) = \\sqrt{2/K} \\cdot \\begin{bmatrix}\\cos{(w_{1}^{T}x+b_{1})} &amp; \\cos{(w_{2}^{T}x+b_{2})} &amp; \\cdots &amp; \\cos{(w_{K}^{T}x+b_{K})}\\end{bmatrix}$            푸리에 변환(fourier transform): 임의의 조건을 만족하는 함수는 주기 함수의 기대값으로 표현될 수 있음\\[\\begin{aligned}  f(x)  &amp;= \\int_{\\mathbb{R}^{K}}{\\exp{\\left[i \\cdot w^{T}x\\right]} \\cdot p(w)}\\text{d}w  \\end{aligned}\\]          $f(x)$:                  $f \\in L^{1}(\\mathbb{R}^d)$: 적분 가능 함수          $f \\in L^{2}(\\mathbb{R}^d)$: 제곱 적분 가능 함수                            $p(w)$: 확률 밀도 함수로서 함수 $f(x)$ 의 스펙트럼 밀도(Spectrum Density)                    $\\exp{[i \\cdot w^{T}x]}$: 복소 지수 함수(complex exponential function)                  $i$: 허수          $\\theta= w^{T}x$: 운동 주기에서 입력값의 위치          $w$: 주파수로서 운동의 방향 및 속도          $x$: 입력값                          보흐너 정리(Bochner’s theorem): 임의의 조건을 만족하는 커널 $\\mathcal{K}: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ 은 어떤 확률 밀도 함수 $p(w)$ 의 푸리에 쌍임\\[\\begin{aligned}  \\mathcal{K}(x,x^{\\prime})  &amp;= \\int_{\\mathbb{R}^{K}}{\\exp{\\left[i \\cdot w^{T}(x-x^{\\prime})\\right]} \\cdot p(w)}\\text{d}w  \\end{aligned}\\]                  연속성(continuous):\\[\\begin{aligned}  \\Vert x - a \\Vert &amp;&lt; \\delta\\\\  \\Vert x^{\\prime} - b \\Vert &amp;&lt; \\delta  \\end{aligned} \\quad  \\Rightarrow \\quad  \\vert \\mathcal{K}(x,x^{\\prime}) - \\mathcal{K}(a,b) \\vert &lt; \\epsilon  \\quad \\text{for} \\quad   \\begin{aligned}  \\forall \\epsilon &amp;&gt; 0\\\\  \\exists \\delta &amp;&gt; 0  \\end{aligned}\\]                    이동 불변성(shift-invariant):\\[\\begin{aligned}  \\mathcal{K}(x,x^{\\prime})  &amp;=\\mathcal{K}(x-x^{\\prime})  \\end{aligned}\\]                    양의 정부호성(positive definite):\\[\\sum_{i=1}^{n}{\\sum_{j=1}^{n}{c_{i} \\cdot c_{j} \\cdot \\mathcal{K}(x_{i},x_{j})}}&gt;0 \\quad \\text{for} \\quad  \\begin{aligned}  \\forall n &amp;\\in \\mathbb{N}\\\\  \\forall x_{1},x_{2},\\cdots,x_{n} &amp;\\in \\mathbb{R}^{d}\\\\  \\forall \\mathbf{c} &amp;\\in \\mathbb{R}^{n} \\setminus \\{\\mathbb{0}\\}  \\end{aligned}\\]                  오일러 공식(Euler’s formula): 복소 지수 함수는 주기 함수(사인과 코사인)의 조합으로 분해될 수 있음\\[\\begin{aligned}  \\exp{[i \\cdot \\theta]}  &amp;=\\cos{\\theta} + i \\cdot \\sin{\\theta}  \\end{aligned}\\]                  $\\because$ fourier transform:\\[\\begin{aligned}  \\mathcal{K}(x-x^{\\prime})  &amp;= \\mathbb{E}_{W \\sim P}[\\exp(i \\cdot w^{T}(x-x^{\\prime}))]  \\end{aligned}\\]                    segmentation:\\[\\begin{aligned}  \\exp[i \\cdot w^{T}(x-x^{\\prime})]  &amp;= \\exp[i \\cdot w^{T}x] \\cdot \\exp[-i \\cdot w^{T}x^{\\prime}]\\\\  &amp;= \\big[\\cos{(w^{T}x)}+i\\sin{(w^{T}x)}\\big]\\cdot\\big[\\cos{(w^{T}x^{\\prime})}-i\\sin{(w^{T}x^{\\prime})}\\big]\\\\  &amp;= \\underbrace{\\cos{(w^{T}x)} \\cdot \\cos{(w^{T}x^{\\prime})} + \\sin{(w^{T}x)} \\cdot \\sin{(w^{T}x^{\\prime})}}_{\\text{real part}} - i(\\cdots)  \\end{aligned}\\]                    only take the real part:\\[\\begin{aligned}  \\exp[i \\cdot w^{T}(x-x^{\\prime})]  &amp;\\approx \\cos{w^{T}(x-x^{\\prime})}  \\end{aligned}\\]                  $\\because \\cos{(a-b)} = \\cos{a} \\cdot \\cos{b} + \\sin{a} \\cdot \\sin{b}$                          무작위 퓨리에 기저 함수(Random Fourier Features): 유한 차원의 특징 공간을 정의하는 기저 함수\\[\\begin{aligned}  \\phi(x)  &amp;= \\sqrt{2}\\cos{(w^{T}x + b)} \\quad \\text{for} \\quad b \\sim \\text{Uniform}(0,2\\pi)  \\end{aligned}\\]                  assumption:\\[\\begin{aligned}  \\frac{1}{2}\\cos{w^{T}(x-x^{\\prime})}  &amp;=\\mathbb{E}_{b}[\\cos{(w^{T}x + b)} \\cdot \\cos{(w^{T}x^{\\prime} + b)}]  \\end{aligned}\\]                    expression expansion:\\[\\begin{aligned}  \\cos{(w^{T}x + b)} \\cdot \\cos{(w^{T}x^{\\prime} + b)}  &amp;=\\frac{1}{2}\\left[\\cos{w^{T}(x-x^{\\prime})} + \\cos{(w^{T}(x+x^{\\prime})+2b)}\\right]  \\end{aligned}\\]                  $\\because \\cos{a}\\cdot\\cos{b} = \\displaystyle\\frac{1}{2}[\\cos{(a-b)} + \\cos{(a+b)}]$                            expected value:\\[\\begin{aligned}  &amp;\\mathbb{E}_{b}\\left[\\cos{(w^{T}x + b)} \\cdot \\cos{(w^{T}x^{\\prime} + b)}\\right]\\\\  &amp;= \\frac{1}{2}\\Big(\\cos{w^{T}(x-x^{\\prime})} + \\mathbb{E}_{b}[\\cos{(w^{T}(x+x^{\\prime})+2b)}]\\Big)\\\\  &amp;= \\frac{1}{2}\\cos{w^{T}(x-x^{\\prime})}  \\end{aligned}\\]                  $\\because \\int_{0}^{2\\pi}{\\cos{(2b + \\cdots)}}\\text{d}b=0$                          Therefore:\\[\\begin{aligned}  \\mathcal{K}(x,x^{\\prime})  &amp;\\approx \\mathbb{E}_{W \\sim P}\\left[\\exp{i \\cdot w^{T}(x-x^{\\prime})}\\right]\\\\  &amp;\\approx \\mathbb{E}_{W \\sim P}\\left[\\cos{w^{T}(x-x^{\\prime})}\\right]\\\\  &amp;\\approx \\mathbb{E}_{W \\sim P}\\Big(\\mathbb{E}_{b \\sim \\text{Uniform}(0,2\\pi)}\\left[\\left&lt;\\phi_{w,b}(x), \\phi_{w,b}(x^{\\prime})\\right&gt;\\right]\\Big)  \\end{aligned}\\]  RFF-GP      RFF-GP(Random Fourier Featres Gaussian Process): 커널 함수 $\\mathcal{K}(\\cdot,\\cdot)$ 에 대하여 정의되는 무한 차원의 재생 커널 힐베르트 공간 \\(f \\in \\mathcal{H}_{\\mathcal{K}}\\) 을 무작위 푸리에 기저 함수(Random Fourier Features) $\\phi(\\cdot)$ 에 대하여 정의되는 유한 차원 선형 함수 공간 \\(f \\in \\mathcal{H}_{RFF} \\subset \\mathcal{H}_{\\mathcal{K}}\\) 으로 근사함으로써(Subspace Approximation), 가우시안 프로세스 \\(f(\\cdot) \\sim \\mathcal{GP}(\\mu(\\cdot),\\mathcal{K}(\\cdot,\\cdot))\\) 를 선형 회귀 모형 \\(\\phi(\\cdot)^{T}\\theta \\sim \\mathcal{GP}(0,\\left&lt;\\phi(\\cdot),\\phi(\\cdot)\\right&gt;)\\) 의 형태로 근사하는 방법론\\[\\begin{aligned}  f(x) \\mid \\theta  &amp;\\sim \\mathcal{N}(0,\\left&lt;\\phi(x),\\phi(x^{\\prime})\\right&gt;)  \\end{aligned}\\]        RFF Summary:\\[\\begin{aligned}  \\mathcal{K}(x,x^{\\prime})  \\approx \\phi(x)^{T}\\phi(x^{\\prime})  \\end{aligned}\\]        original $f(\\cdot)$ be approximated linear combination of basis function:\\[\\begin{aligned}  f(x)  &amp;= \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\mathcal{K}(x,x_{i})}\\\\  &amp;\\approx \\sum_{i=1}^{n}{\\alpha_{i} \\cdot \\phi(x)^{T}\\phi(x_{i})}\\\\  &amp;= \\phi(x)^{T}\\underbrace{\\sum_{i=1}^{n}{\\alpha_{i}\\phi(x_{i})}}_{=:\\theta}  \\end{aligned}\\]          $\\phi(x)$ is chosen randomly, but fixed once drawn      to give probability to $f(x)$, $\\theta$ must be set as a probabilistic variable            Prior of $f(x)$:\\[\\begin{aligned}  \\theta \\sim \\mathcal{N}(0,\\mathbf{I})  \\end{aligned}\\]        Posterior of $f(x) \\mid \\theta$:\\[\\begin{aligned}  f(x) \\mid \\theta  &amp;\\sim \\mathcal{N}(0,\\left&lt;\\phi(x),\\phi(x^{\\prime})\\right&gt;)  \\end{aligned}\\]                  Mean of $f(x) \\mid \\theta$:\\[\\begin{aligned}  \\mathbb{E}[f(x)]  &amp;=\\mathbb{E}[\\phi(x)^{T}\\theta]\\\\  &amp;=\\phi(x)^{T}\\mathbb{E}[\\theta]\\\\  &amp;=0  \\end{aligned}\\]                    Covariance of $f(x) \\mid \\theta$:\\[\\begin{aligned}  \\mathbb{E}[f(x)],\\mathbb{E}[f(x^{\\prime})]  &amp;=0\\\\  \\\\  \\mathbb{E}[f(x) \\cdot f(x^{\\prime})]  &amp;=\\mathbb{E}[\\phi(x)^{T}\\theta\\theta^{T}\\phi(x^{\\prime})]\\\\  &amp;=\\phi(x)^{T}\\mathbb{E}[\\theta\\theta^{T}]\\phi(x^{\\prime})\\\\  &amp;=\\phi(x)^{T}\\mathbf{I}\\phi(x^{\\prime}) \\quad \\because \\Sigma=\\mathbb{E}[(\\theta-\\mu)(\\theta-\\mu)^{T}]\\\\  &amp;=\\left&lt;\\phi(x),\\phi(x^{\\prime})\\right&gt;\\\\  \\\\  \\therefore \\text{Cov}[f(x), f(x^{\\prime})]  &amp;= \\mathbb{E}[f(x) \\cdot f(x^{\\prime})]-\\mathbb{E}[f(x)]\\cdot\\mathbb{E}[f(x^{\\prime})]\\\\  &amp;= \\left&lt;\\phi(x),\\phi(x^{\\prime})\\right&gt;\\\\  \\end{aligned}\\]            "
  },
  
  {
    "title": "Bayes by Backprop",
    "url": "/posts/BBB/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Variational Inference",
    "date": "2024-07-23 00:00:00 +0900",
    





    
    "snippet": "Bayes by Backprop      문제 의식          인공신경망 알고리즘은 파라미터 수가 매우 많아 과적합 문제에서 자유롭지 못하나 단일 최적값만 학습하여 지나치게 확신하는 예측을 수행함. 학습 조기 종료, 배치 정규화, 레이어 정규화, 드롭아웃 등 과적합 방지 기법들은 모형이 산출하는 결과에 대한 정규화 기법으로서 모형(의사결정 과정)...",
    "content": "Bayes by Backprop      문제 의식          인공신경망 알고리즘은 파라미터 수가 매우 많아 과적합 문제에서 자유롭지 못하나 단일 최적값만 학습하여 지나치게 확신하는 예측을 수행함. 학습 조기 종료, 배치 정규화, 레이어 정규화, 드롭아웃 등 과적합 방지 기법들은 모형이 산출하는 결과에 대한 정규화 기법으로서 모형(의사결정 과정) 자체에 대한 정규화 기법이 아님. 즉, 이 기법들은 과적합 문제의 핵심인 과신을 해결하지 못함.              과적합(Overfitting): 모형의 복잡도가 데이터 셋이 제공하는 정보량보다 심화되어 발생하는 현상      과신(Overconfidence): 정보가 부족한 상황에서 단일 가설을 확신하여 예측하는 현상            BBB(Bayes by Backprop): 인공신경망의 가중치에 불확실성을 반영하여 데이터에 대한 설명력을 확보하는 동시에(Likelihood) 사전 정보(Prior)를 활용하여 모형의 복잡도를 제어함으로써(Kullback–Leibler divergence) 일반화 성능을 향상시키는 학습 방법론          How to Approximate: Variational Inference      Objective Function: Evidence Lower Bound      How to Sample from Approx.: Reparameterization Trick      How to Modeling      Approx.                  Multivariate Gaussian Dist.(or Mean-Field Guassian Dist.):\\[\\begin{aligned}  q(w)  &amp;= \\mathcal{N}(\\mu, \\text{diag}(\\sigma^{2}))  \\end{aligned}\\]                    Trainable Parameters:\\[\\begin{aligned}  \\Theta_{\\text{approx.}}  &amp;= (\\mu, \\rho)\\\\  \\sigma  &amp;= \\log{\\left[1 + \\exp(\\rho)\\right]}  \\end{aligned}\\]                  Prior                  Gaussian: L2 Normalization\\[\\begin{aligned}  Q(w)  &amp;=\\mathcal{N}(0,\\sigma^{2})  \\end{aligned}\\]                    Scale Mixture of Gaussian: Approx. Sparse, Heavy-tail Dist.\\[\\begin{aligned}  P(w)  &amp;=\\pi \\cdot \\mathcal{N}(0,\\sigma_{1}^{2}) + (1-\\pi) \\cdot \\mathcal{N}(0,\\sigma_{2}^{2})  \\end{aligned}\\]                  Reparameterization Trick is a technique that transforms the sampling process from an approximate distribution into a differentiable function:\\[w \\sim \\mathcal{N}(\\mu,\\sigma^{2}) \\quad \\rightarrow \\quad w = \\mu + \\sigma \\cdot \\epsilon\\]          $\\epsilon \\sim \\mathcal{N}(0,1)$            Variational Inference:\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]  "
  },
  
  {
    "title": "Variational Inference",
    "url": "/posts/VI/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Objective Function, Variational Inference",
    "date": "2024-07-22 00:00:00 +0900",
    





    
    "snippet": "Information Theory      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikel...",
    "content": "Information Theory      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Event)일수록 높은 정보량을 가짐(Informative)                  해가 동쪽에서 뜨는 사건은 사람들이 확신하고 있는 사건이므로 정보량이 낮은 반면, 해가 서쪽에서 뜨는 사건은 자연 법칙을 거스르는 극히 드문 사건이므로 정보량이 높음                    독립사건은 추가적인 정보량을 가짐(Addictive Information)                  동전을 두 번 던져서 앞면이 두 번 나오는 사건은 동전을 한 번 던져서 앞면이 나오는 사건보다 정보량이 두 배임                          자기정보(Self-Information): 확률변수 $X \\sim P$ 에 대하여, 사건 $X=x$ 가 발생했을 때의 정보량\\[\\begin{aligned}  I(X=x)  &amp;=-\\log{P(X=x)}  \\end{aligned}\\]        엔트로피(Entropy): 자기정보의 기대값으로서, 주어진 확률분포에서 발생 가능한 사건들의 평균적인 정보량\\[\\begin{aligned}  H(P)  = \\mathbb{E}_{X \\sim P}\\left[I(X)\\right]  = -\\sum_{X}{\\log{P(x)} \\cdot P(x)}  \\end{aligned}\\]          사건의 분포가 결정적일수록(Deterministic) 엔트로피가 감소함      사건의 분포가 균등할수록(Uniform) 엔트로피가 증가함            교차 엔트로피(Cross Entropy): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 가 $P$ 에 대하여 제공하는 정보의 불확실성을 측정하는 지표\\[\\begin{aligned}  H(P,Q)  = \\mathbb{E}_{X \\sim P}\\left[-\\log{Q(X)}\\right]  = -\\sum_{X}{\\log{Q(X)} \\cdot \\log{P(X)}}  \\end{aligned}\\]        쿨백 라이블러 발산(Kullback-Leibler Divergence): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 를 $P$ 의 근사 분포로 사용할 때의 비효율성을 측정하는 지표로서, $P$ 에서 샘플링된 $X$ 에 대하여, $P$ 가 제공하는 평균적인 정보량과 $Q$ 가 제공하는 평균적인 정보량의 차이\\[\\begin{aligned}  KL[P(X) \\parallel Q(X)]  = H(P,Q) - H(P)  = \\sum_{X}{\\log{\\frac{P(X)}{Q(X)}} \\cdot P(X)}  \\end{aligned}\\]  Variational Inference      변분 추론(Variational Inference): 정보 이론을 활용하여 제안 분포 $W \\sim Q$ 를 목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에 근사하는 모수 방법론(Parametric Method)\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg}\\min{KL\\big[Q(W) \\parallel P(W \\mid \\mathcal{D})\\big]}  \\end{aligned}\\]                  목표 분포 $W \\mid \\mathcal{D} \\sim P$ 를 잘 설명하는 제안 분포 $W \\sim Q$ 를 탐색하는 것이 이상적\\[\\begin{aligned}  D_{KL}\\big[P(W \\mid \\mathcal{D}) \\parallel Q(W)\\big]  &amp;= \\mathbb{E}_{W \\mid \\mathcal{D} \\sim P}\\left[\\log{\\frac{P(W \\mid \\mathcal{D})}{Q(W)}}\\right]  \\end{aligned}\\]                    목표 분포 $W \\mid \\mathcal{D} \\sim P$ 에서 샘플을 추출할 수 없으므로 대안으로서 목표 분포로 잘 설명될 수 있는 제안 분포 $W \\sim Q$ 를 탐색함\\[\\begin{aligned}  D_{KL}\\big[Q(W) \\parallel P(W \\mid \\mathcal{D})\\big]  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W \\mid \\mathcal{D})}}\\right]  \\end{aligned}\\]                  Kullback-Leibler divergence segmentation:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W \\mid \\mathcal{D})}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W \\mid \\mathcal{D})}]  \\end{aligned}\\]        posterior is decomposed by Bayes’ theorem:\\[\\begin{aligned}  &amp;\\mathbb{E}_{W \\sim Q}[\\log{P(W \\mid \\mathcal{D})}]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{P(\\mathcal{D} \\mid W) \\cdot P(W)}{P(\\mathcal{D})}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]        Therefore:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\Big(\\mathbb{E}_{W \\sim Q}[\\log{p(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]\\Big)\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]        Some items are tied to the Kullback Leibler divergence:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W)]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{\\frac{Q(W)}{P(W)}}\\right]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)} - \\log{P(W)}]\\\\  &amp;= \\mathbb{E}_{W \\sim Q}[\\log{Q(W)}] - \\mathbb{E}_{W \\sim Q}[\\log{P(W)}]  \\end{aligned}\\]        Finally:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]  ELBO      증거 하한(Evidence Lower B ound): 변분 추론의 목적 함수로서 증거 $\\log{P(\\mathcal{D})}$ 의 하한\\[\\begin{aligned}  \\text{ELBO}  &amp;= \\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]          $\\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right]$: 기대 로그 우도로서 근사 분포의 데이터 적합도      $KL[Q(W) \\parallel P(W)]$: 근사 분포와 사전 분포 간 쿨백 라이블러 발산으로서 사전 신념 기준 근사 분포의 복잡도            Kullback-Leibler divergence segmentation:\\[\\begin{aligned}  &amp;KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]\\\\  &amp;= KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  \\end{aligned}\\]          $KL\\big[Q(W) \\parallel P(W)\\big]$ : Kullback-Leibler divergence between approx. and prior      $\\mathbb{E}_{W \\sim Q}\\left[\\log{P(\\mathcal{D} \\mid W)}\\right]$ : expected log likelihood, goodness of fit of the approx. dist. to the data      $\\log{P(\\mathcal{D})}$ : log marginal likelihood            best approx.:\\[\\begin{aligned}  KL[Q(W) \\parallel P(W)] - \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] + \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  &amp;=0  \\end{aligned}\\]        to summarize the evidence,\\[\\begin{aligned}  \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D})}]  &amp;\\ge \\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] - KL[Q(W) \\parallel P(W)]  \\end{aligned}\\]        since evidence is constant for the parameters,\\[\\begin{aligned}  &amp;\\min{KL[Q(W) \\parallel P(W \\mid \\mathcal{D})]}\\\\  &amp;\\Leftrightarrow \\max{\\mathbb{E}_{W \\sim Q}[\\log{P(\\mathcal{D} \\mid W)}] - KL[Q(W) \\parallel P(W)]}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Markov Chain Monte Carlo",
    "url": "/posts/MCMC/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Monte Carlo Simulation, Rejection Sampling, Markov Chain, Markov Chain Monte Carlo",
    "date": "2024-07-21 00:00:00 +0900",
    





    
    "snippet": "Markov Chain Monte Carlo      Markov Chain Monte Carlo(MCMC) : 이전 단계에서 추출한 표본을 기반으로 다음 단계의 표본을 순차로 추출하는 방법으로서, 차원이 높아질수록 표본 분포가 목표 분포로 수렴하는 속도가 지연되는 문제를 완화하나, 자기상관 문제에서 자유롭지 못하고 역전파 학습이 불가능함       ...",
    "content": "Markov Chain Monte Carlo      Markov Chain Monte Carlo(MCMC) : 이전 단계에서 추출한 표본을 기반으로 다음 단계의 표본을 순차로 추출하는 방법으로서, 차원이 높아질수록 표본 분포가 목표 분포로 수렴하는 속도가 지연되는 문제를 완화하나, 자기상관 문제에서 자유롭지 못하고 역전파 학습이 불가능함          Metropolis Hastings Method      Gibbs Sampling      Markov Chain      정의 : 어떤 시스템에 대하여 해당 시스템이 상태 공간 $S$ 에서 이산적인 시점($t=0,1,2,\\cdots$)에서만 상태 전이가 발생한다고 했을 때, 이 시스템이 마르코프 성질을 만족한다면, 이 시스템은 마르코프 체인이라고 볼 수 있음                  마르코프 성질 : 미래의 상태가 현재 상태에만 의존하며 과거의 상태는 고려하지 않는 성질\\[\\begin{aligned}  P(X_{n+1}=j \\mid X_{n}=i,X_{n-1}=i_{n-1},\\cdots,X_{0}=i_{0}) = P(X_{n+1}=j \\mid X_{n}=i)  \\end{aligned}\\]                  $X_{n}$ : 시점 $n$ 에서 시스템이 취하는 상태          $i,j \\in S$ : 특정 상태                          전이확률행렬(Transition Probability Matrix) : 각 상태에서 다른 상태로의 전이 확률을 나타내는 행렬\\[\\mathbf{P}_{n \\times n} = \\{p_{i,j} \\mid i,j \\in n, p_{i,j} \\in S\\}\\]                  $p_{i,j} \\in S$ : 상태 $i$ 에서 $j$ 로의 전이확률                  $0 \\le p_{i,j} \\le 1$          $\\sum_{j}{p_{i,j}}=1$ : 상태 $i$ 에서 다른 상태로 전이될 확률의 합은 1임                          정상확률(Steady-State Probability; $\\pi_{j}$) : 마르코프 체인이 장기적으로 상태 $j$ 를 취할 확률\\[\\pi_{j}=\\sum_{i}{\\pi_{i}\\cdot p_{i,j}}\\]          상태 $j$ 의 정상확률 $\\pi_{j}$ 는 상태 $i$ 에서 $j$ 로 전이할 확률의 기대값($E(x)=\\sum{x\\cdot P(x)}$)임            정상확률분포(Steady-State Probability Distribution; $\\overrightarrow{\\pi}$) : 마르코프 체인이 각 상태를 취할 확률이 시간에 따라 변하지 않고 일정하게 유지되는, 장기적인 확률 분포\\[\\overrightarrow{\\pi}=\\overrightarrow{\\pi}\\cdot\\mathbf{P}\\]  Metropolis Hastings Method      정의 : 목표 분포의 산 모양을 추정하기 위하여, 확률 밀도가 높은 지역일수록(봉우리가 높은 지역일수록) 그 근방에서 더 많은 조약돌을 모으는 방법    절차                  특정 위치에서 샘플링 시작하기\\[\\theta^{(t=0)}\\]                    근방의 조약돌 분포를 조사하여 새로 이동할 위치 $\\psi$ 탐색하기\\[\\psi=\\theta^{(t)}+\\varepsilon \\quad \\text{s.t.} \\quad \\varepsilon \\sim N(0, \\sigma^2)\\]                    새로운 조약돌이 해당 위치 $\\psi$ 에서 발견될 가능성을 조사하여 해당 위치를 수락할지 판단하기\\[\\theta^{(t+1)}  =\\begin{cases}\\begin{aligned}  \\psi, \\quad &amp;\\text{if} \\; u&lt;\\alpha(\\theta^{(t)},\\psi) \\quad \\text{for} \\quad u \\sim \\text{Uniform}(0,1)\\\\  \\theta^{(t)}, \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]                  목표 분포(Target Dist.) : 파라미터 $\\theta^{(t)}$ 의 사후 확률 분포\\[p(\\theta^{(t)}\\mid \\mathcal{D}) \\propto p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})\\]          $\\theta^{(t)}$ : $t$ 번째 파라미터      $p(\\theta^{(t)})$ : 파라미터 $\\theta^{(t)}$ 의 사전 확률 분포      $p(\\mathcal{D} \\mid \\theta^{(t)})$ : 파라미터 $\\theta^{(t)}$ 의 우도 함수            제안 분포(Proposal Dist.) : 시점 $t$ 에서 수락된 파라미터 샘플 $\\theta^{(t)}$ 에 기반하여 다음 시점 $t+1$ 에서 샘플링 위치 $\\psi$ 를 제안하는 분포\\[q(\\psi \\mid \\theta^{(t)}) = N(\\psi;\\theta^{(t)},\\sigma^2)\\]                  제안 분포가 $\\theta^{(t)}$ 을 중심으로 하는 종형 분포인 경우, 다음을 만족함\\[q(\\psi \\mid \\theta^{(t)}) = q(\\theta^{(t)} \\mid \\psi)\\]                  $q(\\psi \\mid \\theta^{(t)})$ : 시점 $t$ 에서 조약돌을 수집한 위치가 $\\theta^{(t)}$ 일 때, 다음 시점 $t+1$ 에서 조약돌을 수집할 위치가 $y$ 일 가능성          $q(\\theta^{(t)} \\mid \\psi)$ : 시점 $t-1$ 에서 조약돌을 수집한 위치가 $\\psi$ 일 때, 다음 시점 $t$ 에서 조약돌을 수집할 위치가 $\\theta^{(t)}$ 일 가능성                            $\\sigma^2$ 의 크기와 샘플링 수렴 여부의 관계                          수락 확률(Acception Prob.) : $\\psi$ 를 다음 시점 $t+1$ 에서 조약돌을 수집할 위치 $\\theta^{(t+1)}$ 로 수락할 확률\\[\\begin{aligned}  \\alpha(\\theta^{(t)}, \\psi)  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})} \\cdot \\frac{q(\\theta^{(t)} \\mid \\psi)}{q(\\psi \\mid \\theta^{(t)})}\\right]}\\\\  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})}\\right]} \\quad \\text{s.t.} \\quad \\psi \\mid \\theta^{(t)} \\sim N(\\theta^{(t)},\\sigma^2)\\\\  &amp;\\propto \\min{\\left[1, \\frac{p(\\psi) \\cdot p(\\mathcal{D} \\mid \\psi)}{p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})}\\right]}  \\end{aligned}\\]          $p(\\psi \\mid \\mathcal{D}) \\propto p(\\psi) \\cdot p(\\mathcal{D} \\mid \\psi)$ : 목표 분포 $p$ 에 대하여 샘플 $\\psi$ 의 사후 확률로서, 다음 시점에서 조약돌을 수집할 위치가 $\\psi$ 일 가능성      $p(\\theta^{(t)} \\mid \\mathcal{D}) \\propto p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})$ : 목표 분포 $p$ 에 대하여 $t$ 번째 파라미터 $\\theta^{(t)}$ 의 사후 확률로서, 다음 시점에서 조약돌을 수집할 위치가 $\\theta^{(t)}$ 일 가능성      Auto-Correlation      자기상관(Auto-Correlation) : 순차로 발생한 일련의 관측치 ${x^{(t)} \\mid t\\text{ is time point}}$ 간에 존재하는 상관관계              $x^{(t)} \\sim N(0,1) \\quad \\text{for} \\quad x^{(0)} = 0$      $y^{(t)} \\sim N(y^{(t-1)},1) \\quad \\text{for} \\quad y^{(0)} = 0$            자기상관계수(Auto-Correlation Coefficient) : 순서에 의미가 있는 데이터에서, 현재 시점의 값 $x^{(t)}$ 과 그 과거 또는 미래의 값 $x^{(t-k)}$ 간의 상관관계를 측정하는 지표\\[R(k)=\\text{Corr}(x^{(t)},x^{(t-k)})\\]                  $k$ : 시간 간격(Lag)                          솎아내기(Thinning) : 매 $k$ 번째 표본을 선택함으로써 자기상관을 줄이는 방법              통상 $k \\le 10$ 으로 설정함            선행 구간(Burn-in Period) : 수렴 상태에 도달하기 전, 초기값 $x^{(t=0)}$ 의 영향력을 최소화하기 위해 일부 반복을 무시하는 구간      Source  https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo"
  },
  
  {
    "title": "Monte Carlo Simulation",
    "url": "/posts/MC/",
    "categories": "BAYES, 2.posterior approx.",
    "tags": "Bayesian, Monte Carlo Simulation, Rejection Sampling",
    "date": "2024-07-20 00:00:00 +0900",
    





    
    "snippet": "Monte Carlo Simulation  몬테-카를로 시뮬레이션(Monte-Carlo Simulation): 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법example $\\Pi$  한 변의 길이가 2인 정사각형 내부에 점을 무작위로 찍었을 때, 그 점이 정사각형에 내접하는 원의 내부에 위치할 확률 실험을 전개하여...",
    "content": "Monte Carlo Simulation  몬테-카를로 시뮬레이션(Monte-Carlo Simulation): 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법example $\\Pi$  한 변의 길이가 2인 정사각형 내부에 점을 무작위로 찍었을 때, 그 점이 정사각형에 내접하는 원의 내부에 위치할 확률 실험을 전개하여, 원주율 $\\pi$ 를 추론하시오.  좌표평면 상에서 주어진 조건을 만족하는 원:          정의 \\(C = \\{ (x, y) \\mid x^2 + y^2 = r^2 \\}\\)      면적 $\\pi r^2 = \\pi \\quad (\\because 2r=2)$        좌표평면 상에서 주어진 조건을 만족하는 정사각형:          정의 \\(R = \\{ (x, y) \\mid -1 \\le x \\le 1, -1 \\le y \\le 1\\}\\)      면적 $(2r)^2=4$            정사각형 내부에 점을 무작위로 찍었을 때, 점이 원 내부에 위치할 가능성:\\[\\begin{aligned}  P((x,y) \\in C)  &amp;=\\frac{N_{circle}}{N}  =\\displaystyle\\frac{\\pi r^2}{(2r)^2}  \\end{aligned}\\]          $N$ : 실행 횟수      $N_{circle}$ : 성공 횟수(원 내부에 위치한 횟수)            몬테-카를로 시뮬레이션을 통한 $\\pi$ 추론값 도출:              실행 횟수(num)가 증가할수록 $\\pi$ 의 추론값이 $3.141592\\cdots$ 에 근접해감      Rejection Sampling      기각 샘플링(Rejection Sampling) : 제안 분포로부터 추출한 관측치를 기각하는 과정을 반복하여 제안 분포를 목표 분포와 유사한 형태로 만드는 방법        Target Dist.:\\[\\begin{aligned}  p(\\theta \\mid \\mathcal{D}) \\propto p(\\mathcal{D} \\mid \\theta) \\cdot p(\\theta)  \\end{aligned}\\]        Proposed Dist.:\\[\\begin{aligned}  q(\\theta)  \\end{aligned}\\]          $q(\\theta)$ must be similar in location and distribution to $p(\\theta \\mid \\mathcal{D})$      $p(\\theta \\mid \\mathcal{D}) \\le M \\cdot q(\\theta) \\quad \\text{for} \\quad \\forall \\theta$            Rejection Rule:\\[\\begin{aligned}  \\text{Accept} \\quad \\phi \\quad \\text{if} \\quad u \\le \\frac{p(\\phi \\mid \\mathcal{D})}{M \\cdot q(\\phi)} \\quad \\text{where} \\quad u \\sim \\text{Uniform}(0,1)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Bayes Action",
    "url": "/posts/Bayes_Action/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Bayesian, Optimization, Objective Function",
    "date": "2024-07-20 00:00:00 +0900",
    





    
    "snippet": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출...",
    "content": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출했다고 하자. 그렇다면 이들 중 무엇을 모수 $\\theta \\mid X$ 의 추정치 $\\hat{\\theta}$ 로 사용하는 것이 적절할까?      Bayes’ Risk : 사후확률분포 $P(\\theta \\mid X)$ 를 사용하여 계산된, 모수 $\\theta$ 에 대하여 추정치 $\\hat{\\theta}$ 를 선택할 때의 기대 손실(Expected Loss)\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;= \\int{\\text{Loss}(\\theta, \\hat{\\theta}) \\cdot P(\\theta \\mid X)}\\text{d}\\theta  \\end{aligned}\\]                  모수 $\\theta \\mid X$ 를 알 수 없으므로, $n$ 번의 샘플링을 통해 도출한 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)} \\sim P(\\theta \\mid X)$ 를 사용하여 근사함\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;\\approx \\frac{1}{N}\\sum_{i=1}^{N}{\\text{Loss}(\\theta^{(i)}, \\hat{\\theta})}  \\end{aligned}\\]                  Bayes Estimator : 모수 $\\theta$ 에 대하여, Bayes’ Risk 를 최소화시키는 추정치 $\\hat{\\theta}$\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathcal{R}(\\hat{\\theta})}  \\end{aligned}\\]                  Posterior Mean : Bayes’ Least Square (BLS) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[(\\theta-\\hat{\\theta})^2\\right]}\\\\  &amp;= \\mathbb{E}_{\\theta \\mid X}(\\theta)  \\end{aligned}\\]                    Posterior Median\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[ \\vert \\theta-\\hat{\\theta} \\vert \\right]}\\\\  &amp;= \\tilde{\\theta}  \\end{aligned}\\]                    Posterior mode : Maximum a posteriori (MAP) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[1_{\\hat{\\theta} \\ne \\theta}\\right]}\\\\  &amp;= \\text{arg} \\max_{\\theta}{P(\\theta \\mid X)}  \\end{aligned}\\]            Loss FunctionContinuous Prob. Variable      Squared Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= (\\theta - \\hat{\\theta})^2  \\end{aligned}\\]        Asymmetric Squared Error Loss\\[\\text{Loss}(\\theta, \\hat{\\theta})  = \\begin{cases}\\begin{aligned}  &amp;(\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} &lt; \\theta&amp;\\\\  &amp;c \\cdot (\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ge \\theta&amp;,\\;0&lt;c&lt;1  \\end{aligned}\\end{cases}\\]        Absolute Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  =  \\vert \\theta - \\hat{\\theta} \\vert   \\end{aligned}\\]  Discrete Prob. Variable      Zero-One Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= 1_{\\hat{\\theta} \\ne \\theta}\\\\  &amp;= \\begin{cases}\\begin{aligned}  &amp;0 \\quad &amp;\\text{if}\\;\\hat{\\theta} = \\theta\\\\  &amp;1 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ne \\theta  \\end{aligned}\\end{cases}  \\end{aligned}\\]        Binary Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\left[\\hat{\\theta} \\cdot \\log{\\theta}+(1-\\hat{\\theta})\\cdot\\log{(1-\\theta)}\\right] \\quad \\text{for}\\;&amp;\\hat{\\theta}\\in\\{0,1\\},\\\\&amp;\\theta\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 베르누이 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Bernoulli}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\theta^{\\hat{\\theta}} \\cdot (1-\\theta)^{1-\\hat{\\theta}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\left[\\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}\\right]  \\end{aligned}\\]                  Categorical Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\sum_{i=1}^{K}{\\hat{\\theta}_{i}\\cdot\\log{\\theta_{i}}} \\quad \\text{for}\\;&amp;\\hat{\\theta}_{i}\\in\\{0,1\\},\\\\&amp;\\theta_{i}\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 카테고리 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Categorical}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\prod_{i=1}^{K}{\\theta_{i}^{\\hat{\\theta}_{i}}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Prior Determination",
    "url": "/posts/Prior/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Bayesian",
    "date": "2024-07-19 00:00:00 +0900",
    





    
    "snippet": "Prior Determination      사전 확률 분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후 확률 분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후 확률 분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전 확률 분포의 가정에 위...",
    "content": "Prior Determination      사전 확률 분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후 확률 분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후 확률 분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전 확률 분포의 가정에 위배된다는 것을 의미한다. 그래서 이전으로 돌아가 사전 확률 분포가 외부 정보와 조화되도록 변경하는 것이 적절하다. (Andrew Gelman)            관측치 갯수($N$)가 많아질수록 사전 확률 분포의 영향력이 약화됨              동전의 미래 행위에 대한 당신의 견해가 이웃 사람의 견해와 크게 다르더라도, 당신의 견해와 이웃 사람의 견해는 일상적으로 실험적인 던지기의 긴 연속에 베이즈의 정리를 적용하여 변형되어 거의 구별할 수 없게 될 것이다(Edwards, Lindman, and Savage, 1963, p.197). 즉, 다양한 신념들은 충분한 근거가 주어지면 간주관적으로 수렴하며, 이 일치를 객관적 신념 상태로 해석할 수 있다.      Non-Informative Dist.      Principle of Indifference : 가능한 모수 공간에서 특별히 어떤 값을 선호하지 않는 원칙에 따라, 관측치가 사후분포에 미치는 영향력을 최대화하는 방법          무차별의 원리가 주장하는 것은 만약 우리의 관심의 대상이 여러 가지 대안 중 어느 것보다 더 예측할 만한 어떠한 알려진 이유가 없다면 그러한 지식에 상대적으로 이러한 대안 각각에 대한 주장들은 동일한 확률을 갖는다는 점이다(Keynes, 1921, p.42).    \\[\\begin{aligned}  X \\mid \\theta &amp;\\sim \\text{Binomial}(n,\\theta)\\\\  \\theta &amp;\\sim \\text{Uniform}(0,1)  \\end{aligned}\\]  Transformation Variant of Flat Prior Dist.      모수 $\\theta$ 가 균등 분포 $\\text{Uniform}(0,1)$ 를 따르는 객관적인 사전확률이라고 하자\\[\\theta \\sim \\text{Uniform}(0,1)\\]        모수 $\\theta$ 를 $\\log{\\displaystyle\\frac{\\theta}{1-\\theta}}$ 로 변수 변환한 $\\psi$ 는 로지스틱 분포 $\\text{Logistic}(0,1)$ 을 따르게 됨\\[\\begin{aligned}  \\psi  &amp;= g(\\theta)\\\\  &amp;= \\log{\\frac{\\theta}{1-\\theta}}\\\\ \\\\  \\theta  &amp;= g^{-1}(\\psi)\\\\  &amp;= \\frac{\\text{exp}(\\psi)}{1+\\text{exp}(\\psi)}\\\\ \\\\  f_{\\psi}(\\psi)  &amp;= f_{\\theta}(g^{-1}(\\psi)) \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi)\\right\\vert \\\\  &amp;= 1 \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi) \\right\\vert \\quad (\\because \\theta \\sim \\text{Uniform}(0,1))\\\\  &amp;= \\frac{\\text{exp}(\\psi)}{(1+\\text{exp}(\\psi))^{2}}\\\\  \\\\  \\therefore \\psi &amp;\\sim \\text{Logistic}(0,1)  \\end{aligned}\\]        즉, 모수 $\\theta$ 의 변수 변환에 의하여 사전분포의 객관성이 상실되었음                  변환 전 : $\\theta \\sim \\text{Uniform}(0,1)$                            변환 후 : $\\psi \\sim \\text{Logistic}(0,1)$                    Jacobian Change of Variables      자코비안 변수 변환(Jacobian Change of Variables) : 기본 변수 $\\overrightarrow{\\theta}$, 변환 변수 $\\overrightarrow{\\psi}=g(\\overrightarrow{\\theta})$ 및 그 밀도 함수 $f$ 에 대하여, 다음을 만족하는 변수 변환 방법\\[\\begin{aligned}  f_{\\psi}\\left(\\psi\\right)  &amp;=f_{\\theta}\\left(\\theta\\right) \\cdot \\left\\vert \\frac{1}{\\text{det}\\left(\\mathbb{J}\\right)} \\right\\vert\\\\  \\overrightarrow{\\theta}  &amp;= \\begin{pmatrix} \\theta_{1} &amp; \\theta_{2} &amp; \\cdots &amp; \\theta_{n} \\end{pmatrix}\\\\  \\overrightarrow{\\psi}  &amp;= \\begin{pmatrix} \\psi_{1} &amp; \\psi_{2} &amp; \\cdots &amp; \\psi_{m} \\end{pmatrix}  \\end{aligned}\\]                  자코비안 행렬(Jacobian Matrix; $\\mathbb{J}$) : 다변수 벡터 값 함수의 모든 편미분을 모아 만든 행렬\\[\\begin{aligned}  \\mathbb{J}  = \\frac{\\partial \\psi}{\\partial \\theta}  = \\begin{pmatrix}  \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_n}\\\\  \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_n}  \\end{pmatrix}  \\end{aligned}\\]                  변환 변수 $\\psi=g(\\theta)$ 가 기본 변수에 대하여 (확률) 밀도의 불변성을 보장한다고 하자\\[\\begin{aligned}  P(a \\le \\theta \\le b)  &amp;= P(g(a) \\le \\psi \\le g(b))\\\\  \\int_{a}^{b}{f_{\\theta}(\\theta)d\\theta}  &amp;= \\int_{g(a)}^{g(b)}{f_{\\psi}(\\psi)d\\psi}  \\end{aligned}\\]        기본 변수의 단위당 밀도와 변환 변수의 단위당 밀도가 동일함\\[f_{\\theta}(\\theta) \\cdot \\Delta\\theta  =f_{\\psi}(\\psi) \\cdot \\Delta\\psi\\]        $\\because \\Delta\\psi=\\displaystyle\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta$\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\Delta\\psi  &amp;= f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)\\\\  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta  \\end{aligned}\\]        따라서 자코비안 변수 변환은 밀도의 불변성을 보장함\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta\\\\  f_{\\psi}(\\psi) \\cdot \\left\\vert \\frac{\\Delta\\psi}{\\Delta\\theta} \\right\\vert  &amp;= f_{\\theta}(\\theta)\\\\  \\therefore f_{\\psi}(\\psi)  &amp;= f_{\\theta}(\\theta) \\cdot \\left\\vert \\frac{\\Delta\\theta}{\\Delta\\psi} \\right\\vert  \\end{aligned}\\]  Jeffreys Priors      Jeffreys Priors : 모수 공간에 대해 불변성을 보장함으로써 변수 변환 후에도 객관성을 보존하는 사전분포\\[\\pi_{J}(\\theta) \\propto \\sqrt{\\mathbf{I}(\\theta)}\\]                  $\\sqrt{\\mathbf{I}(\\theta)}$ : Fisher Information\\[\\begin{aligned}  \\mathbf{I}(\\theta)  = \\mathbb{E}\\left[\\frac{\\text{d}^{2}}{\\text{d}\\theta^{2}}\\log{\\mathcal{L}(\\theta)}\\right]  = \\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta}\\right)^{2}\\right]  \\end{aligned}\\]                  변수 $\\theta$ 에 대한 확률분포가 그 피셔 정보의 자승근에 비례하도록 정의되었다고 하자\\[p(\\theta) \\propto \\sqrt{I(\\theta)}\\]        함수 $g$ 를 통해 변수 $\\theta$ 를 변수 $\\psi$ 로 변환한다고 하자\\[\\psi = g(\\theta)\\]        변환 변수 $\\psi$ 의 확률분포 또한 그 피셔 정보의 자승근에 비례하게 됨\\[p(\\psi) \\propto \\sqrt{I(\\psi)}\\]        미분 법칙에 의해 다음이 성립함\\[\\frac{\\partial \\log{\\mathcal{L}(\\psi)}}{\\partial \\psi}  =\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi}\\]        변환 변수 $\\psi$ 의 피셔 정보 $I(\\psi)$ 는 다음과 같음\\[\\begin{aligned}  I(\\psi)  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi} \\right)^{2}\\right]\\\\  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\theta}\\right)^{2}\\right] \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}\\\\  &amp;=I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}  \\end{aligned}\\]        따라서 변환 변수 $\\psi$ 의 확률분포는 기본 변수 $\\theta$ 의 확률분포의 형태를 유지하되,자코비안 행렬식 $\\left\\vert \\displaystyle\\frac{d\\theta}{d\\psi} \\right\\vert$ 로 보정된 양상을 띠게 됨\\[\\begin{aligned}  p(\\psi) &amp;\\propto \\sqrt{I(\\psi)}\\\\  &amp;= \\sqrt{I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}}\\\\  &amp;= \\sqrt{I(\\theta)} \\cdot \\left\\vert \\frac{d\\theta}{d\\psi} \\right\\vert  \\end{aligned}\\]  Empirical Bayes      실증적 베이즈(Empirical Bayes): 사전 확률 분포를 빈도주의적으로 접근하여 추정하는 방법으로서, 사전 정보가 많지 않지만 관측치가 풍부한 경우 유용하나, 사전 정보가 관측하기 이전에 정의되어야 한다는 원칙에 위배됨          그러므로 하나의 의견이 주어지면, 우리는 진위에 근거하여 그것을 칭찬하거나 책망할 수 있을 뿐이다. 특정한 형태의 습관이 주어지면 우리는 습관이 산출하는 신념도가 그것이 진리로 이끄는 실제 비율에 근접하거나 멀어지는가에 따라서 칭찬하거나 책망할 수 있다. 그렇다면 우리는 의견을 산출하는 습관들을 칭찬하거나 책망하는 것으로부터 파생적으로 의견들을 칭찬하거나 책망할 수 있다(Ramsey, 1926, p.51).            example General Model\\[\\begin{aligned}  X_{i} \\mid \\theta &amp;\\sim N(\\theta, 5^2)\\\\  \\theta &amp;\\sim N(\\mu, \\sigma^2)  \\end{aligned}\\]        Objective Prior:\\[\\theta \\sim N(0, 100^2)\\]        Subjective Prior:\\[\\theta \\sim N(\\mu_{0}, \\sigma_{0}^{2})\\]        Empirical Bayes:\\[\\theta \\sim N\\left(\\frac{1}{N}\\sum_{i=1}^{N}{X_i}, \\frac{1}{N-1}\\sum_{i=1}^{N}{(X_i-\\mu)^2}\\right)\\]  Conjugate Priors      켤레 사전 분포(Conjugate Priors): 관측치 $X$ 와 그 확률분포 \\(\\mathcal{L}_{\\alpha}\\) 에 대하여, 다음의 조건을 만족하는 사전확률분포 \\(\\pi_{\\beta}\\) 가 존재하는 경우, \\(\\pi_{\\beta}\\) 를 \\(\\mathcal{L}_{\\alpha}\\) 의 켤레 사전 분포(Conjugate Prior Dist.)라고 함\\[\\begin{aligned}  \\pi_{\\beta^{\\prime}}(\\theta \\mid X) \\propto \\mathcal{L}_{\\alpha}(\\theta) \\cdot \\pi_{\\beta}(\\theta)  \\end{aligned}\\]          $\\mathcal{L}_{\\alpha}(\\theta)$ : 모수 $\\theta$ 의 우도 함수      $\\pi_{\\beta}(\\theta)$ : 모수 $\\theta$ 의 사전 확률      $\\pi_{\\beta^{\\prime}}(\\theta \\mid X)$ : 모수 $\\theta$ 의 사후 확률      $\\alpha,\\beta,\\beta^{\\prime}$ : 모수들의 집합            예시                            Likelihood          Prior          Posterior                                      $\\text{Bernoulli}(\\theta)$          $\\text{Beta}(\\alpha, \\beta)$          $\\text{Beta}\\Big(\\alpha + n \\cdot \\bar{x}, \\beta + n\\cdot(1-\\bar{x})\\Big)$                          $\\text{Poisson}(\\lambda)$          $\\text{Gamma}(\\alpha, \\beta)$          $\\text{Gamma}(\\alpha+ n \\cdot \\bar{x}, \\beta+n)$                          $\\text{Multinomial}(\\theta)$          $\\text{Dirichlet}(\\alpha)$          $\\text{Dirichlet}(\\alpha+n \\cdot \\bar{x})$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\sigma^2$          $N(\\mu_0, \\sigma_0^2)$          $N\\Bigg( \\displaystyle\\frac{\\displaystyle\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n \\cdot \\bar{x}}{\\sigma^2}}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\displaystyle\\frac{n}{\\sigma^2}}, \\displaystyle\\frac{1}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}} \\Bigg)$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\mu$          $\\text{Inv-Gamma}(\\alpha, \\beta)$          $\\text{Inv-Gamma}\\Bigg(\\alpha + \\displaystyle\\frac{n}{2}, \\beta + \\displaystyle\\frac{n \\cdot (\\bar{x} -\\mu)^2}{2}\\Bigg)$                          $N(\\mu, \\Sigma)$  $\\text{known} \\; \\mu$          $\\text{Inv-Wishart}(\\nu_{0}, S_{0})$          $\\text{Inv-Wishart}(\\nu_{0}+n, S_{0} + n \\cdot \\bar{S})$                    "
  },
  
  {
    "title": "Frequentist vs. Bayesian",
    "url": "/posts/Freq_Bayes/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Bayesian, Optimization, MLE, Bayes' Theorem",
    "date": "2024-07-18 00:00:00 +0900",
    





    
    "snippet": "Frequentist vs. Bayesianism      귀납법(Induction): 관측된 데이터로부터 일반화된 진술(혹은 모형)을 도출하는 방법                            관점          진리          설명                                      존재론(Ontology)         ...",
    "content": "Frequentist vs. Bayesianism      귀납법(Induction): 관측된 데이터로부터 일반화된 진술(혹은 모형)을 도출하는 방법                            관점          진리          설명                                      존재론(Ontology)          사실적 진리(Factual Truth)          실제 세계에서 어떤 일이 일어났는가?                          실증론(Positivism)          빈도적 진리(Frequentist Truth)          반복된 시행에서 수렴하는 비율                          인식론(Epistemology)          인식적 진리(Epistemic Truth)          정보에 따라 믿음이 수렴해가는 대상                            결정론적 귀납화(Determinism): 일반화된 진술의 불확실성을 고려하지 않는 귀납법                  입력값이 $X$ 이면 출력값은 $Y$이다.                    확률론적 귀납화(Probability Theory): 일반화된 진술의 불확실성을 확률 분포로써 정량화하는 귀납법                  반복 실험 결과, $p$ 의 비율로 입력값이 $X$ 이면 결과값이 $Y$ 였다.          입력값이 $X$ 이면 결과값이 $Y$ 임을 $p$ 정도로 신뢰할 수 있다.                      불확실성(Uncertainty): 어떠한 사건에 대하여 확신할 수 없는 상태          우발적 불확실성(Aleatoric Uncertainty): 시스템이 본질적으로 확률적이기에 발생하는 불확실성                  표본 추출의 우발성(Frequentist)          데이터 생성 과정상의 무작위성(Bayesianism)                    인식적 불확실성(Epistemic Uncertainty): 연구자가 충분한 정보를 확보하지 못했기에 발생하는 불확실성                  모형의 구조적 불완전성          모형 가정의 부적합          데이터 희소성          데이터 신호의 모호성          데이터의 모집단 대표성 부족 등                          확률(Probability): 불확실성을 정량적으로 표현하는 도구                                       빈도주의          베이즈주의                                      관점          실증론          인식론                          목표          모수의 정체          모수 인지 수준                          원천          모수 추정 과정          모수에 대한 무지                          불확실성          우발적 불확실성          인식적 불확실성                          준거 집합          다수 사건 결과          단일 사건 진술                          확률 해석          상대 빈도          신념도                          표현          신뢰 구간과 신뢰 수준          사후 확률 분포                    Optimization Methods      최우추정(Maximum Likelihood Estimation) : 우도를 최대화하는 모수의 추정치를 탐색하는 방법\\[\\begin{aligned}  \\max_{\\theta}{p\\left(\\mathcal{D} \\mid \\theta \\right)}  \\end{aligned}\\]          우도(Likelihood): 특정 모수 하에서 사건이 관찰되는 상대 빈도      신뢰 구간(Confidence Interval): 모수를 포함할 것으로 기대되는 구간      신뢰 수준(Confidence Level): 여러 신뢰 구간 중 모수를 포함하는 신뢰 구간의 비율            베이즈 정리(Bayes’ Theorem) : 모수의 사후 확률 분포를 추정하는 방법\\[\\begin{aligned}  \\underbrace{p\\left(\\theta \\mid \\mathcal{D} \\right)}_{\\text{Posterior}}  = \\underbrace{\\frac{p\\left(\\mathcal{D} \\cap \\theta\\right)}{p\\left(\\mathcal{D}\\right)}}_{\\begin{array}{c} \\text{Conditional}\\\\ \\text{Probability} \\end{array}}  = \\frac{\\overbrace{p\\left(\\mathcal{D} \\mid \\theta \\right)}^{\\text{Likelihood}} \\cdot \\overbrace{p\\left(\\theta\\right)}^{\\text{Prior}}}{\\underbrace{p\\left(\\mathcal{D}\\right)}_{\\text{Evidence}}}  \\end{aligned}\\]          사후 확률 분포(Posterior Probability Distribution): 모수에 대한 인식적 불확실성      우도(Likelihood):  데이터에 대한 모수의 상대적 적합성      사전 확률 분포(Prior Probability Distribution): 모수에 대한 사전 정보      증거(Evidence): 데이터가 관찰될 확률      Sample Size: The Necessity for Bayesian  표본의 크기는 결코 크지 않다. 만일 N이 충분한 추정을 얻기에 부족하다면 더 많은 데이터(또는 더 많은 가정)을 확보해야 한다. 그러나 일단 N이 충분히 크다면 데이터를 나눠 더 많은 것(가령 여론조사에서 전국적으로 훌륭한 추정을 얻었다면 남과 여, 지역별, 연령대별 그룹 등으로 나눠 추정할 수 있다)을 얻을 수 있다. N은 충분하지 않다. 만약 충분하더라도 여러분은 이미 더 많은 데이터가 필요한 다음 문제에 직면하기 때문이다. (Andrew Gelman)      대수의 법칙(Law of Large Numbers): 무작위 실험을 반복해서 수행할수록 관측된 상대적 빈도(추정치)가 이론적 확률(모수)에 가까워진다는 법칙        작은 수의 혼란(Law of Small Numbers): 적은 표본에서도 대수의 법칙이 적용될 것이라고 잘못 가정하거나 소규모 데이터로 도출된 결과를 일반화하려는 오류        If the sample size is sufficient,          모수가 특정 값으로 발생할 것이라는 믿음은 신규 관측치에 의해 끊임없이 갱신되어 참값을 중심으로 집중됨. 이는 빈도주의 추론과 베이지안 추론의 결과가 장기적으로 일치함을 의미함.    \\[\\lim_{n \\to \\infty} P(\\theta \\mid X_{1}, X_{2}, \\cdots, X_{n}) \\to \\mathcal{N}(\\theta_{\\text{true}}, \\frac{\\sigma^2}{n})\\]        If the sample size is not large enough,                  빈도주의(Frequentist): 신뢰 수준을 상향 조정하여 모수 추정 과정상의 불확실성을 줄이고자 함\\[\\text{CI}_{\\theta}=\\bar{X}\\pm Z\\cdot\\frac{\\sigma}{\\sqrt{n}}\\]                    베이즈주의(Bayesianism): 모수의 불확실성을 확률로써 표현함\\[p\\left(\\theta \\mid \\mathcal{D}\\right)=\\frac{p\\left(\\mathcal{D} \\mid \\theta\\right) \\cdot p\\left(\\theta\\right)}{p\\left(\\mathcal{D}\\right)}\\]            "
  },
  
  {
    "title": "ExpoMF",
    "url": "/posts/ExpoMF/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, Implicit Feedback, OCCF, Pointwise Approach, Exposure Probability, Bayesian",
    "date": "2024-07-17 00:00:00 +0900",
    





    
    "snippet": "Previous Research      Problems with implicit feedback          암시적 피드백 하에서는 관측된 아이템을 선호 아이템, 미관측된 아이템을 비선호 아이템으로서 추정함. 하지만 관측 행위는 선호 외에 불호와 우연성을, 미관측 행위는 비선호 외에 미노출이라는 경우의 수를 포괄하고 있음. 따라서 미관측된 아이템...",
    "content": "Previous Research      Problems with implicit feedback          암시적 피드백 하에서는 관측된 아이템을 선호 아이템, 미관측된 아이템을 비선호 아이템으로서 추정함. 하지만 관측 행위는 선호 외에 불호와 우연성을, 미관측 행위는 비선호 외에 미노출이라는 경우의 수를 포괄하고 있음. 따라서 미관측된 아이템을 단순히 비선호 아이템으로 치부하는 것은 무리가 있음.            WMF(Weighted Matrix Factorization) : Confidence Weighted Approach\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}, \\overrightarrow{\\mathbf{q}}  &amp;= \\text{arg}\\min_{\\Theta}{\\sum_{(u,i)}{c_{u,i} \\cdot \\left(r_{u,i} - \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right)^{2} + \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}}}  \\end{aligned}\\]          \\(c_{u,i}:=1+\\alpha \\cdot r_{u,i}\\) : Confience Weight            BPR(Bayesian Personalized Ranking) : Pairwise Learning Approach\\[\\begin{aligned}  \\Theta  &amp;= \\text{arg}\\min_{\\Theta}{\\sum_{(u,i,j)}{-\\ln{\\sigma\\left(\\hat{r}_{u,i} - \\hat{r}_{u,j}\\right)} + \\lambda_{\\Theta}\\Vert\\Theta\\Vert^{2}}}  \\end{aligned}\\]  EXMF  EXMF(Exposure Matrix Factorization) : 미관측 아이템에 대한 사용자의 노출 여부를 명시적으로 모델링하는 방법론          WMF : 미관측 항목에 낮은 신뢰도를 부여하고 있으나, 이는 모든 미관측 항목을 단순히 하향 가중하는 직관적인 접근법임      BPR : 관측 항목과 미관측 항목 간 순위에 격차를 벌리고 있으나, 이는 미관측 원인 중 하나인 노출 여부를 명시적으로 다루는 접근법이 아님      EXMF : 사용자 노출 여부를 명시적으로 모델링함으로써 사용자가 관측하지 않은 이유를 설명하고자 함      How to Modeling      사용자 $i$ 가 아이템 $j$ 를 클릭할 가능성\\[\\begin{aligned}  p\\left(r_{i,j},y_{i,j} \\mid \\mu_{i,j}, \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)  &amp;= \\underbrace{p\\left(y_{i,j} \\mid \\mu_{i,j}\\right)}_{\\text{Exposure Prob.}} \\cdot \\overbrace{p\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)^{y_{i,j}}}^{\\text{Click Prob. under Exposure}} \\cdot \\underbrace{\\mathbf{I}\\left[r_{i,j}=0\\right]^{1-y_{i,j}}}_{\\text{non-Click Prob. under non-Exposure}}  \\end{aligned}\\]          \\(r_{i,j} = \\big\\{1,0\\big\\} \\in \\mathbf{R}_{M \\times N}\\) : 클릭 변수      \\(y_{i,j} = \\big\\{1,0\\big\\} \\in \\mathbf{Y}_{M \\times N}\\) : 노출 변수            \\(p\\left(y_{i,j} \\mid \\mu_{i,j}\\right)\\) : 사용자 $i$ 가 아이템 $j$ 에 노출될 가능성\\[\\begin{aligned}  y_{i,j} &amp;\\sim \\text{Bernoulli}\\left(\\mu_{u,i}\\right)  \\end{aligned}\\]        \\(p\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)^{y_{i,j}}\\) : 사용자 $i$ 가 아이템 $j$ 에 노출되었을 때, 아이템을 클릭할 가능성\\[\\begin{aligned}  r_{i,j} \\mid y_{i,j}=1 &amp;\\sim \\mathcal{N}\\left(\\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)  \\end{aligned}\\]        \\(\\mathbf{I}\\left[r_{i,j}=0\\right]^{1-y_{i,j}}\\) : 사용자 $i$ 가 아이템 $j$ 에 노출되지 않았을 때, 아이템을 클릭하지 않을 가능성\\[\\begin{aligned}  r_{i,j} \\mid y_{i,j}=0  &amp;\\sim \\delta_{0}\\\\  &amp;\\approx \\mathcal{N}\\left(\\epsilon, \\lambda^{-1}\\right)   \\end{aligned}\\]          $\\delta_{x=k}: p\\left(x=k\\right)=1$            Objective Function\\[\\begin{aligned}  \\mathcal{J}  &amp;= \\sum_{(i,j)}{\\log{p\\left(r_{i,j},y_{i,j} \\mid \\mu_{i,j}, \\overrightarrow{\\mathbf{u}}_{i}, \\overrightarrow{\\mathbf{v}}_{j} ; \\lambda\\right)}}\\\\  &amp;= \\sum_{(i,j)}{\\log{\\text{Bernoulli}\\left(y_{i,j}\\mid \\mu_{i,j}\\right)} + y_{i,j} \\cdot \\log{\\mathcal{N}\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)} + (1-y_{u,i}) \\cdot \\cancel{\\log{\\mathbf{I}\\left[r_{i,j}=0\\right]}}}\\\\  &amp;= \\sum_{(i,j)}{\\log{\\text{Bernoulli}\\left(y_{i,j}\\mid \\mu_{i,j}\\right)} + y_{i,j} \\cdot \\log{\\mathcal{N}\\left(r_{i,j} \\mid \\overrightarrow{\\mathbf{u}}_{i} \\cdot \\overrightarrow{\\mathbf{v}}_{j}, \\lambda^{-1}\\right)}}  \\end{aligned}\\]        Maximum Likelihood Estimation\\[\\begin{aligned}  \\mu, \\overrightarrow{\\mathbf{u}}, \\overrightarrow{\\mathbf{v}}  &amp;= \\text{arg}\\max_{\\Theta}{\\mathcal{J}}  \\end{aligned}\\]  Optimizer  E-M Algorithm : 잠재 변수의 기대값을 추정하고, 이를 바탕으로 학습 파라미터를 최적화하는 방법론          E-Step(Expectation Step) : 잠재 변수의 기대값 추정      M-Step(Maximization Step) : 잠재 변수의 기대값 추정치를 바탕으로 학습 파라미터 갱신            E-Step(Expectation Step) : 사용자 $i$ 가 아이템 $j$ 에 노출되었는지 여부의 기대값 $\\mathbb{E}\\left[y_{i,j}=1\\right]$ 으로서 사용자가 특정 아이템에 노출될 가능성의 추정치\\[\\begin{aligned}  \\mathbb{E}\\left[y_{i,j}=1\\right]  &amp;= p\\left(y_{i,j}=1 \\mid r_{i,j}\\right)\\\\  &amp;= \\frac{\\overbrace{p\\left(r_{i,j} \\mid y_{i,j}=1\\right)}^{\\text{Likelihood}} \\cdot \\overbrace{p\\left(y_{i,j}=1 \\mid \\mu_{i,j}\\right)}^{\\text{Prior}}}{\\underbrace{p\\left(r_{i,j} \\mid \\mu_{i,j}\\right)}_{\\text{Posterior}}}\\\\  &amp;= \\frac{\\mu_{i,j} \\cdot \\mathcal{N}\\left(r_{u,i} \\mid \\overrightarrow{\\mathbf{p}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}, \\lambda^{-1}\\right)}{\\mu_{i,j} \\cdot \\mathcal{N}\\left(r_{u,i} \\mid \\overrightarrow{\\mathbf{p}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}, \\lambda^{-1}\\right) + \\left(1 - \\mu_{i,j}\\right)}  \\end{aligned}\\]        M-Step(Maximization Step) : User and Item-Latent Factors updated using ALS                  User-Latent Factor\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{i}  \\leftarrow \\left(\\lambda \\sum_{j}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot \\overrightarrow{\\mathbf{v}}_{j} \\otimes \\overrightarrow{\\mathbf{v}}_{j}} + \\gamma_{\\Theta}\\mathbf{I}\\right)^{-1} \\left(\\lambda \\sum_{j}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot r_{i,j} \\cdot \\overrightarrow{\\mathbf{v}}_{j}}\\right)  \\end{aligned}\\]                    Item-Latent Factor\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{j}  \\leftarrow \\left(\\lambda \\sum_{i}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot \\overrightarrow{\\mathbf{u}}_{i} \\otimes \\overrightarrow{\\mathbf{u}}_{i}} + \\gamma_{\\Theta}\\mathbf{I}\\right)^{-1} \\left(\\lambda \\sum_{i}{\\mathbb{E}\\left[y_{i,j}=1\\right] \\cdot r_{i,j} \\cdot \\overrightarrow{\\mathbf{u}}_{i}}\\right)  \\end{aligned}\\]            "
  },
  
  {
    "title": "Bayesian Framework",
    "url": "/posts/Bayesian_Framework/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Epistemology, Bayesian, Bayes' Theorem",
    "date": "2024-07-17 00:00:00 +0900",
    





    
    "snippet": "Causal Inference      역추리 문제(Inverse Inference Problem) : 다양한 원인 중 하나로부터 발생했음이 틀림없는 한 가지 사건이 발생했다고 가정하고, 그 원인들이 존재할 각각의 확률을 추리하는 문제(이영의, 2015, p.62)\\[\\begin{aligned}  P(\\text{cause} \\mid \\text{outc...",
    "content": "Causal Inference      역추리 문제(Inverse Inference Problem) : 다양한 원인 중 하나로부터 발생했음이 틀림없는 한 가지 사건이 발생했다고 가정하고, 그 원인들이 존재할 각각의 확률을 추리하는 문제(이영의, 2015, p.62)\\[\\begin{aligned}  P(\\text{cause} \\mid \\text{outcome})  = \\frac{P(\\text{cause} \\wedge \\text{outcome})}{P(\\text{outcome})}  = \\frac{P(\\text{outcome} \\mid \\text{cause}) \\cdot P(\\text{cause})}{P(\\text{outcome})}  \\end{aligned}\\]          어떤 알려지지 않은 사건($Z$)이 발생하고($p$) 실패한 횟수($n-p$)가 주어졌을 때, 하나의 시행에서 그 사건이 발생할 확률($\\theta$)이 지정될 수 있는 두 가지 확률($\\alpha, \\beta$) 사이에 있을 기회가 요청된다($\\alpha &lt; \\theta &lt; \\beta$). (Bayes, 1763, p.376)              베이즈 정리는 주어진 환경에서 하나의 사건($Z$)에 대해 동일한 환경에서 그것이 어떤 횟수만큼 발생했고($p$) 어떤 다른 횟수만큼 발생하는 데 실패했다는 것을($n-p$) 제외한 그 밖의 것에 대해 아무 것도 알지 못한다는 가정에서($\\theta \\sim \\text{Uniform}$) 해당 사건이 발생할 확률($\\theta$)을 판단할 방법을 찾는 일이다. (Price, 1763, 서문)            직접 확률(Direct Probability; $P(B \\mid A)$) : 시행의 성질이 먼저 규정되고($P(A)$) 이어서 시행에서($P(B \\mid A)$) 하나 또는 그 이상의 가능한 결과가 발생할 확률($P(A \\wedge B)$) (이영의, 2015, p.62)\\[\\begin{aligned}  P(B \\mid A)  &amp;= \\frac{P(A \\wedge B)}{P(A)}  \\end{aligned}\\]        역확률(Inverse Probability; $P(A \\mid B)$) : 이미 시행의 결과가 제시되고($P(B)$) 그 다음 실제로 실행된 시행이($P(B \\mid A)$) 가능한 시행 중($P(B)=\\int{P(B \\mid A) \\cdot P(A)\\text{d}A}$) 특정 시행에 해당할 확률($P(A \\wedge B)$) (이영의, 2015, p.62)\\[\\begin{aligned}  P(A \\mid B)  &amp;= \\frac{P(A \\wedge B)}{P(B)}  \\end{aligned}\\]  Bayes’ Billiard Table Analogy  당구대 $ABCD$ 를 가정하자. 공 $\\mathcal{W}, \\mathcal{O}$ 가 그 위에 굴려지면 어떤 하나의 동일한 부분에 정지할 동일한 확률을 가진다. $\\mathcal{W}$ 으로 선분 $OS$ 의 위치가 결정된다. 그 우측 또는 좌측에 $\\mathcal{O}$ 이 정지하는가에 따라서 사건 $Z$ 의 발생 또는 실패가 결정된다. $\\mathcal{O}$ 를 연속하여 $n$ 회 던진 결과 $p$ 회만큼 우측에 정지했음이 관찰되었다. 이때 $AD$ 와 $OS$ 사이의 미지의 거리 $\\theta$ 가 두 가지 값 $\\alpha, \\beta$ 사잇값을 취할 확률은?      공 $\\mathcal{W}$ 가 던져지기 이전에 $\\theta$ 가 $\\alpha, \\beta$ 사이에 있고,사건 $Z$ 가 $n$ 번의 시행에서 $p$ 번 발생하고 $n-p$ 번 실패할 확률:\\[\\begin{aligned}  P(\\alpha &lt; \\theta &lt; \\beta, X=p)  &amp;= \\int_{\\alpha}^{\\beta}{\\binom{n}{p} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}  \\end{aligned}\\]        사건 $Z$ 가 $p$ 번 발생할 확률:\\[\\begin{aligned}  P(X=p)  &amp;= P(0 &lt; \\theta &lt; 1, X=p)\\\\  &amp;= \\int_{0}^{1}{\\binom{n}{p} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}  \\end{aligned}\\]        $\\theta$ 의 값에 대해 어느 것도 알려지기 이전에($0&lt;\\theta&lt;1$),사건 $Z$ 가 $n$ 번의 시행에서 $p$ 번 발생하고 $n-p$ 번 실패한 것으로 드러날 때,그로부터 $\\theta$ 가 $\\alpha, \\beta$ 사이에 있다고 추측한다면,그 추측이 옳을 확률:\\[\\begin{aligned}  P(\\alpha &lt; \\theta &lt; \\beta \\mid X=p)  &amp;= \\frac{P(\\alpha &lt; \\theta &lt; \\beta, X=p)}{P(0 &lt; \\theta &lt; 1, X=p)}\\\\  &amp;= \\frac{\\int_{\\alpha}^{\\beta}{\\cancel{\\binom{n}{p}} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}{\\int_{0}^{1}{\\cancel{\\binom{n}{p}} \\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}\\\\  &amp;= \\frac{\\int_{\\alpha}^{\\beta}{\\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}{\\int_{0}^{1}{\\theta^{p}(1-\\theta)^{n-p}\\text{d}\\theta}}  \\end{aligned}\\]    Scholum  내가 $Z$ 라고 불렀던 그러한 사건의 경우에, 일정 횟수로 시행하고($n$) 그것이 발생하고($p$) 실패한 횟수($n-p$)를 통해, 그것에 대해서는 다른 어떤 것도 알지 못한 상태에서 그것의 확률에 관해 추측할 수 있고(Non-Informative Prior of $\\theta$), 언급한 면적들의 크기를 계산하는 일반적인 방법에 의해 그러한 추측이 옳을 기회를 알 수 있다(Posterior of $\\theta \\mid \\mathcal{D}$).   그리고 동일한 규칙이 그것에 관해 이루어진 어떤 시행에서도, 우리가 사전에 전혀 알지 못하는 확률을 갖는 사건의 경우에도 사용될 수 있다는 것은 다음을 생각해보면 나타난 것 같다. 즉, 어떤 횟수의 시행에서 그것이 다른 횟수보다 어떤 가능한 다른 횟수로 발생할 것이라는 점을 생각할 이유가 없다.   그러므로 나는 다음부터 당연히 사건 $Z$ 에 대해 주어진 규칙($\\theta$)이 또한 어떠한 시행이 이루어지거나 관찰되기 전에(Prior) 어떤 것도 알려지지 않은(Non-Informative) 사건의 확률(Posterior of $\\theta \\mid \\mathcal{D}$)에도 이용될 수 있다고 간주할 것이다. 나는 그러한 사건을 알려지지 않은 사건(Non-Informative Prior)이라고 부를 것이다. (Bayes, 1763, p.393)Bayesian Framework      베이지안 프레임워크(Bayesian Framework): 데이터 관측 이전의 사전 신념(Prior Belief)을 바탕으로, 데이터 관측 이후의 사후 신념(Posterior Belief)을 갱신함으로써 시행의 성질(모수)이 확정적이지 않은 상태에서 그 성질에 대하여 추론하는 방법론\\[\\begin{aligned}  \\underbrace{P\\left(\\Theta \\mid \\mathcal{D} \\right)}_{\\text{Posterior}}  = \\underbrace{\\frac{P\\left(\\mathcal{D} \\cap \\Theta\\right)}{P\\left(\\mathcal{D}\\right)}}_{\\begin{array}{c} \\text{Conditional}\\\\ \\text{Probability} \\end{array}}  = \\frac{\\overbrace{P\\left(\\mathcal{D} \\mid \\Theta \\right)}^{\\text{Likelihood}} \\cdot \\overbrace{P\\left(\\Theta\\right)}^{\\text{Prior}}}{\\underbrace{P\\left(\\mathcal{D}\\right)}_{\\text{Evidence}}}  \\end{aligned}\\]        사후 확률 분포(Posterior Probability Distribution): 모수에 대한 인식적 불확실성으로서, 단일 사건에 대한 다수 진술의 신뢰도 집합을 나타냄\\[\\begin{aligned}  P\\left(\\Theta \\mid \\mathcal{D} \\right)  \\end{aligned}\\]          시행의 성질에 관한 믿음(Posterior)은 관측 가능한 대상이 아니므로 직접적으로 구할 수 없음      베이즈 정리는 이 믿음(Posterior)을 직접 확률(Likelihood)과 사전 정보(Prior)의 조합으로써 간접적으로 도출함            우도(Likelihood):  데이터에 대한 모수의 상대적 적합성으로서, 데이터 생성 과정상의 무작위성으로 인한 우발적 불확실성을 반영함\\[\\begin{aligned}  P\\left(\\mathcal{D} \\mid \\Theta \\right)  \\end{aligned}\\]        사전 확률 분포(Prior Probability Distribution): 모수에 대한 사전 정보\\[\\begin{aligned}  P\\left(\\Theta\\right)  \\end{aligned}\\]        증거(Evidence): 데이터가 관찰될 확률로서, 모수에 대한 신념을 뒷받침하는 증거로 해석됨\\[\\begin{aligned}  P\\left(\\mathcal{D}\\right)  &amp;= \\int{P(\\mathcal{D} \\mid \\Theta) \\cdot P(\\Theta)\\text{d}\\Theta}  \\end{aligned}\\]          베이지안에서는 모수에 대하여 주장함에 있어 현재 주어진 정보, 가령 사전 정보, 데이터 관측 결과 등을 기반으로 함. 따라서 현재까지 관찰된 데이터가 실현될 가능성은 모수에 대한 주장의 증거(Evidence)임.      [example] 동전 던지기  동전을 던졌을 때 앞면이 나올 확률을 $\\theta$ 라고 하자. $\\theta$ 에 대한 정보가 아무것도 없다고 가정하자. 즉, $\\theta$ 는 0과 1 사이의 무작위수일 것이라고 믿어지고 있다. 동전을 두 번 던졌는데 두 번 다 앞면이 나왔다. 그렇다면 $\\theta$ 에 대한 믿음은 어떻게 변화할까?      Prior Prob. Dist.:\\[\\begin{aligned}  p(\\theta)  =1 \\quad \\because \\theta \\sim \\text{Uniform}(0,1)  \\end{aligned}\\]        Likelihood:\\[\\begin{aligned}  p\\left(X \\mid \\theta\\right)  =\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X} \\quad \\because X \\mid \\theta \\sim \\text{Bin}(n,\\theta)  \\end{aligned}\\]        Evidence:\\[\\begin{aligned}  p(X)  &amp;= \\int_{0}^{1}{p\\left(X \\mid \\theta\\right)}\\text{d}\\theta\\\\  &amp;= \\int_{0}^{1}{\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\int_{0}^{1}{\\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\text{B}(X+1,n-X+1)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{\\Gamma(X+1)\\Gamma(n-X+1)}{\\Gamma(n+2)} \\quad \\because (X+1),(n-X+1) \\in \\mathbb{R}^{+}\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{X!(n-X)!}{(n+1)!} \\quad \\because (X+1),(n-X+1) \\in \\mathbb{Z}^{+}\\\\  &amp;= \\frac{1}{n+1}  \\end{aligned}\\]        Posterior Prob. Dist.:\\[\\begin{aligned}  p\\left(\\theta \\mid X\\right)  &amp;\\propto p\\left(X \\mid \\theta\\right) \\cdot p\\left(\\theta\\right)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}\\\\  \\\\  \\therefore \\theta \\mid X  &amp;\\sim \\text{Beta}(X+1,n-X+1)  \\end{aligned}\\]                  $\\text{Beta}(\\alpha,\\beta)$ : 베타분포\\[f(x)  = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\text{B}(\\alpha,\\beta)}  \\sim \\text{Beta}(\\alpha,\\beta)\\]            Annotation      $\\text{B}(\\alpha,\\beta)$ : 베타 함수\\[\\begin{aligned}  \\text{B}(\\alpha,\\beta)  &amp;= \\int_{0}^{1}{t^{\\alpha-1}(1-t)^{\\beta-1}}\\text{d}t\\\\  &amp;= \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)} \\quad \\text{where}\\; \\alpha,\\beta \\in \\mathbb{R}^{+}  \\end{aligned}\\]        $\\Gamma(n)$ : 감마 함수\\[\\begin{aligned}  \\Gamma(n)  &amp;= \\int_{0}^{\\infty}{t^{(n-1)}e^{-t}}\\text{d}t\\\\  &amp;= (n-1)! \\quad \\text{where}\\; n \\in \\mathbb{Z}^{+}  \\end{aligned}\\]        $\\text{Beta}(\\alpha,\\beta)$ : 베타분포\\[f(x)  = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\text{B}(\\alpha,\\beta)}  \\sim \\text{Beta}(\\alpha,\\beta)\\]  Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Justification of Bayesianism",
    "url": "/posts/Justification/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Epistemology, Bayesian, Bayes' Theorem",
    "date": "2024-07-16 00:00:00 +0900",
    





    
    "snippet": "Condition  윤리적으로 중립인 명제에 대하여 그것의 참 여부에 따라 $0-1$ 사이의 서수적 효용을 획득하거나 상실할 수 있는 내기 상황을 가정함으로써, 베이즈주의는 개인의 신념도를 행위의 자발성과 동일시하는 행동주의적 접근을 취한다(이영의, 2015, p.35). 즉, 내기 상황 하에서 신념과 선호를 기대 효용의 형태로 연결하고, 이를 최적화...",
    "content": "Condition  윤리적으로 중립인 명제에 대하여 그것의 참 여부에 따라 $0-1$ 사이의 서수적 효용을 획득하거나 상실할 수 있는 내기 상황을 가정함으로써, 베이즈주의는 개인의 신념도를 행위의 자발성과 동일시하는 행동주의적 접근을 취한다(이영의, 2015, p.35). 즉, 내기 상황 하에서 신념과 선호를 기대 효용의 형태로 연결하고, 이를 최적화 혹은 효용 극대화라는 선택으로써 측정 가능한 형태로 이끌어낸다.Measurement Condition      측정 조건(Measurement Condition)          신념도는 측정될 방법을 규정할 수 있을 경우에만 완전한 의미를 가진다(이영의, 2015, p.35).            램지 가정(Ramsey’s Assumption)          행위의 집합이 주어지면 합리적 행위자는 최대 기대값을 갖는 행위를 선택한다(이영의, 2015, p.35).            기대 효용 이론(Expected Utility Theory)          $X$ 에 대한 행위자의 신념도가 $p$ 이라는 것은 그 행위자는 $X$ 이면 단위 $1$ 을 지불하고 그렇지 않은 경우에는 $0$ 을 지불하는 도박에 대해 $p$ 를 지불할 용의가 있다는 것이다(de Finetti, 1937, p.62).      Consistency Condition      정합성 조건(Consistency Condition)          여러 가지 명제에 대한 개인의 신념도 집합은 일정한 방식으로 상호 간 일치하거나 입증되어야만 한다(이영의, 2015, p.35).            베이즈주의 공준(Bayesianism Postulate)          이상적으로 합리적인 행위자의 신념도는 확률론의 공리체계를 준수한다(이영의, 2015, p.19).            더치북 논증(Dutch Book Argument) | 실용적 정합화          특정인의 확률함수가 공리체계를 만족시키지 못할 경우에, 하나의 내기 전략이 있고 판돈의 집합이 있는 내기 상황에서 그는 결과에 상관없이 항상 일정한 액수를 잃게 된다(이영의, 2015, p.58).            콕스 정리(Cox’s Theorem) | 논리적 정합화          함수 $G,H$ 가 실수 전체에 대하여 연속이고, 한 개인의 신념 함수 $b$ 가 논리 집합 $\\mathcal{L}$ 에 대하여 $b:\\mathcal{L} \\times \\mathcal{L} \\to \\mathbb{R}$ 인 단조 함수라고 하자. 아래 조건을 만족하는 신념 함수 $b$ 는 존재론적으로 유일한 확률 함수 $P$ 와 엄격히 증가하는 실수 함수 $F$ 에 대하여 $b(A \\mid B) = F(P(A \\mid B))$ 임을 만족한다. 즉, 신념 함수 $b$ 는 확률 함수 $P$ 와 동형이다.                      논리 연산의 일관성(Associativity &amp; Consistency): 이변수 함수 $G$ 가 논리 연산 $\\wedge$ 의 구조적 결합성과 일치하기 위해서는 형태가 곱셈형이거나 이와 동형이어야 함\\[\\begin{aligned}  b(A \\wedge B \\mid C)  &amp;= G(b(A \\mid C), b(B \\mid A \\wedge C))  \\end{aligned}\\]                    부정의 일관성(Negation): 일변수 함수 $H$ 가 부정을 나타내기 위해서는 확률의 여사건 법칙 $1-p$ 에 대응하는 형태를 만족해야 함\\[\\begin{aligned}  b(\\neg A \\mid B)  &amp;= H(b(A \\mid B))  \\end{aligned}\\]                    존재 가능성(Non-Triviality): 전적으로 확신하는 신념과 완전히 부정하는 신념은 서로 다른 값이어야 함            Constraining Priors      사전 확률 제약하기(Constraining Priors): 베이즈주의적 합리성이 주관적 신념의 형식적 정합화를 넘어선 정당화를 제공하기 위해서는 사전 확률 분포가 논리적(Logical), 경험적(Empirical), 또는 규범적(Objective) 제약 하에 형성되어야 함        주관적 베이즈주의(Subjective Bayes) | Belief          나는 진심으로 그러한 절대적 의미에서의 모든 확률 개념을 반대한다. (중략) 확률은 우리가 그에 대해 정신적으로 또는 본능적으로 내리는 평가와 독립적으로 존재하지 않는다는 의미에서 “확률은 존재하지 않는다(de Finetti, 1977, p.199).”            경험적 베이즈주의(Empirical Bayes) | Utility          그러므로 하나의 의견이 주어지면, 우리는 진위에 근거하여 그것을 칭찬하거나 책망할 수 있을 뿐이다. 특정한 형태의 습관이 주어지면 우리는 습관이 산출하는 신념도가 그것이 진리로 이끄는 실제 비율에 근접하거나 멀어지는가에 따라서 칭찬하거나 책망할 수 있다. 그렇다면 우리는 의견을 산출하는 습관들을 칭찬하거나 책망하는 것으로부터 파생적으로 의견들을 칭찬하거나 책망할 수 있다(Ramsey, 1926, p.51).            객관적 베이즈주의(Objective Bayes) | Background, Non-Information          무차별의 원리가 주장하는 것은 만약 우리의 관심의 대상이 여러 가지 대안 중 어느 것보다 더 예측할 만한 어떠한 알려진 이유가 없다면 그러한 지식에 상대적으로 이러한 대안 각각에 대한 주장들은 동일한 확률을 갖는다는 점이다(Keynes, 1921, p.42).      Washing Out Priors      객관성(Objectivity)          절차의 합리성과 결과의 합리성이 대응하지 않을 경우는 어떻게 해야 하는가? (중략) 이 부분에서 우리의 논의에서 처음으로 합리성의 문제가 객관성의 문제와 관련된다. 진리성과 관련하여 어느 사회에서나 통용되는 기준들이 있으며 우리는 그것들이 객관적이라고 부른다. (중략) 베이즈주의적 객관성은 확실하지 않은 의견들 간 성립하는 간주관적 일치이다(이영의, 2015, p.41).            사전 확률 씻겨내기(Washing Out Priors)          동전의 미래 행위에 대한 당신의 견해가 이웃 사람의 견해와 크게 다르더라도, 당신의 견해와 이웃 사람의 견해는 일상적으로 실험적인 던지기의 긴 연속에 베이즈의 정리를 적용하여 변형되어 거의 구별할 수 없게 될 것이다(Edwards, Lindman, and Savage, 1963, p.197). 즉, 다양한 신념들은 충분한 근거가 주어지면 간주관적으로 수렴하며, 이 일치를 객관적 신념 상태로 해석할 수 있다.            두브의 마틴게일 수렴 정리(Doob’s Martingale Convergence Theorem)          일반적 환경에서 조건화에 의한 확률 변화는 장기적으로 안정화된다(이영의, 2015, p.54).  \\(\\mathbb{E}\\left[\\theta \\mid \\mathcal{D}_{n}\\right] \\to \\mathbb{E}\\left[\\theta \\mid \\mathcal{D}_{\\infty}\\right]\\)            조건화 규칙(Rule of Conditionalization)                  엄밀조건화 규칙(Rule of Strict Conditionalization):\\[\\begin{aligned}  \\Pi\\left(\\Theta\\right)  &amp;= P\\left(\\Theta \\mid \\mathcal{D}\\right)  \\end{aligned}\\]                    제프리 조건화 규칙(Jeffrey’s Conditionalization):\\[\\begin{aligned}  \\Pi\\left(\\Theta\\right)  &amp;= Q\\left(\\mathcal{D}\\right) \\cdot P\\left(\\Theta \\mid \\mathcal{D}\\right) + Q\\left(\\neg\\mathcal{D}\\right) \\cdot p\\left(\\Theta \\mid \\neg\\mathcal{D}\\right)  \\end{aligned}\\]            Problem of Induction      귀납의 문제(Problem of Induction)          특정 사례들로부터 보편 결론을 이끌어낼 수 없다.            후험 일치성(Posterior Consistency)          확률 계산법을 준수하고 조건화 규칙에 따라 개정이 이루어진다면, 그리고 그러한 개정의 결과가 궁극적으로 참으로 수렴한다는 점이 보증된다면, 베이즈주의 추리에서는 귀납의 문제가 성립될 수 없다(이영의, 2015, p.55).            슈바르츠 정리(Schwartz’s Theorem)          관측치 \\(X \\sim P(\\theta)\\), 모수 \\(\\theta \\in \\Theta\\), 사전 확률 분포 \\(\\Pi\\), 참 모수 \\(\\theta^{*}\\) 에 대하여, \\(\\theta^{*}\\) 의 근방에 위치한 \\(\\theta\\) 가 사전 확률 분포에서 양의 질량을 가진다고 하자. 즉, \\(\\Pi\\left(\\{\\theta : D_{KL}\\left[P_{\\theta^{*}} \\Vert P_{\\theta}\\right] &lt; \\epsilon\\}\\right) &gt; 0\\) 이다. 이때 사후 확률 분포는 장기적으로 \\(\\theta^{*}\\) 에 집중된다. 즉, \\(\\Pi\\left(\\theta^{*} \\mid X_{1}, \\cdots, X_{n}\\right) \\xrightarrow{n \\to \\infty} 1\\) 이다.      Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Bayesianism",
    "url": "/posts/Bayesianism/",
    "categories": "BAYES, 1.bayes basic",
    "tags": "Epistemology, Bayesian, Bayes' Theorem",
    "date": "2024-07-15 00:00:00 +0900",
    





    
    "snippet": "Epistemology      인식론(Epistemology): 믿음이 어떻게 정당화되어 앎이 되는가에 대한 철학적 논의          앎은 정당화된 참된 믿음(Knowledge is Justified True Belief)              믿음(Belief): 해당 명제가 참임을 믿고 있다.      사실(Truth): 해당 명제가 사실이...",
    "content": "Epistemology      인식론(Epistemology): 믿음이 어떻게 정당화되어 앎이 되는가에 대한 철학적 논의          앎은 정당화된 참된 믿음(Knowledge is Justified True Belief)              믿음(Belief): 해당 명제가 참임을 믿고 있다.      사실(Truth): 해당 명제가 사실이어야 한다.      정당화(Justification): 믿음에는 근거가 있어야 한다.            베이즈주의(Bayesianism): 수량화된 인식론          확률적 귀납 개념에 따르면 과학 이론은 절대적 확실성을 가질 수 없지만 확실한 참과 확실한 거짓이라는 양극단 사이에 존재하는 인식적 값을 가질 수 있으며, 그 값은 새로운 증거에 의해 변경될 수 있다. (이영의, 2015, p.19)              형식 체계(Formalism): 베이즈 정리(Bayes’ Theorem)      해석 체계(Interpretation): 확률의 주관적 해석(Subjective interpretation)            베이지안 프레임워크(Bayesian Framework)                            Formalism          Bayes Module          Interpretation                                      \\(p(\\theta)\\)          사전 확률 분포(Prior)          신념(Belief)                          \\(p(\\mathcal{D}\\mid\\theta)\\)          우도(Likelihood)          참(Truth)                          \\(p(\\mathcal{D})\\)          증거(Evidence)          근거(Reason)                          \\(p(\\theta\\mid\\mathcal{D})\\)          사후 확률 분포(Posterior)          앎(Knowledge)                          \\(p(\\theta\\mid\\mathcal{D})=\\displaystyle\\frac{p(\\mathcal{D}\\mid\\theta)p(\\theta)}{p(\\mathcal{D})}\\)          베이즈 정리(Bayes’ Theorem)          정당화(Justification)                    Formalism      콜모고로프의 확률 공리(Kolmogorov Probability Axiom)          확률 공간(Probability Space) $[\\Omega, F, P]$ 는 다음을 이른다. 즉, $F$ 는 공집합이 아닌 집합 $\\Omega$ 에 대하여 그 시그마 대수($\\sigma$-Algebra)이다. 이때 확률함수(Probability Function) $P$ 는 $F$ 로부터 다음을 만족하는 실수로의 함수이다.              K1 모든 $A \\in F$ 에 대하여 $P(A) \\ge 0$      K2 $P(\\Omega)=1$      K3 $A \\cap B = \\emptyset$ 인 모든 $A,B \\in F$ 에 대하여 $P(A \\vee B) = P(A) + P(B)$        베이즈주의 확률 공리(Bayesian Probability Axiom)          B1 $A,B \\in S$ 에 대하여 $0 \\le P(B \\mid A) \\le 1$      B2 $A$ 가 $B$ 를 논리적으로 함축하면 $P(B \\mid A) = 1$      B3 $B,C$ 가 상호 배타적이면 $P(B \\vee C\\mid A) = P(B \\mid A) + P(C \\mid A)$      B4 $P(A) \\ne 0$ 인 경우 $P(B \\mid A) = \\displaystyle\\frac{P(A \\wedge B)}{P(A)}$        성질(Property)          T1 $B,C$ 가 독립적이면 $P(B \\wedge C \\mid A) = P(B \\mid A) \\cdot P(C \\mid A)$      T2 $P(\\neg B \\mid A) = 1 - P(B \\mid A)$      T3 $P(B \\vee C \\mid A) = P(B \\mid A) + P(C \\mid A) - P(B \\wedge C \\mid A)$      T4 $P(C \\mid A) = P(B \\mid A) \\cdot P(C \\mid A \\wedge B) + P(\\neg B \\mid A) \\cdot P(C \\mid A \\wedge \\neg B)$        베이즈 정리(Bayes’ Theorem)          BT1 $P(\\theta), P(\\mathcal{D}) &gt; 0$ 이면 $P(\\theta \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\mathcal{D} \\mid \\theta) \\cdot P(\\theta)}{P(\\mathcal{D})}$      BT2 $P(\\theta_{1} \\vee \\cdots \\vee \\theta_{n})=1$ 이고 $\\theta_{i} \\vdash \\neg \\theta_{j}(i \\ne j)$ 이면 $P(\\theta_{k} \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\mathcal{D} \\mid \\theta_{k}) \\cdot P(\\theta_{k})}{\\sum_{i}{P(\\mathcal{D} \\mid \\theta_{i}) \\cdot P(\\theta_{i})}}$      BT3 $P(\\theta \\mid \\mathcal{D}) = \\displaystyle\\frac{P(\\theta)}{P(\\theta) + P(\\mathcal{D} \\mid \\neg \\theta) \\cdot P(\\neg \\theta)/P(\\mathcal{D} \\mid \\theta)}$      Interpretation      확률 해석(Probability Interpretation): 확률함수 $P$ 의 의미를 규명하는 해석 체계          해석은 술어 논리, 리만 기하학, 양자역학과 같은 형식체계를 구성하는 공리들과 정의들에 등장하는 미정의된(Undefined) 또는 원초적(Primitive) 용어들에 일상적 의미를 부여하여 그런 공리들과 정리들이 준거 세계에 대해 참이 되도록 하는 작업을 의미한다. (이영의, 2015, p.19)              고전적 해석(Classical interpretation)      논리적 해석(Logical interpretation)      빈도적 해석(Frequentist interpretation)      성향적 해석(Propensity interpretation)      주관적 해석(Subjective interpretation)            주관적 해석(Subjective interpretation) (이영의, 2015, p.34)          베이즈주의는 이처럼 특정 진술에 대한 우리의 믿음, 즉 신념도에 양의 실수를 부여하는 것은 전형적인 확률 판단에 속한다고 보고, 그런 판단을 확률함수 $P$(Probability Function)로 표현한다. 확률함수 $P$ 는 특정 진술을 일정한 수치에 대응시킨다. (이영의, 2015, p.2)              s1 확률은 특정 명제에 대한 행위자의 신념도이다.      s2 확률은 행위, 특히 내기 행위를 조사함으로써 가장 잘 확립될 수 있다.      s3 객관적인 확률은 없다. 만약 객관적 확률이 존재한다면 그것은 이차적 확률이다.      s4 사건은 고유한 확률을 갖지 않는다. 개인은 자신의 확률을 논리적으로 자유롭게 결정할 수 있다.      s5 합리적 개인의 신념은 확률론의 계산법과 무모순적이어야 하고, 동시에 그것에 의해 규제되어야 한다.      Reference  베이즈주의; 합리성으로부터 객관성으로의 여정이영의. (2015). 한국연구재단 저술총서 4. 한국문화사"
  },
  
  {
    "title": "Logistic Regression Analysis",
    "url": "/posts/Logistic_Regression_Analysis/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression",
    "date": "2024-07-14 00:00:00 +0900",
    





    
    "snippet": "Prerequisite      승산(Odds) : 변수 $Y$ 가 반응할 가능성이, 반응하지 않을 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{odds}(Y)  &amp;= \\frac{P(Y=1)}{1-P(Y=1)}  \\end{aligned}\\]        로짓(Logit; Logarithm Odds) : 승산에 로그를 취한...",
    "content": "Prerequisite      승산(Odds) : 변수 $Y$ 가 반응할 가능성이, 반응하지 않을 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{odds}(Y)  &amp;= \\frac{P(Y=1)}{1-P(Y=1)}  \\end{aligned}\\]        로짓(Logit; Logarithm Odds) : 승산에 로그를 취한 값\\[\\begin{aligned}  \\text{logit}(Y)  &amp;= \\ln{\\text{odds}(Y)}\\\\  &amp;= \\ln{\\frac{P(Y=1)}{1-P(Y=1)}}  \\end{aligned}\\]        승산비(Odds Ratio; OR) : 변수 $X$ 가 참일 때 $Y$ 가 반응할 가능성이, $X$ 가 거짓일 때 $Y$ 가 반응할 가능성보다 몇 배 높은가\\[\\begin{aligned}  \\text{OR}(Y \\mid X)  &amp;= \\frac{\\text{odds}(Y \\mid X=1)}{\\text{odds}(Y \\mid X=0)}\\\\  &amp;= \\left[\\frac{P(Y=1\\mid X=1)}{1-P(Y=1 \\mid X=1)}\\right] \\bigg/ \\left[\\frac{P(Y=1\\mid X=0)}{1-P(Y=1 \\mid X=0)}\\right]  \\end{aligned}\\]          $\\text{OR}(Y \\mid X) \\approx 1$ : $X$ 의 단위 변동이 $Y$ 의 승산에 영향을 미치지 않음      $\\text{OR}(Y\\mid X) &lt; 1$ : $X$ 의 단위 변동이 $Y$ 의 승산과 음의 상관관계에 있음      $\\text{OR}(Y \\mid X) &gt; 1$ : $X$ 의 단위 변동이 $Y$ 의 승산과 양의 상관관게에 있음      Logistic Regression      로지스틱 회귀 모형(Logistic Regression) : 범주형 반응변수에 대한 회귀 모형    \\[P(y^{(i)}=1)  = \\frac{1}{1+\\exp{\\left[-\\left(\\beta_{0}+\\beta_{1} \\cdot x^{(i)}\\right)\\right]}}\\]  Logistic Function      범주형 반응변수와 회귀식 간 범위 불일치 문제                  범주형 반응변수 $Y$ 의 공역\\[y^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{true}\\\\  0 \\quad &amp;\\text{false}  \\end{aligned}\\end{cases}\\]                    회귀식의 범위\\[\\begin{aligned}  f(x^{(i)})  = \\beta_{0} + \\beta_{1} \\cdot x^{(i)} \\in (-\\infty,\\infty)  \\end{aligned}\\]                    반응변수 공역과 회귀식 범위 간 불일치\\[\\begin{aligned}  y^{(i)} \\ne \\beta_{0} + \\beta_{1} \\cdot x^{(i)}  \\end{aligned}\\]                  반응변수 재정의를 통한 공역 조정                  확률 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad P(Y=1) \\in [0,1]\\]                    승산(odds) 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad \\text{odds}(Y) \\in [0,\\infty)\\]                    로짓(logit) 변환\\[Y \\in \\{0,1\\} \\quad \\rightarrow \\quad \\text{logit}(Y) \\in (-\\infty,\\infty)\\]                  로지스틱 회귀식 도출                  로짓 변환한 반응변수와 회귀식 연결\\[\\begin{aligned}  \\text{logit}(y^{(i)})  &amp;= \\beta_{0} + \\beta_{1} \\cdot x^{(i)}  \\end{aligned}\\]                    반응변수가 참일 확률에 대한 로지스틱 회귀식 도출\\[\\begin{aligned}  P(y^{(i)}=1)  &amp;= \\frac{1}{1+\\exp\\left[-\\left(\\beta_{0}+\\beta_{1} \\cdot x^{(i)}\\right)\\right]}  \\end{aligned}\\]            $\\beta_{1}$ related to Log Odds Ratio      Logistic Function\\[\\ln{\\frac{P(Y=1)}{1-P(Y=1)}}  =\\beta_0 + \\beta_1 \\cdot X\\]        $\\text{if} \\quad X=1$\\[\\begin{aligned}  \\ln{\\frac{P(Y=1 \\mid X=1)}{1-P(Y=1 \\mid X=1)}}  &amp;= \\beta_0 + \\beta_1 \\times 1 \\\\  &amp;= \\beta_0 + \\beta_1  \\end{aligned}\\]        $\\text{if} \\quad X=0$\\[\\begin{aligned}  \\ln{\\frac{P(Y=1 \\mid X=0)}{1-P(Y=1 \\mid X=0)}}  &amp;= \\beta_0 + \\beta_1 \\times 0 \\\\  &amp;= \\beta_0  \\end{aligned}\\]        $\\beta_1$\\[\\begin{aligned}  \\beta_1  &amp;= \\left(\\beta_0 + \\beta_1\\right) - \\beta_0\\\\  &amp;= \\ln{\\frac{P(Y=1 \\mid X=1)}{1-P(Y=1 \\mid X=1)}} - \\ln{\\frac{P(Y=1 \\mid X=0)}{1-P(Y=1 \\mid X=0)}}\\\\  &amp;= \\ln{\\text{odds}(Y \\mid X=1)} - \\ln{\\text{odds}(Y \\mid X=0)}\\\\  &amp;= \\ln{\\frac{\\text{odds}(Y \\mid X=1)}{\\text{odds}(Y \\mid X=0)}}\\\\  &amp;= \\ln{\\text{OR}(Y \\mid X)}  \\end{aligned}\\]  Maximum Liklihood Estimator      Liklihood Function\\[\\begin{aligned}  \\mathcal{L}(\\theta)  &amp;= \\prod_{i:y=1}{P(x_{i} \\mid \\theta)} \\cdot \\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}  \\end{aligned}\\]          $\\prod_{i:y=1}{P(x_{i} \\mid \\theta)}$ : $\\theta$ 조건부 $Y=1$ 인 관측치들이 발생할 확률      $\\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}$ : $\\theta$ 조건부 $Y=0$ 인 관측치들이 발생할 확률            Maximum Liklihood Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\max_{\\theta}{\\mathcal{L}(\\theta)}\\\\  &amp;= \\text{arg} \\max_{\\theta}{\\prod_{i:y=1}{P(x_{i} \\mid \\theta)} \\cdot \\prod_{j:y=0}{1-P(x_{j} \\mid \\theta)}}\\\\  &amp;= \\text{arg} \\max_{\\theta}{\\sum_{i:y=1}{P(x_{i} \\mid \\theta)} + \\sum_{j:y=0}{P(x_{j} \\mid \\theta)}}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Improvement of OLS",
    "url": "/posts/Improvement_of_OLS/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression",
    "date": "2024-07-13 00:00:00 +0900",
    





    
    "snippet": "Improvement of OLSComponents of Error\\[\\begin{aligned}\\text{Error}&amp;= \\mathbb{E}\\left[\\left(Y-\\hat{f}(X)\\right)^{2}\\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^{2...",
    "content": "Improvement of OLSComponents of Error\\[\\begin{aligned}\\text{Error}&amp;= \\mathbb{E}\\left[\\left(Y-\\hat{f}(X)\\right)^{2}\\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^{2}\\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2} + \\varepsilon^{2} - 2 \\cdot \\varepsilon \\cdot \\left(f(X)-\\hat{f}(X)\\right) \\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\varepsilon^{2}\\right] - 2 \\cdot \\mathbb{E}\\left[\\varepsilon\\right] \\cdot \\mathbb{E}\\left[f(X)-\\hat{f}(X) \\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\sigma^{2}\\\\\\\\\\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right]&amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)+\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right] + 2 \\cdot \\mathbb{E}\\left[f(X)-\\overline{f}(X)\\right] \\cdot \\mathbb{E}\\left[\\overline{f}(X)-\\hat{f}(X)\\right]\\\\&amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\\\\\\\mathbb{Bias}\\left[\\hat{f}(X)\\right]&amp;= \\mathbb{E}\\left[\\hat{f}(X)\\right] - f(X)\\\\\\mathbb{Var}\\left[\\hat{f}(X)\\right]&amp;= \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\\\\\\\therefore \\text{Error}&amp;= \\mathbb{Bias}^{2}\\left[\\hat{f}(X)\\right] + \\mathbb{Var}\\left[\\hat{f}(X)\\right] + \\sigma^{2}\\end{aligned}\\]  $Y$ : 실제 관측치  $\\varepsilon \\sim N(0, \\sigma^2)$ : 노이즈  $f(X)$ : 실제 함수  $\\hat{f}(X)$ : $f(X)$ 에 대한 예측값  $\\overline{f}(X)$ : $\\hat{f}(X)$ 의 평균Bias-Variance Trade-off      편향(Bias) : 모형이 학습 데이터의 패턴을 충분히 학습하지 못해 발생하는 과소적합(Underfitting) 문제로서, 학습 데이터에 내재된 패턴의 복잡도에 비해 모형이 간소화되어 설계된 경우 발생함        분산(Variance) : 모형이 학습 데이터에 너무 과도하게 적응하여 발생하는 과대적합(Overfitting) 문제로서, 모형 복잡도에 비해 학습 데이터가 희소한 경우 발생함        편향-분산 트레이드오프(Bias-Variance Trade-off) : 모형 복잡도에 따른 편향과 분산의 상충 관계  Improvement of OLS  최소자승추정량은 BLUE(Best Linear Unbias Estimator)로서, 편향이 $0$ 인 추정량 중 분산이 가장 작은 추정량임. 만약 편향이 $0$ 이어야 한다는 제약 조건을 완화한다면 분산을 더 줄일 수 있지 않을까?  변수 선택(Feature Selection) : $p$ 개의 설명변수 중 반응변수와 관련이 있다고 생각되는 설명변수들을 식별하여 추정하는 방법          전진 선택(Forward Selection)      후진 선택(Backward Elimination)      혼합 선택(Stepwise Selection)        수축(Shrinkage) : $p$ 개의 설명변수를 모두 포함하는 모형을 추정하되, 회귀계수를 최소자승추정량보다 작은 값으로 수축함으로써 분산을 줄이는 방법          Ridge Regression      LASSO Regression        차원축소(Dimension Reduction) : $p$ 개의 설명변수를 저차원 공간으로 사영(Projection)하는 방법          주성분 분석(Principal Component Analysis; PCA)      선형 판별 분석(Linear Discriminant Analysis; LDA)      Feature Selection  Occam’s Razor  Entities should not be multiplied beyond necessity.      전진 선택(Forward Selection) : 어떤 변수도 선택되지 않은 상태에서 가장 설명력이 좋은 변수를 하나씩 추가하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(x_{i})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(x_{j \\ne i};\\hat{x}_{i})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(x_{k \\ne i,j};\\hat{x}_{i},\\hat{x}_{j})]\\\\  &amp;\\vdots  \\end{aligned}\\]        후진 선택(Backward Elimination) : 모든 변수가 포함된 상태에서 시작하여 불필요한 변수를 하나씩 제거하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(\\not{x_{i}})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(\\not{x_{j \\ne i}};\\not{\\hat{x}_{i}})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(\\not{x_{k \\ne i,j}};\\not{\\hat{x}_{i}},\\not{\\hat{x}_{j}})]\\\\  &amp;\\vdots  \\end{aligned}\\]        혼합 선택(Stepwise Selection) : 어떤 변수도 선택되지 않은 상태에서 Forward Selection 과 Backward Elimination 을 번갈아 수행하는 방법  Metrics      Adjusted Coefficient of Determination($\\text{Adj.}R^2$)\\[\\text{Adj.}R^2 = \\frac{(n-1)R^2-p}{n-p-1}\\]        Akaike Information Criteria(AIC)\\[\\begin{aligned}  \\text{AIC}  &amp;= -2\\ln{\\hat{L}}+2k  \\end{aligned}\\]                  $\\hat{L}$ : 모델 적합도로서 \\(\\overrightarrow{x}_{i}\\) 가 주어졌을 때 $y_{i}$ 가 발생할 가능성\\[\\begin{aligned}  \\hat{L}  &amp;= \\prod_{i=1}^{n}{P(Y=y_{i} \\mid X=\\overrightarrow{x}_{i};\\hat{\\overrightarrow{\\theta}})}\\\\  \\hat{\\overrightarrow{\\theta}}  &amp;= \\begin{pmatrix}\\hat{\\beta_{0}}&amp;\\hat{\\beta_{1}}&amp;\\cdots&amp;\\hat{\\beta_{d}}\\end{pmatrix}  \\end{aligned}\\]                    $k$ : 모델 복잡도                  Bayesian Information Criteria(BIC)\\[\\begin{aligned}  \\text{BIC}  &amp;= -2\\ln{\\hat{L}}+k\\ln{n}  \\end{aligned}\\]  Shrinkage Methods      p-norm : $n$ 차원 벡터 $\\overrightarrow{x}=\\begin{pmatrix}x_{1}&amp;x_{2}&amp;\\cdots&amp;x_{n}\\end{pmatrix}$ 의 크기를 정의하는 방법    \\[\\Vert x \\Vert _{p}=(\\vert x_{1} \\vert ^{p}+ \\vert x_{2} \\vert ^{p}+\\cdots+ \\vert x_{n} \\vert ^{p})^{\\frac{1}{p}}\\]        가중치 규제(Weight Regulation) : 회귀계수 최적값을 탐색함에 있어 회귀계수 벡터 $\\overrightarrow{\\beta}$ 의 크기에 제약을 두는 것    \\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{\\left[L_{OLS}+\\lambda \\Vert \\beta \\Vert _{p}^{2}\\right]}  \\end{aligned}\\]          $L_{OLS}(\\overrightarrow{\\beta})$ : 최소자승법에 기초한 손실 함수      $\\overrightarrow{\\beta}$ : 회귀계수 벡터      $\\lambda$ : 회귀계수 벡터 $\\overrightarrow{\\beta}$ 크기 제약 강도      p : 벡터 크기 정의 방법                  p=1 : LASSO          p=2 : Ridge                    Sourse  http://scott.fortmann-roe.com/docs/BiasVariance.html  https://github.com/lovit/python_ml_intro  https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html  https://observablehq.com/@petulla/l1-l2l_1-l_2l1-l2-norm-geometric-interpretation"
  },
  
  {
    "title": "Variable Issues",
    "url": "/posts/Variable_Issues/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression",
    "date": "2024-07-12 00:00:00 +0900",
    





    
    "snippet": "Qualitative PredictorsLevel 2  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\...",
    "content": "Qualitative PredictorsLevel 2  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 학생인 사람의 신용카드 대금 평균      $\\beta_1$ : 학생인 사람과 학생이 아닌 사람의 신용카드 대금 평균 차이      Level 3  어느 신용카드 사에서 고객의 인종(황인/흑인/백인)에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      지시 변수(Indicate Variable)\\[d_{1}^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if Black}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\\\  \\quad  d_{2}^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if White}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d_{1}^{(i)} + \\beta_{2} \\cdot d_{2}^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if Black}\\\\  \\beta_{0} + \\beta_{2} + \\varepsilon^{(i)} \\quad &amp;\\text{if White}\\\\  \\beta_{0} + \\varepsilon^{(i)} \\quad &amp;\\text{if Asian}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 황인의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 흑인의 신용카드 대금 평균      $\\beta_1$ : 황인과 흑인의 신용카드 대금 평균 차이      $\\beta_0 + \\beta_2$ : 백인의 신용카드 대금 평균      $\\beta_2$ : 황인과 백인의 신용카드 대금 평균 차이      Qualitative &amp; Quantitative  어느 신용카드 사에서 고객의 신용카드 대금에 관한 회귀 모형을 설계하고자 한다. 고객의 수입과 학생 여부에 관한 데이터를 확보하고 있다.      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형    \\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 참조 수준(Reference Level) 으로서 $x$(Income)이 동일한 수준일 때 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : $x$(Income)이 동일한 수준일 때 학생인 사람의 신용카드 대금 평균      $\\beta_1$ : $x$(Income)이 동일한 수준일 때 학생인 사람과 학생이 아닌 사람의 신용카드 대금 평균 차이      $\\beta_2$ : 학생 여부와 무관하게, $x$(Income) 단위 변동에 따른 $y$ 의 변동성      Effect Coding  어느 신용카드 사에서 고객이 학생인지 여부에 따른 신용카드 대금에 관한 회귀 모형을 설계하고자 한다.      Effect Coding : 각 범주의 효과를 비교하기 위하여 참조 수준을 명시적으로 사용하지 않고 전체 평균과 비교하는 범주형 변수 인코딩 방법        지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  -1 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]        선형 회귀 모형\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\beta_{0} + \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} - \\beta_{1} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]          $\\beta_0$ : 모든 사람들의 신용카드 대금 평균      $\\beta_0 + \\beta_1$ : 학생인 사람의 신용카드 대금 평균      $\\beta_0 - \\beta_1$ : 학생이 아닌 사람의 신용카드 대금 평균      $\\beta_1$ : 학생 여부에 따른 신용카드 대금 평균의 차이      Interaction Terms      상호작용 효과 (Interaction Effect) : 두 개 이상의 설명변수가 결합하여 반응변수에 미치는 영향이, 각 설명변수의 주효과를 가산한 것과 다를 때 발생하는 효과로서, 한 설명변수가 반응변수에 미치는 효과가 다른 설명변수의 수준에 영향을 받는 경우 발생함\\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot x_{1}^{(i)} + \\beta_{2} \\cdot x_{2}^{(i)} + \\underbrace{\\beta_{3} \\cdot x_{1}^{(i)}x_{2}^{(i)}}_{\\text{Interaction Term}} + \\varepsilon^{(i)}\\\\  &amp;= \\beta_{0} + \\underbrace{\\left(\\beta_{1} + \\beta_{3} \\cdot x_{2}^{(i)}\\right)}_{\\tilde{\\beta}_{1}} \\cdot x_{1}^{(i)} + \\beta_{2} \\cdot x_{2}^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\beta_{0} + \\beta_{1} \\cdot x_{1}^{(i)} + \\underbrace{\\left(\\beta_{2} + \\beta_{3} \\cdot x_{1}^{(i)}\\right)}_{\\tilde{\\beta}_{2}} \\cdot x_{2}^{(i)} + \\varepsilon^{(i)}  \\end{aligned}\\]          주효과(Main Effect; $\\beta_{1}, \\beta_{2}$) : 설명변수가 반응변수에 독립적으로 미치는 직접적인 효과      시너지 효과(Synergy Effect; $\\beta_{3}$) : 설명변수 간 상호작용을 통해 나타나는, 가산적이지 않은 효과            계층적 원리(Hierarchical Principle)          교호작용 효과(Interaction Effect)의 유효성이 입증되어 모형에 포함하는 경우, 해당 교호작용을 구성하는 주효과(Main Effects)는 유효성 여부와 상관없이 모형에 포함해야 함. 주효과를 제외하는 경우 교호작용 효과 해석이 불분명해질 수 있기 때문임. 가령 실제 상호작용 효과가 아니라, 주효과의 부분적인 영향을 나타낼 수 있음.            범주형 설명변수와 연속형 설명변수 간 교호작용 효과          어느 신용카드 사에서 고객의 신용카드 대금에 관한 회귀 모형을 설계하고자 한다. 고객의 수입과 학생 여부에 관한 데이터를 확보하고 있다. 이때 수입과 학생 여부에 대한 교호작용 효과의 유효성을 알아보고자 한다.                      지시 변수(Indicate Variable)\\[d^{(i)}  = \\begin{cases}\\begin{aligned}  1 \\quad &amp;\\text{if student}\\\\  0 \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]                    선형 회귀 모형                  학생 여부와 수입 간 교호작용 효과가 있다는 것보다는 학생일 때와 학생이 아닐 때 수입이 신용카드 대금에 미치는 영향력에 차이가 있다는 것으로 해석하는 것이 바람직함        \\[\\begin{aligned}  y^{(i)}  &amp;= \\beta_{0} + \\beta_{1} \\cdot d^{(i)} + \\beta_{2} \\cdot x^{(i)} + \\beta_{3} \\cdot d^{(i)} x^{(i)} + \\varepsilon^{(i)}\\\\  &amp;= \\begin{cases}\\begin{aligned}  \\left(\\beta_{0} + \\beta_{1}\\right) + \\left(\\beta_{2} + \\beta_{3}\\right) \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{if student}\\\\  \\beta_{0} + \\beta_{2} \\cdot x^{(i)} + \\varepsilon^{(i)} \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}  \\end{aligned}\\]                  $\\beta_2$ : 학생이 아닌 사람의 $x$(Income) 단위 변동에 따른 $y$ 변동성          $\\beta_2 + \\beta_3$ : 학생인 사람의 $x$(Income) 단위 변동에 따른 $y$ 변동성                    "
  },
  
  {
    "title": "Regression Diagnostics",
    "url": "/posts/Regression_Diagnostics/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression",
    "date": "2024-07-11 00:00:00 +0900",
    





    
    "snippet": "Regression Diagnostics      회귀 진단(Regression Diagnostics) : 고전적 선형 회귀 가정이 위배되는지 진단하는 절차        고전적 선형 회귀 가정이 위배됨에 따라 발생하는 문제점          A.1 반응변수와 설명변수 간 비선형성 문제(Non-linearity Problem)      A.2 오차항 간...",
    "content": "Regression Diagnostics      회귀 진단(Regression Diagnostics) : 고전적 선형 회귀 가정이 위배되는지 진단하는 절차        고전적 선형 회귀 가정이 위배됨에 따라 발생하는 문제점          A.1 반응변수와 설명변수 간 비선형성 문제(Non-linearity Problem)      A.2 오차항 간 상관성 문제(Auto-correlation Problem)      A.3 이상치 및 영향점 문제(Outlier &amp; Influential Points Problem)      A.4 오차항의 이분산성 문제(Hetero-scedasticity Problem)      A.5 설명변수 간 다중공선성 문제(Multi-col-linearity Problem)      Non-linearity Problem      $Y$ 가 $X$ 의 선형 결합이 아니라고 하자\\[\\begin{aligned}  y_i= f(x_i)+\\varepsilon_i  \\end{aligned}\\]        최소자승추정량 \\(\\hat{\\beta}_{1}\\) 을 다음과 같이 이해할 수 있음\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i - \\overline{x})(f(x_i)+\\varepsilon_i - \\overline{f(x)} - \\overline{\\varepsilon})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(\\varepsilon_i-\\overline{\\varepsilon})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot \\varepsilon_i}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} - \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot \\overline{\\varepsilon}}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}  \\end{aligned}\\]        \\(\\hat{\\beta}_{1}\\) 의 기대값은 다음과 같음\\[\\begin{aligned}  \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}} + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot \\mathbb{E}\\left[\\varepsilon_i\\right]} \\quad \\text{s.t.} \\quad X \\perp \\varepsilon\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot 0} \\quad (\\because \\varepsilon \\sim N(0,\\sigma^2))\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right]  \\end{aligned}\\]        따라서 \\(\\hat{\\beta}_{1}\\) 은 \\(\\beta_{1}\\) 의 불편추정량이 될 수 없음\\[\\begin{aligned}  \\mathbb{Bias}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] - \\beta_1\\\\  &amp;= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(f(x_i)-\\overline{f(x)})}}{\\sum_{i=1}^{n}{(x_i - \\overline{x})^2}}\\right] - \\beta_1\\\\  &amp;\\ne 0  \\end{aligned}\\]  Auto-correlation Problem      최소자승추정량 \\(\\hat{\\beta}_{1}\\) 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{Var}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{Var}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\\\  &amp;= \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]} \\quad (\\because \\sigma_{i^{\\forall}}^{2}=\\sigma^{2})  \\end{aligned}\\]        $\\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right] \\ne 0$ 이므로 최소분산성을 보장할 수 없음\\[\\begin{aligned}  \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sigma^{2}\\sum_{i=1}^{n}{w_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}  \\end{aligned}\\]  Durbin-Watson Statistic      더빈-왓슨 통계량(Durbin-Watson Statistic) : 잔차의 1차 자기상관성을 측정하는 지표\\[\\begin{aligned}  DW  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}}  \\end{aligned}\\]          $DW \\approx 0$ : 양의 자기상관이 매우 강함      $DW \\approx 2$ : 자기상관 없음      $DW \\approx 4$ : 음의 자기상관이 매우 강함            $0\\le DW \\le 4 \\quad (\\because -1 \\le \\rho \\le 1)$                  $DW$ 의 분자를 다음과 같이 세분화할 수 있음\\[\\begin{aligned}  \\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}  &amp;= \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2} - 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}\\\\  \\end{aligned}\\]                    $n$ 이 매우 클 경우 다음이 성립함\\[\\begin{aligned}  \\sum_{t=2}^{n}{\\varepsilon_{t}^2}  &amp;\\approx \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2}\\\\  \\therefore \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2}  &amp;\\approx 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t}^2}  \\end{aligned}\\]                    자기상관계수 $\\rho$ 의 정의에 의해 다음이 성립함\\[\\begin{aligned}  \\rho  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\overline{\\varepsilon})(\\varepsilon_{t-1}-\\overline{\\varepsilon})}}{\\sum_{t=1}^{n}{(\\varepsilon_{t}-\\overline{\\varepsilon})^{2}}}\\\\  &amp;= \\frac{\\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}} \\quad(\\because \\varepsilon \\sim N(0, \\sigma^2))\\\\  \\therefore \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}  &amp;= \\rho \\cdot \\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}  \\end{aligned}\\]                    따라서 분자를 다음과 같이 이해할 수 있음\\[\\begin{aligned}  \\therefore \\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}  &amp;= \\sum_{t=2}^{n}{\\varepsilon_{t}^2} + \\sum_{t=2}^{n}{\\varepsilon_{t-1}^2} - 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t} \\cdot \\varepsilon_{t-1}}\\\\  &amp;\\approx 2 \\cdot \\sum_{t=2}^{n}{\\varepsilon_{t}^2} - 2 \\cdot \\rho \\cdot \\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}\\\\  &amp;\\approx 2(1-\\rho) \\cdot \\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}  \\end{aligned}\\]                    따라서 $DW$ 는 $\\rho$ 와 다음의 관계가 성립함\\[\\begin{aligned}  \\therefore DW  &amp;= \\frac{\\sum_{t=2}^{n}{(\\varepsilon_{t}-\\varepsilon_{t-1})^{2}}}{\\sum_{t=1}^{n}{(\\varepsilon_{t})^{2}}}\\\\  &amp;\\approx 2(1-\\rho) \\cdot \\frac{\\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}}{\\sum_{t=1}^{n}{\\varepsilon_{t}^{2}}}\\\\  &amp;= 2(1-\\rho)  \\end{aligned}\\]            Hetero-scedasticity Problem      최소자승추정량 \\(\\hat{\\beta}_{1}\\) 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{Var}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{Var}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} \\quad (\\because \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right] = 0)  \\end{aligned}\\]        $\\sigma_{i}^{2} \\ne \\sigma_{j \\ne i}^{2}$ 이므로 최소분산성을 보장할 수 없음\\[\\begin{aligned}  \\sigma^{2}\\cdot\\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}}  \\end{aligned}\\]  Breusch-Pagan Test      브레쉬-파건 검정(Breusch-Pagan Test) : 잔차의 등분산성에 관한 검정        관심 모수 $\\sigma^2$ 의 점 추정량 도출                  다중선형회귀모형에서 $i$ 번째 관측치의 잔차 $\\varepsilon^{(i)}$ 는 다음과 같이 정의됨\\[\\begin{aligned}  y^{(i)}  &amp;= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{p} \\cdot x^{(i)}_{p} + \\varepsilon^{(i)}\\\\  \\varepsilon^{(i)}  &amp;= y^{(i)} - \\left(\\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{p} \\cdot x^{(i)}_{k} \\right)  \\end{aligned}\\]                    잔차 자승 $\\varepsilon^{2}$ 은 오차 분산 $\\sigma^2$ 의 간접적인 추정치임\\[\\begin{aligned}  \\hat{\\sigma}^{2}  &amp;= \\frac{1}{n-(p+1)} \\cdot \\sum_{i=1}^{n}{(\\varepsilon_{i} - \\overline{\\varepsilon})^{2}}\\\\  &amp;= \\frac{1}{n-(p+1)} \\cdot \\sum_{i=1}^{n}{\\varepsilon_{i}^{2}} \\quad (\\because \\varepsilon \\sim N(0,\\sigma^2))  \\end{aligned}\\]              귀무가설과 대립가설 설정          $H_0:\\quad \\sigma_{i}^2 = \\sigma_{j\\ne i}^2$      $H_1:\\quad \\sigma_{i}^2 \\ne \\sigma_{j\\ne i}^2$            검정통계량 도출\\[BP \\sim \\chi^{2}(p)\\]                  잔차 자승 $\\varepsilon_{i}^{2}$ 에 대한 보조회귀모형 정의\\[\\begin{aligned}  \\varepsilon_{i}^{2}  &amp;= \\gamma_{0} + \\gamma_{1} \\cdot x^{(i)}_{1} + \\cdots + \\gamma_{k} \\cdot x^{(i)}_{p} + \\epsilon^{(i)}  \\end{aligned}\\]                    보조회귀모형의 결정계수 $R^2$ 도출\\[\\begin{aligned}  R^{2}  &amp;= 1 - \\frac{RSS}{TSS}\\\\  &amp;= 1 - \\frac{\\sum_{i=1}^{n}{\\epsilon_{i}^{2}}}{\\sum_{i=1}^{n}{\\left(\\varepsilon_{i}^{2}-\\overline{\\varepsilon^{2}}\\right)^{2}}}  \\end{aligned}\\]                    검정통계량 도출\\[BP = n \\cdot R^2 \\sim \\chi^{2}(p)\\]            Multi-col-linearity Problem      반응변수 $Y$ 가 설명변수 $X_1, X_2$ 의 선형 결합이라고 하자\\[\\begin{aligned}  Y = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\varepsilon  \\end{aligned}\\]        설명변수 $X_1$ 에 대한 가중치 $\\beta_1$ 의 의미\\[\\begin{aligned}  \\beta_1  &amp;= \\frac{\\partial Y}{\\partial X_1}  \\end{aligned}\\]        설명변수 $X_1$ 에 대한 가중치 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_{1}$\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})(y^{(i)}-\\overline{y})}}{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})^{2}}} - \\frac{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})(x^{(i)}_{2}-\\overline{x}_{2})}}{\\sum_{i=1}^{n}{(x^{(i)}_{1}-\\overline{x}_{1})^{2}}} \\cdot \\hat{\\beta}_{2}\\\\  &amp;= \\frac{\\mathbb{Cov}\\left[X_1, Y\\right]}{\\mathbb{Var}\\left[X_1\\right]} - \\frac{\\mathbb{Cov}\\left[X_1, X_2\\right]}{\\mathbb{Var}\\left[X_1\\right]} \\cdot \\hat{\\beta}_{2}  \\end{aligned}\\]        $X_2$ 가 $X_1$ 의 선형 결합으로 표현될 수 있다고 하자\\[\\begin{aligned}  X_2 = \\delta + \\alpha \\cdot X_1 + \\epsilon  \\end{aligned}\\]        \\(\\mathbb{Cov}\\left[X_1, X_2\\right] \\ne 0\\) 이므로 \\(\\hat{\\beta}_{1}\\) 은 \\(\\hat{\\beta}_{2}\\) 를 포함하게 되어 \\(Y\\) 에 대한 \\(X_1\\) 만의 순수한 설명력을 의미한다고 해석할 수 없음\\[\\begin{aligned}  Y  &amp;= \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\varepsilon\\\\  &amp;= \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot \\left(\\delta + \\alpha \\cdot X_1\\right) + \\varepsilon\\\\  &amp;= \\left(\\beta_0 + \\delta \\cdot \\beta_2 \\right) + \\left(\\beta_1 + \\alpha \\cdot \\beta_2\\right) \\cdot X_1 + \\varepsilon  \\end{aligned}\\]  VIF      분산팽창계수(Variance Inflation Factor; VIF) : 변동성을 기준으로 다중공선성을 측정하는 지표로서, 통상 10을 초과하는 경우 다중공선성이 높다고 판단함\\[\\begin{aligned}  VIF_k  &amp;= \\frac{1}{1-R_{k}^{2}}  \\end{aligned}\\]          $VIF_i$ : $i$ 번째 설명변수의 분산팽창계수      $R_i^2$ : $i$ 번째 설명변수에 대한 결정계수            $R_k^2$                  다중선형회귀모형은 다음과 같이 정의됨\\[\\begin{aligned}  y^{(i)}  &amp;= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\cdot x^{(i)}_{1} + \\cdots + \\hat{\\beta}_{k} \\cdot x^{(i)}_{p} + \\varepsilon^{(i)}  \\end{aligned}\\]                    $k$ 번째 설명변수에 대한 보조회귀모형 도출\\[\\begin{aligned}  x_{k}^{(i)}  &amp;= \\gamma_{0} + \\gamma_{1} \\cdot x^{(i)}_{1} + \\cdots + \\gamma_{k-1} \\cdot x^{(i)}_{k-1} + \\gamma_{k+1} \\cdot x^{(i)}_{k+1} + \\cdots +\\gamma_{p} \\cdot x^{(i)}_{p} + \\epsilon^{(i)}  \\end{aligned}\\]                    보조회귀모형의 결정계수 $R_k^2$ 도출\\[\\begin{aligned}  R_{k}^{2}  &amp;= 1 - \\frac{RSS_k}{TSS_k}\\\\  &amp;= 1 - \\frac{\\sum_{i=1}^{n}{\\epsilon_{i}^{2}}}{\\sum_{i=1}^{n}{\\left(x_{k}^{(i)}-\\overline{x}_{k}\\right)^{2}}}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Multiple Linear Regression Analysis",
    "url": "/posts/Multiple_Linear_Regression_Analysis/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression, f Test",
    "date": "2024-07-10 00:00:00 +0900",
    





    
    "snippet": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+...",
    "content": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+\\varepsilon^{(k)}\\]        VS. Simple Linear Regression                      Simple Linear Regression\\[\\begin{aligned}  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}  \\end{aligned}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제하지 않은 상태에서 추정되었다. 때문에 해당 요인($X_{i}$)과 다른 요인들 간 상관관계가 있을 경우, $\\beta_{i}$ 은 다른 요인들의 변화가 매출에 미치는 영향력을 포함하게 된다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 없다.                            Multiple Linear Regression\\[\\text{Sales}^{(k)}=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제한 상태에서 추정되었다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 있다.                    Normal Equation      정규방정식(Normal Equation) : 최소자승법에 기초하여 추정한 가중치 벡터\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{RSS}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]    정규방정식 도출 과정                  변수 갯수가 $P$ 이고 관측치 갯수가 $N$ 인 다중 선형 회귀 모형을 선형대수로 표현하면 다음과 같음\\[\\overrightarrow{\\hat{y}} = \\mathbf{X}\\hat{\\overrightarrow{\\beta}}\\]                  $\\mathbf{X}_{N \\times P}$ : Design Matrix                            $RSS$ 도출\\[\\begin{aligned}  RSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\right\\Vert^2\\\\  &amp;= (\\overrightarrow{y}^T - \\overrightarrow{\\beta}^T \\mathbf{X}^T)(\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;= \\overrightarrow{y}^T \\overrightarrow{y} - \\overrightarrow{y}^T \\mathbf{X} \\overrightarrow{\\beta} - \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y} + \\overrightarrow{\\beta}^T \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}  \\end{aligned}\\]                    $\\because \\overrightarrow{y}^T \\mathbf{X} \\overrightarrow{\\beta} = \\left(\\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y}\\right)^T = \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y}$\\[RSS = \\overrightarrow{y}^T \\overrightarrow{y} - 2 \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y} + \\overrightarrow{\\beta}^T \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}\\]                    $RSS$ 를 $\\overrightarrow{\\beta}$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial}{\\partial \\overrightarrow{\\beta}} RSS  &amp;= -2 \\mathbf{X}^T \\overrightarrow{y} + 2 \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}\\\\  &amp;= 0 \\quad (\\because \\min_{\\overrightarrow{\\beta}}{RSS})  \\end{aligned}\\]                    $\\overrightarrow{\\beta}$ 에 대하여 정리\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}\\\\  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{RSS}  \\end{aligned}\\]                  회귀계수의 해석          설명변수 $X_{i}$ 의 회귀계수 $\\beta_{i}$ 는 다른 모든 설명변수가 일정할 때 $X_{i}$ 가 $1$ 단위 변화함에 따른 $Y$ 변화 단위의 추정치이다. 즉, 다른 모든 설명변수에 대하여 변동이 없는 상태에서, $X_{i}$ 가 $1$ 단위 변화했을 때 $Y$ 가 $\\beta_{i}$ 만큼 변화할 것이라 추정된다.      회귀계수의 유의성 검정: F-검정      정의 : 반응변수에 대한 설명변수들의 설명력이 통계적으로 유의한가에 관한 검정    귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_1=\\beta_2 =\\cdots =\\beta_p=0$      $H_{1}: \\quad$ 적어도 하나의 $i$ 에 대하여 $\\beta_{i} \\ne 0$            검정통계량 도출\\[F  = \\frac{ESS/p}{RSS/(n-p-1)} \\sim F(p, n-p-1)\\]                  회귀변동(Explained Sum of Square; ESS) : 모형에 의해 설명되는 반응변수의 변동성\\[ESS=TSS-RSS\\]                    총변동(Total Sum of Square; TSS) : 반응변수의 총 변동성\\[\\begin{aligned}  TSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overline{y} \\right\\Vert^2\\\\  &amp;= \\sum{\\left(y^{(i)}-\\overline{y} \\right)^2}  \\end{aligned}\\]                    잔차변동(Residual Sum of Square) : 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\right\\Vert^2\\\\  &amp;= \\sum{\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2}  \\end{aligned}\\]            부분 유의성 검정  Occam’s Razor  Entities should not be multiplied beyond necessity.      정의 : 설명변수 추가에 따른 부분적 효과의 통계적 유의성에 관한 검정    모형 예시          $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon$      $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\varepsilon$        귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_3=\\beta_4=0$      $H_{1}: \\quad \\beta_{3} \\ne 0 \\quad \\text{or} \\quad \\beta_{4} \\ne 0$            검정통계량 도출\\[F  = \\frac{(RSS_{0}-RSS)/q}{RSS/(n-p-1)} \\sim F(q, n-p-1)\\]                  $RSS$ : 설명변수 $X_{3}, X_{4}$ 를 추가한 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 + \\beta_3 x^{(i)}_3 + \\beta_4 x^{(i)}_4 \\right) \\right]^2}  \\end{aligned}\\]                    $RSS_{0}$ : 설명변수 $X_{3}, X_{4}$ 를 추가하지 않은 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS_{0}  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 \\right) \\right]^2}  \\end{aligned}\\]            $n$ : 관측치 갯수      $p$ : 총 설명변수 갯수      $q$ : 검정 대상 설명변수($X_{3}, X_{4}$) 를 제외한 설명변수의 갯수      Sourse  https://www.linkedin.com/pulse/understanding-linear-regression-basics-divyesh-sonar-snv4c/"
  },
  
  {
    "title": "Regression Coefficient Estimation",
    "url": "/posts/Regression_Coefficient_Estimation/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression, Estimation, OLS",
    "date": "2024-07-09 00:00:00 +0900",
    





    
    "snippet": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\va...",
    "content": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left(y_{i} - \\hat{y}_{i} \\right)^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left[ y_{i} - \\left(\\beta_{0} + \\beta_{1} x_{i} \\right) \\right]^2}}  \\end{aligned}\\]        최소자승추정량(OLS Estimator)          편향 \\(\\beta_{0}\\) 의 최소자승추정량 \\(\\hat{\\beta}_{0} = \\overline{Y} - \\hat{\\beta}_{1} \\overline{X}\\)      가중치 \\(\\beta_{1}\\) 의 최소자승추정량 \\(\\hat{\\beta}_{1} = \\displaystyle\\frac{Cov(X,Y)}{Var(X)}\\)      OLS Estimator      $Loss(\\beta_0, \\beta_1)=\\displaystyle\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}$ 을 $\\beta_0$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_0}Loss(\\beta_0, \\beta_1)\\\\  &amp;= -2 \\times \\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_0 + \\beta_1 x_{i}\\right)\\right]} \\\\  &amp;= -2 \\times \\left[\\sum_{i=1}^{n}{y_{i}} - n \\beta_{0}-\\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\right] \\cdots ①\\\\  &amp;= -2n \\times (\\overline{Y} - \\beta_0 - \\beta_1 \\overline{X}) \\\\  &amp;= 0  \\end{aligned}\\]        편향 $\\beta_0$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 도출\\[\\therefore  \\hat{\\beta_0}  = \\overline{Y} - \\hat{\\beta_1}\\overline{X} \\quad (\\text{s.t.} \\; n \\ne 0)\\]        $Loss(\\beta_0, \\beta_1)=\\displaystyle\\sum_{i=1}^{n}{e_{i}^{2}}$ 을 $\\beta_0$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_1} Loss(\\beta_0, \\beta_1)\\\\  &amp;= -2\\times\\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_0+\\beta_1 x_{i}\\right)\\right] \\times x_{i}}\\\\  &amp;= -2\\times\\left[\\sum_{i=1}^{n}{y_{i}x_{i}}-\\beta_0\\sum_{i=1}^{n}{x_{i}}-\\beta_1\\sum_{i=1}^{n}{x_{i}^2}\\right] \\cdots ② \\\\  &amp;= 0  \\end{aligned}\\]        식 $①$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ① \\times \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}} - n \\beta_{0} \\sum_{i=1}^{n}{x_{i}} - \\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{0}\\overline{X}-n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\\\  &amp;= 0  \\end{aligned}\\]        식 $②$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ② \\times n \\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_0 \\sum_{i=1}^{n}{x_{i}} - n \\beta_1 \\sum_{i=1}^{n}{(x_{i})^2}\\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n^{2} \\beta_0 \\overline{X} - n \\beta_1 \\sum_{i=1}^{n}{x_{i}^2}\\\\  &amp;= 0  \\end{aligned}\\]        식 ①, ② 의 변형을 뺄셈\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\left(① \\times \\displaystyle\\sum_{i=1}^{n}X_i - ② \\times n \\right)\\\\  &amp;= \\left[n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\right] -  \\left[n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_1 \\sum_{i=1}^{n}{(x_{i})^2}\\right]\\\\  &amp;= \\beta_1 \\times n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{x_{i}^2}-\\left(\\overline{X}\\right)^{2}\\right] - n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}x_{i}}-\\overline{Y}\\overline{X}\\right]\\\\  &amp;= \\beta_1 \\times n^{2} Var\\left[X\\right] - n^{2} Cov\\left[Y,X\\right]\\\\  &amp;= 0  \\end{aligned}\\]        가중치 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 도출\\[\\hat{\\beta}_{1}  = \\frac{Cov\\left[Y,X\\right]}{Var\\left[X\\right]}\\]  Gauss-Markov Assumptions      A.1 반응변수와 설명변수의 선형성 가정          The Linear Model is Correctly Specified.            A.2 관측치 간 오차항의 자기상관 없음(No Autocorrelation) 가정          $\\mathbb{Cov}\\left[\\varepsilon_i, \\varepsilon_j\\right]=0$ If $i \\ne j$            A.3 오차항의 기대값에 관한 가정          $\\mathbb{E}\\left[\\varepsilon_i\\right]=0$ For Every $i=1,\\cdots,n$            A.4 오차항의 등분산성(Homoskedasticity) 가정          $\\mathbb{Var}\\left[\\varepsilon_i\\right]=\\sigma^2$ For Every $i=1,\\cdots,n$            A.5 설명변수의 비확률성 가정 혹은 설명변수 간 통계적 독립성 가정          $X_i$ is Non-Random For Every $i=1,\\cdots,n$      OLS $\\hat{\\beta}_{1}$ subject to Gauss-Markov Assumptions      가중치 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_1$ 은 $Y$ 의 선형 결합\\[\\begin{aligned}  \\hat{\\beta}_1  &amp;= \\frac{\\mathbb{Cov}(X,Y)}{\\mathbb{Var}(X)}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}(x_i-\\overline{x})(y_i-\\overline{y})}{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}\\\\  \\\\  \\sum_{i=1}^{n}{(x_i-\\overline{x})(y_i-\\overline{y})}  &amp;= \\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot y_i} - \\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot \\overline{y}}\\\\  &amp;= \\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot y_i} - \\overline{y} \\cdot \\sum_{i=1}^{n}{(x_i-\\overline{x})}\\\\  &amp;= \\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot y_i}\\\\  \\\\  \\therefore \\hat{\\beta}_{1}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x}) \\cdot y_i}}{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}\\\\  &amp;= w_1 \\cdot y_1 + w_2 \\cdot y_2 + \\cdots + w_n \\cdot y_n\\\\  w_{i}  &amp;=\\frac{(x_i-\\overline{x})}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}  \\end{aligned}\\]        $w_i$ 에 대하여 다음이 성립함                  $\\sum_{i=1}^{n}{w_i}=\\displaystyle\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})}}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}=0$                    $\\sum_{i=1}^{n}{w_i \\cdot x_i}=1$\\[\\begin{aligned}  \\sum_{i=1}^{n}{w_i \\cdot x_i}  &amp;= \\sum_{i=1}^{n}{\\frac{(x_i-\\overline{x})}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}} \\cdot x_i}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})\\cdot x_i}}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}\\\\  \\\\  \\sum_{i=1}^{n}{(x_i-\\overline{x})\\cdot x_i}  &amp;= \\sum_{i=1}^{n}{(x_{i}^{2}-\\overline{x}\\cdot x_{i})}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}^{2}} - \\overline{x}\\cdot\\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}^{2}} - n\\cdot \\overline{x}^{2}\\\\  &amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}\\\\  \\\\  \\therefore \\sum_{i=1}^{n}{w_i \\cdot x_i}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})\\cdot x_i}}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\sum_{j=1}^{n}{(x_j-\\overline{x})^2}}\\\\  &amp;= 1  \\end{aligned}\\]                    $\\sum_{i=1}^{n}{w_i^2}=\\displaystyle\\frac{1}{\\sum_{i=1}^{n}(x_i-\\overline{x})^2}$\\[\\begin{aligned}  \\sum_{i=1}^{n}{w_i^2}  &amp;= \\sum_{i=1}^{n}{\\left(\\frac{(x_{i}-\\overline{x})}{\\sum_{j=1}^{n}(x_{j}-\\overline{x})^2}\\right)^{2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\left(\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^2}\\right)^{2}}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^2} \\cdot \\sum_{j=1}^{n}{(x_{j}-\\overline{x})^2}}\\\\  &amp;= \\frac{1}{\\sum_{j=1}^{n}{(x_{j}-\\overline{x})^2}}  \\end{aligned}\\]                  따라서 최소자승추정량 $\\hat{\\beta_1}$ 과 그 모수 $\\beta_1$ 사이에는 다음이 성립함\\[\\begin{aligned}  \\hat{\\beta}_{1}  &amp;= \\sum_{i=1}^{n}{w_i \\cdot y_i}\\\\  &amp;= \\sum_{i=1}^{n}{w_i \\cdot (\\beta_0+\\beta_1 \\cdot x_i+\\varepsilon_i)}\\\\  &amp;= \\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}  \\end{aligned}\\]  Gauss-Markov Theorem  고전적 선형 회귀 가정(Classical Linear Regression Assumptions or Gauss-Markov Assumptions) 하 최소자승추정량은 선형 불편 추정량 중 분산이 가장 작은 추정량(Best Linear Unbiased Estimator; BLUE)이다.      가중치 $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 의 확률분포\\[\\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\sigma^2\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]\\right)\\]        편향 $\\beta_{0}$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 의 확률분포\\[\\hat{\\beta}_{0} \\sim N\\left(\\beta_{0}, \\sigma^{2} \\left[\\displaystyle\\frac{1}{n} + \\displaystyle\\frac{\\overline{x}^{2}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]\\right)\\]        오차항 $\\varepsilon$ 의 모분산 $\\sigma^2$ 을 그 표본분산으로 추정함\\[\\sigma^2 \\xrightarrow{\\text{P}} \\displaystyle\\frac{\\text{RSS}}{n-2}\\]  OLS is Unbiased Estimator      고전적 선형 회귀 가정 하 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_1$ 의 기대값은 다음과 같음\\[\\begin{aligned}  \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\beta_1\\right] + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\beta_1 + \\mathbb{E}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\beta_1 + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i \\cdot \\varepsilon_i\\right]}\\\\  &amp;= \\beta_1 + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot \\mathbb{E}\\left[\\varepsilon_i\\right]} \\quad \\text{s.t.} \\quad X \\perp \\varepsilon\\\\  &amp;= \\beta_1 + \\sum_{i=1}^{n}{\\mathbb{E}\\left[w_i\\right] \\cdot 0} \\quad (\\because \\varepsilon \\sim N(0,\\sigma^2))\\\\  &amp;= \\beta_1  \\end{aligned}\\]        따라서 고전적 선형 회귀 가정 하 최소자승추정량 $\\hat{\\beta}_1$ 은 $\\beta_1$ 의 불편 추정량임\\[\\begin{aligned}  \\therefore \\mathbb{Bias}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] - \\beta_1\\\\  &amp;= 0  \\end{aligned}\\]  OLS is Efficient Estimator      $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_1$ 의 분산은 다음과 같음\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\mathbb{Var}\\left[\\beta_1 + \\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\mathbb{Var}\\left[\\sum_{i=1}^{n}{w_i \\cdot \\varepsilon_i}\\right]\\\\  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}  \\end{aligned}\\]        $\\because \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]=0$\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}}  \\end{aligned}\\]        $\\because \\sigma_{i^{\\forall}}^{2}=\\sigma^{2}$\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]  &amp;= \\sigma^{2} \\cdot \\sum_{i=1}^{n}{w_{i}^{2}}  \\end{aligned}\\]        따라서 고전적 선형 회귀 가정 하 $\\hat{\\beta}_1$ 은 $\\beta_1$ 의 불편 추정량 중 분산이 가장 작은 추정량임\\[\\sigma^{2} \\cdot \\sum_{i=1}^{n}{w_{i}^{2}} \\le \\sum_{i=1}^{n}{w_{i}^{2} \\cdot \\sigma_{i}^{2}} + \\sum_{i}\\sum_{j \\ne i}{w_{i} \\cdot w_{j} \\cdot \\mathbb{Cov}\\left[\\varepsilon_{i}, \\varepsilon_{j}\\right]}\\]  Sourse  https://medium.com/@luvvaggarwal2002/linear-regression-in-machine-learning-9e8af948d3eb"
  },
  
  {
    "title": "Simple Linear Regression Analysis",
    "url": "/posts/Simple_Linear_Regression_Analysis/",
    "categories": "DATA MINING TECHS, 2.regression analysis",
    "tags": "Statistics, Regression, t Test, Goodness of Fit Test, R2",
    "date": "2024-07-08 00:00:00 +0900",
    





    
    "snippet": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들...",
    "content": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들이 더 행복한가?      소득이 증가할 때 소비는 얼마나 증가하는가?      교육수준이 높을수록 임금이 증가하는가?        변수(Variable)          예측 대상이 되는 변수($Y$)                  반응변수(Response Variable)          종속변수(Dependent Variable)          내생변수(Endogenous Variable)                    예측에 활용되는 변수($X$)                  설명변수(Explanatory Variable)          독립변수(Independent Variable)          외생변수(Exogenous Variable)                    Simple Linear Regression Model      단순 선형 회귀 모형(Simple Linear Regression Model) : 반응변수와 단일 설명변수 간 선형 상관관계를 모델링하는 모형\\[\\begin{aligned}  Y  &amp;=\\beta_0+\\beta_1X+\\varepsilon\\\\  y_{i}  &amp;=\\beta_0+\\beta_1 x_{i}+\\varepsilon_{i}  \\end{aligned}\\]    회귀계수(Regression Coefficient) : 모형이 추론하고자 하는 모수(Parameter)로서 상수          편향(Bias; $\\beta_0$) : 설명변수의 값이 $0$ 일 때 종속변수의 값      가중치(Weight; $\\beta_1$) : 설명변수가 종속변수에 미치는 영향력의 방향과 강도            오차항(Error Term; $\\varepsilon$) : 확률변수\\[\\begin{aligned}  \\varepsilon = y-\\left(\\beta_{0} + \\beta_{1} x \\right) \\sim N(0, \\sigma^2)  \\end{aligned}\\]                  잔차(Residual; $\\epsilon$) : 최적 회귀계수 하 오차항의 추정치\\[\\epsilon=y-\\left(\\hat{\\beta}_{0} + \\hat{\\beta}_{1} x \\right)\\]            회귀계수의 유의성 검정: T-검정  반응변수와 설명변수가 통계적으로 유의한(Statistically Significant) 관계를 가지는가에 관한 가설검정임. 단, 검정 결과 두 변수 간 관계가 통계적으로 유의하다는 결론이 도출되더라도, 이 결론은 두 변수 간 상관관계(Correlation)의 유의성을 보장할 뿐, 두 변수 간 선형관계(Linear Relationship) 혹은 인과관계(Causation)의 유의성을 보장하지는 않음.  관심 모수에 대한 점 추정량 도출          관심 모수 : $\\beta_{1}$      점 추정량 : \\(\\hat{\\beta}_{1} \\sim N(\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right], \\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]^2) \\quad \\text{s.t.}\\;n&gt;30\\)                  최소자승추정량의 평균 : \\(\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] = \\beta_{1}\\)          최소자승추정량의 분산 : \\(\\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]^2 = \\sigma^2\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right] \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0,\\sigma^2)\\)                      귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_{1} = 0$      $H_{1}: \\quad \\beta_{1} \\ne 0$            검정통계량 도출\\[\\begin{aligned}  T = \\frac{\\hat{\\beta}_{1}-0}{\\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]} \\sim t(n-2)  \\end{aligned}\\]  Goodness of Fit      적합도(Goodness of Fit) : 모형이 반응변수의 변동을 얼마나 잘 설명하고 있는가    반응변수(Response Variable)          $y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\varepsilon_{i}$      $\\hat{y}=\\beta_{0}+\\beta_{1}x$      $\\overline{y}=\\beta_{0}+\\beta_{1}\\overline{x} \\quad \\text{s.t.}\\; \\varepsilon \\sim N(0, \\sigma^2)$            반응변수의 변동성 세분화\\[\\begin{aligned}  \\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} + \\varepsilon_{i}\\right) -\\overline{y}\\right]^{2}} \\\\  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right) + \\varepsilon_i \\right]^{2}} \\\\  &amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right)^2 + \\varepsilon_{i}^{2} + 2 \\times \\varepsilon_{i} \\times \\left(\\hat{y}_{i}-\\overline{y}\\right)\\right]} \\\\  &amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^{2}} + \\sum_{i=1}^{n}{\\varepsilon_{i}^2} + 2\\times\\sum_{i=1}^{n}{\\varepsilon_{i}\\left(\\hat{y}_{i}-\\overline{y}\\right)} \\\\  &amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^2} + \\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}\\quad(\\because \\sum_{i=1}^{n}{\\hat{y}_{i}-\\overline{y}} = 0)  \\end{aligned}\\]                  총변동(Total Sum of Square; TSS) : 반응변수의 총 변동성\\[TSS=\\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}\\]                    회귀변동(Explained Sum of Square; ESS) : 모형에 의해 설명되는 반응변수의 변동성\\[ESS=\\sum_{i=1}^{n}{\\left(\\hat{y}_{i}-\\overline{y}\\right)^2}\\]                    잔차변동(Residual Sum of Square; RSS) : 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;=\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}\\\\  &amp;=\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}  \\end{aligned}\\]                  결정계수(Coefficient of Determination; $R^2$) : 총변동 대비 회귀변동의 비율로 측정된 적합도\\[\\begin{aligned}  R^2  &amp;= \\frac{ESS}{TSS} \\\\  &amp;= \\frac{ESS}{ESS + RSS} \\\\  &amp;= 1 - \\frac{RSS}{TSS}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Summarize Statistical Method",
    "url": "/posts/Summarize_Statistical_Methods/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics, Normality Test, Shapiro-Wilk Test, Homogeneity of Variance Test, Levene’s Test, ANOVA",
    "date": "2024-07-07 00:00:00 +0900",
    





    
    "snippet": "수치형 변수의 평균에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 평균      $\\mu$      $\\bar{X}$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu...",
    "content": "수치형 변수의 평균에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 평균      $\\mu$      $\\bar{X}$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu=\\mu_0$      One Sample t-Test      statsmodels.stats.ttest_mean              두 집단 간 평균 비교  (독립표본)      $\\mu_1-\\mu_2$      \\(\\bar{X}_{1} - \\bar{X}_{2}\\)      $(n_1 + n_2)&gt;30$ or $X_{1}\\sim N, X_{2} \\sim N$      $H_0: \\mu_1 - \\mu_2 = 0$      Two Sample t-Test      statsmodels.stats.weightstats.ttest_ind              두 집단 간 평균 비교  (쌍체표본)      $\\mu_d$      $\\bar{X}_d$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu_d=0$      Paired t-Test      statsmodels.stats.ttest_mean              셋 이상 그룹 간 평균 비교      $\\mu_1, \\cdots, \\mu_m$      $\\bar{X}_1, \\cdots, \\bar{X}_m$      $n_i&gt;30$ or $X_{i} \\sim N$  $\\sigma_{i}^{2}=\\sigma_{j}^{2}$      $H_0: \\mu_1 = \\cdots = \\mu_m$      ANOVA      statsmodels.stats.anova.AnovaRM              양적변수 간의 상관관계      $\\beta_0, \\beta_1$  $(y=\\beta_0+\\beta_1 x + \\epsilon)$      $\\hat{\\beta}_0, \\hat{\\beta}_1$      반응변수와 설명변수 간 선형성  설명변수 간 독립성  오차의 등분산성  오차의 정규성      $H_0: \\beta_i=0$      Regression      statsmodels.api.OLS      범주형 변수의 비율에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 비율      $\\pi$      $p$      $np&gt;5$  $n(1-p)&gt;5$      $H_0: \\pi=\\pi_0$      One Sample z-Test      statsmodels.stats.proportion.proportions_ztest              두 집단 간 비율 비교      $\\pi_1 - \\pi_2$      $p_1 - p_2$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1-\\pi_2=0$      Two Sample z-Test      statsmodels.stats.proportion.proportions_ztest              적합성 검정      $\\pi_1, \\cdots, \\pi_m$      $p_1, \\cdots, p_m$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1=p_{0}^{(1)}, \\cdots, \\pi_m=p_{0}^{(m)}$      Chi-square test      scipy.stats.chisquare              독립성 검정                    $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0:$ 두 범주형 변수가 독립      Chi-square test      scipy.stats.chi2_contingency              양적변수와의 상관관계      $\\beta_0, \\beta_1$  $(\\pi=\\beta_0+\\beta_1 x)$      $\\hat{\\beta}_0, \\hat{\\beta}_1$      $Y \\sim B$      $H_0: \\beta_i=0$      Logistic regression      sklearn.linear_models.LogisticRegression      refer.정규성 검정(Shapiro-Wilk Test)  귀무가설과 대립가설 설정          $H_{0}:\\quad X \\sim N(\\mu, \\sigma^2)$      $H_{1}:\\quad X \\not\\sim N(\\mu, \\sigma^2)$            검정통계량 도출\\[W=\\frac{\\left(\\sum_{i=1}^{n} \\alpha_{i} X_{i}\\right)^2}{\\sum_{i=1}^{n}\\left(X_{i} - \\overline{X}\\right)^2}\\]                  $\\overrightarrow{X}$ : 표본의 관측치 $X_{i}$ 를 크기에 따라 오름차순 정렬한 순위 통계량 벡터\\[\\begin{aligned}  \\overrightarrow{X}  =\\begin{pmatrix} X_{1}&amp;X_{2}&amp;\\cdots&amp;X_{n} \\end{pmatrix}^{T}  \\end{aligned}\\]                  $\\overline{X}=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}$ : 표본평균                            $\\overrightarrow{\\alpha}$ : 순위 통계량 벡터 $\\overrightarrow{X}$ 의 계수 벡터\\[\\overrightarrow{\\alpha}=\\displaystyle\\frac{\\overrightarrow{m}^{T}\\mathbb{V}^{-1}}{\\Vert \\mathbb{V}^{-1}\\overrightarrow{m} \\Vert}\\]                              $\\overrightarrow{m}$ : 기대 순위 통계량 벡터\\[\\overrightarrow{m}=\\begin{pmatrix} E\\left[X_{1}\\right]&amp;E\\left[X_{2}\\right]&amp;\\cdots&amp;E\\left[X_{n} \\right]\\end{pmatrix}^{T}\\]                                $\\mathbb{V}$ : 기대 순위 통계량의 공분산 행렬\\[\\mathbb{V}_{i,j}=\\text{Cov}\\Big[E\\left[X_{i}\\right],E\\left[X_{j}\\right]\\Big]\\]                    $\\overrightarrow{m}^{T}\\mathbb{V}^{-1}$ : $\\mathbb{V}^{-1}$ 에 의해 선형 변환되어 상호 독립된 기대 순위 통계량 벡터          $\\Vert \\mathbb{V}^{-1}\\overrightarrow{m} \\Vert$ : 정규화 항                      표본 $Y \\sim N(0,1)$ 를 활용한 경험적 분포 생성                  표준정규분포로부터 $n$ 개의 관측치로 구성된 표본을 반복적으로 생성\\[\\begin{aligned} \\overrightarrow{Y}^{(k)} =\\begin{pmatrix} Y_{1}^{(k)}&amp;Y_{2}^{(k)}&amp;\\cdots&amp;Y_{k}^{(k)} \\end{pmatrix}^{T} \\quad \\text{for}\\; Y^{(k)}_{i} \\sim N(0,1) \\end{aligned}\\]                    각 표본에 대하여 검정통계량 도출\\[W^{(k)}=\\frac{\\left(\\sum_{i=1}^{k} \\alpha_{i} Y_{i}\\right)^2}{\\sum_{i=1}^{k}\\left(Y_{i} - \\overline{Y}\\right)^2}\\]                    $n$ 의 크기에 따른 $W$ 의 경험적 분포 도출\\[f_{W}:n \\rightarrow W\\]                    $W$ 의 경험적 분포에서 특정 $w$ 값보다 작거나 같은 값을 가질 확률 도출\\[\\begin{aligned} \\text{p-value} &amp;=F_{W}(w)\\\\ &amp;=P(W \\le w) \\end{aligned}\\]              표본 $X$ 에 대한 검정통계량 $W$ 의 $\\text{p-value}$ 와 유의수준 $\\alpha$ 비교                  $F_{W}(W) \\le \\alpha$ : $X \\not\\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 현저히 낮다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각한다.                            $\\alpha &lt; F_{W}(W)$ : $X \\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 어느 정도 존재한다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮다고 볼 수 없음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각하지 않는다.                    등분산 검정(Levene’s Test)  관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\sigma_{1}^{2},\\sigma_{2}^{2},\\cdots,\\sigma_{k}^{2}\\)      점 추정량 : \\(S_{1}^{2},S_{2}^{2},\\cdots,S_{k}^{2}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad$ 모든 $i$ 에 대하여 $\\displaystyle\\frac{\\sigma_{i}^{2}}{\\sigma_{j \\ne i}^{2}}=1$      $H_{1}:\\quad$ 어떤 $i$ 에 대하여 $\\displaystyle\\frac{\\sigma_{i}^{2}}{\\sigma_{j \\ne i}^{2}} \\ne 1$            검정통계량 도출\\[F=\\frac{\\text{SSB} / (k-1)}{\\text{SSW} / (N-k)} \\sim F(k-1, N-k)\\]                  SSB(Sum of Square Between) : 집단 간 편차 자승의 합\\[\\text{SSB}=\\sum_{i=1}^{k}{N_{i}\\left(\\overline{Z}^{(i)}-\\overline{Z}\\right)^2} \\sim \\chi^2(k-1)\\]                  $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}_{\\forall}\\) 의 평균          $\\overline{Z}$ : 모든 관측치 $X^{(\\forall)}_{\\forall}$ 에 대하여 그 절대편차 \\(Z^{(\\forall)}_{\\forall}\\) 의 평균          $k$ : 표본 내 집단 갯수                            SSW(Sum of Within) : 집단 내 편차 자승의 합\\[\\text{SSW}=\\sum_{i=1}^{k}\\sum_{j=1}^{N_{i}}{\\left(Z^{(i)}_{j}-\\overline{Z}^{(i)}\\right)^2} \\sim \\chi^2(N-k)\\]                              \\(Z^{(i)}_{j}\\) : \\(i\\) 번째 집단의 \\(j\\) 번째 관측치 \\(X^{(i)}_{j}\\) 의 절대편차\\[Z^{(i)}_{j}=\\left\\vert X^{(i)}_{j}-\\overline{X}^{(i)} \\right\\vert\\]                    $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}_{\\forall}\\) 의 평균          $N$ : 표본 내 관측치 갯수                            F-Dist.($F(\\nu_1, \\nu_2)$) : 서로 독립인 확률변수 $V_{1}\\sim\\chi^2(\\nu_1),V_{2}\\sim\\chi^2(\\nu_2)$ 간 비율로 구성되는 확률변수의 분포\\[F=\\frac{V_1/\\nu_1}{V_2/\\nu_2} \\sim F(\\nu_1,\\nu_2)\\]            "
  },
  
  {
    "title": "A/B Test",
    "url": "/posts/A_B_Test/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics, A/B Test, Two Sample t Test, Paired Sample t Test, Goodness of Fit Test, Test of Independence",
    "date": "2024-07-06 00:00:00 +0900",
    





    
    "snippet": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더...",
    "content": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더 높은 성과를 보이는지 판단함. 이때 두 집단을 무작위로 추출함으로써, 두 집단이 제3의 요인들에 대하여 완전히 동질적일 수는 없지만 확률적으로 유사한 분포를 가지도록 함.      refer. Correlation VS. Causality  Example: 아이스크림 판매량과 물놀이 사고 간 관계성  한 지자체에서 물놀이 사고를 줄이는 것을 목표로 하고 있다. 조사 결과 아이스크림 판매량과 물놀이 사고 빈도 간의 상관관계가 높음을 알 수 있었다. 즉, 아이스크림 판매량이 증가하면 물놀이 사고가 증가하는 것이 데이터로부터 파악되었다. 이를 근거로 아이스크림 판매량 증가가 물놀이 사고 증가의 원인이라고 판단하였고, 물놀이 사고를 줄이기 위해 아이스크림 가격을 올려 판매량을 줄이는 정책을 입안하였다.  아이스크림 판매량과 물놀이 사고를 동시에 증가시키는 제3의 요인이 존재한다면?  Example: 웹사이트 디자인 개편과 매출 증가 간 관계성  어떤 쇼핑몰 웹 사이트에서 3개월에 걸쳐 디자인 개편 프로젝트를 진행하였고, 지난주에 성공적으로 새 디자인을 적용하였다. 그랬더니 갑자기 그 전에 비해 일 매출이 $10\\%$ 증가했다. 매출 증가는 웹사이트 디자인 개편 덕분이라고 판단할 수 있는가?  새 디자인이 적용된 날 갑자기 경쟁 쇼핑몰이 문을 닫았다면?  새 디자인이 적용된 날 갑자기 인기 상품이 입고되었다면?  새 디자인이 적용된 날 갑자기 경기가 좋아졌다면?Two Sample t-Test      2표본 t 검정(Two Sample t-Test) : 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저 리그 야구경기를 마무리하는 데 걸리는 시간에 대한 우려가 팬과 구단주 사이에서 점차 더 커지고 있다. 이 문제의 심각성을 평가하기 위해서, 한 통계 전문가는 5년 전과 금년에 임의표본을 구성하는 경기들을 마무리하는데 걸린 시간을 기록하였다. 한 경기를 마무리하는 데 걸리는 시간이 5년 전보다 금년이 더 길다고 결론을 내릴 수 있는가?        관심 모수에 대한 점 추정량 도출          관심 모수 : $\\mu_1-\\mu_2$      점 추정량 : $\\overline{X}_1-\\overline{X}_2$        귀무가설과 대립가설 설정          $H_{0}:\\quad \\mu_1-\\mu_2=D_{0}$      $H_{1}:\\quad \\mu_1-\\mu_2 \\ne D_{0}$      Independent Samples t-Test      독립표본 t 검정(Independent Samples t-Test) : 등분산 가정이 성립하는 경우($\\sigma^2_1=\\sigma^2_2$)의 2표본 t 검정        합동분산(Pooled Variance; $S_p^2$) : 모분산이 동일한 것으로 간주되는 두 독립표본의 분산을 각각의 자유도로 가중평균한 값\\[\\begin{aligned}  S_p^2  &amp;= \\frac{\\nu_1 \\cdot S_{1}^2 + \\nu_2 \\cdot S_{2}^2}{\\nu_1+\\nu_2}  \\end{aligned}\\]        합동분산이 적용된 검정통계량 도출\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{\\displaystyle\\frac{S_p^2}{n_1}+\\displaystyle\\frac{S_p^2}{n_2}}}  \\sim t(\\nu_1+\\nu_2)  \\end{aligned}\\]                  $\\overline{X}_1-\\overline{X}_2$ 의 기대값 도출\\[\\begin{aligned}  E\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= E\\left[\\overline{X}_1\\right]-E\\left[\\overline{X}_2\\right]\\\\  &amp;=\\mu_1 - \\mu_2  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= Var\\left[\\overline{X}_1\\right] + Var\\left[\\overline{X}_2\\right] - 2\\times Cov\\left[\\overline{X}_1,\\overline{X}_2\\right] \\\\  &amp;= \\frac{S_p^2}{n_1} + \\frac{S_p^2}{n_2}\\quad (\\because Cov\\left[\\overline{X}_1,\\overline{X}_2\\right]=0)  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\displaystyle\\frac{S_p^2}{n_1}+\\displaystyle\\frac{S_p^2}{n_2}}}  \\sim t(\\nu_1+\\nu_2)  \\end{aligned}\\]            Welch’s t-Test      Welch’s t 검정(Welch’s t-Test) : 등분산 가정이 성립하지 않는 경우($\\sigma^2_1 \\ne \\sigma^2_2$)의 2표본 t 검정        Welch-Satterthwaite 자유도(Welch-Satterthwaite Degree of Freedom; $\\nu_W$) : 표준오차로써 측정된 종합적인 변동성을 각 표본들이 변동성에 대하여 기여한 정도를 가중평균한 값\\[\\begin{aligned}  \\nu_W  &amp;= \\left(\\frac{S_{1}^{2}}{n_{1}}+\\frac{S_{2}^{2}}{n_{2}}\\right)^2 \\bigg/ \\left[\\frac{(S_{1}^2/n_1)^2}{\\nu_1} + \\frac{(S_{2}^2/n_2)^2}{\\nu_2} \\right]  \\end{aligned}\\]          $\\left(\\displaystyle\\frac{S_{1}^{2}}{n_{1}}+\\displaystyle\\frac{S_{2}^{2}}{n_{2}}\\right)^2$ : 표준오차로써 측정된 확률변수 $\\overline{X}_1-\\overline{X}_2$ 의 종합적인 변동성      $\\displaystyle\\frac{(S_{1}^2/n_1)^2}{\\nu_1} + \\displaystyle\\frac{(S_{2}^2/n_2)^2}{\\nu_2}$ : 표본들이 확률변수 $\\overline{X}_1-\\overline{X}_2$ 의 종합적인 변동성에 대하여 각각 기여한 정도            Welch-Satterthwaite 자유도를 따르는 검정통계량 도출\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{\\displaystyle\\frac{S_1^2}{n_1}+\\displaystyle\\frac{S_2^2}{n_2}}}  \\sim t(\\nu_W)  \\end{aligned}\\]                  $\\overline{X}_1-\\overline{X}_2$ 의 기대값 도출\\[\\begin{aligned}  E\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= E\\left[\\overline{X}_1\\right]-E\\left[\\overline{X}_2\\right]\\\\  &amp;=\\mu_1 - \\mu_2  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= Var\\left[\\overline{X}_1\\right] + Var\\left[\\overline{X}_2\\right] - 2\\times Cov\\left[\\overline{X}_1,\\overline{X}_2\\right] \\\\  &amp;= \\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\quad (\\because Cov\\left[\\overline{X}_1,\\overline{X}_2\\right]=0)  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\displaystyle\\frac{S_1^2}{n_1}+\\displaystyle\\frac{S_2^2}{n_2}}}  \\sim t(\\nu_{W})  \\end{aligned}\\]            Paired Sample t-Test      쌍체표본 t 검정(Paired Sample t-Test) : 쌍을 이루는 두 변수 간 차이의 평균이 기대되는 값($\\mu_0$)과 통계적으로 유의한 차이가 있는지 검정하는 방법          주식시장의 변동은 일부 투자자들로 하여금 주식을 팔고 그들의 자금을 더 안전한 투자로 이동시키게 만든다. 최근 주식시장의 변동이 주식 보유에 어느 정도 영향을 미쳤는지를 결정하기 위해 주식을 소유하고 있는 170 명을 대상으로 서베이를 실시하였다. 실험 대상자들의 재작년 말과 작년 말 주식 보유액을 기록하였다. 주식 보유액이 감소했다고 추론할 수 있는가?              쌍체표본(Paired Sample) : 동일한 대상에 대하여 두 번의 측정을 통해 얻은 표본 혹은 변수 간 상관관계가 존재하는 두 대상에 대하여 측정을 통해 얻은 표본        관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\mu=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\)      점 추정량 : \\(\\overline{X}=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad \\mu=\\mu_{0}$      $H_{1}:\\quad \\mu \\ne \\mu_{0}$            검정통계량\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{\\overline{X}-\\mu_{0}}{\\displaystyle\\frac{S}{\\sqrt{n}}}  \\sim t(\\nu)  \\end{aligned}\\]                  $\\overline{X}$ 의 기대값 도출\\[\\begin{aligned}  E\\left[ \\overline{X} \\right]  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\left(\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right)\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(B)}_{i}}\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(A)}_{i}}\\right]-E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(B)}_{i}}\\right]\\\\  &amp;= E\\left[\\overline{X}_{A}\\right]-E\\left[\\overline{X}_{B}\\right]\\\\  &amp;=\\mu_A - \\mu_B  \\end{aligned}\\]                    $\\overline{X}$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}\\right]  &amp;=Var\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}-X^{(B)}_{i}}\\right]\\\\  &amp;=Var\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right]\\\\  &amp;=Var\\left[\\overline{X}_{A}-\\overline{X}_{B}\\right]\\\\  &amp;=Var\\left[\\overline{X}_{A}\\right] + Var\\left[\\overline{X}_{B}\\right] - 2 \\times Cov \\left[\\overline{X}_{A}, \\overline{X}_{B}\\right]\\\\  &amp;=\\frac{S_{A}^{2}}{n}+\\frac{S_{B}^{2}}{n}-2\\times\\frac{r_{A,B}}{n}\\quad(\\because Cov \\left[\\overline{X}_{A}, \\overline{X}_{B}\\right] \\ne 0)\\\\  &amp;=\\frac{S^2}{n}  \\end{aligned}\\]                    $\\overline{X}$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{S}{\\sqrt{n}}}  \\sim t(\\nu)  \\end{aligned}\\]            Goodness-of-Fit Test      적합성 검정(Goodness-of-Fit Test) : 범주형 자료에 대하여 관찰된 비율이 기대되는 비율과 통계적으로 유의한 차이가 있는지 검정하는 방법          마케팅 조사 기관 Scott 가 수행한 시장 점유율에 대한 조사에서, 몇 년동안 시장점유율은 A사 $30\\%$, B사 $50\\%$, C사 $20\\%$ 수준을 보이며 안정적이었다. 최근에 C사는 기능이 향상된 제품을 출시하였다. 이에 신제품의 출시가 시장점유율의 변화에 영향을 미치고 있는지 파악하고자 한다. Scott 가 $200$ 명의 고객을 소비자 패널로 활용하여 조사를 수행한 결과, 아래의 표와 같은 구매 선호도를 얻었다. 신제품 출시에 따라 시장점유율이 변화했다고 볼 수 있는가?        관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\pi_{A},\\quad \\pi_{B},\\quad \\pi_{C}\\)      점 추정량 : \\(p_{A},\\quad p_{B},\\quad p_{C}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad \\pi_{A}=0.3 \\; \\text{and} \\; \\pi_{B}=0.5 \\; \\text{and} \\; \\pi_{C}=0.2$      $H_{1}:\\quad \\pi_{A} \\ne 0.3 \\; \\text{or} \\; \\pi_{B} \\ne 0.5 \\; \\text{or} \\; \\pi_{C} \\ne 0.2$            검정통계량\\[\\begin{aligned}  X  &amp;= \\sum_{i=1}^{k}{Z_{i}^2} \\quad \\text{for} \\quad Z_{i} \\sim N(0,1)\\\\  &amp;= \\sum_{i=1}^{k}{\\left(\\frac{\\Omega_{i} - e_{i}}{\\sqrt{e_{i}}}\\right)^2} \\sim \\chi^2{(\\nu)}  \\end{aligned}\\]                  $Z_{i}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[Z_{i}=\\frac{\\Omega_{i} - e_{i}}{\\sqrt{e_{i}}} \\sim N(0,1)\\]                    $\\Omega_{i}$ : $i$ 번째 카테고리에 해당하는 관측치의 관측 빈도                                            회사              A              B              C              계                                                          관측 빈도              48              98              54              200                                                  $e_{i}$ : $\\Omega_{i}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                                            회사              A              B              C                                                          기대 빈도              60              100              40                              \\[\\begin{aligned}  e_{i}  &amp;=E\\left[\\Omega_{i} \\right]\\\\  &amp;= n \\cdot p_{i}  \\end{aligned}\\]                    $\\sqrt{e_{i}}$ : $\\Omega_{i}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  Var\\left[\\Omega_{i}\\right]  &amp;= n \\cdot p_{i} \\cdot (1-p_{i})\\\\  &amp;= e_{i} \\cdot (1-p_{i})\\\\  &amp;\\approx e_{i} \\cdot 1  \\end{aligned}\\]                    $\\chi^2{(\\nu)}$ : 자유도가 $\\nu$ 인 카이제곱 분포                  $\\nu=k-1$          $k$ : 카테고리 갯수                    Test of Independence      독립성 검정(Test of Independence) : 두 범주형 자료가 통계적으로 독립인지 검정하는 방법          맥주 회사 Alber’s 에서는 라이트 맥주, 일반 맥주, 흑 맥주를 생산하여 유통한다. 이 기업의 시장조사팀은 성별에 따라 선호하는 맥주에 차이가 있는지 알아보고자 한다. 만약 맥주의 품종별 선호도가 성별에 독립적이라면 맥주광고는 모든 고객에 대해 획일적으로 이루어질 것이다. 반면, 품종별 선호도가 성별에 의존적이라면 세분 시장의 목표 고객에 따라 상이한 촉진 전략을 수행해야 할 것이다. 아래 분할표는 무작위 추출된 $150$ 명이 각 맥주에 대해 시음한 후 응답한 품종별 선호도이다. 맥주의 품종별 선호도는 성별에 대하여 독립적이라 볼 수 있는가?        귀무가설과 대립가설 설정          $H_{0}:\\quad$ 품종별 선호도(열 변수; $Y$)는 성별 선호도(행 변수; $X$)에 대하여 독립적이다.      $H_{1}:\\quad$ 품종별 선호도(열 변수; $Y$)는 성별 선호도(행 변수; $X$)에 대하여 독립적이라 볼 수 없다.            검정통계량 도출\\[\\begin{aligned}  X  &amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{l}{Z_{i,j}^2} \\quad \\text{for} \\quad Z_{i,j} \\sim N(0,1)\\\\  &amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{l}{\\left(\\frac{\\Omega_{i,j} - e_{i,j}}{\\sqrt{e_{i,j}}}\\right)^2} \\sim \\chi^2{(\\nu)}  \\end{aligned}\\]                  $Z_{i,j}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[Z_{i,j}=\\frac{\\Omega_{i,j} - e_{i,j}}{\\sqrt{e_{i,j}}} \\sim N(0,1)\\]                    $\\Omega_{i,j}$ : 변수 $X$ 의 $i$ 번째 카테고리와 변수 $Y$ 의 $j$ 번째 카테고리에 해당하는 관측치의 관측 빈도                                            품종              라이트              일반              흑              계                                                          남성              20              40              20              80                                      여성              30              30              10              70                                      계              50              70              10              150                                                  $e_{i,j}$ : $\\Omega_{i,j}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                                            품종              라이트              일반              흑                                                          남성              26.67              37.33              16.00                                      여성              23.33              32.67              14.00                              \\[\\begin{aligned}  e_{i,j}  &amp;= E\\left[\\Omega_{i,j} \\right]\\\\  &amp;=n \\cdot p_{i,j}\\\\  &amp;=n \\cdot P(X_{i} \\cap Y_{j})\\\\  &amp;=n \\cdot P(X_{i})P(Y_{j}) \\quad \\left(\\because P(Y_{j} \\vert X_{i})=P(Y_{j})\\right)  \\end{aligned}\\]                    $\\sqrt{e_{i,j}}$ : $\\Omega_{i,j}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  Var\\left[\\Omega_{i,j}\\right]  &amp;= n \\cdot p_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;= e_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;\\approx e_{i,j} \\cdot 1  \\end{aligned}\\]                    $\\chi^2{(\\nu)}$ : 자유도가 $\\nu$ 인 카이제곱 분포                  $\\nu=(k-1)(l-1)$          $k$ : 변수 $X$ 의 카테고리 갯수          $l$ : 변수 $Y$ 의 카테고리 갯수                    Sourse  https://varify.io/en/blog/ab-testing/"
  },
  
  {
    "title": "Statistical Inference",
    "url": "/posts/Statistical_Inference/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics, Estimation, z Test, t Test",
    "date": "2024-07-05 00:00:00 +0900",
    





    
    "snippet": "EstimationPoint Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                    ...",
    "content": "EstimationPoint Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                      모수          $\\theta$          $\\mu$          $\\sigma^2$          $\\pi$                          점 추정량          $\\hat{\\theta}$          $\\overline{X}$          $S^2$          $P$                          좋은 점 추정량의 성질          불편성(Unbiasedness) : 기대값이 모수와 같아 모수로부터 음이나 양으로 편향되지 아니함      효율성(Efficiency) : 모수의 불편 추정량 가운데에서 분산이 최소임      일치성(Consistency) : 표본의 크기 $n$ 이 커질수록 평균자승오차가 $0$ 에 수렴함      불편 추정량(Unbiased Estimator)      정의 : 기대값이 모수와 같아 모수로부터 음이나 양으로 편향되지 아니한 추정량          불편 추정량은 평균적으로 모수를 음으로 편향되게 평가하거나(과소평가), 양으로 편향되게 평가(과대평가)하지 않음. 단, 불편 추정량에 대하여 특정 표본에서 도출된 일부 실현값에는 오차가 존재할 수 있음.    \\[\\begin{aligned}  Bias(\\hat{\\theta})  &amp;= E(\\hat{\\theta}) - \\theta \\\\  &amp;= 0  \\end{aligned}\\]          $Bias(\\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 편향(Bias)      $E(\\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 기대값            예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 불편 추정량임      표본분산 $S^2$ 은 모분산 $\\sigma^2$ 의 불편 추정량임      효율적 추정량(Efficient Estimator)      정의 : 모수의 불편 추정량 가운데에서 분산이 최소인 불편 추정량\\[\\begin{aligned}  \\min{MSE(\\theta, \\hat{\\theta})}  &amp;= \\min{E\\left[(\\hat{\\theta}-\\theta)^2\\right]}\\\\  &amp;= \\min{\\bigg[Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\\bigg]}  \\end{aligned}\\]          $MSE(\\theta, \\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대한 평균자승오차(Mean Squared Error)      $E[(\\hat{\\theta}-\\theta)^2]$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 오차 자승의 기대값            예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 불편 선형 추정량(Unbiased Linear Estimator) 중 가장 효율적인 추정량(Best Linear Unbiased Estimator; BLUE) 임                  선형 추정량 : \\(w_1x_1 + w_2x_2+\\cdots+e\\)          비선형 추정량 : \\(x_1^2,\\quad x_1 \\times x_2,\\quad \\displaystyle\\frac{x_1}{x_2}\\)                    일치 추정량(Consistent Estimator)      정의 : 표본의 크기 $n$ 이 커질수록 평균자승오차가 $0$ 에 수렴하는 추정량\\[\\begin{aligned}  \\displaystyle\\lim_{n \\rightarrow \\infty}{MSE(\\hat{\\theta})}  &amp;= \\displaystyle\\lim_{n \\rightarrow \\infty}{Var(\\hat{\\theta})} + \\displaystyle\\lim_{n \\rightarrow \\infty}{Bias(\\hat{\\theta})}^2\\\\  &amp;= 0  \\end{aligned}\\]        예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 일치 추정량임      Confidence Intervals      정의 : 신뢰 가능한 수준 하에서 모수를 포함할 수 있다고 추정되는 구간으로서 신뢰수준을 담보한 구간 추정량(Interval Estimator)          표본평균 $\\overline{X}$ 이 모평균 $\\mu$ 의 좋은 점 추정량이라고 해서 항상 그 실현값 $\\overline{x}_i$ 가 $\\mu$ 와 일치하지는 않음. 때문에 특정 표본에서 구한 추정치 $\\overline{x}_i$ 를 활용하여 $\\mu$ 를 포함할 가능성이 있는 구간을 만들어서 $\\mu$ 을 추정함. 신뢰구간은 이러한 구간 추정량에 대하여 $\\mu$ 를 포함할 가능성을 담보하고 있음.            구성\\[\\text{CI}=\\left(\\overline{X}-z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}, \\overline{X}+z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}\\right)\\]                  신뢰수준(Confidence Level; $1-\\alpha$) : 신뢰구간이 담보하는, 해당 구간이 모수 $\\mu$ 를 포함할 가능성\\[P(\\mu \\in \\text{CI})=1-\\alpha\\]                    오차한계(Margin of Error; \\(z_{\\alpha / 2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}\\)) : 모수 $\\mu$ 와 그 점 추정량 $\\overline{X}$ 에 대하여 신뢰구간의 끝(한계)과 $\\mu$ 사이의 최대 차이로서, $\\mu$ 와 $\\overline{X}$ 의 차이(오차)를 수용할 수 있는 범위를 결정하는 값                  길이\\[\\text{Length}(\\text{CI}) = 2 \\times z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]          $(1-\\alpha)\\uparrow \\; \\Rightarrow L\\uparrow$ : 신뢰수준이 높을수록 신뢰구간의 길이가 증가함      $\\sigma\\uparrow \\; \\Rightarrow L\\uparrow$ : 모집단의 분포가 널리 퍼져 있을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함      $n\\downarrow \\; \\Rightarrow L\\uparrow$ : 표본의 크기가 작을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함            도출                  중심극한정리에 의해 $n$ 이 충분히 크면 다음이 성립함\\[\\begin{aligned}  \\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})  \\end{aligned}\\]                    확률변수 $\\overline{X}$ 를 다음과 같이 표준화할 수 있음\\[\\begin{aligned}  Z=\\displaystyle\\frac{\\overline{X} - \\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)  \\end{aligned}\\]                    $100(1-\\alpha)\\%$ 신뢰수준 하 신뢰구간은 다음과 같음\\[\\begin{aligned}  P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})  &amp;=P(-z_{\\alpha/2}&lt;\\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}&lt;z_{\\alpha/2})\\\\  &amp;=P(-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\overline{X}-\\mu&lt;z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(-\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;-\\mu&lt;-\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\mu&lt;\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=1-\\alpha  \\end{aligned}\\]            Hypothesis Testing  통계적 가설(Statistical Hypothesis) : 모집단의 모수에 대한 주장          귀무가설(Null-Hypothesis; $H_0$) : 사실이 아니라는 충분한 근거를 얻기 전에는 사실이라고 믿어지는 가설      대립가설(Alternative Hypothesis; $H_1$) : 연구자의 주장으로서 귀무가설이 기각될 때 채택되는 가설        가설검정(Hypothesis Testing) : 귀무가설을 기각할 충분한 증거가 있는지 살핌으로써 대립가설을 우회로 증명하는 절차          귀무가설과 대립가설 설정      유의수준 설정      모수 추정법 적용 가능 여부 검토      검정통계량과 p-value 도출      귀무가설 기각 여부 결정      검정 결과 해석      종류      양측검정(Two-Sided Test) : 귀무가설에 대한 기각역을 양측에 설정하는 검정    \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu\\ne70  \\end{aligned}\\]        단측검정(One-Sided Test) : 귀무가설에 대한 기각역을 단측에만 설정하는 검정                  우측검정 : 기각역을 우측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu \\le 70,\\\\  H_1&amp;:\\;\\mu &gt; 70  \\end{aligned}\\]                    좌측검정 : 기각역을 좌측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu&lt;70  \\end{aligned}\\]            오류와 신뢰성      오류(Error) : 사실과 다르게 판단함              제1종 오류(Type 1 Error) : 귀무가설이 참일 때 귀무가설을 기각하는 오류      제1종 오류(Type 2 Error) : 귀무가설이 거짓일 때 귀무가설을 기각하지 않는 오류            검정의 유의수준(Significance Level) : 제1종 오류를 범할 확률\\[\\alpha\\]          통계학에서는 보수적 태도(귀무가설을 기각하지 않으려는 태도)를 취하므로 제1종 오류에 민감함            검정의 신뢰수준(Confidence Level) : 제1종 오류를 범할 확률 $\\alpha$ 에 대하여, 귀무가설이 참일 때 귀무가설을 기각하지 않을 확률\\[1-\\alpha\\]        검정의 검정력(Power) : 제2종 오류를 범할 확률 $\\beta$ 에 대하여, 귀무가설이 거짓일 때 귀무가설을 기각할 확률\\[1-\\beta\\]  검정통계량과 유의확률 도출      검정통계량(Test Statistic) : 귀무가설이 참이라고 가정했을 때 얻은 결과    \\[\\begin{aligned}  Z  &amp;=\\displaystyle\\frac{\\overline{X}-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\\\  &amp;=\\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} + \\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\\\  &amp;=0 + \\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}  \\end{aligned}\\]                  귀무가설이 참인 경우 검정통계량의 분포 : 평균이 $0$ 이고 분산이 $1$ 인 가우시안 분포를 따름\\[\\begin{aligned}  Z \\sim N(0,1)  \\end{aligned}\\]                    귀무가설이 참이 아닌 경우 검정통계량의 분포 : 평균이 $\\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}$ 이고 분산이 $1$ 인 가우시안 분포를 따름\\[\\begin{aligned}  Z \\sim N(\\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}},1)  \\end{aligned}\\]                  유의확률(Significance Probability Value; $\\text{p-value}$) : 검정통계량($Z$)보다 극단적인 결과($Y$)가 관측될 확률로서, 표본이 귀무가설과 양립하는 정도    \\[\\begin{aligned}  \\text{p-value}  &amp;= P\\left(\\vert Y \\vert \\ge \\vert Z \\vert \\Big\\vert H_{0}\\right) \\quad \\text{for}\\; Y \\sim N(0,1)  \\end{aligned}\\]  귀무가설 기각 여부 결정      검정통계량 $Z$ 의 실현값 $z$ 가 $0$ 과 차이가 많이 나면 기각함\\[\\vert z \\vert &gt;z_{\\alpha/2}\\]          기각치(Reject Value; $z_{\\alpha/2}$) : 차이가 많이 나는 기준이 되는 값으로서, 유의수준 $\\alpha$ 에 따라 결정됨            귀무가설이 참일 때 표본이 발생할 확률 $\\text{p-value}$ 이 현저하게 낮으면 기각함\\[\\text{p-value} &lt; \\alpha\\]          유의수준(Significance Level; $\\alpha$) : 현저하게 낮은 기준이 되는 값으로서, 제1종 오류 수용 정도      검정 결과 해석      통계적 유의성(Statistically Significant) : 유의함이 실제로는 존재하지 않을 수도 있지만, 주어진 정보를 활용하여 판단했을 때는 존재하였음        귀무가설을 기각할 수 없을 때는 귀무가설이 제한적으로 사실이라고 받아들임          귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각하지 않는다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_{0}$ 과 통계적으로 유의한 차이가 있다고 볼 수 없다.            귀무가설을 기각할 때는 대립가설이 사실이라고 잠정적으로 결론을 내림          귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각한다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_0$ 과 통계적으로 유의한 차이가 있다.      Student t-Dist.  모분산 $\\sigma^2$ 을 모르는 경우 표본평균 $\\overline{X}$ 에 대하여 가설검정 시 우선 표본분산 $S^2$ 을 활용하여 모분산 $\\sigma^2$ 을 추정해야 함. 추정된 모분산으로 도출된 검정통계량은 자유도 $\\nu$ 에 따라 그 폭이 상이한 분포를 따르게 됨. 이처럼 자유도에 따라 변화하는 분산의 변동성을 반영하기 위해 표준정규분포 $Z \\sim N(0,1)$ 대신 스튜던트 t 분포 $T \\sim t(\\nu)$ 를 사용함.      스튜던트 t 분포($t(\\nu)$) : 표준정규분포를 따르는 확률변수 $Z$ 와 자유도가 $\\nu$ 인 카이제곱분포를 따르는 확률변수 $V$ 로 구성되는 확률변수의 분포    \\[T=\\frac{Z}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}} \\quad \\text{for}\\;Z \\sim N(0,1),\\; V \\sim \\chi^2(\\nu)\\]                  카이제곱분포($\\chi^2(\\nu)$) : 자유도가 $\\nu$ 로 주어졌을 때 표준정규분포를 따르는 독립적인 확률변수 $Z_{i}\\left(=\\displaystyle\\frac{X_{i}-\\overline{X}}{\\sigma}\\right)$ 들의 자승의 합의 분포로서, 모분산을 추정하는 데 사용됨\\[\\begin{aligned}  V  &amp;=\\sum_{i=1}^{k}{Z_{i}^2} \\quad \\text{for}\\; Z_{\\forall} \\sim N(0,1)\\\\  &amp;=\\sum_{i=1}^{k}{\\left(\\frac{X_{i}-\\overline{X}}{\\sigma}\\right)^2}\\\\  &amp;=\\frac{1}{\\sigma^2} \\times \\sum_{i=1}^{k}{\\left(X_{i}-\\overline{X}\\right)^2}\\\\  &amp;=\\frac{1}{\\sigma^2} \\times \\nu \\cdot \\frac{1}{\\nu} \\sum_{i=1}^{k}{\\left(X_{i}-\\overline{X}\\right)^2}\\\\  &amp;=\\nu \\times \\frac{S^2}{\\sigma^2} \\sim \\chi^2(\\nu)  \\end{aligned}\\]                  스튜던트 t 분포를 활용한 표본 $X \\sim N(\\mu, \\sigma^2)$ 의 검정통계량 $T$ 도출\\[\\begin{aligned}  T  &amp;= Z \\times \\frac{1}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}}\\\\  &amp;= \\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\times \\frac{1}{\\sqrt{\\displaystyle\\frac{\\sigma^2}{S^2}}}\\\\  &amp;= \\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{S}{\\sqrt{n}}} \\sim t(\\nu)  \\end{aligned}\\]  Sourse  https://u5man.medium.com/to-err-is-human-what-the-heck-is-type-i-and-type-ii-error-b2c78190a45c  https://wikidocs.net/163986"
  },
  
  {
    "title": "Sample Dist.",
    "url": "/posts/Sample_Dist/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics",
    "date": "2024-07-04 00:00:00 +0900",
    





    
    "snippet": "Random SampleStatistical Inference  통계적 추론(Statistical Inference)          정의 : 표본을 사용하여 모집단의 성격을 추정하는 작업                  표본의 측정치를 모집단의 측정치에 대한 추정치로 간주함                    목표 : 표본오차의 크기 최소화       ...",
    "content": "Random SampleStatistical Inference  통계적 추론(Statistical Inference)          정의 : 표본을 사용하여 모집단의 성격을 추정하는 작업                  표본의 측정치를 모집단의 측정치에 대한 추정치로 간주함                    목표 : 표본오차의 크기 최소화                  표본은 모집단의 부분집합일 뿐이지, 모집단은 아니므로 모수와 통계량은 완전히 일치할 수 없음                      표본오차(Sampling Error) : 응답오차, 측정오차, 표본선택편향이 해결되었음에도 발생하는 실제값과 예측값의 차이          응답오차(Response Error) : 응답자의 응답 거부 혹은 잘못된 응답으로 인해 발생하는 오차      측정오차(Measurement Error) : 데이터의 틀린 측정이나 기입으로 인해 발생하는 오차      표본선택편향(Sample Selection Bias) : 모집단의 각 관측치들이 표본에 포함될 확률이 서로 다른 경우      Population &amp; Sample  모수는 그 값이 알려져 있지 않은 고정된 수이다. 이 값을 추정하기 위하여 표본의 통계량을 사용하므로, 통계량은 모수의 추정량이라 할 수 있다. 그런데 모집단에서 어떤 표본을 추출하느냐에 따라 통계량의 실현값이 달라진다. 따라서 모수는 상수(Constant), 통계량은 확률변수(Random Variable)라고 볼 수 있다.  모집단(Population)의 모수(Parameter)          모평균 : $\\mu$      모분산 : $\\sigma^2$        표본(Sample)의 통계량(Statistic)                  표본평균 : $\\overline{X}$\\[\\begin{aligned}  \\overline{X}  &amp;= \\frac{1}{n}(X_{1}+X_{2}+\\cdots+X_{n}) \\quad \\text{for}\\; X_{\\forall} \\in \\Omega\\\\  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}  \\end{aligned}\\]                    표본분산 : $S^2$\\[\\begin{aligned}  S^2  &amp;= \\frac{1}{\\nu}\\left[\\vert X_{1} - \\overline{X}\\vert^2 + \\vert X_{2} - \\overline{X}\\vert^2 + \\cdots + \\vert X_{n} - \\overline{X}\\vert^2 \\right]\\\\  &amp;= \\frac{1}{\\nu}\\sum_{i=1}^{n}(X_{i}-\\overline{X})^2  \\end{aligned}\\]                    note 자유도(Degree of Freedom; $\\nu$) : 주어진 자료 내에서 독립적으로 변할 수 있는 확률변수의 수                  어떠한 자료에 대하여 그 기술통계량이 주어지는 경우, 특정 관측치의 정보가 불분명하더라도 해당 관측치가 취할 수 있는 값은 제한되어 있음          표본분산 $S^2$ 을 계산하기 위해서는 표본평균 $\\overline{X}$ 을 먼저 계산해야 하므로, 분산 계산 시 동원되는 관측치 중 독립적으로 변할 수 있는 관측치의 수는 $n-1$ 임          이 경우 관측치 수 $n$ 이 아니라 자유도 $\\nu=n-1$ 로 나눈 값이 모분산 $\\sigma^2$ 의 비편향 추정량임                    Random Sample      모집단으로부터 관측치 $X_1, X_2, X_3, \\cdots, X_n$ 를 추출하여 구성한 표본에 대하여\\[\\begin{aligned}  \\{X_1, X_2, X_3, \\cdots, X_N\\}  \\end{aligned}\\]        모집단의 각 개체가 표본의 원소로서 선택될 확률이 모두 같고,\\[P(X_{i}=x_{i})=\\frac{1}{N} \\quad \\text{for}\\;i=1,2,\\cdots,N\\]        원소 $X_1, X_2, X_3, \\cdots, X_n$ 이 모두 모집단의 분포를 따르는 확률변수이고,\\[\\begin{aligned}  E\\left[X_{i^{\\forall}}\\right]&amp;=\\mu \\\\  Var\\left[X_{i^{\\forall}}\\right]&amp;=\\sigma^2  \\end{aligned}\\]        원소 $X_1, X_2, X_3, \\cdots, X_n$ 이 모두 통계적으로 독립인 경우\\[P(X_{j^{\\forall}} \\vert X_{i^{\\forall}}) = P(X_{j^{\\forall}})\\]  Sample DistributionWhat? Sample Dist.  표본분석의 목적 : 모수 추정          표본의 평균 $\\overline{X}$ 가 모집단의 평균 $\\mu$ 를 얼마나 잘 추정하는가      확률변수 $\\overline{X}$ 의 기대값 $E(\\overline{X})$ 은 상수 $\\mu$ 에 가까운가      추정량 $\\overline{X}$ 의 기대값 $E(\\overline{X})$ 과 모수 $\\mu$ 사이에는 얼마나 큰 추정오차가 존재하는가        추정량과 추정치의 정의          추정량(Estimator) : 모수를 추정하는 값으로서 통계량(Statistics)                  모평균 $\\mu$ 의 추정량 : 표본평균 $\\overline{X}$          모분산 $\\sigma^2$ 의 추정량 : 표본분산 $S^2$          모표준편차 $\\sigma$ 의 추정량 : 표본표준편차 $S$                    추정치(Estimate) : 특정 표본에서 얻어진 추정량의 실현값(Realized Value)        표본분포(Sampling Distribution) : 모수에 대한 추정량의 확률분포                  모집단의 평균을 추정하기 위해 여러 표본을 뽑을 때 표본 평균의 추정치들의 분포\\[\\overline{X} \\sim N(\\mu, \\displaystyle\\frac{\\sigma^2}{n}) \\quad (\\text{s.t.}\\;n&gt;30)\\]                    모집단의 평균을 추정하기 위해 여러 표본을 뽑을 때 표본 비율의 추정치들의 분포\\[P \\sim N(\\pi, \\displaystyle\\frac{\\pi(1-\\pi)}{n}) \\quad (\\text{s.t.}\\;n&gt;30)\\]            Statistics      $\\overline{X}$ 의 기대값 : $E\\left[\\overline{X}\\right]=\\mu$\\[\\begin{aligned}  E\\left[\\overline{X}\\right]  &amp;= E\\left[\\frac{1}{n}(\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n)\\right]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[\\overline{x}_1\\right]+E\\left[\\overline{x}_2\\right]+\\cdots+E\\left[\\overline{x}_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}(\\mu + \\cdots + \\mu)\\\\  &amp;=\\mu  \\end{aligned}\\]        $\\overline{X}$ 의 분산 : $Var\\left[\\overline{X}\\right]=\\displaystyle\\frac{\\sigma^2}{n}$\\[\\begin{aligned}  Var\\left[\\overline{X}\\right]  &amp;= Var\\left[\\frac{1}{n}(\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n)\\right]\\\\  &amp;=Var\\left[\\frac{1}{n}\\overline{x}_1\\right]+Var\\left[\\frac{1}{n}\\overline{x}_2\\right]+\\cdots+Var\\left[\\frac{1}{n}\\overline{x}_n\\right]\\\\  &amp;(\\because Cov\\left[\\overline{x}_i, \\overline{x}_j\\right]=0)\\\\  &amp;=\\frac{1}{n^2}Var\\left[\\overline{x}_1\\right]+\\frac{1}{n^2}Var\\left[\\overline{x}_2\\right]+\\cdots+\\frac{1}{n^2}Var\\left[\\overline{x}_n\\right]\\\\  &amp;=\\frac{1}{n^2}\\sigma^2 + \\frac{1}{n^2}\\sigma^2 + \\cdots + \\frac{1}{n^2}\\sigma^2\\\\  &amp;=\\frac{1}{n^2}(\\sigma^2 + \\cdots + \\sigma^2)\\\\  &amp;=\\frac{\\sigma^2}{n}  \\end{aligned}\\]        표준오차(Standard Error; $SE$) : $\\overline{X}$ 의 표준편차          표본 $sample1, sample2, \\cdots$ 에 의해 얻어진 추정량 $\\overline{X}$ 의 실현값 $\\overline{x}_1, \\overline{x}_2, \\cdots$ 은 $\\mu$ 를 기준으로 얼마나 널리 퍼져 있는가    \\[\\begin{aligned}  SE  &amp;=\\sqrt{\\frac{\\sigma^2}{n}}\\\\  &amp;=E\\left[\\vert\\overline{x}_{i}-\\mu\\vert\\right]  \\end{aligned}\\]          $\\overline{X}$ 의 표준편차는 모수 $\\mu$ 와 그 추정치 $\\overline{x}_{i}$ 의 차이의 평균임      $Var(\\overline{X})$ 가 작을수록 모수 $\\mu$ 에 근사하는 추정량 $\\overline{X}$ 가 실현될 가능성이 높음      Central Limit Theorem      중심극한정리(Central Limit Theorem; $CLT$)          평균이 $\\mu$ 이고, 분산이 $\\sigma^2$ 인 모집단에서 크기가 $n$ 인 표본을 추출하는 경우 $n$ 이 증가할수록 표본평균 $\\overline{X}$ 의 분포는 평균이 $\\mu$ 이고, 분산이 $\\sigma^2$ 일 때의 가우시안 분포에 근사함    \\[\\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n}),\\quad \\text{s.t.}\\,n &gt; 30\\]          $n \\le 30$ 인 경우에는 모집단의 분포에 의존함      $n &gt; 30$ 인 경우에는 모집단의 분포와 상관 없이 성립함      ProportionPopulation Proportion      모비율(Population Proportion; $\\pi$) : 모집단 중 특정 성질을 가지는 관측치 비율\\[\\pi \\times 100\\%\\]        모비율에 대한 확률변수 정의 : 베르누이 확률변수\\[X \\sim Bernoulli(\\pi)\\]                  관측치 $X_i$ 가 성질을 만족하면 $1$, 만족하지 않으면 $0$ 이라고 하자\\[X=  \\begin{cases}  1\\quad \\text{with probability}\\;\\pi\\\\  0\\quad \\text{with probability}\\;1-\\pi  \\end{cases}\\]                    확률변수 $X$ 의 기대값\\[\\begin{aligned}  E\\left[X\\right]  &amp;=1\\times\\pi + 0\\times(1-\\pi) \\\\  &amp;=\\pi  \\end{aligned}\\]                    확률변수 $X$ 의 분산\\[\\begin{aligned}  Var\\left[X\\right]  &amp;=(1-\\pi)^2\\times\\pi + (0-\\pi)^2\\times(1-\\pi) \\\\  &amp;=\\pi(1-\\pi)  \\end{aligned}\\]            Sample Proportion      표본비율(Sample Proportion; $P$) : 모비율에 대한 표본평균          크기가 $n$ 인 표본을 추출할 때 모비율 $\\pi$ 에 대한 표본평균 $P$ 는 다음과 같음    \\[\\begin{aligned}  P  &amp;= \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}{p_i}  \\end{aligned}\\]        $P$ 의 기대값 : $E\\left[P\\right]=\\pi$\\[\\begin{aligned}  E\\left[P\\right]  &amp;= E\\left[\\frac{1}{n}(p_1+p_2+\\cdots+p_n)\\right]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[p_1+p_2+\\cdots+p_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[p_1\\right]+E\\left[p_2\\right]+\\cdots+E\\left[p_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}(\\pi + \\cdots + \\pi)\\\\  &amp;=\\pi  \\end{aligned}\\]        $P$ 의 분산 : $Var\\left[P\\right]=\\displaystyle\\frac{\\pi(1-\\pi)}{n}$\\[\\begin{aligned}  Var\\left[P\\right]  &amp;= Var\\left[\\frac{1}{n}(p_1+p_2+\\cdots+p_n)\\right]\\\\  &amp;= Var\\left[\\frac{1}{n}p_1\\right]+Var\\left[\\frac{1}{n}p_2\\right]+\\cdots+Var\\left[\\frac{1}{n}p_n\\right]\\\\  &amp;= \\frac{1}{n^2}Var\\left[p_1\\right]+\\frac{1}{n^2}Var\\left[p_2\\right]+\\cdots+\\frac{1}{n^2}Var\\left[p_n\\right]\\\\  &amp;= \\frac{1}{n^2}\\Big[\\pi(1-\\pi)+\\cdots+\\pi(1-\\pi)\\Big]\\\\  &amp;= \\frac{\\pi(1-\\pi)}{n}  \\end{aligned}\\]        표본비율에 대한 중심극한정리          표본의 크기 $n$ 이 충분히 크면 표본비율 $P$ 는 다음과 같은 분포를 따르게 됨    \\[P \\sim N(\\pi, \\frac{\\pi(1-\\pi)}{n})\\]  "
  },
  
  {
    "title": "One Class Collaborative Filtering",
    "url": "/posts/OCCF/",
    "categories": "RECOMMENDER SYSTEM, 4.one class collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Implicit Feedback, OCCF",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Prob. Dist. Functions",
    "url": "/posts/Prob_Dist_Functions/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "Discrete Prob. Dist.이산 균등 분포(Discrete Uniform Dist.)      정의 : 실현 가능한 각각의 결과가 동일한 확률로 발생하는 분포\\[X \\sim \\text{DiscreteUniform}(a,b)\\]          $1,2,3,4,5,6$ 까지 눈금이 있는 주사위를 굴릴 때, 각 눈금이 나올 확률의 분포      ...",
    "content": "Discrete Prob. Dist.이산 균등 분포(Discrete Uniform Dist.)      정의 : 실현 가능한 각각의 결과가 동일한 확률로 발생하는 분포\\[X \\sim \\text{DiscreteUniform}(a,b)\\]          $1,2,3,4,5,6$ 까지 눈금이 있는 주사위를 굴릴 때, 각 눈금이 나올 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)=\\frac{1}{n}\\]          $X$ : 이산 균등 분포를 따르는 확률변수      $k=a,\\cdots,b$ : 발생 가능한 결과      $n$ : 발생 가능한 결과의 갯수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{a+b}{2}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{(b-a+1)^2-1}{12}\\]  이항 분포(Bi-Nomial Dist.)      정의 : 고정된 횟수($n$)의 독립적인 베르누이 시행에서 성공 횟수를 나타내는 분포\\[X \\sim \\text{Bin}(n,p)\\]          열 번의 동전 던지기 실험에서 앞면이 나오는 횟수가 특정 값일 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)  = \\begin{pmatrix}n\\\\ k\\\\ \\end{pmatrix} p^{k} \\cdot (1-p)^{n-k}\\]          $X$ : 이항 분포를 따르는 확률변수      $k=0,1,2,\\cdots,n$ : 성공 횟수      $p$ : 성공 가능성      $n$ : 베르누이 시행 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=n \\cdot p\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=n \\cdot p \\cdot (1-p)\\]  포아송 분포(Poisson Dist.)      정의 : 단위 시간 혹은 공간 안에서 사건 발생 횟수를 나타내는 분포\\[X \\sim \\text{Poi}(\\lambda)\\]          한 시간 동안 특정 웹사이트에 접속하는 사용자 수가 특정 값일 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)  = \\frac{\\lambda^{k}}{k!}\\text{exp}(-\\lambda)\\]          $X$ : 포아송 분포를 따르는 확률변수      $k=0,1,2,\\cdots,n$ : 단위 시간 혹은 공간 안에서 사건 발생 횟수      $\\lambda$ : 단위 시간 혹은 공간 안에서 평균 사건 발생 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\lambda\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\lambda\\]  다항 분포(Multi-Nomial Dist.)      정의 : 여러 카테고리의 결과가 있는 일련의 실험에서 각 카테고리 결과의 횟수를 나타내는 분포\\[X \\sim \\text{Multin}(n;p_1, \\cdots, p_k)\\]          설문조사에서 예, 아니오, 무응답 응답자 수가 특정 값일 확률을 나타내는 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X_1=x_1, \\cdots, X_k=x_k)  = {n \\choose x_{1} ~ \\cdots ~ x_{k}} p_{1}^{x_{1}} \\cdots p_{k}^{x_{k}}\\]          $X$ : 다항 분포를 따르는 확률변수      $x_i=0,1,2,\\cdots,n$ : $i$ 번째 카테고리의 성공 횟수      $p_{i}$ : $i$ 번째 카테고리의 성공 가능성      $\\sum_{i}{x_{i}}=n$ : 시행 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X_{i}\\big]=n \\cdot p_{i}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{i}\\big]=n \\cdot p_{i} \\cdot (1-p_{i})\\]        공분산(Covariance)\\[\\mathbb{Cov}\\big[X_{i},X_{j}\\big]=-n \\cdot p_{i} \\cdot p_{j}\\]  Continuous Prob. Dist.균등 분포(Uniform Dist.)      정의 : 주어진 구간에서 모든 값이 일정한 확률을 가지는 분포\\[X \\sim \\text{Uniform}(a,b)\\]          $0$ 과 $1$ 사이의 수를 무작위로 선택할 때, 특정 값이 선택될 확률의 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{b-a} \\quad \\text{for}\\;a&lt;x&lt;b\\]        기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{a+b}{2}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{(b-a)^2}{12}\\]  베타 분포(Beta Dist.)      정의 : 두 매개변수 $\\alpha$ 와 $\\beta$ 에 의해 모양이 결정되는, $0$ 과 $1$ 사이의 값에 대한 확률 분포\\[X \\sim \\text{Beta}(\\alpha,\\beta)\\]          어떤 사건의 성공 횟수($\\alpha$)와 실패 횟수($\\beta$)가 주어졌을 때, 해당 사건의 성공 가능성이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\\]          $X$ : 베타 분포를 따르는 확률 변수      $x$ : 주로 성공 가능성      $\\alpha$ : 주로 성공 횟수로서, 클수록 우편향된 형태의 분포가 됨      $\\beta$ : 주로 실패 횟수로서, 클수록 좌편향된 형태의 분포가 됨              $\\Gamma(\\cdot)$ : 감마 함수\\[\\begin{aligned}  \\Gamma(n)  &amp;= \\int_{0}^{\\infty}{t^{n-1}e^{-t}}\\text{d}t\\\\  &amp;= (n-1)! \\quad \\text{s.t.}\\;n \\in \\mathbf{Z}^{+}  \\end{aligned}\\]                  기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{\\alpha}{\\alpha+\\beta}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{\\alpha \\cdot \\beta}{(\\alpha+\\beta)^2 \\cdot (\\alpha+\\beta+1)}\\]  지수 분포(Exponential Dist.)      정의 : 단일 사건의 대기 시간을 나타내는 분포\\[X \\sim \\text{Exp}(\\lambda)\\]          특정 버스 정류장에서 버스가 도착할 때까지 대기 시간이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\lambda \\cdot \\text{exp}(-\\lambda \\cdot x)\\]          $X$ : 지수 분포를 따르는 확률 변수      $x$ : 대기 시간      $\\lambda$ : 단위 시간 당 사건 발생률            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{1}{\\lambda}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{1}{\\lambda^{2}}\\]  감마 분포(Gamma Dist.)      정의 : 여러 지수적 사건의 총 대기 시간을 나타내는 분포\\[X \\sim \\text{Gamma}(k, \\theta)\\]          (여러 부품이 결합된) 특정 기계가 고장 나기 전까지 작동하는 시간이 특정 값일 확률 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{x^{k-1}\\exp\\left(-\\frac{x}{\\theta}\\right)}{\\theta^{k} \\cdot \\Gamma(k)}\\]          $X$ : 감마 분포를 따르는 확률 변수      $x &gt; 0$ : 총 대기 시간      $k$ : 형태 매개변수로서, 지수적 사건 발생 횟수      $\\theta$ : 스케일 매개변수로서, 지수적 사건의 평균 대기 시간      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=k \\cdot \\theta\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=k \\cdot \\theta^{2}\\]  역감마 분포(Inverse-Gamma Dist.)      정의 : 감마 분포의 역수를 따르는 확률 분포\\[\\begin{aligned}  X &amp;\\sim \\text{Gamma}(k, \\theta)\\\\  \\frac{1}{X} &amp;\\sim \\text{Inv-Gamma}(k, \\theta)  \\end{aligned}\\]          정규 분포 $N(\\mu, \\sigma^2)$ 의 분산 $\\sigma^2$ 에 대한 사전확률분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(Y=y) = \\frac{\\theta^{k} \\cdot y^{-k-1} \\cdot \\exp\\left(-\\frac{\\theta}{y}\\right)}{\\Gamma(k)}\\]          $Y=\\displaystyle\\frac{1}{X}$ : 역감마 분포를 따르는 확률 변수      $k$ : 형태 매개변수      $\\theta$ : 스케일 매개변수      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[Y\\big]=\\frac{\\theta}{k-1} \\quad \\text{s.t.}\\; k&gt;1\\]        분산(Variance)\\[\\mathbb{V}\\big[Y\\big]=\\frac{\\theta^2}{(k-1)^2(k-2)} \\quad \\text{s.t.}\\; k&gt;2\\]  정규 분포(Normal Dist.)      정의 : 자연 및 사회 과학에서 발생하는 대부분의 현상을 설명하는 대표적인 분포\\[X \\sim N(\\mu, \\sigma^2)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\exp\\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2}\\right)\\]          $\\mu$ : 평균      $\\sigma$ : 표준편차            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\mu\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\sigma^2\\]  비중심 T-분포(Non-central T-Dist.)      정의 : 평균이 $0$ 이 아닌 정규 분포에 기반한 표본 평균의 분포\\[X \\sim t_{\\nu}(\\delta)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x)  = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\nu \\pi}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1 + \\frac{1}{\\nu}\\left(\\frac{x-\\delta}{\\sigma}\\right)^{2}\\right)^{-\\frac{\\nu+1}{2}}\\]          $\\nu$ : 자유도(Degree of Freedom)      $\\delta$ : 비중심 매개변수(Non-Centrality Parameter)로서, 분포의 중심      $\\sigma$ : 스케일 매개변수로서, 표준편차      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]  =  \\begin{cases}\\begin{aligned}  &amp;\\delta \\cdot \\frac{\\Gamma\\left(\\frac{\\nu-1}{2}\\right)}{\\sqrt{\\frac{\\nu}{2}}\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\quad &amp;\\text{if}\\; \\nu &gt; 1\\\\  &amp;\\text{undefined} \\quad &amp;\\text{if}\\; \\nu \\le 1  \\end{aligned}\\end{cases}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]  =  \\begin{cases}\\begin{aligned}  &amp;\\frac{\\nu(1+\\delta^2)}{\\nu-2}-\\left(\\delta \\cdot \\frac{\\Gamma\\left(\\frac{\\nu-1}{2}\\right)}{\\sqrt{\\frac{\\nu}{2}}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\right)^2 \\quad &amp;\\text{if}\\; \\nu &gt; 2\\\\  &amp;\\infty \\quad &amp;\\text{if}\\; \\nu \\le 2  \\end{aligned}\\end{cases}\\]  카이제곱 분포(Chi-Squared Dist.)      정의 : 표준 정규 분포를 따르는 독립적인 확률변수들의 자승의 합이 특정 값일 확률에 대한 분포\\[X \\sim \\chi^{2}(k)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{2^{\\frac{k}{2}}\\cdot \\Gamma\\left(\\frac{k}{2}\\right)}x^{\\frac{k}{2}-1}\\exp(-\\frac{x}{2})\\]          $X$ : 카이제곱 분포를 따르는 확률변수              $x &gt; 0$ : $k$ 개의 독립적인 표준 정규 분포 $N(0,1)$ 를 따르는 확률변수 $Z_{i}$ 의 자승의 합\\[x = \\sum_{i=1}^{k}{Z_{i}^{2}} \\quad \\text{for} \\; Z_{i} \\sim N(0,1)\\]            $k$ : 자유도로서 확률변수 $z_{i}$ 의 갯수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=k\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=2k\\]  스케일된 역 카이제곱 분포(Scaled Inverse-Chi-Squared Dist.)      정의 : 카이제곱 분포의 역수를 따르는 확률 분포\\[\\begin{aligned}  X &amp;\\sim \\chi^{2}(k)\\\\  \\frac{\\sigma^2}{X} &amp;\\sim \\text{Scaled-Inv-}\\chi^{2}(k,\\sigma^2)  \\end{aligned}\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(Y=y) = \\frac{1}{\\Gamma\\left(\\frac{k}{2}\\right)}\\left(\\frac{k}{2\\sigma^2}\\right)^{\\frac{k}{2}}y^{-\\frac{k}{2}-1}\\exp\\left(-\\frac{k}{2\\sigma^2y}\\right)\\]          $Y=\\displaystyle\\frac{\\sigma^2}{X}$ : 스케일된 역카이제곱 분포를 따르는 확률변수      $y &gt; 0$      $k$ : 자유도      $\\sigma^2$ : 스케일 매개변수      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{k \\cdot \\sigma^2}{k-2} \\quad \\text{s.t.}\\; k&gt;2\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{2 \\cdot k^2 \\cdot \\sigma^4}{(k-2)^2(k-4)} \\quad \\text{s.t.}\\; k&gt;4\\]  위샤트 분포(Wishart Dist.)      정의 : 양정치 행렬(Positive Definite Matrix)에 대한 확률 분포\\[X \\sim W_{p}(\\mathbf{V},n)\\]          다변량 정규 분포(Multi-variat Normal Distribution) $N(\\mu, \\Sigma)$ 의 공분산 행렬 $\\Sigma$ 에 대한 사전확률분포            확률 밀도 함수(Prob. Density Function, PDF)\\[\\begin{aligned}  P(X=\\mathbf{X})   &amp;= \\frac{1}{2^{\\frac{np}{2}} \\vert \\mathbf{V} \\vert ^{\\frac{n}{2}}\\Gamma_{p}(\\frac{n}{2})} \\vert \\mathbf{X} \\vert ^{\\frac{n-p-1}{2}}\\exp\\left(-\\frac{1}{2}\\text{tr}(\\mathbf{V}^{-1}\\mathbf{X})\\right)\\\\  \\Gamma_{p}\\left(\\displaystyle\\frac{n}{2}\\right)  &amp;=\\pi^{\\frac{p(p-1)}{4}}\\prod_{i=1}^{p}{\\Gamma\\left(\\displaystyle\\frac{n-(i-1)}{2}\\right)}\\\\  \\text{tr}(\\mathbf{V}^{-1}\\mathbf{X})  &amp;=\\sum_{i}{(\\mathbf{V}^{-1}\\mathbf{X})_{ii}}  \\end{aligned}\\]          $X$ : 위샤트 분포를 따른 확률변수      \\(\\mathbf{X}=\\sum_{i=1}^{n}{\\overrightarrow{z}_{i} \\cdot \\overrightarrow{z}_{i}^{T}}\\) : $p \\times p$ 양정치 행렬(Positive Definite Matrix)                  표준 정규 분포 \\(N(0,1)\\) 를 따르는 \\(p\\) 차원 벡터 \\(\\overrightarrow{z}_{1},\\overrightarrow{z}_{2},\\cdots,\\overrightarrow{z}_{n}\\) 생성          외적 \\(\\overrightarrow{z}_{i} \\cdot \\overrightarrow{z}_{i}^{T}\\) 을 통해 \\(p \\times p\\) 양정치 행렬 \\(n\\) 개 생성          $n$ 개의 $p \\times p$ 양정치 행렬을 덧셈하여 $\\mathbf{X}$ 생성                    $n&gt;p-1$ : 자유도로서 $\\overrightarrow{z}_{i} \\sim N(0,1)$ 갯수              $\\mathbf{V}&gt;0$ : 양정치 행렬로서, 벡터 $\\overrightarrow{z}_{i} \\sim N(0,1)$ 간 공분산을 조정함으로써 분포의 형태와 스케일을 결정            $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=n \\cdot \\mathbf{V}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{ij}\\big]=n(\\mathbf{V}_{ij}^{2}+\\mathbf{V}_{ii}\\mathbf{V}_{jj})\\]  디리클레 분포(Dirichlet Dist.)      정의 : 베타분포의 다변수 확장으로서, 여러 카테고리의 비율에 대한 확률 분포\\[X \\sim \\text{Dirichlet}(\\alpha_{1}, \\cdots, \\alpha_{k})\\]          각 정당에 대한 투표 비율이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X_1=x_1, \\cdots, X_k=x_k) = \\frac{\\Gamma(\\alpha_{1}+\\cdots+\\alpha_{k})}{\\Gamma(\\alpha_{1}) \\cdots \\Gamma(\\alpha_{k})}x_{1}^{\\alpha_{1}-1} \\cdots x_{k}^{\\alpha_{k}-1}\\]          $0 \\le x_{i} \\le 1$ : 전체 카테고리 대비 $i$ 번째 카테고리가 차지하는 비중      $\\alpha_{i}$ : $i$ 번째 카테고리의 강도      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X_{i}\\big]=\\frac{\\alpha_{i}}{\\sum_{i}{\\alpha_{i}}}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{i}\\big]=\\frac{\\alpha_{i}(\\sum_{i}{\\alpha_{i}}-\\alpha_{i})}{\\left(\\sum_{i}{\\alpha_{i}}\\right)^{2}(\\sum_{i}{\\alpha_{i}}+1)}\\]        공분산(Covariance)\\[\\mathbb{V}\\big[X_{i},X_{j}\\big]=-\\frac{\\alpha_{i} \\cdot \\alpha_{j}}{\\left(\\sum_{i}{\\alpha_{i}}\\right)^{2}(\\sum_{i}{\\alpha_{i}}+1)}\\]  "
  },
  
  {
    "title": "Probability",
    "url": "/posts/Probability/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics",
    "date": "2024-07-02 00:00:00 +0900",
    





    
    "snippet": "ProbabilityRandom Experiment  확률실험(Random Experiment) : 사건의 불확실성을 가진 프로세스          사건의 불확실성 : 결과(Outcome)를 사전에 알 수 없는 성질        표본공간(Sample Space) : 확률실험에서 발생 가능한 모든 결과의 집합                  동전 던지기\\...",
    "content": "ProbabilityRandom Experiment  확률실험(Random Experiment) : 사건의 불확실성을 가진 프로세스          사건의 불확실성 : 결과(Outcome)를 사전에 알 수 없는 성질        표본공간(Sample Space) : 확률실험에서 발생 가능한 모든 결과의 집합                  동전 던지기\\[S = \\{H, T\\}\\]                    주사위 던지기\\[S = \\{1, 2, 3, 4, 5, 6\\}\\]                    전구의 수명\\[S = \\{x \\in R \\,|\\, x \\ge 0\\}\\]                    올해 순 이익\\[S = R\\]              사건(Event) : 표본공간의 부분집합으로서 발생 가능한 결과의 일부          단순 사건(Simple Event) : 어떤 결과 하나만으로 이루어진 사건                              동전을 한 번 던졌을 때 앞면이 나오는 사건\\[E=\\{H\\}\\]                                주사위를 한 번 던졌을 때 3이 나오는 사건\\[E=\\{3\\}\\]                              복합 사건(Compound Event) : 두 개 이상의 결과로 이루어진 사건                              동전을 두 번 던졌을 때 서로 다른 면이 나오는 사건\\[E=\\{HT, TH\\}\\]                                주사위를 한 번 던졌을 때 짝수가 나오는 사건\\[E=\\{2,4,6\\}\\]                              Probability      확률(Probability) : 주어진 표본공간 $S$ 에 대하여 그 사건 $A$ 가 발생할 상대적 가능성\\[P(A),\\quad \\text{s.t.}\\;0 \\le P(A) \\le 1\\]    확률 부여 방법          고전적 접근법 : 확률실험의 대칭성(Symmetric Nature)을 이용하여 각 결과가 발생할 가능성을 논리적으로 추론하는 방법                  어떤 확률실험이 발생 가능성이 동일한(Equally Likely) $n$ 개의 결과를 가질 때, 단순 사건이 발생할 확률은 $\\displaystyle\\frac{1}{n}$ 임          $n$ 개의 결과 중 $n_A$ 개 결과를 취하는 복합 사건이 발생할 확률은 $\\displaystyle\\frac{n_A}{n}$ 임                    상대 빈도 접근법 : 반복되는 경험에 따라 확률을 부여하는 방법으로서 경험적 접근법                  어떤 확률실험을 $n$ 번 반복했을 때, 어떤 결과가 $k \\le n$ 번 발생했다면 그 결과가 발생할 확률은 $\\displaystyle\\frac{k}{n}$ 임          실험 횟수가 증가할수록 정확도가 높아짐          실험 횟수가 매우 크고, 모든 실험이 동일한 환경에서 이루어졌을 때 정당성을 가짐                    주관적 접근법 : 고전적 접근법, 상대 빈도 접근법에 의해 확률을 부여하는 것이 불가능한 경우 개인적인 판단에 의해 확률을 부여하는 방법            확률의 공리(Axioms of Probability)          주어진 표본공간 $S$ 에 대하여 그 사건 $A_i\\,(i=1,2,\\cdots n)$ 는 다음을 만족해야 함              $P(S)=1$      $0 \\le P(A_i) \\le 1$      $A_1, A_2, \\cdots, A_n$ 이 상호배타적이라면 $P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+P(A_3)+\\cdots +P(A_n)$                              상호배타성(Mutually Exclusive or Disjoint)\\[A_i \\cap A_j = \\phi\\]                                    확률 법칙          주어진 표본공간 $S$ 에 대하여 그 사건 $A_i\\,(i=1,2,\\cdots n)$ 는 다음을 만족함              $P(\\phi)=0$      \\(P(A_i')=1-P(A_i)\\), \\(A_i'=\\{x \\in S \\vert x \\notin A_i \\}\\)      $A_i\\subseteq A_j \\Rightarrow P(A_i) \\le P(A_j)$      $P(A_i \\cup A_j)=P(A_i) + P(A_j) - P(A_i \\cap A_j)$      $A_1, A_2, \\cdots, A_n$ 이 집단전체적이라면 $P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n)=1$                              집단전체성(Collectively Exhaustive)\\[A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n = S\\]                              Joint Probability      결합 확률(Joint Probability) : 확률변수 $A, B$ 에 대하여 그 값 $A_i \\in A$ 와 $B_j \\in B$ 가 동시에 발생할 확률\\[P(A_i \\cap B_j)\\]        결합확률표          표본공간 $S$ 에 대하여 확률변수 $A={A_1, A_2, A_3, \\cdots, A_i, \\cdots, A_n}$ 를 상호배타적이고 집단전체적인 사건들의 집합이라고 하자. 또한 확률변수 $B={B_1, B_2, B_3, \\cdots, B_j, \\cdots, B_m}$ 를 또 다른 상호배타적이고 집단전체적인 사건들의 집합이라고 하자. 이때 사건 $A_i, B_j$ 가 동시에 발생할 결합 확률 $P(A_i \\cap B_j)$ 는 다음의 표와 같다.                                           $B_1$          $B_2$          $\\cdots$          $B_m$          $\\sum_{j=1}^{m}P(A_i \\cap B_j)$                                      $A_1$          $P(A_1 \\cap B_1)$          $P(A_1 \\cap B_2)$          $\\cdots$          $P(A_1 \\cap B_m)$          $P(A_1)$                          $A_2$          $P(A_2 \\cap B_1)$          $P(A_2 \\cap B_2)$          $\\cdots$          $P(A_2 \\cap B_m)$          $P(A_2)$                          $\\vdots$          $\\vdots$          $\\vdots$          $\\ddots$          $\\vdots$          $\\vdots$                          $A_n$          $P(A_n \\cap B_1)$          $P(A_n \\cap B_2)$          $\\cdots$          $P(A_n \\cap B_m)$          $P(A_n)$                          $\\sum_{i=1}^{n}P(A_i \\cap B_j)$          $P(B_1)$          $P(B_2)$          $\\cdots$          $P(B_m)$          $1$                    Statistical Independence      조건부 확률(Conditional Probability) : 사건 $A_1$ 이 발생했을 때 사건 $A_2$ 가 발생할 확률\\[P(A_2 \\vert A_1) = \\frac{P(A_2 \\cap A_1)}{P(A_1)} \\quad (\\text{s.t.}\\, P(A_1)&gt;0)\\]        베이즈 정리(Bayes Theorem)\\[\\begin{aligned}  P(B \\vert A)  &amp;= \\frac{P(B)P(A \\vert B)}{P(A)}\\\\  &amp;= \\frac{P(B) \\times \\frac{P(A \\cap B)}{P(B)}}{P(A)}\\\\  &amp;= \\frac{P(B \\cap A)}{P(A)}  \\end{aligned}\\]                  일반화                  사건 $B_1, B_2, B_3, \\cdots, B_m$ 이 상호배타적이고 집단전체적이라면, 사건 $A$ 와 $B_j\\,(j=1,2,3,\\cdots,m)$ 에 대하여 다음이 성립함        \\[\\begin{aligned}  P(B_j \\vert A)  &amp;= \\frac{P(A \\vert B_j) \\times P(B_j)}{\\displaystyle\\sum_{i=1}^{m}P(A \\vert B_i)P(B_i)}  \\end{aligned}\\]                  통계적 독립성(Statistical Independence) : 한 사건의 발생 여부가 다른 사건이 발생할 가능성에 아무런 영향을 끼치지 못하는 경우\\[P(A_2 \\vert A_1) = P(A_2) \\quad \\text{or} \\quad P(A_1 \\vert A_2) = P(A_1)\\]                  사건 $A_1$ 과 $A_2$ 가 통계적으로 독립적이면 다음을 만족함\\[P(A_1 \\cap A_2) = P(A_1)P(A_2)\\]                    사건 $A_1$ 과 $A_2$ 가 상호배타적이라고 해서 통계적으로 독립이라고 볼 수는 없음                              사건 $A_1$ 과 $A_2$ 가 상호배타적인 경우\\[P(A_1 \\cap A_2) = 0 \\quad (\\text{s.t.} \\, P(A_1)&gt;0, P(A_2)&gt;0)\\]                                사건 $A_1$ 과 $A_2$ 가 통계적으로 독립인 경우\\[\\begin{aligned}  P(A_2 \\vert A_1)  &amp;=\\frac{P(A_2 \\cap A_1)}{P(A_1)} \\\\  &amp;=P(A_2) \\quad (\\text{s.t.} \\, P(A_1)&gt;0, P(A_2)&gt;0)  \\end{aligned}\\]                              Random VariablesWhat? Random Variable      확률변수(Random Variable) : 표본공간 $S$ 에 대하여 그 결과에 숫자를 배정하는 규칙으로서, 그 값이 확률실험 결과에 의해 결정되는 변수        확률 분포(Probability Distribution) : 확률변수의 값 $x \\in X$ 에 대하여 각각에 대응하는 확률 값 $P(x)$ 의 분포        확률분포함수 : 확률변수를 정의역으로, 그 분포를 치역으로 가지는 함수\\[\\begin{aligned}  f(x)=P(X=x)  \\end{aligned}\\]        누적분포함수(Cumulative Distribution Function) : 확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k)  \\end{aligned}\\]  ExampleProbability Experiment of Tossing a Coin Twice      표본공간 $S$ 정의\\[S=\\{HH,HT,TH,TT\\}\\]        결과 $outcome \\in S$ 의 확률 정의                            $outcome \\in S$          $P(outcome)$                                      $HH$          $0.25$                          $HT$          $0.25$                          $TH$          $0.25$                          $TT$          $0.25$                    규칙1 같은 면이면 1, 다른 면이면 0      확률변수 $X$ 정의 : $X = {0, 1}$                            $outcome \\in S$          $x \\in X$                                      $HH$          $1$                          $HT$          $0$                          $TH$          $0$                          $TT$          $1$                          확률변수 $x \\in X$ 의 확률분포                            $x \\in X_1$          $P(x)$                                      $1$          $0.5$                          $0$          $0.5$                    규칙2 앞면의 갯수      확률변수 $X$ 정의 : $X = {0, 1, 2}$                            $outcome \\in S$          $x \\in X$                                      $HH$          $2$                          $HT$          $1$                          $TH$          $1$                          $TT$          $0$                          확률변수 $x \\in X$ 의 확률분포                            $x \\in X$          $P(x)$                                      $2$          $0.25$                          $1$          $0.5$                          $0$          $0.25$                    Discrete Random VariableWhat? Discrete Random Variable      이산확률변수(Discrete Random Variable) : 변수가 취할 수 있는 값의 수를 셀 수 있는 확률변수\\[X=\\{x_i\\,|\\,i=1,2,3,\\cdots,n\\}\\]          동전 앞면의 수      주사위 눈의 수      자녀의 수      한 시간 동안 방문한 고객의 수            이산확률분포(Discrete Probability Distribution) : 이산확률변수 $X$ 가 취할 수 있는 값 $x \\in X$ 에 대하여 그 값이 발생할 확률 $P(x)$ 의 분포\\[P(X)\\]        확률질량함수(Probability Mass Function; $pmf$) : 이산확률변수를 정의역으로, 그 확률분포를 치역으로 가지는 함수\\[\\begin{aligned}  f:\\,X\\rightarrow P(X)  \\end{aligned}\\]          이산확률변수 $X={x_1, x_2, x_3, \\cdots, x_n}$ 에 대하여 그 확률질량함수는 다음의 조건을 만족해야 함                  $0 \\le P(x) \\le 1, \\; x^{\\forall} \\in X$          $\\displaystyle\\sum_{i=1}^{n}P(x_i)=1$                          누적분포함수(Cumulative Distribution Function; $cdf$) : 이산확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k) \\\\  &amp;=\\sum_{x=1}^{k}f(x)  \\end{aligned}\\]  Descriptive Statistic      기대값(Expected Value; $E$) : 각 값이 발생할 확률에 따라 가중평균된 값          이산확률변수 $X$ 가 값 $x_i (i=1,2,3,\\cdots,n)$ 을 가질 확률이 $P(x_i)$ 일 때, $X$ 의 기대값 $E\\left[X\\right]$ 를 다음과 같이 정의함    \\[\\begin{aligned}  E\\left[X\\right]  &amp;= \\mu \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n}x_iP(x_i)  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $E\\left[\\alpha \\right]=\\alpha$          $E\\left[\\alpha X \\right]=\\alpha E\\left[X \\right]$          $E\\left[\\alpha X \\pm \\beta Y \\right] = \\alpha E\\left[X \\right] \\pm \\beta E\\left[Y \\right]$          $X, Y$ 가 독립이면 $E \\left[XY \\right]=E \\left[X \\right]E \\left[Y \\right]$                          분산(Variance; $Var$)          이산확률변수 $X$ 가 값 $x_i (i=1,2,3,\\cdots,n)$ 을 가질 확률이 $P(x_i)$ 일 때, $X$ 의 분산 $Var(X)$ 를 다음과 같이 정의함    \\[\\begin{aligned}  Var \\left[X \\right]  &amp;=\\sigma^2\\\\  &amp;=\\displaystyle\\sum_{i=1}^{n}(x_i-\\mu)^2P(x_i)\\\\  &amp;=E \\left[(X-\\mu)^2 \\right]\\\\  &amp;=E \\left[X^2 \\right]-E \\left[X \\right]^2  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $Var\\left[\\alpha \\right]=0$          $Var\\left[\\alpha X \\right]=\\alpha^2Var\\left[X \\right]$          $Var\\left[\\alpha + X \\right]=Var\\left[X \\right]$          $Var\\left[\\alpha X \\pm \\beta Y \\right] = \\alpha^2Var\\left[X \\right] + \\beta^2Var\\left[Y \\right] \\pm 2\\alpha\\beta Cov\\left[X, Y \\right]$                    Statistical Independence      이산확률변수의 결합확률분포(Joint Probability Distribution)          이산확률변수 $x \\in X, y \\in Y$ 에 대하여 그 결합확률분포 $P(x, y)$ 는 $X=x, Y=y$ 일 확률을 추정한 분포로 정의함    \\[P(X=x_i, Y=y_j)=P(x_i \\cap y_j)\\]\\[\\begin{aligned}  for\\; X&amp;=\\{x_i\\,|\\,i=1,2,\\cdots,n\\},\\\\  Y&amp;=\\{y_j\\,|\\,j=1,2,\\cdots,m\\}  \\end{aligned}\\]          공리                  $0 \\le P(x_i,y_j) \\le 1$          $\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)=1$                    규칙                  $P_X(x_i)=\\displaystyle\\sum_{j=1}^{m}P(x_i,y_j)$          $P_Y(y_j)=\\displaystyle\\sum_{i=1}^{n}P(x_i,y_j)$                          이산확률변수의 공분산\\[\\begin{aligned}  Cov\\left[X,Y\\right]  &amp;=\\sigma_{XY}\\\\  &amp;=E\\left[(X-\\mu_{X})(Y-\\mu_{Y})\\right]\\\\  &amp;=E\\left[XY\\right]-\\mu_{X}\\mu_{Y}\\\\  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)-\\mu_{X}\\mu_{Y}  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y, Z$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $Cov\\left[X, \\alpha \\right]=0$          $Cov\\left[X+\\alpha, Y+\\beta \\right]=Cov\\left[X,Y \\right]$          $Cov\\left[\\alpha X, \\beta Y \\right]=\\alpha\\beta Cov\\left[X,Y \\right]$          $Cov\\left[X+Y,Z \\right]=Cov\\left[X,Z \\right]+Cov\\left[Y,Z \\right]$                          이산확률변수 간 통계적 독립                  모든 $(x_i, y_j)$ 에 대하여 다음을 만족하는 경우 이산확률변수 $X, Y$ 는 통계적으로 독립임\\[P(x_i \\vert y_j)=P_X(x_i) \\quad \\text{or} \\quad P(y_j \\vert x_i)=P_Y(y_j)\\]            이산확률변수 $X, Y$ 가 통계적으로 독립이면 다음이 성립함                  $ P(x_{i}, y_{j})=P_X(x_{i})P_Y(y_{j}) $          $ Cov\\left[X,Y \\right]=0 $                            위 명제에 근거하여 다음이 성립함\\[\\begin{aligned}  Cov\\left[X,Y \\right]  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)-\\mu_{X}\\mu_{Y}\\\\  &amp;=0\\\\  \\therefore \\mu_{X}\\mu_{Y}  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} x_iy_jP_X(x_i)P_Y(y_j)  \\end{aligned}\\]            Continuous Random VariableWhat? Continuous Random Variable      연속확률변수(Continuous Random Variable) : 변수가 취할 수 있는 값이 연속적이어서 그 수를 셀 수 없는 확률변수\\[X=(l,u) \\quad \\text{or} \\quad X=[l,u]\\]          길이      무게      시간      기온            연속확률분포(Continuous Probability Distribution) : 연속확률변수 $X$ 가 취할 수 있는 값 $x \\in X$ 에 대하여 그 값이 발생할 확률 $P(x)$ 의 분포\\[P(X)\\]        확률밀도함수(Probability Density Function; $pdf$) : 연속확률변수를 정의역으로, 그 확률분포를 치역으로 가지는 함수\\[\\begin{aligned}  f:\\,X\\rightarrow P(X)  \\end{aligned}\\]          구간 $X=(l, u)$ 혹은 $X=[l,u]$ 에서 정의된 연속확률변수 $x \\in X$ 에 대하여 그 확률밀도함수는 다음의 조건을 만족해야 함                  $\\displaystyle\\int_{l}^{u}f(x)dx=1$                          $f(x \\in [a, b])=P(a \\le x \\le b)=\\displaystyle\\int_{a}^{b}f(x)dx$              $f(k)=P(k \\le x \\le k)=\\displaystyle\\int_{k}^{k}f(x)dx=0$                                $f(x) \\ge 0 \\quad \\text{for} \\; x^{\\forall} \\in X$                          누적분포함수(Cumulative Distribution Function; $cdf$) : 연속확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k) \\\\  &amp;=\\displaystyle\\int_{x=1}^{k}f(x)dx  \\end{aligned}\\]  Continuous Statistic      기대값(Expected Value; $E$)\\[\\begin{aligned}  E \\left[X \\right]  &amp;=\\mu\\\\  &amp;=\\displaystyle\\int_{x=l}^{u}xf(x)dx  \\end{aligned}\\]        분산(Variance; $Var$)\\[\\begin{aligned}  Var \\left[X \\right]  &amp;=\\sigma^2\\\\  &amp;=E \\left[(X-\\mu)^2 \\right]\\\\  &amp;=\\displaystyle\\int_{x=l}^{u}(x-\\mu)^2f(x)dx  \\end{aligned}\\]  "
  },
  
  {
    "title": "What? Statistics",
    "url": "/posts/Statistics/",
    "categories": "DATA MINING TECHS, 1.statistics",
    "tags": "Statistics",
    "date": "2024-07-01 00:00:00 +0900",
    





    
    "snippet": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : ...",
    "content": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : 데이터를 수집, 정리, 제시, 요약하는 방법을 연구함      추론통계학(Inferential Statistics) : 표본으로부터 모집단의 성격을 추정하는 방법을 연구함      What? Descriptive StatisticData Set  구성          관측치(Observation) : 분석하려는 집합에 속한 하나의 개체      변수(Variable) : 개체의 특징        Data Type          정량적 자료(Quantitative Data) : 수로 표현되는 자료로서 숫자 자체가 의미를 가지는 자료                  이산형 자료(Discrete Data) : 셀 수 있는 정수 형태의 자료          연속형 자료(Continuous Data) : 셀 수 없는 실수 형태의 자료                    정성적 자료(Qualitative Data) : 범주(Category)에 따라 나뉘는 자료      Descriptive Statistic      기술통계량(Descriptive Statistic) : 숫자로 측정한 데이터 세트의 특징    명목 척도(Nominal Scale)                  고유한 값(Unique Value)만을 구분하는 척도                  전공 : 경영학, 경제학, 통계학                      순서 척도(Ordinal Scale)                  값들 사이에 분명한 순위가 있는 척도                  직급 : 사원, 대리, 팀장, 과장, 차장, 부장                            값의 간격은 의미를 갖지 않음              구간 척도(Interval Scale)                  값의 간격이 산술적 의미를 갖는 척도                  기온 $0^{\\circ}C$ 와 $10^{\\circ}C$ 의 간격은 기온 $20^{\\circ}C$ 와 $30^{\\circ}C$ 의 간격과 동일함                            값 사이의 비율은 산술적 의미를 갖지 않음                  기온 $30^{\\circ}C$ 가 $20^{\\circ}C$ 보다 $50%$ 더 따뜻하다고 볼 수 없음                      비율 척도(Ratio Scale)                  값 사이의 비율이 산술적 의미를 갖는 척도                  순익 $2,000,000$ 원은 순익 $1,000,000$ 원 보다 순익 두 배라고 볼 수 있음                            $0$ 이 절대영점으로서 의미를 가짐                  매출 $0$ 원은 매출이 하나도 없음을 의미함                    Summary Quantitative Data      중심 위치 측도 : 대표값으로서 값의 대부분이 어디쯤 위치하는지 측정하는 지표        변이 측도 : 관측치들이 얼마나 퍼져 있는가를 나타내는 측도  중심 위치 측도      평균(Mean; $\\mu$) : 관측치들의 합을 그 갯수로 나눈 값\\[\\mu = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}\\]        중위수(Median; $Q_2$) : 모든 관측치를 크기에 따라 오름차순 정렬했을 때 중앙에 오는 값                  평균 vs. 중위수 : 관측치에 이상치가 포함되어 있거나, 분포가 지나치게 비대칭일 경우, 중위수가 대표값으로서 선호됨                          사분위수(Quartile; $Q_i$) : 모든 관측치를 크기에 따라 오름차순으로 정렬했을 때, 하위 25%($Q_1$), 하위 50%($Q_2$), 하위 75%($Q_3$)에 해당하는 값      변이 측도      범위(Range) : 최대값과 최소값의 차이\\[\\text{R}=X_{max}-X_{min}\\]        사분위범위(Interquartile Range) : 관측치를 크기를 기준으로 오름차순 정렬했을 때 제3사분위수와 제1사분위수의 차이\\[\\text{IQR}=Q_{3}-Q_{1}\\]        평균절대편차(Mean Absolute Deviation; MAD) : 관측치와 평균 사이 거리의 평균\\[\\text{MAD} = \\frac{1}{N}\\sum_{i=1}^{N} \\vert X_{i}-\\mu \\vert\\]        분산(Variance; $\\sigma^2$) : 관측치와 평균 간 편차 자승의 평균\\[\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2\\]        표준편차(Standard Deviation; $\\sigma$) : 분산의 자승근\\[\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2}\\]          자료에서 사용된 단위와 동일한 단위로 측정되므로 해석에 용이함      변이 측도를 활용한 이상치 판별      경험 법칙(Empirical Rule) : 관측치 분포가 종 모양의 대칭 형태를 띠는 경우, 실증적으로 획득된 분포에 대한 일반적인 원칙이 성립함              $(\\mu - 1\\sigma, \\mu + 1\\sigma)$ 에는 관측치의 약 68%가 존재함      $(\\mu - 2\\sigma, \\mu + 2\\sigma)$ 에는 관측치의 약 95%가 존재함      $(\\mu - 3\\sigma, \\mu + 3\\sigma)$ 에는 관측치의 약 99%가 존재함            사분위수 범위를 활용한 이상치 판별              이상치 판단 기준으로서 상한선 및 하한선 설정                  상한선 : $Q_{3}+1.5\\cdot\\text{IQR}$          하한선 : $Q_{1}-1.5\\cdot\\text{IQR}$                            내부 범위 설정\\[\\text{Outlier} \\notin [Q_{1}-1.5\\cdot\\text{IQR}, Q_{3}+1.5\\cdot\\text{IQR}]\\]            변수 간 관계      공분산(Covariance) : 두 변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]          $\\sigma_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\sigma_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\sigma_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음            피어슨 상관계수(Pearson Correlation Coefficient; PCC) : 공분산의 단위 의존적(Unit-Dependent)인 문제를 완화한 지표로서, 공분산을 두 변수의 편차의 곱으로 나눈 값\\[\\rho_{XY} = \\frac{\\sigma_{XY}}{\\sigma_{X}\\sigma_{Y}}\\]          $-1\\le\\rho_{XY}\\le1$      $\\rho_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\rho_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\rho_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음      Summary with Graphs수치형 변수      Box Plot : 사분위수를 기준으로 데이터의 대략적인 분포를 나타낸 그래프            Histogram : 데이터 범위를 동일 간격 구간으로 나누어 해당 구간에 위치한 데이터 갯수를 나타낸 그래프                      Density Estimate : 커널밀도추정법을 통해 히스토그램을 연속된 곡선으로 나타낸 그래프                          Q-Q Normality Plot : 데이터 분포 형태가 정규 분포에 얼마나 근접한지 나타내는 그래프      수치형 변수 간 관계      히트 맵(Heatmap) : 두 변수 간 상관관계가 강할수록 채도를 짙게 나타낸 그래프            산점도(Scatter Plot)      범주형 변수      도수분포표(Frequency Table) : 각 범주에 해당하는 관측치 갯수를 요약한 표            Bar Plot : 도수분포표의 값을 막대 높이로 나타낸 그래프            Pie Chart : 도수분포표의 빈도 비율을 부채꼴 모양으로 나타낸 그래프      범주형 변수 간 관계      분할표(Cross Table) : 두 범주형 변수에 의해 생성되는 범주별 빈도수를 요약한 표            Mosaic Plot : 분할표에서 각 범주의 비율을 상자의 너비와 높이로 나타낸 그래프      Sourse  https://thirdspacelearning.com/gcse-maths/statistics/frequency-table/  https://www.jaspersoft.com/articles/what-is-a-bar-chart  https://proclusacademy.com/blog/customize_matplotlib_piechart/  https://www.questionpro.com/cross-tabulation.html"
  },
  
  {
    "title": "AutoEncoder based Collaborative Filtering",
    "url": "/posts/AutoRec/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "Paper Review, AI Application, Recommender System, Collaborative Filtering, Autoencoder, Bayesian",
    "date": "2024-06-19 00:00:00 +0900",
    





    
    "snippet": "AutoRec  문제 의식          RBM-CF(Restricted Boltzmann Machines for Collaborative Filtering): 확률적 생성 모형으로서, 평점값마다 별도의 파라미터를 설정하므로 학습 파라미터 수가 급증하고, 확률 생성 과정을 근사 학습하므로 수렴 속도가 느림      LLORMA(Local Low-Ra...",
    "content": "AutoRec  문제 의식          RBM-CF(Restricted Boltzmann Machines for Collaborative Filtering): 확률적 생성 모형으로서, 평점값마다 별도의 파라미터를 설정하므로 학습 파라미터 수가 급증하고, 확률 생성 과정을 근사 학습하므로 수렴 속도가 느림      LLORMA(Local Low-Rank Matrix Approximation): 행렬분해 기반 잠재요인 모형으로서, 사용자 취향이 전역적으로 일관되지 않을 수 있다는 전제 하에 사용자-아이템 상호작용 행렬을 다수의 하위 행렬로 재구성하고, 각각을 지역적 저차원(Local Low Rank)으로 근사하나, 구조가 복잡함        AutoRec: 오토인코더 기반 협업필터링 모형으로서, 연속적 출력값을 결정론적 함수로 도출하는 단일 신경망 구조를 통해 선행 협업필터링 모형에 비해 계산 효율성과 구조적 간결성을 도모함          Sedhain, S., Menon, A. K., Sanner, S., &amp; Xie, L.  (2015, May).  Autorec: Autoencoders meet collaborative filtering.  In Proceedings of the 24th international conference on World Wide Web (pp. 111-112).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$: user-item explicit feedback matrix  $\\mathbf{V} \\in \\mathbb{R}^{M \\times K}$: linear transformation matrix @ encoder  $\\mathbf{W} \\in \\mathbb{R}^{K \\times M}$: linear transformation matrix @ decoder  $\\overrightarrow{\\beta} \\in \\mathbb{R}^{K}$: bias vector @ encoder  $\\overrightarrow{\\mathbf{b}} \\in \\mathbb{R}^{M}$: bias vector @ decoder  $f(\\cdot)$: activation function @ encoder  $g(\\cdot)$: activation function @ decoderHow to Modeling      Prediction\\[\\begin{aligned}  \\hat{\\mathbf{r}}_{i}  &amp;= g\\left[\\mathbf{W} \\cdot f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{r}}_{i} + \\overrightarrow{\\beta}) + \\overrightarrow{\\mathbf{b}} \\right]  \\end{aligned}\\]                  Encoder(Dimensionality Reduction):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{i}  &amp;= f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{r}}_{i} + \\overrightarrow{\\beta})  \\end{aligned}\\]                    Decoder(Reconstruction):\\[\\begin{aligned}  \\hat{\\mathbf{r}}_{i}  &amp;= g(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                  Optimization\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\min{\\sum_{i=1}^{N}{\\Vert \\overrightarrow{\\mathbf{r}}_{i} - h(\\overrightarrow{\\mathbf{r}}_{i} ; \\Theta) \\Vert_{\\mathcal{O}}^{2}} + \\frac{\\lambda}{2}\\Vert \\Theta \\Vert_{F}^{2}}  \\end{aligned}\\]          \\(h(\\overrightarrow{\\mathbf{r}}_{i} ; \\Theta)\\): Reconstruction Output      \\(\\Theta\\): Learning Parameters      \\(\\Vert \\cdot \\Vert_{\\mathcal{O}}^{2}\\): L2 Loss Computed only for Observed Entries      \\(\\Vert \\cdot \\Vert_{F}^{2}\\): Regularization Term      CDAE  문제 의식: AutoRec 의 한계점          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측과 미관측이 특정한 선택 경로와 제약 조건 하에서 발생했다는 점을 간과하고 선호와 비선호로 이분하는 데서 오는 체계적 왜곡          자명해 문제(Trivial Solution): AutoRec 은 명시적 피드백 데이터 하에서 관측만을 사용하여 최적화를 수행하나, 암시적 피드백 데이터 하에서 이는 모든 상호작용을 $1$ 로 예측하는 자명해로 수렴함                    Personalization Problem: AutoRec 은 행렬 복원에 초점을 맞추어 최적화를 수행하므로 히스토리는 유사하나 잠재적 선호 구조(latent preference structure)는 다른 사용자들 간에 제공되는 추천의 개인화가 미흡할 수 있음        CDAE(Collaborative Denoising AutoEncoder): 잡음을 활용하여 암시적 피드백 데이터 하에서 손상된 선호도를 복원하고, 사용자 잠재 벡터를 활용하여 개인화 성능 향상을 꾀하는 오토인코더 기반 협업필터링 모형          Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M.  (2016, February).  Collaborative denoising auto-encoders for top-n recommender systems.  In Proceedings of the ninth ACM international conference on web search and data mining (pp. 153-162).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item implicit feedback matrix  $\\mathbf{X} \\in \\mathbb{R}^{M \\times N}$: masked $\\mathbf{Y}$  $\\mathbf{M} \\in \\mathbb{R}^{M \\times N}$: masking matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\mathbf{V} \\in \\mathbb{R}^{M \\times K}$: linear transformation matrix @ encoder  $\\mathbf{W} \\in \\mathbb{R}^{K \\times M}$: linear transformation matrix @ decoder  $\\overrightarrow{\\beta} \\in \\mathbb{R}^{K}$: bias vector @ encoder  $\\overrightarrow{\\mathbf{b}} \\in \\mathbb{R}^{M}$: bias vector @ decoder  $f(\\cdot)$: activation function @ encoder  $g(\\cdot)$: activation function @ decoderHow to Modeling      Generate Masking Noise\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\overrightarrow{\\mathbf{y}}_{u} \\odot \\overrightarrow{\\mathbf{m}}_{u}, \\quad \\overrightarrow{\\mathbf{m}}_{u} \\sim \\text{Bernouli}(1-p)^{N}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{m}}_{u} \\sim \\text{Bernouli}(1-p)^{N}\\): \\(m_{u,i} \\sim \\text{Bernouli}(1-p)\\) independently            Prediction\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{u}  &amp;= g\\left[\\mathbf{W} \\cdot f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{x}}_{u} + \\overrightarrow{\\mathbf{u}}_{u} + \\overrightarrow{\\beta}) + \\overrightarrow{\\mathbf{b}} \\right]  \\end{aligned}\\]                  Encoder(Dimensionality Reduction):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u}  &amp;= f(\\mathbf{V} \\cdot \\overrightarrow{\\mathbf{x}}_{u} + \\overrightarrow{\\mathbf{u}}_{u} + \\overrightarrow{\\beta})  \\end{aligned}\\]                    Decoder(Reconstruction):\\[\\begin{aligned}  \\hat{\\mathbf{y}}_{u}  &amp;= g(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{u} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                  Optimization\\[\\begin{aligned}  \\Theta  &amp;= \\text{arg} \\min{\\frac{1}{M}\\sum_{u=1}^{M}{\\mathbb{E}_{\\mathbf{X} \\sim P(\\cdot \\mid \\mathbf{Y})}[\\mathcal{L}(\\mathbf{y}_{u}, \\hat{\\mathbf{y}}_{u})] + \\frac{\\lambda}{2} \\Vert \\Theta \\Vert_{F}^{2}}}  \\end{aligned}\\]          \\(\\mathcal{L}(\\mathbf{y}_{u}, \\hat{\\mathbf{y}}_{u})\\): Reconstruction Loss      \\(\\mathbb{E}_{\\mathbf{X} \\sim P(\\cdot \\mid \\mathbf{Y})}\\): Average Loss because of Stochasticity of Noise      \\(\\Theta\\): Learning Parameters      \\(\\Vert \\cdot \\Vert_{F}^{2}\\): Regularization Term      Mult-VAE  문제 의식          Implicit Feedback Problem                  구조적 편향 문제(Structural Bias): 관측을 선호, 미관측을 비선호로 확정적으로 간주하기에 불확실한 요소가 존재함(관측 불완전성)          자명해 문제(Trivial Solution): 관측과 미관측의 비율이 균등하지 않아 모든 상호작용을 $0$ 으로 예측하는 자명해로 수렴할 위험이 있음(데이터 희소성)                            Competitive Relationship between Items: 사용자 선택 과정에는 아이템 간 암묵적인 경쟁적 구조가 존재하므로 사용자가 특정 아이템과 상호작용할 확률은 다른 아이템과 상호작용할 확률과 독립적으로 계산되어서는 안 됨            Uncertainty of Latent Representation: 관측 불완전성, 데이터 희소성 등 암시적 피드백 데이터의 정보 불확실성으로 인하여 사용자 잠재 선호를 확정적으로 도출하기에 문제가 있으므로 사용자 선호가 취할 수 있는 다양한 가능성을 고려해야 함        Mult-VAE(Multinomial Variational AutoEncoder): 확률적 생성 과정을 통해 표현의 다양성을 확보하되, 사전 정보로 규제함으로써 과잉 표현을 규제하고 일반화를 도모하는 오토인코더 기반 협업필터링 모형          Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T.  (2018, April).  Variational autoencoders for collaborative filtering.  In Proceedings of the 2018 world wide web conference (pp. 689-698).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item implicit feedback matrix  $f(\\cdot)$: encoder networks  $g(\\cdot)$: decoder networksHow to Modeling      Bayesian Framework                  $Q$ is approx. dist. of latent preference vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u} \\sim \\mathcal{N}(\\mu_{u}, \\text{diag}(\\sigma_{u}^{2}))  \\end{aligned}\\]                  $\\mu_{u}, \\text{diag}(\\sigma_{u}^{2})$ is inferred by encoder networks $f(\\cdot)$                            $\\Pi$ is prior dist. of latent preference vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u} \\sim \\mathcal{N}(0, \\mathbf{I})  \\end{aligned}\\]                    $P$ is likelihood:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u} \\sim \\text{Multinomial}(\\vert \\mathcal{R}_{u}^{+} \\vert, \\delta[g(\\overrightarrow{\\mathbf{z}}_{u})])  \\end{aligned}\\]                  \\(\\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u}\\) is generated by decoder networks \\(g(\\cdot)\\)          to reflect the competitive relationship between items when the user selects an item,                          likelihood is multinomial dist., not $n$ independent binomial dist.              $\\delta(\\cdot)$ is softmax function, not sigmoid function                                                Objective Function is ELBO:\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max{\\mathbb{E}_{\\mathbf{Z} \\mid \\mathbf{Y} \\sim Q}[\\log{p(\\overrightarrow{\\mathbf{y}}_{u} \\mid \\overrightarrow{\\mathbf{z}}_{u})}] - \\beta \\cdot KL[Q(\\overrightarrow{\\mathbf{z}}_{u}) \\Vert \\Pi(\\overrightarrow{\\mathbf{z}}_{u})]}  \\end{aligned}\\]  "
  },
  
  {
    "title": "User Free Models",
    "url": "/posts/User_Free_Models/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, MLP, Attention Mechanism",
    "date": "2024-06-05 00:00:00 +0900",
    





    
    "snippet": "SLIM  문제 의식: 효율성과 정확성의 Trade-off          이웃 기반 협업 필터링(Neighborhood-based Collaborative Filtering): 유사도 기반 휴리스틱 함수를 통해 예측하므로 계산 효율성은 높지만 아이템 간 관계 학습이 불가하여 추천 정확도가 낮음      잠재요인 모형(Latent Factor Mode...",
    "content": "SLIM  문제 의식: 효율성과 정확성의 Trade-off          이웃 기반 협업 필터링(Neighborhood-based Collaborative Filtering): 유사도 기반 휴리스틱 함수를 통해 예측하므로 계산 효율성은 높지만 아이템 간 관계 학습이 불가하여 추천 정확도가 낮음      잠재요인 모형(Latent Factor Model): 사용자, 아이템 간 관계 학습을 수반하므로 추천 정확도는 높지만 계산 비용이 발생하여 실시간 추천에 부적합        SLIM(Sparse LInear Methods): 아이템 간 유사도를 선형 회귀계수 행렬로 학습하고 이를 기반으로 예측을 수행하는 선형 회귀 모형          Ning, X., &amp; Karypis, G.  (2011, December).  Slim: Sparse linear methods for top-n recommender systems.  In 2011 IEEE 11th international conference on data mining (pp. 497-506).  IEEE.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\mathbf{W} \\in \\mathbb{R}^{N \\times N}$: sparse aggregation coefficient matrix  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      Linear Regression:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\mathbf{W}_{i} \\cdot \\mathbf{Y}_{u*}\\\\  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{w_{i,j} \\cdot y_{u,j}}  \\end{aligned}\\]        Objective Function:\\[\\begin{gathered}  \\hat{\\mathbf{W}}  = \\text{arg} \\min{\\frac{1}{2} \\Vert \\mathbf{Y} - \\mathbf{Y}\\mathbf{W}\\Vert_{F}^{2} + \\frac{\\beta}{2} \\Vert \\mathbf{W} \\Vert_{F}^{2} + \\lambda \\Vert \\mathbf{W} \\Vert_{1}}\\\\  \\text{subject to} \\quad  \\begin{aligned}  \\mathbf{W} &amp;\\ge 0\\\\  \\text{diag}(\\mathbf{W})&amp;=0  \\end{aligned}  \\end{gathered}\\]          \\(\\Vert \\mathbf{Y} - \\mathbf{Y}\\mathbf{W}\\Vert_{F}^{2}\\): Reconstruction Loss      \\(\\Vert \\mathbf{W} \\Vert_{F}^{2}\\): L2 Norm Regulation to Prevent Overfitting      \\(\\Vert \\mathbf{W} \\Vert_{1}\\): L1 Norm Regulation to Induce Sparsity      FISM  문제 의식: SLIM 의 사용자 선호 구성 방식          SLIM 은 아이템 간 유사도를 휴리스틱 함수가 아니라 학습을 통해 도출한다는 점에서 아이템 기반 협업 필터링의 정확도 문제를 개선함      하지만 사용자의 타깃 아이템에 대한 선호 구성 시 히스토리를 구성하는 아이템들이 서로 독립적으로 기여한다고 가정함      이 독립성 가정은 사용자 선호가 과거 경험의 단순 집계로 환원될 수 있다는 잘못된 전제에 기반함      즉, 사용자 선호가 히스토리 아이템들의 집합적 구성과 그 내부의 상호작용 구조에 의해 형성된다는 점을 간과함        FISM(Factored Item Similarity Models): 사용자 선호를 히스토리 아이템들의 집합적 평균으로 구성하는 아이템 기반 협업 필터링 모형          Kabbur, S., Ning, X., &amp; Karypis, G.  (2013, August).  Fism: factored item similarity models for top-n recommender systems.  In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 659-667).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: target item idx  $j=1,2,\\cdots,N$: history item idx  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vectorHow to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(j)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        History Item Aggregation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\frac{1}{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert^{\\beta}}\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\overrightarrow{\\mathbf{q}}_{j}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$            Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{p}}_{i}  \\end{aligned}\\]  NAIS  문제 의식: FISM 의 히스토리 아이템 집계 방식          FISM 은 사용자 선호 표현 시 히스토리 아이템 간 기여도 차이를 간과하여 히스토리 아이템들을 단순 평균함        NAIS(Neural Attentive Item Similarity Model): 사용자 선호를 히스토리 아이템으로써 구성하되, 개별 아이템의 기여도에 따라 가중 평균하는 아이템 기반 협업 필터링 모형          He, X., He, Z., Song, J., Liu, Z., Jiang, Y. G., &amp; Chua, T. S.  (2018).  NAIS: Neural attentive item similarity model for recommendation.  IEEE Transactions on Knowledge and Data Engineering, 30(12), 2354-2366.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: target item idx  $j=1,2,\\cdots,N$: history item idx  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vectorHow to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(i)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(j)  \\end{aligned}\\]        History Item Aggregation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{ATTN}(\\overrightarrow{\\mathbf{p}}_{i}, \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:], \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{p}}_{i}  \\end{aligned}\\]  How to Attention      Attention Weight is Calculated by Smoothed Softmax:\\[\\begin{aligned}  \\alpha_{i,j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})}}{\\left[\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})}}\\right]^{\\beta}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$            Attention Score Function:                  Concatenation:\\[\\begin{aligned}  f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})  &amp;= \\overrightarrow{\\mathbf{w}} \\cdot \\text{ReLU}(\\mathbf{W}[\\overrightarrow{\\mathbf{p}}_{i} \\oplus \\overrightarrow{\\mathbf{q}}_{j}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]                    Element-wise Product:\\[\\begin{aligned}  f(\\overrightarrow{\\mathbf{p}}_{i},\\overrightarrow{\\mathbf{q}}_{j})  &amp;= \\overrightarrow{\\mathbf{w}} \\cdot \\text{ReLU}(\\mathbf{W}[\\overrightarrow{\\mathbf{p}}_{i} \\odot \\overrightarrow{\\mathbf{q}}_{j}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]            "
  },
  
  {
    "title": "Latent Factor Model with Attention Mechanism",
    "url": "/posts/LFM_ATTN/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP, Attention Mechanism",
    "date": "2024-05-22 00:00:00 +0900",
    





    
    "snippet": "DACR: History Embedding with ATTN  문제 의식: Implicit Feedback Problem          DeepCF                  표현 학습(Representation Learning): 사용자와 아이템 간 선형 관계를 바탕으로 저차원 잠재요인 공간을 효율적으로 구성          매칭 함수 학습(M...",
    "content": "DACR: History Embedding with ATTN  문제 의식: Implicit Feedback Problem          DeepCF                  표현 학습(Representation Learning): 사용자와 아이템 간 선형 관계를 바탕으로 저차원 잠재요인 공간을 효율적으로 구성          매칭 함수 학습(Matching Function Learning): 다양한 매칭 함수를 근사하여 사용자와 아이템 간 비선형 상호작용 포착                    Implicit Feedback Problem                  관측치의 불완전성(Observation Incompleteness): 관측과 미관측이 반드시 선호와 비선호를 의미하지 않음          선호의 비가시성(Hidden Signal): 관측치의 불완전성으로 인하여 선호의 정도나 의도를 포착하기 어려움          즉, 암시적 피드백 데이터는 행동 매칭 데이터이기에 선호 매칭에 사용하기 위해서는 내재된 선호 정보를 부각하고 잡음을 여과하는 절차가 필요함                      DACR(Deep Collaborative Recommendation Algorithm Based on Attention Mechanism): 사용자, 아이템 표현 및 그 결합 표현에 어텐션 메커니즘(Attention Mechanism)을 적용하여 차원별 가중치를 명시적으로 설계함으로써 입력 중 집중할(Focus) 정보를 선별하여 강조하는 앙상블 모형          Cui, C., Qin, J., &amp; Ren, Q.  (2022).  Deep collaborative recommendation algorithm based on attention mechanism.  Applied Sciences, 12(20), 10594.        Components          ARL: Attention Representation Learning      AML: Attnetion Matching Function Learning      DACR: ARL &amp; AML Emsemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$  $\\delta$: softmax function  $\\sigma$: sigmoid functionHow to Modeling      DACR is ARL &amp; AML Emsemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ARL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AML)}}])  \\end{aligned}\\]  ARL      Linear Transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]          $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{D}$      $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{D}$            Attention Weight:\\[\\begin{aligned}  \\alpha_{u}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{p}}_{u} + \\overrightarrow{\\mathbf{b}})\\\\  \\alpha_{i}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{q}}_{i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        Representation Learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{p}}_{u} \\oplus [\\alpha_{u} \\odot \\overrightarrow{\\mathbf{p}}_{u}]\\right)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{q}}_{i} \\oplus [\\alpha_{i} \\odot \\overrightarrow{\\mathbf{q}}_{i}]\\right)  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        if use ARL as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  AML      History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Vector Concatenation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i}  \\end{aligned}\\]        Attention Weight:\\[\\begin{aligned}  \\alpha_{u,i}  &amp;= \\delta(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{x}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        Matching Function Learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}\\left(\\overrightarrow{\\mathbf{x}}_{u,i} \\oplus [\\alpha_{u,i} \\odot \\overrightarrow{\\mathbf{x}}_{u,i}]\\right)  \\end{aligned}\\]        if use AML as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Latent Factor Models with CNN",
    "url": "/posts/LFM_CNN/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP, CNN",
    "date": "2024-05-08 00:00:00 +0900",
    





    
    "snippet": "ConvNCF: ID Embedding with CNN  문제 의식: NeuMF 의 다차원 고차 상호작용 포착 한계점          GMF 는 동일 차원 상호작용만 포착하므로 다차원 고차 상호작용 반영 불가      NCF 는 다양한 매칭 함수 근사 가능하나 고차원 입력 시 파라미터 수 폭증        ConvNCF: 외적과 합성곱 신경망을 활용하...",
    "content": "ConvNCF: ID Embedding with CNN  문제 의식: NeuMF 의 다차원 고차 상호작용 포착 한계점          GMF 는 동일 차원 상호작용만 포착하므로 다차원 고차 상호작용 반영 불가      NCF 는 다양한 매칭 함수 근사 가능하나 고차원 입력 시 파라미터 수 폭증        ConvNCF: 외적과 합성곱 신경망을 활용하여 다차원 간 고차 상호작용을 포착하는 단일 모형          He, X., Du, X., Wang, X., Tian, F., Tang, J., &amp; Chua, T. S.  (2018).  Outer product-based neural collaborative filtering.  arXiv preprint arXiv:1808.03912.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\mathbf{E}_{u,i} \\in \\mathbb{R}^{K \\times K}$: interaction map of user $u$ and item $i$  $\\overrightarrow{\\mathbf{x}}_{u,i}$: interdimensional high-level interaction vector of user $u$ and item $i$  $\\overrightarrow{\\mathbf{z}}_{u,i} \\in \\mathbb{R}^{K}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u) \\in \\mathbb{R}^{K}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i) \\in \\mathbb{R}^{K}  \\end{aligned}\\]        Outer product of user $u$ and item $i$:\\[\\begin{aligned}  \\mathbf{E}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\otimes \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        Capture interdimensional high-level interaction of user $u$ and item $i$:    \\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u,i}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{u,i})\\right]  \\end{aligned}\\]          \\(\\mathcal{W} \\in \\mathbb{R}^{2 \\times 2}\\): Kernel Window Dimension      The number of Filters per Kernel Size is 32      Dimension of Feature Map is reduced $K \\times K, K/2 \\times K/2, \\cdots, 1 \\times 1$            Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u,i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  COMET: Dual Embedding with CNN  문제 의식: 히스토리의 다차원 고차 상호작용 구조 모델링 부재          아이디 임베딩(ID Embedding): 맥락 정보 없이 목표 사용자-아이템 쌍 상호작용만을 반영함      히스토리 임베딩(History Embedding): 맥락 정보를 반영하나 맥락 내 구조적 관계 정보를 모델링하지 않음      실제 추천은 사용자의 히스토리 아이템 간 상호작용과, 아이템에 반응한 사용자 간 집합의 구조적 맥락에서 발생함        COMET(COnvolutional diMEnsion inTeraction): 히스토리 간 다차원 고차 상호작용 구조를 반영한 듀얼 임베딩(Dual-Embedding) 기반 잠재요인 모형          Lin, Z., Feng, L., Guo, X., Zhang, Y., Yin, R., Kwoh, C. K., &amp; Xu, C.  (2023).  Comet: Convolutional dimension interaction for collaborative filtering.  ACM Transactions on Intelligent Systems and Technology, 14(4), 1-18.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user id embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item id embedding vector  \\(\\mathbf{E}_{u} \\in \\mathbb{R}^{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert \\times K}\\): history embedding map of user $u$  \\(\\mathbf{E}_{i} \\in \\mathbb{R}^{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert \\times K}\\): history embedding map of item $i$  $\\overrightarrow{\\mathbf{x}}_{u}$: history interaction vector of user $u$  $\\overrightarrow{\\mathbf{x}}_{i}$: history interaction vector of item $i$  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Interaction Modeling:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\cdots (\\left\\{\\overrightarrow{\\mathbf{q}}_{j} \\mid \\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}\\right\\})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\cdots (\\left\\{\\overrightarrow{\\mathbf{p}}_{v} \\mid \\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}\\right\\})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\left[(\\overrightarrow{\\mathbf{p}}_{u} + \\overrightarrow{\\mathbf{u}}_{u}) \\odot (\\overrightarrow{\\mathbf{q}}_{i} + \\overrightarrow{\\mathbf{v}}_{i})\\right])  \\end{aligned}\\]  Interaction Modeling      History Embedding Maps:\\[\\begin{aligned}  \\mathbf{E}_{u}  = \\begin{bmatrix}  \\overrightarrow{\\mathbf{q}}_{1 \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}\\\\  \\overrightarrow{\\mathbf{q}}_{2 \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}\\\\  \\vdots\\\\  \\overrightarrow{\\mathbf{q}}_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}  \\end{bmatrix},\\quad  \\mathbf{E}_{i}  = \\begin{bmatrix}  \\overrightarrow{\\mathbf{p}}_{1 \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}\\\\  \\overrightarrow{\\mathbf{p}}_{2 \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}\\\\  \\vdots\\\\  \\overrightarrow{\\mathbf{p}}_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}  \\end{bmatrix}  \\end{aligned}\\]        CNN:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{u})\\right]\\\\  \\overrightarrow{\\mathbf{x}}_{i}  &amp;= \\text{Flatten}\\left[\\text{Conv}_{\\text{ReLU}}(\\mathbf{E}_{i})\\right]  \\end{aligned}\\]          \\(\\mathcal{W} \\in \\mathbb{R}^{\\vert \\mathcal{R}^{+} \\setminus \\{u,i\\} \\vert \\times H}\\): Kernel Window Dimension                  \\(H \\in \\{1,8,32,128\\}\\): Kernel Window Size          The number of Filters per Kernel Size is 8          Max Pooling Applied                          Generate History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Distance Embedding based Latent Factor Model",
    "url": "/posts/Dist_Embedding/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP",
    "date": "2024-04-24 00:00:00 +0900",
    





    
    "snippet": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수...",
    "content": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수 학습(Matching Function Learning)          사용자-아이템 쌍을 입력으로 하여 매칭 함수를 직접 학습하는 방법      복잡하고 비선형적인 매칭 함수를 근사할 수 있음      DDFL      문제 의식: 내적(Dot Product) 혹은 코사인 유사도(Cosine Similarity)를 매칭 함수로 사용하여 학습된 사용자, 아이템 표현은 삼각 부등식(Triangular Inequality)을 만족하기 어려움    삼각 부등식(Triangular Inequality)                  세 점 사이의 거리에 대한 제한 조건으로서, $A$ 와 $C$ 사이 거리는 $A$ 에서 $B$, 그리고 $B$ 에서 $C$ 로 우회하는 거리보다 크거나 같아야 함\\[\\begin{aligned}  \\text{d}\\left[A,C\\right] \\le \\text{d}\\left[A,B\\right] + \\text{d}\\left[B,C\\right]  \\end{aligned}\\]                    사용자 $u$ 가 아이템 $i$ 를 직접적으로 선호하는 정도는, 사용자 $u$ 가 아이템 $j$ 를 선호하는 정도 및 아이템 $i$ 와 $j$ 간 유사한 정도의 합보다 작거나 같아야 함\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}  \\le \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{j}  + \\overrightarrow{\\mathbf{q}}_{i} \\cdot \\overrightarrow{\\mathbf{q}}_{j}  \\end{aligned}\\]              DDFL(Deep Dual Function Learning-based Model) : 거리 함수 학습 모듈과 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          Shah, S. T. U., Li, J., Guo, Z., Li, G., &amp; Zhou, Q.  (2020, September).  DDFL: a deep dual function learning-based model for recommender systems.  In International Conference on Database Systems for Advanced Applications (pp. 590-606).  Cham: Springer International Publishing.        Components          MeFL: Metric Function Learning      MaFL: Matching Function Learning      DDFL: MeFL &amp; MaFL Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector @ MeFL  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector @ MeFL  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector @ MaFL  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector @ MaFL  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      DDFL is MeFL &amp; MaFL Ensemble:                  predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(MeFL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(MaFL)}})  \\end{aligned}\\]                    final matching score of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]            MeFL      Conversion Transformation:\\[\\begin{aligned}  x_{u,i}  &amp;=\\alpha\\left(1-y_{u,i}\\right)  \\end{aligned}\\]          $y_{u,i} \\in \\mathbf{Y}$ is Implicit Feedback      $\\alpha$ is Distance Factor            History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{X}_{u*}\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{X}_{*i}  \\end{aligned}\\]        Calculate Euclidean Distance:\\[\\begin{aligned}  \\text{dist}[\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{q}}_{i}]  &amp;= \\Vert \\overrightarrow{\\mathbf{p}}_{u} - \\overrightarrow{\\mathbf{q}}_{i} \\Vert_{2}\\\\  &amp;= \\sqrt{\\sum_{k=1}^{K}{(p_{k}^{(u)} - q_{k}^{(i)})^{2}}}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\text{dist}[\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{q}}_{i}])  \\end{aligned}\\]        if use MeFL as a single prediction module:                  compute distance:\\[\\begin{aligned}  \\hat{d}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]                    convert distance to matching score:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= 1 - \\frac{\\hat{d}_{u,i}}{\\alpha}  \\end{aligned}\\]            MaFL      History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        if use MaFL as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "Semi-Dual Embedding based Latent Factor Model",
    "url": "/posts/Semi_Dual_Embedding/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, MLP, Attention Mechanism",
    "date": "2024-04-10 00:00:00 +0900",
    





    
    "snippet": "DRNet  문제 의식          기존 협업 필터링이 모델링하는 관계 유형                  잠재요인 모형(Latent Factor Model): 사용자-아이템 관계 모델링, 개인화 추천 성능 우수 (ex. NCF)          아이템 기반 협업 필터링(User Free Model): 아이템-아이템 관계 모델링, 데이터 희소성 강...",
    "content": "DRNet  문제 의식          기존 협업 필터링이 모델링하는 관계 유형                  잠재요인 모형(Latent Factor Model): 사용자-아이템 관계 모델링, 개인화 추천 성능 우수 (ex. NCF)          아이템 기반 협업 필터링(User Free Model): 아이템-아이템 관계 모델링, 데이터 희소성 강건 (ex. SLIM, FISM)                    어텐션 기반 히스토리 아이템 집계 방식 (ex. NAIS)                  사용자가 과거에 더 선호한 아이템일수록 새로운 아이템 선택에 더 큰 영향력을 행사함          사용자의 선호 정도에 기반하여 집중도를 차등 부여하여 집계할 필요가 있음                      DRNet(Dual Relation Net-work) : 사용자-아이템 매칭 함수와 아이템-아이템 매칭 함수를 병렬 학습하는 모형          Ji, D., Xiang, Z., &amp; Li, Y.  (2020).  Dual relations network for collaborative filtering.  IEEE Access, 8, 109747-109757.        Components          Affection Network: Modeling User-Item Relation      Association Network: Modeling Item-Item Relation      Dual-Relation Network: Affection Network &amp; Association Network Combination      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user id embedding vector @ affection network  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item id embedding vector @ affection network  $\\overrightarrow{\\mathbf{p}}_{i} \\in \\mathbb{R}^{K}$: target item id embedding vector @ association network  $\\overrightarrow{\\mathbf{q}}_{j} \\in \\mathbb{R}^{K}$: history item id embedding vector @ association network  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      Dual-Relation Network:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma\\left(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AFFECT)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ASSO)}}]\\right)  \\end{aligned}\\]  Affection Network      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]  Association Network      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{i}  &amp;= \\text{Emb}(i)\\\\  \\overrightarrow{\\mathbf{q}}_{j}  &amp;= \\text{Emb}(j)  \\end{aligned}\\]        Global Item Vector of User $u$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\text{ATTN}(\\overrightarrow{\\mathbf{h}},\\text{Affection}(u,\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}), \\mathbf{Q}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{x}}_{u} \\odot \\overrightarrow{\\mathbf{p}}_{i})  \\end{aligned}\\]  How to Attention      Query Vector is Global Context Vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}  \\end{aligned}\\]        Key Vector is Generated by Affection Network:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(AFFECT)}}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        Global Item Vector of User $u$ is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{u}  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\alpha_{u,j} \\cdot \\overrightarrow{\\mathbf{q}}_{j}}  \\end{aligned}\\]        Attention Weight is Calculated by Smoothed Softmax:\\[\\begin{aligned}  \\alpha_{u,j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}},\\overrightarrow{\\mathbf{z}}_{u,j}^{\\text{(AFFECT)}})}}{\\left[\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}},\\overrightarrow{\\mathbf{z}}_{u,j}^{\\text{(AFFECT)}})}}\\right]^{\\beta}}  \\end{aligned}\\]          $0 &lt; \\beta \\le 1$: Smoothing Factor            Attention Score Function is Dot Product:\\[\\begin{aligned}  f(q,k)  &amp;= q \\cdot k  \\end{aligned}\\]  "
  },
  
  {
    "title": "Dual Embedding based Latent Factor Models",
    "url": "/posts/Dual_Embedding/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP",
    "date": "2024-03-27 00:00:00 +0900",
    





    
    "snippet": "Embedding Type  아이디 임베딩(ID Embedding)          Embedding user and item identifiers into a low-dimensional vector space      사용자의 고유한 선호 정보나 아이템의 고유한 특징 정보를 반영한 표현을 도출함      사용자와 아이템의 맥락 정보가 부족하여 행동...",
    "content": "Embedding Type  아이디 임베딩(ID Embedding)          Embedding user and item identifiers into a low-dimensional vector space      사용자의 고유한 선호 정보나 아이템의 고유한 특징 정보를 반영한 표현을 도출함      사용자와 아이템의 맥락 정보가 부족하여 행동 패턴이나 구매 패턴을 반영하기 어려움        히스토리 임베딩(History Embedding)          Generate each user and item expressions based on past interaction history      사용자의 행동 패턴이나 아이템의 구매 패턴을 반영한 표현을 도출함      사용자와 아이템을 상호간에 의존하여 표현하므로 고유 정보를 보존하기 어려움      DELF  문제 의식: 아이디 임베딩(ID Embedding)과 히스토리 임베딩(History Embedding)의 상호 보완적 관계          아이디 임베딩은 고유 정보를 보존한 표현을 생성하는 데 강점      히스토리 임베딩은 맥락 정보를 반영한 표현을 생성하는 데 강점        DELF(Dual Embedding based Deep Latent Factor Model): 사용자와 아이템의 아이디 임베딩과 히스토리 임베딩을 조합하여 다양한 매칭 함수를 병렬 학습하는 모형          Cheng, W., Shen, Y., Zhu, Y., &amp; Huang, L.  (2018, July).  DELF: A dual-embedding based deep latent factor model for recommendation.  In IJCAI (Vol. 18, pp. 3329-3335).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user ID embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item ID embedding vector  $\\overrightarrow{\\mathbf{m}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{n}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\text{ATTN}(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}}, \\mathbf{H}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:], \\mathbf{Y}[\\forall j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\},:])\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\text{ATTN}(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}}, \\mathbf{H}[\\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\},:], \\mathbf{X}[\\forall v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\},:])  \\end{aligned}\\]        Pairwise Neural Interaction Layers:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}^{(1)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(2)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{m}}_{u} \\oplus \\overrightarrow{\\mathbf{n}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(3)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{n}}_{i})\\\\  \\overrightarrow{\\mathbf{z}}_{u,i}^{(4)}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{m}}_{u} \\oplus \\overrightarrow{\\mathbf{q}}_{i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{(1)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(2)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(3)} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{(4)}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  How to Attention      Another ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}_{v}  &amp;=\\text{Emb}(v)\\\\  \\overrightarrow{\\mathbf{y}}_{j}  &amp;=\\text{Emb}(j)  \\end{aligned}\\]        Query Vector is Global Context Vector:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}^{\\text{(user)}},  \\quad  \\overrightarrow{\\mathbf{h}}^{\\text{(item)}}  \\end{aligned}\\]        Key Vector is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{h}}_{v}  &amp;= \\text{tanh}(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{x}}_{v} + \\overrightarrow{\\mathbf{b}})\\\\  \\overrightarrow{\\mathbf{h}}_{j}  &amp;= \\text{tanh}(\\mathbf{W} \\cdot \\overrightarrow{\\mathbf{y}}_{j} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]        History Embedding Vector is Generated by:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;= \\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\alpha_{j} \\cdot \\overrightarrow{\\mathbf{y}}_{j}}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;= \\sum_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}{\\alpha_{v} \\cdot \\overrightarrow{\\mathbf{x}}_{v}}\\\\  \\end{aligned}\\]        Attention Weight is Calculated by Softmax:\\[\\begin{aligned}  \\alpha_{j}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}},\\overrightarrow{\\mathbf{h}}_{j})}}{\\sum_{j \\in \\mathcal{R}_{u}^{+} \\setminus \\{i\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(user)}},\\overrightarrow{\\mathbf{h}}_{j})}}}\\\\  \\alpha_{v}  &amp;= \\frac{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}},\\overrightarrow{\\mathbf{h}}_{v})}}{\\sum_{v \\in \\mathcal{R}_{i}^{+} \\setminus \\{u\\}}{\\exp{f(\\overrightarrow{\\mathbf{h}}^{\\text{(item)}},\\overrightarrow{\\mathbf{h}}_{v})}}}  \\end{aligned}\\]        Attention Score Function is Dot Product:\\[\\begin{aligned}  f(q,k)  &amp;= q \\cdot k  \\end{aligned}\\]  DNCF  문제 의식: 아이디 임베딩(ID Embedding)과 히스토리 임베딩(History Embedding)의 분리로 인한 표현력의 제약          DELF 는 아이디 임베딩과 히스토리 임베딩을 분리하여 매칭 함수 학습을 수행함      각 표현이 서로의 표현력을 보완하거나 강화하지 못함        DNMF(Deep Neural Matrix Factorization): 아이디 임베딩과 히스토리 임베딩을 결합한 하나의 표현을 생성하여 NeuMF 의 표현력을 강화하는 앙상블 모형          He, G., Zhao, D., &amp; Ding, L.  (2021).  Dual-embedding based neural collaborative filtering for recommender systems.  arXiv preprint arXiv:2102.02549.        Components          DGMF: Dual-Embedding based Generalized Matrix Factorization      DMLP: Dual-Embedding based Multi-Layer Perceptron      DNMF: DGMF &amp; DMLP Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbb{R}^{K}$: user ID embedding vector  $\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbb{R}^{K}$: item ID embedding vector  $\\overrightarrow{\\mathbf{m}}_{u} \\in \\mathbb{R}^{K}$: user history embedding vector  $\\overrightarrow{\\mathbf{n}}_{i} \\in \\mathbb{R}^{K}$: item history embedding vector  $\\overrightarrow{\\mathbf{u}}_{u}$: user embedding combination vector  $\\overrightarrow{\\mathbf{v}}_{i}$: item embedding combination vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      DNMF is DGMF &amp; DMLP Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(DGMF)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(DMLP)}}] + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  DGMF      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Embedding Combination:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Agg}(\\overrightarrow{\\mathbf{p}}_{u}, \\overrightarrow{\\mathbf{m}}_{u})\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Agg}(\\overrightarrow{\\mathbf{q}}_{i}, \\overrightarrow{\\mathbf{n}}_{i})  \\end{aligned}\\]          element-wise sum      element-wise mean      concatenation      attention            Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        If use DGMF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  DMLP      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;=\\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;=\\text{Emb}(i)  \\end{aligned}\\]        History Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{m}}_{u}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{u}^{+} \\setminus \\{i\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{u*}\\\\  \\overrightarrow{\\mathbf{n}}_{i}  &amp;=\\frac{1}{\\sqrt{\\vert \\mathcal{R}_{i}^{+} \\setminus \\{u\\} \\vert}}\\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        Embedding Combination:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\overrightarrow{\\mathbf{p}}_{u} \\oplus \\overrightarrow{\\mathbf{m}}_{u}\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\overrightarrow{\\mathbf{q}}_{i} \\oplus \\overrightarrow{\\mathbf{n}}_{i}  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        If use DMLP as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i} + \\overrightarrow{\\mathbf{b}})  \\end{aligned}\\]  "
  },
  
  {
    "title": "History Embedding based Latent Factor Models",
    "url": "/posts/Hist_Embedding/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP",
    "date": "2024-03-13 00:00:00 +0900",
    





    
    "snippet": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수...",
    "content": "Learning Objectives  표현 학습(Representation Learning)          사용자와 아이템을 공동의 잠재요인 공간에 표현하는 방법      매칭 강도 추정 시 내적(Inner Product) 등 선형 유사도 함수를 적용함      저차원(Low-rank) 유사도 구조를 효율적으로 포착할 수 있음        매칭 함수 학습(Matching Function Learning)          사용자-아이템 쌍을 입력으로 하여 매칭 함수를 직접 학습하는 방법      복잡하고 비선형적인 매칭 함수를 근사할 수 있음      DMF  문제 의식: 아이디 임베딩(ID Embedding) 입력 표현의 한계점          아이디 임베딩 방식은 초기 표현(식별자)의 정보량이 부족하여 학습이 느리거나 성능이 제한됨        DMF(Deep Matrix Factorization): 사용자-아이템 상호작용 행렬과 그 전치 행렬을 초기 표현으로 사용하여 저차원 표현 학습을 수행하는 모형          Xue, H. J., Dai, X., Zhang, J., Huang, S., &amp; Chen, J.  (2017, August).  Deep matrix factorization models for recommender systems.  In IJCAI (Vol. 17, pp. 3203-3209).      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\cos(\\overrightarrow{\\mathbf{u}}_{u}, \\overrightarrow{\\mathbf{v}}_{i})\\\\  &amp;= \\frac{\\overrightarrow{\\mathbf{u}}_{u} \\cdot \\overrightarrow{\\mathbf{v}}_{i}}{\\Vert \\overrightarrow{\\mathbf{u}}_{u} \\Vert \\cdot \\Vert \\overrightarrow{\\mathbf{v}}_{i} \\Vert}  \\end{aligned}\\]  DeepCF  문제 의식: 표현 학습 방식과 매칭 함수 학습 방식의 상호 보완적 관계          표현 학습은 저차원 유사도 구조를 포착하여 사용자, 아이템의 일반화된 표현을 도출하는 데 강점      매칭 함수 학습은 사용자와 아이템 간 복잡하고 비선형적인 상호작용 과정을 근사하는 데 강점        DeepCF: 표현 학습 모듈과 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          Deng, Z. H., Huang, L., Wang, C. D., Lai, J. H., &amp; Yu, P. S.  (2019, July).  Deepcf: A unified framework of representation learning and matching function learning in recommender system.  In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 61-68).        Components          CFNet-rl: Representation Learning      CFNet-ml: Matching Function Learning      CFNet: CFNet-rl &amp; CFNet-ml Ensemble      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      CFNet is CFNet-rl &amp; CFNet-ml Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(RL)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(ML)}}])  \\end{aligned}\\]  CFNet-rl      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        if use CFNet-rl as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  CFNet-ml      generate user latent factor vector through linear transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{u*}  \\end{aligned}\\]        generate user latent factor vector through linear transformation:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\mathbf{W} \\cdot \\mathbf{Y}_{*i}  \\end{aligned}\\]        predictive vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        if use CFNet-ml as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  J-NCF  문제 의식          아이디 임베딩(ID Embedding): 사용자와 아이템 표현을 무작위로 초기화한 후 매칭 함수 학습을 수행하므로 표현 학습이 미흡함 (ex. NCF)      히스토리 임베딩(History Embedding): 사용자-아이템 상호작용 행렬과 그 전치 행렬을 활용하여 표현 학습을 수행하나 매칭 함수는 선형 유사도 함수에 의존함 (ex. DMF)      앙상블(Ensemble): 표현 학습과 매칭 함수 학습을 분리하여 수행하므로 각 모듈이 서로의 학습을 보완하거나 강화하지 못함 (ex. CFNet)        J-NCF(Joint Neural Collaborative Filtering): 표현 학습과 매칭 함수 학습을 통합 훈련(Joint Training)하는 모형          Chen, W., Cai, F., Chen, H., &amp; Rijke, M. D.  (2019).  Joint neural collaborative filtering for recommender systems.  ACM Transactions on Information Systems (TOIS), 37(4), 1-30.      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$: user-item interaction matrix  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      user latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{u*})  \\end{aligned}\\]        item latent factor vector representation learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\mathbf{Y}_{*i})  \\end{aligned}\\]        matching function learning:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        Predict interaction probability of user $u$ and item $i$:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  "
  },
  
  {
    "title": "ID Embedding based Latent Factor Model",
    "url": "/posts/ID_Embedding/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering, Latent Factor Model, MLP",
    "date": "2024-02-29 00:00:00 +0900",
    





    
    "snippet": "How to aggregate  요소별 곱(Element-wise Product): 두 벡터 간 상응하는 차원끼리 곱셈하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 독립성 가정      사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 반영 표현      동일 차원 상호작용만 포...",
    "content": "How to aggregate  요소별 곱(Element-wise Product): 두 벡터 간 상응하는 차원끼리 곱셈하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 독립성 가정      사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 반영 표현      동일 차원 상호작용만 포착하므로 다차원 상호작용 반영 불가        벡터 결합(Vector Concatenation): 두 벡터를 결합하는 방법          사용자, 아이템 잠재요인 공간 독립 가정      사용자, 아이템 벡터 정보 보존 표현      모형이 사용자-아이템 쌍별(Pairwise) 상호작용(Interaction) 신호 직접 학습        외적(Outer Product): 두 벡터 간 외적하는 방법          사용자, 아이템 잠재요인 공간 동일 가정      잠재요인 차원 간 종속성 가정      그 대각성분은 요소별 곱셈에서 포착하는 동일 차원 간 상호작용 신호에 해당함      NeuMF  문제 의식: 내적(Inner Product) 기반 잠재요인 모형의 한계점          내적은 사용자와 아이템 간 동일 차원 상호작용을 포착하고 이를 단순 합산하는 방법임      사용자와 아이템 간 상호작용은 개별 차원에서 출력하는 신호 간에 경중이 있을 수 있음      사용자와 아이템 간 상호작용은 비선형적일 수 있고, 다차원 간에도 성립할 수 있음        NeuMF: 선형 매칭 함수 학습 모듈과 비선형 매칭 함수 학습 모듈을 병렬 학습하는 앙상블 모형          He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S.  (2017, April).  Neural collaborative filtering.  In Proceedings of the 26th international conference on world wide web (pp. 173-182).        Components          GMF(Generalized Matrix Factorization) : 요소별 곱 기반 선형 매칭 함수 모듈      NCF(Neural Collaborative Filtering) : 벡터 결합 및 다층 신경망(MLP) 기반 비선형 매칭 함수 학습 모듈      NeuMF(Neural Matrix Factorization) : GMF 와 NCF 의 예측 벡터(Predictive Vector)를 종합하여 예측을 수행하는 앙상블 모형      Notation  $u=1,2,\\cdots,M$: user idx  $i=1,2,\\cdots,N$: item idx  $\\overrightarrow{\\mathbf{u}}_{u} \\in \\mathbb{R}^{K}$: user latent factor vector  $\\overrightarrow{\\mathbf{v}}_{i} \\in \\mathbb{R}^{K}$: item latent factor vector  $\\overrightarrow{\\mathbf{z}}_{u,i} \\in \\mathbb{R}^{K}$: predictive vector of user $u$ and item $i$  $\\hat{y}_{u,i}$: interaction probability of user $u$ and item $i$How to Modeling      NeuMF is GMF &amp; NCF Ensemble\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot [\\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(GMF)}} \\oplus \\overrightarrow{\\mathbf{z}}_{u,i}^{\\text{(NCF)}}])  \\end{aligned}\\]  GMF      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\overrightarrow{\\mathbf{u}}_{u} \\odot \\overrightarrow{\\mathbf{v}}_{i}  \\end{aligned}\\]        If use GMF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  NCF      ID Embedding:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{u}}_{u}  &amp;= \\text{Emb}(u)\\\\  \\overrightarrow{\\mathbf{v}}_{i}  &amp;= \\text{Emb}(i)  \\end{aligned}\\]        Predictive Vector of user $u$ and item $i$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{u,i}  &amp;= \\text{MLP}_{\\text{ReLU}}(\\overrightarrow{\\mathbf{u}}_{u} \\oplus \\overrightarrow{\\mathbf{v}}_{i})  \\end{aligned}\\]        If use NCF as a single prediction module:\\[\\begin{aligned}  \\hat{y}_{u,i}  &amp;= \\sigma(\\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{z}}_{u,i})  \\end{aligned}\\]  Source  https://iq.opengenus.org/neural-collaborative-filtering/"
  },
  
  {
    "title": "Deep Learning based Collaborative Filtering",
    "url": "/posts/DL_based_CF/",
    "categories": "RECOMMENDER SYSTEM, 2.mlp based collaborative filtering",
    "tags": "AI Application, Recommender System, Collaborative Filtering",
    "date": "2024-02-15 00:00:00 +0900",
    





    
    "snippet": "MLP  Merit          User, Item Representation Learning      Matching function learning      Modeling nonlinear interactions between users and items      ID Embedding      ID Embedding: Embedding us...",
    "content": "MLP  Merit          User, Item Representation Learning      Matching function learning      Modeling nonlinear interactions between users and items      ID Embedding      ID Embedding: Embedding user and item identifiers into a low-dimensional vector space            NCF: ID Embedding based Latent Factor Model(Linear and Non-Linear Matching Function Ensemble)          He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S.  (2017, April).  Neural collaborative filtering.  In Proceedings of the 26th international conference on world wide web (pp. 173-182).      History Embedding      History Embedding: Generate each user and item expressions based on past interaction history              by aggregating the raw representations of one entity with which the another entity interacted      by reducing the dimensionality of the user-item interaction matrix and its transpose        DMF: History Embedding based Latent Factor Model(Representation Learning)          Xue, H. J., Dai, X., Zhang, J., Huang, S., &amp; Chen, J.  (2017, August).  Deep matrix factorization models for recommender systems.  In IJCAI (Vol. 17, pp. 3203-3209).        DeepCF: History Embedding based Latent Factor Model(Representation Learning and Matching Function Learning Ensemble)          Deng, Z. H., Huang, L., Wang, C. D., Lai, J. H., &amp; Yu, P. S.  (2019, July).  Deepcf: A unified framework of representation learning and matching function learning in recommender system.  In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 61-68).        J-NCF: History Embedding based Latent Factor Model(Representation Learning and Matching Function Learning Serial)          Chen, W., Cai, F., Chen, H., &amp; Rijke, M. D.  (2019).  Joint neural collaborative filtering for recommender systems.  ACM Transactions on Information Systems (TOIS), 37(4), 1-30.      Dual Embedding      Dual Embedding: Use both ID Embedding and History Embedding        DELF: Dual Embedding based Latent Factor Model(Ensemble with separate ID embedding and history embedding)          Cheng, W., Shen, Y., Zhu, Y., &amp; Huang, L.  (2018, July).  DELF: A dual-embedding based deep latent factor model for recommendation.  In IJCAI (Vol. 18, pp. 3329-3335).        DNCF: Dual Embedding based Latent Factor Model(Ensemble combining ID embedding and history embedding)          He, G., Zhao, D., &amp; Ding, L.  (2021).  Dual-embedding based neural collaborative filtering for recommender systems.  arXiv preprint arXiv:2102.02549.      Semi-Dual Embedding      Semi-Dual Embedding: Apply dual embedding to only one side of the user or item        DRNet: User Dual Embedding          Ji, D., Xiang, Z., &amp; Li, Y.  (2020).  Dual relations network for collaborative filtering.  IEEE Access, 8, 109747-109757.      Distance Embedding      Distance Embedding: Calculate Similarity through distance, not inner product, outer product, or concatenation        DDFL: Distance Embedding based Latent Factor Model          Shah, S. T. U., Li, J., Guo, Z., Li, G., &amp; Zhou, Q.  (2020, September).  DDFL: a deep dual function learning-based model for recommender systems.  In International Conference on Database Systems for Advanced Applications (pp. 590-606).  Cham: Springer International Publishing.      AutoEncoder  Merit          Restore the user-item interaction matrix      Dimensionality Reduction of the user-item interaction matrix      Feature Extraction        AutoRec: AutoEncoder Application          Sedhain, S., Menon, A. K., Sanner, S., &amp; Xie, L.  (2015, May).  Autorec: Autoencoders meet collaborative filtering.  In Proceedings of the 24th international conference on World Wide Web (pp. 111-112).        CDAE: Denoising AutoEncoder Application          Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M.  (2016, February).  Collaborative denoising auto-encoders for top-n recommender systems.  In Proceedings of the ninth ACM international conference on web search and data mining (pp. 153-162).        VACF: Variational AutoEncoder Application          Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T.  (2018, April).  Variational autoencoders for collaborative filtering.  In Proceedings of the 2018 world wide web conference (pp. 689-698).      CNN  Merit          Modeling interdimensional high-level interactions between users and items        ConvNCF: Modeling interdimensional high-level interactions          He, X., Du, X., Wang, X., Tian, F., Tang, J., &amp; Chua, T. S.  (2018).  Outer product-based neural collaborative filtering.  arXiv preprint arXiv:1808.03912.        COMET: Modeling interdimensional high-level interactions          Lin, Z., Feng, L., Guo, X., Zhang, Y., Yin, R., Kwoh, C. K., &amp; Xu, C.  (2023).  Comet: Convolutional dimension interaction for collaborative filtering.  ACM Transactions on Intelligent Systems and Technology, 14(4), 1-18.      Attention Mechanism  Merit          Select important information and remove noise        DACR: History Embedding based Latent Factor Model Assist.          Cui, C., Qin, J., &amp; Ren, Q.  (2022).  Deep collaborative recommendation algorithm based on attention mechanism.  Applied Sciences, 12(20), 10594.      "
  },
  
  {
    "title": "Collaborative Filtering",
    "url": "/posts/CF/",
    "categories": "RECOMMENDER SYSTEM, 1.recsys basic",
    "tags": "AI Application, Recommender System, Collaborative Filtering",
    "date": "2024-02-01 00:00:00 +0900",
    





    
    "snippet": "Collaborative Filtering      협업 필터링(Collaborative Filtering): 과거 여러 사용자들이 다양한 아이템에 대하여 평가 점수를 매긴 기록을 활용하여 아직 상호작용하지 않은 아이템에 대한 사용자의 평점을 추론하는 방법론              사용자 기반 협업 필터링(User-Based Collaborative ...",
    "content": "Collaborative Filtering      협업 필터링(Collaborative Filtering): 과거 여러 사용자들이 다양한 아이템에 대하여 평가 점수를 매긴 기록을 활용하여 아직 상호작용하지 않은 아이템에 대한 사용자의 평점을 추론하는 방법론              사용자 기반 협업 필터링(User-Based Collaborative Filtering): Identify like-minded users      아이템 기반 협업 필터링(Item-Based Collaborative Filtering): Identify buying patterns            사용자-아이템 상호작용 행렬(User-Item Interaction Matrix): $M$ 명의 사용자와 $N$ 가지 아이템 간의 상호작용을 수치적으로 표현한 행렬로서, 통상 행 벡터는 사용자를, 열 벡터는 아이템을 의미함    \\[r_{u,i} \\in \\mathbf{R} \\in \\mathbb{R}^{M \\times N}\\]          협업 필터링은 실질적으로 사용자-아이템 상호작용 행렬의 결측치(위 예시의 $-1$)를 채우는 방법이므로 행렬 완성 문제라고도 부름      Function      Bias-aware Collaborative Filtering Function\\[\\begin{aligned}  \\hat{r}_{u,i}  &amp;= \\mu + \\beta_{u} + \\beta_{i} + \\text{what}  \\end{aligned}\\]          $\\hat{r}_{u,i}$: 사용자 $u$ 의 아이템 $i$ 에 대한 평점 예측값      $\\mu$: 커뮤니티 평점 평균      $\\beta_{u}$: 사용자 $u$ 의 평균 평점 편차로서 사용자의 평점 척도      $\\beta_{i}$: 아이템 $i$ 의 평균 평점 편차로서 아이템의 인기도            What?          k-NN Algorithm(Memory based Collaborative Filtering)      Matrix Factorization Algorithm(Latent Factor Model)      Memory based Collaborative Filtering      메모리 기반 협업 필터링(Memory based Collaborative Filtering): (사용자 기반 협업 필터링 기준으로) 사용자가 상호작용하지 않은 아이템에 대한 선호를 예측함에 있어, 해당 아이템에 대한 피어 그룹의 선호를 유사도만큼 가중 평균하는 방법\\[\\begin{aligned}  \\text{what}  &amp;= \\frac{\\sum_{v \\in p(i \\mid u)}{\\text{sim}(u,v) \\cdot \\left(r_{v,i}-\\overline{r}_{v}\\right)}}{\\sum_{v \\in p(i \\mid u)}{\\vert \\text{sim}(u,v) \\vert}}  \\end{aligned}\\]          $v \\in p(i \\mid u)$ : 타깃 사용자 $u$ 의 $k$-Nearest Neighbor 중 타깃 아이템 $i$ 에 대하여 펑점을 매긴 사용자 집합으로서 피어 그룹(Peer Group)      How to Calculate $\\text{sim}(u,v)$      피어슨 상관계수(Pearson Correlation Coefficient): 사용자 벡터 간 평점 척도에 차이가 클 경우 유용함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;= \\frac{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{u,j}-\\overline{r}_{u}\\right)\\cdot\\left(r_{v,j}-\\overline{r}_{v}\\right)}}{\\sqrt{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{u,j}-\\overline{r}_{u}\\right)^{2}}}\\cdot\\sqrt{\\sum_{j \\in I_{u} \\cap I_{v}}{\\left(r_{v,j}-\\overline{r}_{v}\\right)^{2}}}}  \\end{aligned}\\]        코사인 유사도(Cosine Measure): 상호작용 데이터가 희박할 경우 유용함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;= \\frac{\\overrightarrow{\\mathbf{r}}_{u} \\cdot \\overrightarrow{\\mathbf{r}}_{v}}{\\Vert \\overrightarrow{\\mathbf{r}}_{u} \\Vert_{L2} \\cdot \\Vert \\overrightarrow{\\mathbf{r}}_{v} \\Vert_{L2}}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{r}}_{u} \\in \\mathbf{R}_{M \\times N}\\) : 사용자-아이템 상호작용 행렬의 행 벡터로서 사용자 벡터      Discount Methods      유사도 할인(Discounted Similarity): 두 사용자 간 공동으로 상호작용한 아이템 갯수($\\vert I_{u} \\cap I_{v}\\vert$)가 적을 경우, 유사도 값을 신뢰하기 어려우므로 이에 비례하여 유사도를 할인함\\[\\begin{aligned}  \\text{sim}(u,v)  &amp;\\leftarrow \\underbrace{\\frac{\\min{\\Big(\\vert I_{u} \\cap I_{v}\\vert, \\beta\\Big)}}{\\beta}}_{\\text{Discount Factor}} \\cdot \\text{sim}(u,v)  \\end{aligned}\\]        중요도 할인(Discounted Importance): 대중성 있는 아이템의 경우 사용자가 이미 경험했거나 인지하고 있지만 소비하지 아니하기로 결정한 아이템일 가능성이 높으므로, 대중성에 비례하여 아이템의 중요도(평점)을 할인함\\[\\begin{aligned}  \\overrightarrow{\\mathbf{r}}_{i}  &amp;\\leftarrow \\underbrace{\\log{\\frac{M}{m_{i}}}}_{\\text{Discount Factor}} \\cdot \\overrightarrow{\\mathbf{r}}_{i}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{r}}_{i} \\in \\mathbf{R}_{M \\times N}\\): 사용자-아이템 상호작용 행렬의 열 벡터로서 아이템 벡터      $M$: 총 사용자 수      $m_{i}$: 아이템 $i$ 에 대하여 상호작용한 사용자 수      Latent Factor Model      잠재요인 모형(Latent Factor Model) : 사용자 벡터와 아이템 벡터를 정체를 알 수 없는 $k$ 개의 특징 공간으로 사상하는 방법              협업 필터링에서 사용자는 아이템들에 대한 평점 집합으로(Row vector of the user-item interaction matrix), 아이템은 사용자들로부터 받은 평점 집합으로(Column vector of the user-item interaction matrix) 표현됨. 이처럼 사용자와 아이템은 각각 서로를 표현하는 벡터 공간 축이 되므로 직접 비교할 수 없음. 잠재요인 모형은 공통된 표현 수단인 잠재요인을 가정함으로써 이 문제를 해결함.      MF      Matrix Factorization: Original Latent Factor Model\\[\\begin{aligned}  \\text{what}  &amp;= \\overrightarrow{\\mathbf{p}}_{u} \\cdot \\overrightarrow{\\mathbf{q}}_{i}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{p}}_{u} \\in \\mathbf{P}_{M \\times K}\\): 사용자-잠재요인 벡터로서, 사용자 $u$ 의 선호 정보로 해석됨      \\(\\overrightarrow{\\mathbf{q}}_{i} \\in \\mathbf{Q}_{N \\times K}\\): 아이템-잠재요인 벡터로서, 아이템 $i$ 의 특징 정보로 해석됨            SVD++ : 특정 사용자가 특정 아이템에 대하여 매길 평점을 추론함에 있어, 목표 아이템 외에 사용자가 상호작용했던 다른 아이템들의 잠재요인 정보들을 함께 고려하는 방법\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u} \\leftarrow \\overrightarrow{\\mathbf{p}}_{u} + \\frac{\\sum_{j \\in R(u)}{\\overrightarrow{\\mathbf{q}}_{j}}}{\\sqrt{\\vert R(u)\\vert}}  \\end{aligned}\\]          \\(\\displaystyle\\frac{\\sum_{j \\in R(u)}{\\overrightarrow{\\mathbf{q}}_{j}}}{\\sqrt{\\vert R(u)\\vert}}\\): 사용자 $u$ 가 상호작용한 아이템 벡터의 평균으로서, $u$ 가 상호작용한 아이템들의 평균적인 특성      $R(u)$: 사용자 $u$ 가 상호작용한 아이템 집합      Optimization      Objective Function for Bias-unaware Matrix Factorization\\[\\begin{aligned}  \\hat{\\overrightarrow{\\mathbf{p}}}_{u}, \\hat{\\overrightarrow{\\mathbf{q}}}_{i}  &amp;= \\text{arg} \\min_{\\Theta}{\\mathcal{J}\\left(r_{u,i},\\hat{r}_{u,i}\\right) + \\lambda_{\\Theta}\\Vert \\Theta \\Vert^{2}}  \\end{aligned}\\]        교대최소제곱법(Alternating Least Square; ALS): $\\mathbf{P},\\mathbf{Q}$ 에 대하여 한 번에 하나의 행렬을 고정한 상태에서 다른 행렬을 최적화하는 과정을 번갈아 반복하여 수렴시키는 최적화 알고리즘으로서, 최소자승법을 활용하므로 각 사용자의 상호작용 데이터를 독립적으로 연산할 수 있어 병렬 처리에 적합함        Objective Function:\\[\\begin{aligned}  \\hat{\\overrightarrow{\\mathbf{p}}}_{u}  &amp;= \\text{arg} \\min_{\\mathbf{p}}{\\Vert \\overrightarrow{\\mathbf{r}}_{u} - \\mathbf{Q} \\cdot \\overrightarrow{\\mathbf{p}}_{u}\\Vert^{2} + \\lambda \\Vert \\overrightarrow{\\mathbf{p}}_{u} \\Vert^{2}}, \\quad \\text{where Q is fixed}\\\\  \\hat{\\overrightarrow{\\mathbf{q}}}_{i}  &amp;= \\text{arg} \\min_{\\mathbf{q}}{\\Vert \\overrightarrow{\\mathbf{r}}_{i} - \\mathbf{P} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\Vert^{2} + \\lambda \\Vert \\overrightarrow{\\mathbf{q}}_{i} \\Vert^{2}}, \\quad \\text{where P is fixed}  \\end{aligned}\\]        Optimality Condition:\\[\\begin{aligned}  \\frac{\\partial L}{\\partial \\overrightarrow{\\mathbf{p}}_{u}}  &amp;= -2\\mathbf{Q}^{T} \\cdot \\left(\\overrightarrow{\\mathbf{r}}_{u} - \\mathbf{Q} \\cdot \\overrightarrow{\\mathbf{p}}_{u}\\right) + 2\\lambda \\cdot \\overrightarrow{\\mathbf{p}}_{u} = 0\\\\  \\frac{\\partial L}{\\partial \\overrightarrow{\\mathbf{q}}_{i}}  &amp;= -2\\mathbf{P}^{T} \\cdot \\left(\\overrightarrow{\\mathbf{r}}_{i} - \\mathbf{P} \\cdot \\overrightarrow{\\mathbf{q}}_{i}\\right) + 2\\lambda \\cdot \\overrightarrow{\\mathbf{q}}_{i} = 0  \\end{aligned}\\]        Optimality Params:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{p}}_{u}  &amp;\\leftarrow \\left(\\mathbf{Q}^{T}\\mathbf{Q} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{Q}^{T}\\overrightarrow{\\mathbf{r}}_{u}\\\\  \\overrightarrow{\\mathbf{q}}_{i}  &amp;\\leftarrow \\left(\\mathbf{P}^{T}\\mathbf{P} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{P}^{T}\\overrightarrow{\\mathbf{r}}_{i}  \\end{aligned}\\]  Source  https://towardsdatascience.com/essentials-of-recommendation-engines-content-based-and-collaborative-filtering-31521c964922  https://buomsoo-kim.github.io/recommender%20systems/2020/09/25/Recommender-systems-collab-filtering-12.md/"
  },
  
  {
    "title": "What? Recommender System",
    "url": "/posts/What_RecSys/",
    "categories": "RECOMMENDER SYSTEM, 1.recsys basic",
    "tags": "AI Application, Recommender System, Metric",
    "date": "2024-01-18 00:00:00 +0900",
    





    
    "snippet": "What? RecSys      추천시스템(Recommender System): 정보과부하 문제(Information Overload Problem)를 해결하기 위한 개인화 정보 필터링 서비스(Personalized Information Filtering Service) 로서, 사용자에게 적합한 아이템을 제안함으로써 개인화된 경험을 제공하는 기술   ...",
    "content": "What? RecSys      추천시스템(Recommender System): 정보과부하 문제(Information Overload Problem)를 해결하기 위한 개인화 정보 필터링 서비스(Personalized Information Filtering Service) 로서, 사용자에게 적합한 아이템을 제안함으로써 개인화된 경험을 제공하는 기술          정보과부하 문제(Information Overload Problem): 인간이 처리할 수 있는 정보량 이상의 정보가 제공되어 오히려 개인의 정보 학습 및 의사결정이 방해 받는 현상            검색 엔진과 비교                                       Search Engine          Recommender System                                      사용자의 자세          능동성          수동성                          사용자 선호 파악          검색어          알고리즘                          사용자 선호 정보          검색 키워드          사용자 프로파일  아이템 프로파일  사용자 과거 행동                          사용자-아이템 상호작용 데이터(User-Item Interaction Data): 사용자의 아이템에 대한 선호 여부 및 정도를 포함하는 데이터          명시적 선호 데이터(Explicit Rating Data): 제시된 평가 시스템에 따라 직접 표출된 선호도      암시적 선호 데이터(Implicit Rating Data): 행동을 통해 우회로 표출된 선호도                  암시적 선호를 순서적으로 나타내는 경우, 이를 선호보다는 확신으로 해석함                    순서적 선호 데이터(Ordinal Rating Data): 정해진 숫자 또는 연속적인 범위로 표시된 선호도      단항 선호 데이터(Unary Rating Data): 상호작용이 있었다는 사실을 기록한 데이터      Filtering Methods      Most Popular(Best Seller)        내용 기반 필터링 기법(Content-based Filtering Method; CB): 타깃 사용자가 상호작용한 아이템의 콘텐츠를 분석하여 이와 유사한 콘텐츠를 보유하고 있는 아이템을 추천하는 방법          Show me more of the same what I’ve liked!                협업 필터링 기법(Collaborative Filtering Method; CF): 타깃 사용자의 구매 기록을 바탕으로 유사한 사용자 혹은 아이템을 탐색하여 추천하는 방법          Tell me what’s popular among my peers!                하이브리드 기법(Hybrid Method): 협업 필터링 기법과 내용 기반 필터링 기법을 결합하는 방법                                       Content-based Filtering          Collaborative Filtering                                      빅데이터          X          Rating Sparsity Problem                          사용자 의존성          X          Cold Start Problem                          아이템 커스터마이징          X          Grey Sheep Problem                          도메인 지식 필요성          Feature Engineering Problem          X                          도메인 종속성          X          CORS Problem  (Cross-Origin Resource Sharing)                          추천 결과의 참신성          X          Popularity Bias Problem                          추천 결과의 의외성          Trival Recommendation Problem          X                    Goal  추천시스템의 목적: 고객 가치 창출을 통한 기업 이윤 도모          가치 명제(Value Proposition): 고객이 필요로 하는 가치를 창출하기 위한 상품 및 서비스 조합      구매 가치(Purchase Value): 상품 및 서비스를 구매함으로써 고객이 직접적으로 얻게 되는 실용 가치      브랜드 가치(Brand Value): 브랜드에 대한 고객의 주관적/무형적 평가에 기초한, 고객이 특정 브랜드를 소유 및 경험함으로써 누리는 심리적 가치      관계 가치(Relationship Value): 특정 기업에 대한 구매 가치나 브랜드 가치를 넘어서 기업이 고객과 형성하게 되는 관계의 양적, 질적 정도        좋은 추천시스템의 요건          효과적(Effective): 사용자에게 얼마나 잘 맞는 아이템을 제안할 수 있는가      효율적(Efficient): 제안 생성 및 제공 과정에서 컴퓨팅 자원을 얼마나 잘 활용할 수 있는가      설명력(Explainable): 사용자에게 아이템을 제안한 근거나 로직을 설명할 수 있는가      설득력(Persuasive): 사용자가 제안된 아이템을 실제로 구매하거나 사용하도록 유도할 수 있는가        효과적인 추천의 목표          적합성(Relevance): 사용자가 관심 있을 것으로 짐작되는 아이템을 제안함      참신성(Novelty): 사용자가 이전에 관측하지 못했을 것으로 짐작되는 아이템을 제안함      의외성(Serendipity): 사용자가 예상하지 못했을 것으로 짐작되는 아이템을 제안함      다양성(Diversity): 제안된 정보 묶음이 확일적이지 않고 다양한 특성을 가진 정보들로 구성되어 있음      MetricsFocusing on Relevance  Ordinal Rating Prediction          RMSE(Root Mean Squared Error)      MAE(Mean Absolute Error)        Unary Rating Prediction          Recall      Precision      F1-Score        Top-K Rank Prediction          NDCG(Normalized Discounted Cumulative Gain): under the Explicit Ratings      MAP(Mean Average Precision): under the Implicit Ratings      MRR(Mean Reciprocal Rank)      Focusing on Diversity  Variance-based Diversity          Shanon Entropy      Simpson Concentration      Renyi Entropy        Equity-based Diversity          The Gini Coefficient derived from a Lorenz curve      Source  https://www.idownloadblog.com/2016/04/26/youtube-new-homepage-design/  https://towardsdatascience.com/essentials-of-recommendation-engines-content-based-and-collaborative-filtering-31521c964922"
  },
  
  {
    "title": "Recurrent Neural Networks",
    "url": "/posts/RNN/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Deep Learning, RNN, NLP",
    "date": "2024-01-14 00:00:00 +0900",
    





    
    "snippet": "Why? Recurrent-Net      Time series data is datawhere there is a sequence between features:            Fully connected layers treat the positions of input features equally,so they do not structural...",
    "content": "Why? Recurrent-Net      Time series data is datawhere there is a sequence between features:            Fully connected layers treat the positions of input features equally,so they do not structurally reflect order information between features:            RNN(Recurrent Neural Networks) involves preprocessing operationsthat preserve sequence information:      Vanilla RNN      update hidden state $\\overrightarrow{\\mathbf{z}}_{t}$:\\[\\begin{aligned}  \\overrightarrow{\\mathbf{z}}_{t}  &amp;= \\text{tanh}(\\mathbf{U}\\cdot\\overrightarrow{\\mathbf{x}}_{t}+\\mathbf{W}\\cdot\\overrightarrow{\\mathbf{z}}_{t-1}+\\overrightarrow{\\mathbf{b}}_{h})  \\end{aligned}\\]          $\\text{tanh}$ : activation function      $\\overrightarrow{\\mathbf{x}}_{t}$ : input value @ $t$      $\\mathbf{U}$ : weight matrix of input value @ $t$      $\\overrightarrow{\\mathbf{z}}_{t-1}$ : hidden state @ $t-1$      $\\mathbf{W}$ : weight matrix of hidden state @ $t-1$      $\\overrightarrow{\\mathbf{b}}_{h}$ : bias            print output $\\overrightarrow{\\mathbf{y}}_{t}$\\[\\begin{aligned}  \\overrightarrow{\\mathbf{y}}_{t}  &amp;= \\text{softmax}(\\mathbf{V}\\cdot\\overrightarrow{\\mathbf{z}}_{t}+\\overrightarrow{\\mathbf{b}}_{o})  \\end{aligned}\\]          $\\text{softmax}$ : activation function      $\\overrightarrow{\\mathbf{z}}_{t}$ : hidden state @ $t$      $\\mathbf{V}$ : weight matrix of hidden state @ $t$      $\\overrightarrow{\\mathbf{b}}_{o}$ : bias      LSTM      vanilla rnn suffers from the problems of long-term dependencies:              Long-term dependencies are problems in which the initial order information is not preserved as the sequence gets longer due to the vanishing gradient.            LSTM(Long Short-Term Memory) is technique to alleviate vanishing gradient through gate adjustment:              forget gate: generate forget rule      input gate: generate remember rule and cell state update      cell state: determine how much to remember and how much to forget      output gate: generate hidden state and output            forget gate:            input gate:            cell state:            output gate:      Sourse  https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr"
  },
  
  {
    "title": "Convolutional Neural Networks",
    "url": "/posts/CNN/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Deep Learning, CNN, CV",
    "date": "2024-01-13 00:00:00 +0900",
    





    
    "snippet": "Why? Conv-Net      image data is spatially structured data:            fully connected layers flatten the dimensionality of the input,collapsing its spatial structure:            CNN(Convolutional ...",
    "content": "Why? Conv-Net      image data is spatially structured data:            fully connected layers flatten the dimensionality of the input,collapsing its spatial structure:            CNN(Convolutional Neural Networks) involves preprocessing operationsthat preserve spatial structure:      How to Extract Features      Components              합성곱 레이어(Convolution Layer)      합동 레이어(Pooling Layer)      평탄화 레이어(Flatten Layer)      완전 연결 계층(Fully-Connected Layer)            합성곱 연산(Convolution Operation): 입력값의 부분 공간을 커널(Kernel)과 요소별 곱셈(Element-wise Product) 및 그 결과를 합산하여 피처 맵(Feature Map)을 추출하는 연산            커널(Kernel): 입력값의 부분 공간과 요소별 곱셈(Element-wise Product)하는 여과기(Filter)            피처 맵(Feature Map) : 합성곱 연산 결과 입력값 형상의 특징으로서 반환된 새로운 배열로서 원소값은 부분 공간이 커널과 매칭되는 정도를 나타냄            합동 연산(Pooling Operation): 피처 맵(Featur Map)에 대하여 그 부분 공간마다 대표값을 추출하여 요약된 행렬을 구성하는 연산      Sourse  https://medium.com/@PK_KwanG/cnn-step-2-flattening-50ee0af42e3e  https://medium.com/@alejandro.itoaramendia/convolutional-neural-networks-cnns-a-complete-guide-a803534a1930"
  },
  
  {
    "title": "Neural Networks",
    "url": "/posts/NN/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Deep Learning, FFNN",
    "date": "2024-01-12 00:00:00 +0900",
    





    
    "snippet": "Neural NetworksPerceptron      퍼셉트론(Perceptron) : 다수의 신호를 입력 받아 하나의 신호를 출력하는 알고리즘    \\[\\begin{aligned}  y = \\begin{cases}  0 \\quad &amp; \\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{x}...",
    "content": "Neural NetworksPerceptron      퍼셉트론(Perceptron) : 다수의 신호를 입력 받아 하나의 신호를 출력하는 알고리즘    \\[\\begin{aligned}  y = \\begin{cases}  0 \\quad &amp; \\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{x}} \\le \\theta \\\\  1 \\quad &amp; \\overrightarrow{\\mathbf{w}} \\cdot \\overrightarrow{\\mathbf{x}} &gt; \\theta \\\\  \\end{cases}, \\quad x \\in \\{0,1\\}  \\end{aligned}\\]        논리 회로(Logic Gate) : 하나 이상의 논리 입력을 받아 일정한 논리 연산을 거쳐 논리 출력을 얻는 회로                                Gate          Desc                                      AND          입력값이 모두 $1$ 이면 $1$ 을 출력함                          OR          입력값이 하나라도 $1$ 이면 $1$ 을 출력함                          NOT          입력값이 $0$ 이면 $1$ 을, $1$ 이면 $0$ 을 출력함                          NAND          입력값이 모두 $1$ 이면 $0$ 을 출력함                          NOR          입력값이 하나라도 $1$ 이면 $0$ 을 출력함                          XOR          입력값이 서로 다르면 $1$ 을, 같으면 $0$ 을 출력함                          XNOR          입력값이 서로 다르면 $0$ 을, 같으면 $1$ 을 출력함                          MLP(Multi-Layer Perceptron)                      단층 퍼셉트론은 선형 분류기로서 게이트를 다양한 가중치 조합을 통해 표현할 수 있으나, 비선형 분류기를 요하는 일부 게이트(XOR, XNOR)에 대해서는 표현이 불가능함                            이는 NAND, OR, AND 게이트를 표현하는 퍼셉트론들의 조합으로 표현할 수 있음                                                    $X_{1}$              $X_{2}$              $Z_{1}$ NAND              $Z_{2}$ OR              $Y$ AND                                                          $0$              $0$              $1$              $0$              $0$                                      $0$              $1$              $1$              $1$              $1$                                      $1$              $0$              $1$              $1$              $1$                                      $1$              $1$              $0$              $1$              $0$                                          Neural Network      인공신경망(Artifical Neural Network) : 생물학적 신경망에서 영감을 얻은 통계학적 학습 알고리즘            MLP(Multi-Layer Perceptron) is FC(Fully-Connected) FFNN(Feed-Forward Neural Network)              Layer : 하나 이상의 퍼셉트론으로 구성된 모듈      FC(Fully-Connected) : 레이어의 모든 뉴런이 다음 레이어의 모든 뉴런과 연결된 상태      FFNN(Feed-Forward Neural Network) : 신호가 하나의 방향으로만 전달되는 인공신경망            MLP Definition    \\[\\begin{aligned}  \\hat{y}  &amp;= \\text{MLP}(\\overrightarrow{\\mathbf{x}})\\\\  &amp;= F^{(N)} \\circ \\cdots \\circ F^{(i)} \\circ \\cdots \\circ F^{(1)}(\\overrightarrow{\\mathbf{x}})  \\end{aligned}\\]          $F^{(i)} = h \\circ g$ : Single Layer      \\(\\overrightarrow{\\mathbf{y}}^{(i)}\\) : Activation Value      $h(\\overrightarrow{\\mathbf{z}}^{(i)})$ : Activation Function      \\(\\overrightarrow{\\mathbf{z}}^{(i)}\\) : Net Input      \\(g(\\overrightarrow{\\mathbf{y}}^{(i-1)})=\\mathbf{W}^{(i)} \\cdot \\overrightarrow{\\mathbf{y}}^{(i-1)} + \\overrightarrow{\\mathbf{b}}^{(i)}\\) : Summed Input Function or Weighted Sum Function            활성화 함수(Activation Function) : 다음 레이어 뉴런으로의 전달 여부를 판단하는 함수($h(\\cdot)$)                                           Function          Output                                      Step          \\(\\text{step}(x)=\\begin{cases} 1, \\ \\text{if} \\ x&gt;0 \\\\ 0, \\ \\text{otherwise} \\end{cases}\\)          \\(y \\in \\{0, 1\\}\\)                          Sigmoid          \\(\\text{sigmoid}(x)=\\displaystyle\\frac{1}{1+e^{-x}}\\)          \\(y \\in [0, 1]\\)                          TANH          \\(\\begin{aligned}\\text{tanh}(x)&amp;=\\frac{\\text{sinh}(x)}{\\text{cosh}(x)} \\\\ &amp;=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\\end{aligned}\\)          \\(y \\in [-1, 1]\\)                          ReLU          \\(\\text{ReLU}(x)=\\max(0,x)\\)          \\(y \\in [0, \\infty]\\)                          Softmax          \\(\\text{softmax}(x)_{i} = \\displaystyle\\frac{\\exp{x_i}}{\\sum_{j \\ne i}{\\exp{x_j}}}\\)          \\(y \\in [0, 1]\\)                    Backward PropagationGradient Descent      그라디언트(Gradient) : 다변수 함수에 대하여 모든 방향으로의 순간변화율 벡터    \\[\\begin{aligned}  \\nabla{f(x_{1},x_{2},\\cdots,x_{n})}  &amp;= \\begin{pmatrix}  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{1}}\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{2}}\\\\  \\vdots\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{n}}\\\\  \\end{pmatrix}  \\end{aligned}\\]        경사하강법(Gradient Descent) : 손실 함수의 도함수(그라디언트)를 최소화하는 가중치를 추정하는 방법    \\[\\begin{aligned}  \\Theta \\gets \\Theta - \\eta \\cdot \\nabla_{\\Theta}\\mathcal{L}  \\end{aligned}\\]          $\\Theta$ : Learning Parameter      $\\eta$ : Learning Rate or Learning Step      $\\nabla_{\\Theta}\\mathcal{L}$ : Gradient of the Loss Function is Learning Direction      Backward Propagation      역전파(Backward Propagation) : 경사하강법을 활용하여 오차를 출력층에서 입력층 방향으로 전파하며 가중치를 조정하는 학습 방법            Learning Direction                  손실 $\\mathcal{L}$ 를 $1$ 번째 계층의 $1$ 번째 가중치 $w^{(1)}_{1}$ 에 대하여 미분하면 다음과 같음\\[\\begin{aligned}  \\frac{\\partial}{\\partial w^{(1)}_{1}}\\mathcal{L}(y,\\hat{y})  &amp;= \\frac{\\partial \\mathcal{L}}{\\partial\\cancel{\\overrightarrow{\\mathbf{y}}^{(N)}}}  \\times \\frac{\\partial\\cancel{\\overrightarrow{\\mathbf{y}}^{(N)}}}{\\partial\\cancel{\\overrightarrow{\\mathbf{z}}^{(N)}}}  \\times \\frac{\\partial\\cancel{\\overrightarrow{\\mathbf{z}}^{(N)}}}{\\partial\\cancel{\\overrightarrow{\\mathbf{y}}^{(N-1)}}}  \\times \\cdots \\times  \\frac{\\partial\\cancel{\\overrightarrow{\\mathbf{y}}^{(1)}}}{\\partial\\cancel{\\overrightarrow{\\mathbf{z}}^{(1)}}}  \\times   \\frac{\\partial\\cancel{\\overrightarrow{\\mathbf{z}}^{(1)}}}{\\partial w^{(1)}_{1}}  \\end{aligned}\\]                    위 각 항목을 일반화하면 다음과 같음\\[\\begin{aligned}  \\frac{\\partial \\mathcal{L}}{\\partial \\overrightarrow{\\mathbf{y}}^{(N)}}  =1, \\quad  \\frac{\\partial \\overrightarrow{\\mathbf{y}}^{(i)}}{\\partial \\overrightarrow{\\mathbf{z}}^{(i)}}  =h^{\\prime}(\\overrightarrow{\\mathbf{z}}^{(i)}), \\quad  \\frac{\\partial \\overrightarrow{\\mathbf{z}}^{(i)}}{\\partial \\overrightarrow{\\mathbf{y}}^{(i-1)}}  =\\mathbf{W}^{(i)}, \\quad  \\frac{\\partial \\overrightarrow{\\mathbf{z}}^{(k)}}{\\partial \\mathbf{W}^{(k)}}  =\\overrightarrow{\\mathbf{y}}^{(k-1)}  \\end{aligned}\\]                    따라서 파라미터 갱신 방향은 다음과 같이 일반화할 수 있음\\[\\begin{aligned}  \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}^{(k)}}  &amp;= \\overrightarrow{\\mathbf{y}}^{(k-1)} \\times \\prod_{i=k+1}^{N}{\\mathbf{W}^{(i)}} \\times \\prod_{i=k}^{N}{h^{\\prime}(\\overrightarrow{\\mathbf{z}}^{(i)})}  \\end{aligned}\\]            Optimizer      Update Learning Rate-based Approach                      Adagrad : 이전까지 누적 갱신 규모를 반영하여 학습률을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\frac{\\eta}{\\sqrt{\\phi_{t}}} \\times \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}}\\\\  \\phi_{t}  &amp;= \\phi_{t-1} + \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}} \\odot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}}  \\end{aligned}\\]                    RMSProp : 이전까지 누적 갱신 규모를 지수가중이동평균하여 반영하여 학습률을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\frac{\\eta}{\\sqrt{\\phi_{t}}} \\times \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}}\\\\  \\phi_{t}  &amp;= \\rho \\cdot \\phi_{t-1} + (1-\\rho) \\cdot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}} \\odot \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\Theta_{t}}  \\end{aligned}\\]                  Update Learning Direction-based Approach                      Momentum : 직전 시점 갱신 방향을 관성 계수($\\gamma$)만큼 반영하여 갱신 방향을 결정함\\[\\begin{aligned}  \\Theta_{t}  &amp;= \\Theta_{t-1} - \\phi_{t}\\\\  \\phi_{t}  &amp;= \\eta \\cdot \\frac{\\partial \\mathcal{L}_{t-1}}{\\partial \\Theta_{t-1}} + \\gamma \\cdot \\phi_{t-1}  \\end{aligned}\\]            Sourse  https://codetorial.net/tensorflow/basics_of_optimizer.html  https://namu.wiki/jump/JsjHPjk9qYK%2Fl54QLaGyq5jupzXBHwWbSS0dMWuO%2B3lzPTdSDH1TiTY1jg9ysGRCY1f5J8NIWqRsnWauQXGsLQ%3D%3D  https://gentlesark.tistory.com/44  https://www.asimovinstitute.org/neural-network-zoo/  https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html  https://towardsdatascience.com/an-intuitive-explanation-of-gradient-descent-83adf68c9c33"
  },
  
  {
    "title": "t-SNE",
    "url": "/posts/t_SNE/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2024-01-11 00:00:00 +0900",
    





    
    "snippet": "Prerequisite      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Even...",
    "content": "Prerequisite      정보이론(Information Theory): 신호에 존재하는 정보의 양을 측정하는 이론으로서, 특정 확률분포의 특성을 알아내거나, 두 확률분포 간 유사성을 정량화하는 데 사용함    Shannon’s Information Theory Principles          자주 발생하지 않는 사건(Unlikely Event)일수록 높은 정보량을 가짐(Informative)                  해가 동쪽에서 뜨는 사건은 사람들이 확신하고 있는 사건이므로 정보량이 낮은 반면, 해가 서쪽에서 뜨는 사건은 자연 법칙을 거스르는 극히 드문 사건이므로 정보량이 높음                    독립사건은 추가적인 정보량을 가짐(Addictive Information)                  동전을 두 번 던져서 앞면이 두 번 나오는 사건은 동전을 한 번 던져서 앞면이 나오는 사건보다 정보량이 두 배임                          자기정보(Self-Information): 확률변수 $X \\sim P$ 에 대하여, 사건 $X=x$ 가 발생했을 때의 정보량\\[\\begin{aligned}  I(X=x)  &amp;=-\\log{P(X=x)}  \\end{aligned}\\]        엔트로피(Entropy): 자기정보의 기대값으로서, 주어진 확률분포에서 발생 가능한 사건들의 평균적인 정보량\\[\\begin{aligned}  H(P)  = \\mathbb{E}_{X \\sim P}\\left[I(X)\\right]  = -\\sum_{X}{\\log{P(x)} \\cdot P(x)}  \\end{aligned}\\]          사건의 분포가 결정적일수록(Deterministic) 엔트로피가 감소함      사건의 분포가 균등할수록(Uniform) 엔트로피가 증가함            교차 엔트로피(Cross Entropy): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 가 $P$ 에 대하여 제공하는 정보의 불확실성을 측정하는 지표\\[\\begin{aligned}  H(P,Q)  = \\mathbb{E}_{X \\sim P}\\left[-\\log{Q(X)}\\right]  = -\\sum_{X}{\\log{Q(X)} \\cdot \\log{P(X)}}  \\end{aligned}\\]        쿨백 라이블러 발산(Kullback-Leibler Divergence): 확률변수 $X$ 의 분포 $P$ 와 그 근사 분포 $Q$ 에 대하여, $Q$ 를 $P$ 의 근사 분포로 사용할 때의 비효율성을 측정하는 지표로서, $P$ 에서 샘플링된 $X$ 에 대하여, $P$ 가 제공하는 평균적인 정보량과 $Q$ 가 제공하는 평균적인 정보량의 차이\\[\\begin{aligned}  KL[P(X) \\parallel Q(X)]  = H(P,Q) - H(P)  = \\sum_{X}{\\log{\\frac{P(X)}{Q(X)}} \\cdot P(X)}  \\end{aligned}\\]  t-SNE      t-분포 확률적 이웃 임베딩(t-Distribution Stochastic Neighbor Embedding): 고차원 공간 상에서의 관측치 간 거리를 보존하면서 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소 기법      Similarity Dist. in High Rank      Gaussian Kernel:\\[\\begin{aligned}  \\mathcal{K}(\\overrightarrow{\\mathbf{x}}_{i}, \\overrightarrow{\\mathbf{x}}_{j})  &amp;= \\exp{\\left[-\\frac{\\Vert \\overrightarrow{\\mathbf{x}}_{i}-\\overrightarrow{\\mathbf{x}}_{j}\\Vert^{2}}{2\\sigma_{i}^{2}}\\right]}  \\end{aligned}\\]        Gaussian-based Conditional Probabilities:\\[\\begin{aligned}  p(j \\mid i)  &amp;= \\frac{\\mathcal{K}(\\overrightarrow{\\mathbf{x}}_{i}, \\overrightarrow{\\mathbf{x}}_{j})}{\\sum_{k \\ne i}{\\mathcal{K}(\\overrightarrow{\\mathbf{x}}_{i}, \\overrightarrow{\\mathbf{x}}_{k})}}  \\end{aligned}\\]        Symmetrization of probability through joint probability calculation:\\[\\begin{aligned}  p(i,j)  &amp;= \\frac{p(j \\mid i) + p(i \\mid j)}{2n}  \\end{aligned}\\]  Similarity Dist. in Low Rank      Cauchy Dist. Kernel:\\[\\begin{aligned}  \\mathcal{K}(\\overrightarrow{\\mathbf{y}}_{i}, \\overrightarrow{\\mathbf{y}}_{j})  &amp;= \\frac{1}{1 + \\Vert \\overrightarrow{\\mathbf{y}}_{i} - \\overrightarrow{\\mathbf{y}}_{j} \\Vert^{2}}  \\end{aligned}\\]          cauchy dist. is t-dist. when the degree of freedom is $1$            L1 Regularization:\\[\\begin{aligned}  q(i,j)  &amp;= \\frac{\\mathcal{K}(\\overrightarrow{\\mathbf{y}}_{i}, \\overrightarrow{\\mathbf{y}}_{j})}{\\sum_{k \\ne l}{\\mathcal{K}(\\overrightarrow{\\mathbf{y}}_{k}, \\overrightarrow{\\mathbf{y}}_{l})}}  \\end{aligned}\\]  Optimization      Objective Function:\\[\\begin{aligned}  \\mathcal{L}  &amp;=\\sum_{i}{KL[P(i) \\parallel Q(i)]}\\\\  &amp;= \\sum_{i}\\sum_{j}{\\log{\\frac{p(i,j)}{q(i,j)}} \\cdot p(i,j)}  \\end{aligned}\\]        Optimization:\\[\\begin{aligned}  \\hat{\\mathbf{Y}}  &amp;= \\left\\{\\overrightarrow{\\mathbf{y}}_{i} \\mid \\text{arg} \\min{\\mathcal{L}}\\right\\}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Dimensionality Reduction",
    "url": "/posts/Dimensionality_Reduction/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2024-01-10 00:00:00 +0900",
    





    
    "snippet": "Curse of Dimensionality      차원의 저주(Curse of Dimensionality) : 고차원일수록 관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해져서 알고리즘이 제대로 학습하지 못하는 현상            차원 축소의 당위성          Manifold hypothesis      M...",
    "content": "Curse of Dimensionality      차원의 저주(Curse of Dimensionality) : 고차원일수록 관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해져서 알고리즘이 제대로 학습하지 못하는 현상            차원 축소의 당위성          Manifold hypothesis      Many high-dimensional data sets that occur in the real world actually lie along low-dimensional latent manifolds inside that high-dimensional space.          Dimensionality Reduction Methods  차원 선택(Feature Selection) : 유효한 차원을 선별하는 방법                  Filter Approach                    Wrapper Approach                  Forward Selection          Backward Elimination          Stepwise Selection                      차원 추출(Feature Extraction) : 원본의 특징을 보존하는 새로운 차원을 추출하는 방법          $\\text{arg} \\max_{\\overrightarrow{w}}{\\sigma^{2}}$                  주성분 분석(Principle Component Analysis; PCA)          선형 판별 분석(Linear Discriminant Analysis; LDA)                    $\\text{arg} \\max_{\\overrightarrow{w}}{\\text{dist}}$                  다차원 척도법(Multi-Dimensional Scaling; MDS)                    Reveal Non-Linear Structure                  t-SNE(t-distributed Stochastic Neighbor Embedding)          LLE(Locally Linear Embedding)          ISOMAP(ISOmetric feature MAPping)                    "
  },
  
  {
    "title": "DBSCAN",
    "url": "/posts/DBSCAN/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2024-01-09 00:00:00 +0900",
    





    
    "snippet": "DBSCAN      DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만...",
    "content": "DBSCAN      DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empty Subset                      Maximality                  표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 에 대하여, $\\overrightarrow{p} \\in C \\subseteq D$ 이고, $\\overrightarrow{q}$ 가 $\\overrightarrow{p}$ 로부터 밀도 기준 도달 가능한(Directly Density-Reachable) 벡터이면, $\\overrightarrow{q} \\in C$ 임                            Connectivity                  군집 $C$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 간에는 밀도 기준 연결되어 있음(Density-Connected)                    Concept$\\varepsilon$-neighborhood of a point  표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}$ 에 대하여, $\\overrightarrow{p}$ 의 이웃 집합 $N_{\\varepsilon}(\\overrightarrow{p})$ 은 $\\overrightarrow{p}$ 와의 거리가 $\\varepsilon$ 이하인 관측치 벡터 $\\overrightarrow{q}$ 의 집합임\\[N_{\\varepsilon}(\\overrightarrow{p})=\\{\\overrightarrow{q} \\in D \\mid d(\\overrightarrow{p},\\overrightarrow{q}) \\le \\varepsilon\\}\\]Directly Density-Reachable  Core Point Condition 을 만족하는 관측치 벡터 $\\overrightarrow{p} \\in D$ 에 대하여, 그 이웃 관측치 벡터($\\varepsilon$-neighborhood of a point) $\\overrightarrow{q}$ 는 $\\overrightarrow{p}$ 로부터 밀도 기준 직접 도달 가능한(Directly Density-Reachable) 관측치 벡터임      Core Point Condition\\[\\vert N_{\\varepsilon}(\\overrightarrow{p}) \\vert \\ge \\text{MinPts}\\]        Reachability\\[\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{p})\\]  Density-Reachable  Core Point Condition 을 만족하는 관측치 벡터 \\(\\overrightarrow{p} \\in D\\) 에 대하여, \\(\\overrightarrow{p}\\) 와 \\(\\overrightarrow{q}\\) 사이에 \\(\\overrightarrow{p}\\) 로부터 밀도 기준 직접 도달 가능한 관측치 벡터 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2},\\cdots,\\overrightarrow{x}_{n}\\) 이 연쇄적으로 존재한다면, \\(\\overrightarrow{q}\\) 는 \\(\\overrightarrow{p}\\) 로부터 밀도 기준 도달 가능한(Density-Reachable) 관측치 벡터임  \\(\\vert N_{\\varepsilon}(\\overrightarrow{p})\\vert \\ge \\text{MinPts}\\) : Core Point Condition  \\(\\overrightarrow{x}_{1} \\in N_{\\varepsilon}(\\overrightarrow{p})\\) : Reachability  \\(\\vert N_{\\varepsilon}(\\overrightarrow{x}_{\\forall})\\vert \\ge \\text{MinPts}\\) : \\(\\overrightarrow{x}_{\\forall}\\) 의 이웃 벡터 갯수가 하한선 $\\text{MinPts}$ 이상임  \\(\\overrightarrow{x}_{i+1} \\in N_{\\varepsilon}(\\overrightarrow{x}_{i})\\) : \\(\\overrightarrow{x}_{i+1}\\) 는 \\(\\overrightarrow{x}_{i}\\) 의 이웃 벡터임  \\(\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{x}_{n})\\) : $\\overrightarrow{q}$ 는 $\\overrightarrow{x}_{n}$ 의 이웃 벡터임Density-Connected  Core Point Condition 을 만족하는 관측치 벡터 \\(\\overrightarrow{p},\\overrightarrow{q} \\in D\\) 에 대하여, \\(\\overrightarrow{p}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 동시에 \\(\\overrightarrow{q}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 관측치 벡터 \\(\\overrightarrow{x} \\in D\\) 가 적어도 하나 존재한다면, \\(\\overrightarrow{p},\\overrightarrow{q}\\) 는 밀도 기준 연결되어 있음(Density-Connected)  $\\vert N_{\\varepsilon}(\\overrightarrow{p})\\vert \\ge \\text{MinPts}$  $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{p})$  $\\vert N_{\\varepsilon}(\\overrightarrow{q})\\vert \\ge \\text{MinPts}$  $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{q})$Sourse  https://ai.plainenglish.io/dbscan-density-based-clustering-aaebd76e2c8c  https://journals.sagepub.com/doi/10.1177/1748301817735665"
  },
  
  {
    "title": "k-Means",
    "url": "/posts/k_Means/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2024-01-08 00:00:00 +0900",
    





    
    "snippet": "k-Means      k-Means: 중심점 기반 배타적 분리형 군집화 알고리즘으로서, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화하는 군집을 탐색함    \\[\\begin{aligned}  \\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{\\mathbf{...",
    "content": "k-Means      k-Means: 중심점 기반 배타적 분리형 군집화 알고리즘으로서, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화하는 군집을 탐색함    \\[\\begin{aligned}  \\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{\\mathbf{x}}_{j} \\in C_{i}}{\\Vert\\overrightarrow{\\mathbf{x}}_{j}-\\overrightarrow{\\mu}_{i}\\Vert^2}}  \\end{aligned}\\]  Centroid Search Process      군집 갯수 설정\\[\\begin{aligned} X=C_{1} \\cup C_{2} \\cup \\cdots \\cup C_{k}, \\quad C_{i} \\cap C_{j \\ne i} = \\emptyset \\end{aligned}\\]        $k$ 개의 초기 군집 중심 벡터 $\\overrightarrow{c}$ 임의 선정\\[\\begin{aligned} M=\\left\\{\\overrightarrow{\\mu}_{1},\\overrightarrow{\\mu}_{2},\\cdots,\\overrightarrow{\\mu}_{k}\\right\\} \\end{aligned}\\]        모든 관측치 벡터 $\\overrightarrow{x}$ 를 가장 가까운 거리에 위치한 중심 벡터 $\\overrightarrow{\\mu}$ 의 군집에 배타적으로 할당\\[\\begin{aligned} \\overrightarrow{\\mathbf{x}}_{j} \\rightarrow C_{i} \\quad \\text{s.t.} \\quad  &amp; i=\\text{arg} \\min_{i}{\\Vert\\overrightarrow{\\mathbf{x}}_{j}-\\overrightarrow{\\mu}_{i}\\Vert^2}\\\\ &amp; \\overrightarrow{\\mu}_{i} \\in C_{i} \\end{aligned}\\]        각 군집별 할당된 관측치 벡터들의 평균 벡터로 군집 중심 벡터 갱신\\[\\begin{aligned} \\overrightarrow{\\mu}_{i} &amp;=\\displaystyle\\frac{1}{\\vert C_{i} \\vert}\\sum_{\\overrightarrow{\\mathbf{x}}_{j}\\in C_{i}}{\\overrightarrow{\\mathbf{x}}_{j}} \\end{aligned}\\]        ③, ④의 과정을 반복하여 최적의 군집 중심 벡터 집합 $\\hat{M}$ 탐색\\[\\begin{aligned} \\hat{M} &amp;= \\left\\{\\overrightarrow{\\mu}_{i} \\mid \\text{arg} \\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{\\mathbf{x}}_{j} \\in C_{i}}{\\Vert\\overrightarrow{\\mathbf{x}}_{j}-\\overrightarrow{\\mu}_{i}\\Vert^2}}\\right\\} \\end{aligned}\\]  Limitation      Sensitive to initial cluster centroids            Sensitive to outliers            Difficulty detecting clusters of non-spherical shapes            Difficulty detecting clusters of different sizes            Difficulty detecting clusters of different densities      Sourse  https://ai-times.tistory.com/158  https://github.com/pilsung-kang/multivariate-data-analysis/blob/master/09%20Clustering/09-2_K-Means%20Clustering.pdf  https://github.com/lovit/python_ml_intro/blob/master/lecture_notes/10_clustering.pdf  https://paulvanderlaken.com/2018/12/12/visualizing-the-inner-workings-of-the-k-means-clustering-algorithm/"
  },
  
  {
    "title": "Clustering",
    "url": "/posts/Clustering/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering, Metric",
    "date": "2024-01-07 00:00:00 +0900",
    





    
    "snippet": "Cluster Analysis      군집 분석(Cluster Analysis): 표본을 관측치 간 유사성과 상이성을 계산하여 군집 내 응집도를 최대화하는 동시에 군집 간 분리도를 최대화하는 $k$ 개의 군집으로 분할하는 작업              Cluster analysis or clustering is the task of grouping a...",
    "content": "Cluster Analysis      군집 분석(Cluster Analysis): 표본을 관측치 간 유사성과 상이성을 계산하여 군집 내 응집도를 최대화하는 동시에 군집 간 분리도를 최대화하는 $k$ 개의 군집으로 분할하는 작업              Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. (by.Wikipedia)            구분          Hard(or Crisp) Clustering      Soft(or Fuzzy) Clustering      Partitional Clustering      Hierarchical Clustering      Metrics  External : 정답 정보와의 비교          Rand Statistic      Jaccard Coefficient      Folks and Mallows Index      Hurbert $\\Gamma$ Statistic      V-Measure        Internal : 군집 내 응집도          Cophenetic Correlation Coefficient      Sum of Squared Error(SSE)      Cohesion and Separation        Relative : 군집 간 분리도          Dunn Family of Indices      Davies-Bouldin Index      Semi-partial R-squared      SD Validity Index      Silhouette      External Metrics      V-Measure : 정확성과 완전성의 조화평균\\[\\begin{aligned}  \\text{V}  &amp;= 2\\times\\frac{H(C \\mid K) \\cdot C(K \\mid C)}{H(C \\mid K) + C(K \\mid C)}  \\end{aligned}\\]          $H(C \\mid K)$ : 정확성(Homogeneity)      $C(K \\mid C)$ : 완전성(Completeness)            정확성(Homogeneity) : 각 군집의 클래스에 대한 엔트로피 합계\\[\\begin{aligned}  H(C \\mid K)  &amp;= -\\sum_{k=1}^{K}{\\sum_{c=1}^{C}{P(c \\mid k) \\cdot \\log{P(c \\mid k)}}}  \\end{aligned}\\]          $k$ : 군집 번호      $c$ : 클래스 번호      $P(c \\mid k)$ : 군집 $K=k$ 가 주어졌을 때, 클래스 $C=c$ 가 발생할 가능성            완전성(Completeness) : 각 클래스의 군집에 대한 엔트로피 합계\\[\\begin{aligned}  C(K \\mid C)  &amp;= -\\sum_{c=1}^{C}{\\sum_{k=1}^{K}{P(k \\mid c) \\cdot \\log{P(k \\mid c)}}}  \\end{aligned}\\]          $P(k \\mid c)$ : 클래스 $C=c$ 가 주어졌을 때, 군집 $K=k$ 가 발생할 가능성      Internal Metrics      Sum of Squared Error(SSE) : 각 군집의 중심점 벡터와 해당 군집 내 관측치 벡터 간 거리 자승으로 측정한 군집 응집도\\[\\begin{aligned}  \\text{SSE}  &amp;= \\sum_{k=1}^{K}{\\sum_{\\overrightarrow{x}_{i} \\in C_{k}}{\\Vert \\overrightarrow{x}_{i}-\\overrightarrow{\\mu}_{k} \\Vert^2}}  \\end{aligned}\\]          $k$ : 군집 번호      $C_{k}$ : $k$ 번째 군집      \\(\\overrightarrow{x}_{i} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 $i$ 번째 관측치 벡터      \\(\\overrightarrow{\\mu}_{k} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 중심 벡터      Relative Metrics      Dunn Index : 군집 내 응집도(Cohesion) 최대값 대비 군집 간 분리도(Separation) 최소값 비율\\[\\begin{aligned}  \\text{DI}  &amp;= \\frac{\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}}{\\max_{1 \\le k \\le K}{\\Delta(C_{k})}}  \\end{aligned}\\]          $\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}$ : 군집 간 분리도 최소값으로서 분리도에 대한 최악의 경우      $\\max_{1 \\le k \\le K}{\\Delta(C_{k})}$ : 군집 내 응집도 최대값으로서 응집도에 대한 최악의 경우            실루엣 계수(Silhouette) : 군집 내 응집성(cohesion)과 군집 간 분리도(separation)를 종합적으로 고려하여 측정한 개별 관측치 벡터에 대한 군집화 적합성의 평균값\\[\\begin{aligned}  \\text{S}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\frac{b(\\overrightarrow{x}_{i})-a(\\overrightarrow{x}_{i})}{\\max{[a(\\overrightarrow{x}_{i}),b(\\overrightarrow{x}_{i})]}}}  \\end{aligned}\\]          \\(a(\\overrightarrow{x}_{i})\\) : 관측치 벡터 \\(\\overrightarrow{x}_{i}\\) 기준 군집 내 응집도로서, 해당 관측치와 같은 군집에 속한 관측치와의 평균 거리      \\(b(\\overrightarrow{x}_{i})\\) : 관측치 벡터 \\(\\overrightarrow{x}_{i}\\) 기준 군집 간 분리도로서, 해당 관측치와 다른 군집에 속한 관측치와의 평균 거리 중 최소값      Sourse  https://www.scaler.com/topics/supervised-and-unsupervised-learning/  https://towardsdatascience.com/a-brief-introduction-to-unsupervised-learning-20db46445283  https://tyami.github.io/machine%20learning/clustering/"
  },
  
  {
    "title": "Ensemble",
    "url": "/posts/Ensemble/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Supervised Learning, Ensemble",
    "date": "2024-01-06 00:00:00 +0900",
    





    
    "snippet": "Ensemble      앙상블 기법(Ensemble) : 예측 오차를 줄이기 위하여 다양한 모형들을 결합하는 기법    예측 오차를 어떻게 줄일 것인가?          By Reducing Variance, Prevent Overfitting      By Reducing Bias, Prevent Underfitting        모형 간 다양성...",
    "content": "Ensemble      앙상블 기법(Ensemble) : 예측 오차를 줄이기 위하여 다양한 모형들을 결합하는 기법    예측 오차를 어떻게 줄일 것인가?          By Reducing Variance, Prevent Overfitting      By Reducing Bias, Prevent Underfitting        모형 간 다양성을 어떻게 확보할 것인가?          Provide different random subset of the training data to each other      Using some measurement ensuring it is substantially different from the other members        모형별 결과물을 어떻게 결합할 것인가?          Simple Voting      Weighted Voting      Bias-Variance Trade-off  Notation          $Y$ : 실제 관측치      $\\varepsilon \\sim N(0, \\sigma^2)$ : 노이즈      $f(X)$ : 실제 함수      $\\hat{f}(X)$ : $f(X)$ 에 대한 예측값      $\\overline{f}(X)$ : $\\hat{f}(X)$ 의 평균            error segmentation:\\[\\begin{aligned}  \\text{Error}  &amp;= \\mathbb{E}\\left[\\left(Y-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X) + \\varepsilon - \\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2} + \\varepsilon^{2} - 2 \\cdot \\varepsilon \\cdot \\left(f(X)-\\hat{f}(X)\\right) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\varepsilon^{2}\\right] - 2 \\cdot \\mathbb{E}\\left[\\varepsilon\\right] \\cdot \\mathbb{E}\\left[f(X)-\\hat{f}(X) \\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right] + \\sigma^{2}  \\end{aligned}\\]        estimation error:\\[\\begin{aligned}  &amp;\\mathbb{E}\\left[\\left(f(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)+\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right] + 2 \\cdot \\mathbb{E}\\left[f(X)-\\overline{f}(X)\\right] \\cdot \\mathbb{E}\\left[\\overline{f}(X)-\\hat{f}(X)\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(f(X)-\\overline{f}(X)\\right)^{2}\\right] + \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        estimation error consists of bias and variance:\\[\\begin{aligned}  \\mathbb{Bias}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\hat{f}(X)\\right] - f(X)\\\\  \\mathbb{Var}\\left[\\hat{f}(X)\\right]  &amp;= \\mathbb{E}\\left[\\left(\\overline{f}(X)-\\hat{f}(X)\\right)^{2}\\right]  \\end{aligned}\\]        therefore:\\[\\begin{aligned}  \\therefore \\text{Error}  &amp;= \\mathbb{Bias}^{2}\\left[\\hat{f}(X)\\right] + \\mathbb{Var}\\left[\\hat{f}(X)\\right] + \\sigma^{2}  \\end{aligned}\\]        Bias-Variance Trade-off:              Bias is the underfitting problem that occurs when a model does not sufficiently learn the patterns of the training data.      Variance is the overfitting problem that occurs when a model adapts too much to the training data.      Why? Ensemble\\[\\begin{aligned}\\xi_{\\text{ensemble}} \\le \\xi_{\\text{avg}}\\end{aligned}\\]      $m$ 번째 모형의 예측값을 다음과 같이 정의하자\\[\\begin{aligned}  \\underbrace{y_{m}(x)}_{\\begin{array}{c} \\text{predict value} \\\\ \\text{of m-th model} \\end{array}}  &amp;= \\underbrace{f(x)}_{\\text{real value}} + \\underbrace{\\epsilon_{m}(x)}_{\\begin{array}{c} \\text{error} \\\\ \\text{of m-th model} \\end{array}}  \\end{aligned}\\]        $m$ 번째 모형의 예측 오차의 자승을 다음과 같이 나타낼 수 있음\\[\\begin{aligned}  \\therefore \\mathbb{E}\\left[\\epsilon_{m}^{2}(x)\\right]  &amp;= \\mathbb{E}\\left[\\left(y_{m} - f(x)\\right)^{2}\\right]  \\end{aligned}\\]        개별 모형의 예측 오차 자승 평균 $\\xi_{\\text{avg}}$\\[\\begin{aligned}  \\xi_{\\text{avg}}  &amp;= \\frac{1}{M}\\sum_{m=1}^{M}{\\mathbb{E}\\left[\\epsilon_{m}^{2}(x)\\right]}  \\end{aligned}\\]        앙상블 모형의 예측 오차 자승 $\\xi_{\\text{ensemble}}$\\[\\begin{aligned}  \\xi_{\\text{ensemble}}  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{y_{m}(x)}-f(x)\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{y_{m}(x)}-\\frac{1}{M}\\sum_{m=1}^{M}{f(x)}\\right)^{2}\\right]\\\\  &amp;= \\mathbb{E}\\left[\\left(\\frac{1}{M}\\sum_{m=1}^{M}{\\epsilon_{m}(x)}\\right)^{2}\\right]  \\end{aligned}\\]        Cauchy-Schwartz Inequation\\[\\begin{aligned}  \\left(\\alpha_{1} \\cdot \\beta_{1} + \\cdots + \\alpha_{n} \\cdot \\beta_{n}\\right)^{2} \\le \\left(\\alpha_{1}^{2}+\\cdots+\\alpha_{n}^{2}\\right)\\left(\\beta_{1}^{2}+\\cdots+\\beta_{n}^{2}\\right)  \\end{aligned}\\]        $\\text{if} \\quad \\alpha_{m}=1, \\beta_{m}=\\epsilon_{m}(x)$\\[\\begin{aligned}  \\left(\\sum_{m=1}^{M}{1 \\cdot \\epsilon_{m}(x)}\\right)^{2} \\le M \\cdot \\sum_{m=1}^{M}{\\epsilon_{m}^{2}(x)}  \\end{aligned}\\]        $\\times \\displaystyle\\frac{1}{M^{2}}$\\[\\begin{aligned}  \\underbrace{\\left(\\frac{1}{M}\\sum_{m=1}^{M}{\\epsilon_{m}(x)}\\right)^{2}}_{\\xi_{\\text{ensemble}}} \\le \\underbrace{\\frac{1}{M} \\sum_{m=1}^{M}{\\epsilon_{m}^{2}(x)}}_{\\xi_{\\text{avg}}}  \\end{aligned}\\]  Bagging      Bagging(Bootstrap Aggregating) : 데이터 세트로부터 생성된 $M$ 개의 부트스트랩(Bootstrap)을 통해 $M$ 개의 개별 모형들을 병렬 학습하는 방법    \\[\\begin{aligned}  y(x)  &amp;= \\delta\\Big[y_{1}(x), y_{2}(x), \\cdots, y_{M}(x)\\Big]  \\end{aligned}\\]          By Reducing Variance, Prevent Overfitting      Provide different random subset of the training data to each other            부트스트랩(Bootstrap) : 전체 데이터 세트를 $K$ 개의 데이터 블록으로 분할한 후 $K$ 번 복원추출하여 재구성한 훈련용 데이터 세트                  데이터 세트 \\(x \\in \\mathcal{D}\\) 를 \\(k\\) 개의 데이터 블록 \\(\\Lambda^{(1)}, \\cdots, \\Lambda^{(K)}\\) 으로 나누자\\[\\begin{aligned}  \\mathcal{D}  &amp;= \\left\\{ x_{1}, x_{2}, \\cdots, x_{N} \\right\\}\\\\  &amp;= \\Lambda^{(1)} \\cup \\Lambda^{(2)} \\cup \\cdots \\cup \\Lambda^{(K)} \\quad \\text{s.t.}\\quad \\Lambda^{(i)} \\cap \\Lambda^{(j \\ne i)} = \\emptyset  \\end{aligned}\\]                    \\(\\Lambda^{(k)}\\) 를 \\(K\\) 번 복원추출하여 \\(m\\) 번째 모형의 훈련용 데이터 세트를 구성함\\[\\begin{aligned}  \\Omega^{(m)}_{\\text{trn}}  &amp;= \\left\\{\\Lambda^{(k)}_{l} \\mid \\Lambda^{(k)} \\subseteq \\mathcal{D}, k \\in \\{1, 2, \\cdots, K\\}, l=1,2,\\cdots,K\\right\\}  \\end{aligned}\\]                  OOB(Out of Bag) : 부트스트랩에 포함되지 않는 데이터 블록 집합으로서 검증용 데이터 세트로 활용됨                  $m$ 번째 모형의 검증용 데이터 세트는 해당 모형의 부트스트랩에 포함되지 않은 데이터 블록으로 구성함\\[\\begin{aligned}  \\Omega^{(m)}_{\\text{val}}  &amp;= \\bigcup_{k=1}^{K}{\\Lambda^{(k)}} \\setminus \\Omega^{(m)}_{\\text{trn}}  \\end{aligned}\\]                    하나의 데이터 블록이 부트스트랩에 포함되지 않을 확률\\[\\begin{aligned}  \\lim_{K \\rightarrow \\infty}{\\left(1-\\frac{1}{K}\\right)^{K}}  = e^{-1} \\approx 0.368  \\end{aligned}\\]                  Result Aggregating Function($\\delta(\\cdot)$)          Simple Voting      Weighted Voting(training accuarcy of individual models)      Weighted Voting(probability result)      Staking      Boosting      Boosting : 직렬로 나열된 개별 모형들에 대하여 모든 훈련 데이터 세트를 순차 학습하되, 현재 순번 모형이 오류를 줄이는 데 실패한 데이터 포인트에 대하여, 해당 포인트의 중요도를 가중함으로써 다음 모형이 더 집중하여 학습시키는 방법    \\[\\begin{aligned}  y_{M}(x)  &amp;= \\sum_{t=1}^{M}{\\alpha_{t} \\cdot h_{t}(x)}  \\end{aligned}\\]          By Reducing Bias, Prevent Underfitting      Using some measurement ensuring it is substantially different from the other members            예측값 $y_{t}(x)$ 및 모형 $h_{t}(x)$                  $t$ 번째 순번에서 $i$ 번째 관측치의 예측값 $y_{t}(x_{i})$ 을 다음과 같이 정의하자\\[\\begin{aligned}  \\underbrace{y_{t}(x_{i})}_{\\begin{array}{c} \\text{predict value} \\\\ \\text{of t-th model} \\end{array}}  &amp;= \\underbrace{f(x_{i})}_{\\text{real value}} + \\underbrace{\\epsilon_{t}(x_{i})}_{\\begin{array}{c} \\text{error} \\\\ \\text{of t-th model} \\end{array}}  \\end{aligned}\\]                    $t+1$ 번째 순번에서 $i$ 번째 관측치의 예측값 $y_{t+1}(x_{i})$ 을 다음의 규칙에 따라 갱신함\\[\\begin{aligned}  y_{t+1}(x_{i})  &amp;= y_{t}(x_{i}) + \\alpha_{t+1} \\cdot h_{t+1}(x_{i})  \\end{aligned}\\]                    이때 $t+1$ 번째 순번 모형 $h_{t+1}$ 을 다음과 같이 도출함\\[\\begin{aligned}  h_{t+1}  &amp;= \\text{arg} \\min_{h}{\\sum_{i=1}^{n}{L\\left[\\epsilon_{t}(x_{i}), h(x_{i})\\right]}}  \\end{aligned}\\]                  모형별 중요도(가중 평균)                  $t$ 번째 순번 모형의 중요도 $\\alpha_{t}$ 를 다음과 같이 정의함\\[\\begin{aligned}  \\alpha_{t}  &amp;= \\frac{1}{2}\\ln{\\frac{1-\\xi_{t}}{\\xi_{t}}}  \\end{aligned}\\]                    이때 $t$ 번째 순번 모형의 예측 오류율 $\\xi_{t}$ 은 다음과 같음\\[\\begin{aligned}  \\xi_{t}  &amp;= \\frac{\\sum_{i=1}^{n}{w_{i} \\cdot \\mathbb{I}\\left[h_{t}(x_{i}) \\ne f(x_{i})\\right]}}{\\sum_{j=1}^{n}{w_{j}}}  \\end{aligned}\\]                  관측치별 중요도                  $t$ 번째 순번에서 $i$ 번째 관측치 $x_{i} \\in \\mathcal{D}$ 의 중요도 $P(x_{i})$ 를 다음과 같이 정의하자\\[\\begin{aligned}  P(x_{i})  &amp;= \\frac{w_{i}}{\\sum_{j=1}^{n}{w_{j}}}  \\end{aligned}\\]                    $i$ 번째 관측치 $x_{i} \\in \\mathcal{D}$ 의 가중치 $w_i$ 를 다음의 규칙에 따라 갱신함\\[\\begin{aligned}  w_i  &amp; \\leftarrow w_{i} \\cdot \\exp{\\bigg[\\alpha_{t} \\cdot \\mathbb{I}\\left[h_{t}(x_{i}) \\ne f(x_{i})\\right]\\bigg]}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Decision Tree",
    "url": "/posts/Decision_Tree/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-05 00:00:00 +0900",
    





    
    "snippet": "Decision Tree      결정 트리(Decision Tree): 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘              루트 노드(Root Node) : 깊이가 $0$ 인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : ...",
    "content": "Decision Tree      결정 트리(Decision Tree): 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘              루트 노드(Root Node) : 깊이가 $0$ 인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건      리프 노드(Leaf Node) : 하위 노드가 존재하지 않는 노드로서 최종 범주      서브트리(Subtree) : 어떠한 규칙 노드를 루트 노드로 가지는 하위 트리로서 판별 규칙 집합의 부분집합      Recursive Partitioning      재귀적 분기(Recursive Partitioning) : 판별 규칙을 기준으로 상위 노드를 분할하여 순도가 높은 하위 노드를 생성하는 반복적인 과정                  판별 규칙 : 어떤 분기에서 하나의 설명변수를 사용하여 생성한 분할 조건                            순도(Purity) : 어떤 노드에 속한 관측치들이 동일한 범주에 속하는 정도                          순도를 정확히 측정하기 어려우므로 그 대리변수로서 불순도(Impurity)를 사용함                    Discriminant Rule      어떤 노드에 대하여, 설명변수 $X_{i} \\ge x_{i}$ 를 기준으로 해당 노드를 분할한다고 하자\\[\\begin{aligned}  y=\\begin{cases}  N_{\\text{Left}},\\quad &amp; \\text{if} \\quad X_{i} \\ge x_{i}\\\\  N_{\\text{Right}},\\quad &amp; \\text{if} \\quad X_{i} &lt; x_{i}\\\\  \\end{cases}  \\end{aligned}\\]        판별 규칙 $X_{i} \\ge x_{i}$ 의 비용 $\\mathcal{J}(X_{i} \\ge x_{i})$ 는 다음과 같음\\[\\begin{aligned}  \\mathcal{J}(X_{i} \\ge x_{i})  &amp;= \\frac{m_{\\text{Left}}}{m}I_{\\text{Left}} + \\frac{m_{\\text{Right}}}{m}I_{\\text{Right}}  \\end{aligned}\\]          $m$ : 결정 노드에 속한 관측치 갯수      $m_{\\text{Left}}$ : 좌측 하위 노드로 분기한 관측치 갯수      $I_{\\text{Left}}$ : 좌측 하위 노드의 불순도      $m_{\\text{Right}}$ : 우측 하위 노드로 분기한 관측치 갯수      $I_{\\text{Right}}$ : 우측 하위 노드의 불순도            설명변수 $X_{i}$ 기준 분할 시 최적의 분기점 $\\hat{x}_{i}$ 는 다음과 같음\\[\\begin{aligned}  \\hat{x}_{i}  =\\text{arg} \\min_{x_{i}}{\\mathcal{J}(X_{i} \\ge x_{i})}  \\end{aligned}\\]        특정 노드를 분할하는 최적의 설명변수 $\\hat{X}_{i}$ 는 다음과 같음\\[\\begin{aligned}  \\hat{X}_{i}  = \\text{arg} \\min_{X_{i}}{\\left\\{\\min{\\mathcal{J}(X_{1})},\\min{\\mathcal{J}(X_{2})},\\cdots,\\min{\\mathcal{J}(X_{n})}\\right\\}}  \\end{aligned}\\]  Impurity      지니 지수(Gini Index) : 불순도를 경제적 불평등 개념 에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율            엔트로피 지수(Entropy Index) : 불순도를 정보 획득의 불확실성 개념 에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= -\\sum_{i=1}^{c}{\\left[p_{i} \\cdot \\log_{2}{p_{i}}\\right]}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율      Pruning      가지치기(Pruning) : 자세하게 구분된 영역을 통합함으로써 과적합을 방지하는 기법으로서, Full Tree 를 생성하여 모든 노드에 대하여 비용 복잡도 지수를 계산하고, 그 값이 가장 낮은 노드에 대하여 가지치기를 반복적으로 수행하면서 최적의 가지치기 강도 $\\alpha$ 하 트리를 도출함        비용 복잡도 지수(Cost-Complexity)\\[\\begin{aligned}  R_{\\alpha}(T)  &amp;= L(T) + \\alpha \\cdot \\vert\\text{Leaf}(T)\\vert\\\\  L(T)  &amp;= \\sum_{m=1}^{\\vert\\text{Leaf}(T)\\vert}{\\sum_{\\overrightarrow{\\mathbf{x}}_{i} \\in R_{m}}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}}  \\end{aligned}\\]          $T$ : 타깃 노드를 루트 노드로 하는 서브트리      $\\text{Leaf}(T)$ : $T$ 의 리프 노드 집합      $R_{m} \\in \\text{leaf}(T)$ : $T$ 의 $m$ 번째 리프 노드      \\(\\overrightarrow{\\mathbf{x}}_{i} \\in R_{m}\\) : \\(R_{m}\\) 에 속한 \\(i\\) 번째 관측치 벡터      $\\alpha$ : 가지치기 강도      $L(T)$ : $T$ 의 훈련 관측치에 대한 예측 손실      $R_{\\alpha}(T)$ : 타깃 노드의 비용 복잡도 지수      DTR      재귀적 분기\\[\\begin{aligned}  \\hat{X}_{i}  &amp;= \\text{arg} \\min_{X_{i}}{\\{\\mathcal{J}(X_{1},\\hat{x}_{1}),\\mathcal{J}(X_{2},\\hat{x}_{2}),\\cdots,\\mathcal{J}(X_{n},\\hat{x}_{n})\\}}\\\\  \\hat{x}_{i}  &amp;= \\text{arg} \\min_{x_{i}}{\\mathcal{J}(X_{i},x_{i})}\\\\  \\mathcal{J}(X_{i},x_{i})  &amp;= \\frac{m_{\\text{Left}}}{m}L_{\\text{Left}}+\\frac{m_{\\text{Right}}}{m}L_{\\text{Right}}  \\end{aligned}\\]        손실 함수                      판별 분석 : 불순도(Impurity)를 최소화하도록 분기\\[\\begin{aligned}  \\mathcal{L}_{\\text{GINI}}(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]                    회귀 분석 : 오차(Error)를 최소화하도록 분기\\[\\begin{aligned}  \\mathcal{L}_{\\text{MSE}}(N_{k})  &amp;= \\sum_{i=1}^{m}{(y_{i}-\\hat{y}_{i})^2}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Support Vector Machine",
    "url": "/posts/SVM/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-04 00:00:00 +0900",
    





    
    "snippet": "Support Vector Machine      서포트 벡터 머신(Support Vector Machine): 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) ...",
    "content": "Support Vector Machine      서포트 벡터 머신(Support Vector Machine): 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장 가까이 위치한 벡터      마진(Margin) : 인접한 두 범주의 서포트 벡터를 지나는 평행한 두 직선 사이의 유클리드 거리      Decision Function      Class of New Obs \\(\\overrightarrow{\\mathbf{q}}\\):\\[\\begin{aligned}  y_{q}  &amp;= \\begin{cases}  +1, \\quad &amp;\\text{if} \\quad f(\\overrightarrow{\\mathbf{q}}) &gt; 0 \\\\  -1, \\quad &amp;\\text{if} \\quad f(\\overrightarrow{\\mathbf{q}}) &lt; 0 \\\\  \\end{cases}  \\end{aligned}\\]        Decision Function is the Projection Distance between the Hyperplane and the Vector:\\[\\begin{aligned}  f(\\overrightarrow{\\mathbf{q}})  &amp;= \\overrightarrow{\\mathbf{w}}^{*} \\cdot \\overrightarrow{\\mathbf{q}} + b^{*}\\\\  &amp;= \\left(\\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{\\mathbf{x}}_{i}}\\right) \\cdot \\overrightarrow{\\mathbf{q}} + \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{\\mathbf{x}}_{j}\\overrightarrow{\\mathbf{x}}_{i}\\right]}  \\end{aligned}\\]  Concept      Hyper-Plane\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}+b  &amp;=0  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{x}}\\) : 초평면 위에 위치한 벡터      \\(\\overrightarrow{\\mathbf{w}}\\) : 초평면의 법선 벡터      \\(b\\) : 편향으로서 세로축 절편            Class\\[\\begin{aligned}  y_{i} = \\begin{cases}  +1,\\quad &amp;\\text{if} \\quad \\overrightarrow{\\mathbf{x}}_{i} \\in \\mathbf{X}^{+}\\\\  -1,\\quad &amp;\\text{if} \\quad \\overrightarrow{\\mathbf{x}}_{i} \\in \\mathbf{X}^{-}  \\end{cases}  \\end{aligned}\\]        Support Vector                  Left Support Vector \\(\\overrightarrow{\\mathbf{x}}^{+}\\):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{+}+b  &amp;=+1  \\end{aligned}\\]                    Right Support Vector \\(\\overrightarrow{\\mathbf{x}}^{-}\\):\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{-}+b  &amp;=-1  \\end{aligned}\\]            Margin      우측 서포트 벡터 \\(\\overrightarrow{\\mathbf{x}}^{-}\\) 를 방향 \\(\\overrightarrow{\\mathbf{w}}\\) 으로 크기 \\(\\text{margin}\\) 만큼 이동하면 좌측 서포트 벡터 \\(\\overrightarrow{\\mathbf{x}}^{+}\\) 에 안착한다고 하자\\[\\begin{aligned}  \\overrightarrow{\\mathbf{x}}^{+}  &amp;= \\overrightarrow{\\mathbf{x}}^{-} + \\text{margin} \\cdot \\overrightarrow{\\mathbf{w}}  \\end{aligned}\\]        \\(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{+}+b=1\\) 을 다음과 같이 재정의할 수 있음\\[\\begin{aligned}  \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{+}+b  &amp;=1\\\\  \\overrightarrow{\\mathbf{w}}^{T}\\left(\\overrightarrow{\\mathbf{x}}^{-} + \\text{margin} \\cdot \\overrightarrow{\\mathbf{w}}\\right)+b  &amp;=1\\\\  \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{-} + \\text{margin} \\cdot \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{w}} + b  &amp;=1\\\\  \\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}^{-} + b\\right) + \\text{margin} \\cdot \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{w}}  &amp;=1\\\\  -1 + \\text{margin} \\cdot  \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2  &amp;= 1  \\end{aligned}\\]        따라서 마진을 다음과 같이 도출할 수 있음\\[\\begin{aligned}  \\text{margin}  &amp;= \\frac{2}{ \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2}  \\end{aligned}\\]  Maximum Margin      Definition of Optimization Problem                  Objective Function:\\[\\begin{aligned}  \\max{\\frac{2}{ \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2}}  \\Rightarrow \\min{\\frac{1}{2} \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2}  \\end{aligned}\\]                    Constraint:\\[\\begin{aligned}  y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}+b\\right)  \\ge 1  \\end{aligned}\\]                  Lagrangian Function                  Lagrangian Function:\\[\\begin{aligned}  \\mathcal{L}(\\overrightarrow{\\mathbf{w}},b,\\lambda)  &amp;=\\frac{1}{2} \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\left[y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}+b\\right)-1\\right]}  \\end{aligned}\\]                  $\\lambda_{i}\\ge 0$ : 라그랑주 승수                            Complementary Slackness, KKT Conditions:\\[\\begin{aligned}  \\lambda_{i}\\cdot\\left[y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}+b\\right)-1\\right]  &amp;=0  \\end{aligned}\\]                  Support Vector : \\(y_{i \\in SV}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i \\in SV}+b\\right)-1=0 \\quad \\because \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i \\in SV}+b = 1\\)          Others : \\(\\lambda_{i \\notin SV}=0 \\quad \\because \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i \\notin SV}+b &gt; 1\\)                          Maximum Margin\\[\\begin{aligned}  \\hat{\\Theta}  &amp;= \\text{arg} \\max{\\mathcal{L}\\left(\\overrightarrow{\\mathbf{w}},b,\\lambda\\right)}  \\end{aligned}\\]                  The Normal Vector \\(\\overrightarrow{\\mathbf{w}}^{*}\\) that maximizes the margin is:\\[\\overrightarrow{\\mathbf{w}}^{*}  = \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{\\mathbf{x}}_{i}}\\]                    The Bias \\(b^{*}\\) that maximizes the margin is:\\[\\begin{aligned}  b^{*}  &amp;= y_{i \\in SV} - \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i \\in SV}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}{\\left[y_{i} - \\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}\\right]}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}{\\left[y_{i} - \\left(\\sum_{j \\in SV}{\\lambda_{j}y_{j}\\overrightarrow{\\mathbf{x}}_{j}}\\right)\\overrightarrow{\\mathbf{x}}_{i}\\right]}\\quad \\because \\overrightarrow{\\mathbf{w}}^{*}=\\sum_{i}{\\lambda_{i}y_{i}\\overrightarrow{\\mathbf{x}}_{i}}\\\\  &amp;= \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{\\mathbf{x}}_{j}\\overrightarrow{\\mathbf{x}}_{i}\\right]}  \\end{aligned}\\]                    The Support Vector \\(\\overrightarrow{\\mathbf{x}}_{SV} \\in SV\\) that maximizes the margin is:\\[\\begin{aligned}  SV   &amp;= \\left\\{\\overrightarrow{\\mathbf{x}}_{SV} \\mid \\overrightarrow{\\mathbf{w}}^{*} \\cdot \\overrightarrow{\\mathbf{x}}_{SV} + b^{*} = \\vert 1 \\vert \\right\\}\\\\  &amp;= \\left\\{ \\overrightarrow{\\mathbf{x}}_{SV} \\mid \\left(\\sum_{i=1}^{n}{\\lambda_{i}^{*}y_{i}\\overrightarrow{\\mathbf{x}}_{i}}\\right) \\cdot \\overrightarrow{\\mathbf{x}}_{SV} + \\frac{1}{ \\vert SV \\vert }\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{\\mathbf{x}}_{j}\\overrightarrow{\\mathbf{x}}_{i}\\right]}= \\vert 1 \\vert  \\right\\}  \\end{aligned}\\]            Soft Margin  Soft Margin : 마진 위반 $\\xi$ 를 허용하여 일부 이상 관측치를 배제했을 때 마진을 최대화하는 초평면을 탐색함          마진 위반(Margin Violation; $\\xi$) : 초평면 근방에서 발생 가능한 소수의 이상 관측치에 대한 오류로서, 해당 관측치로부터 서포트 벡터를 지나고 초평면과 평행한 직선까지의 유클리드 거리            Definition of Optimization Problem\\[\\begin{aligned}  \\min{\\left[\\frac{1}{2}{ \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2}+C\\sum_{i=1}^{n}{\\xi_i}\\right]}  \\quad \\text{s.t.} \\quad &amp;y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}+b\\right) \\ge 1-\\xi_i,\\\\  &amp;\\xi_i \\ge 0  \\end{aligned}\\]          $\\xi_{i}$ : 관측치 벡터 $\\overrightarrow{x}_{i}$ 에 대한 마진 위반              $C$ : 마진 위반에 대한 규제 강도                          Lagrangian Function\\[\\begin{aligned}  \\mathcal{L}(\\overrightarrow{\\mathbf{w}},b,\\lambda,\\xi,\\mu)  &amp;= \\left[\\frac{1}{2} \\Vert \\overrightarrow{\\mathbf{w}} \\Vert ^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\left[y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}+b\\right)-\\left(1-\\xi_{i}\\right)\\right]}\\right] + \\left[C\\sum_{i=1}^{n}{\\xi_{i}}-\\sum_{i=1}^{b}{\\mu_{i}\\xi_{i}}\\right]  \\end{aligned}\\]          $\\lambda \\ge 0$ : 제약 조건 \\(y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}+b\\right) \\ge 1-\\xi_{i}\\) 에 대한 라그랑주 승수      $\\mu \\ge 0$ : 제약 조건 $\\xi_{i} \\ge 0$ 에 대한 라그랑주 승수      Kernel Trick      정의 : 선형으로는 구분하기 어려운 저차원 공간상의 데이터 세트를, 적절한 결정 경계를 찾을 수 있는 고차원 공간으로 매핑하는 기법            커널 함수(Kernel Function)                            Name          Function                                      Linear          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = X \\cdot X^{\\prime}\\)                          Polynomial          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\left(X \\cdot X^{\\prime} + \\beta\\right)^{d}\\)                          RBF          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\displaystyle\\frac{\\Vert X-X^{\\prime} \\Vert^{2}}{2\\ell^{2}}\\right]}\\)                          Sigmoid          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\text{tanh}\\left(\\alpha \\cdot X \\cdot X^{\\prime} + \\beta\\right)\\)                          Laplacian          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\gamma \\Vert X-X^{\\prime} \\Vert_{1}\\right]}\\)                          Exponential          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp{\\left[-\\gamma \\Vert X-X^{\\prime} \\Vert_{2}\\right]}\\)                          Matern          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\displaystyle\\frac{2^{1-\\nu}}{\\Gamma\\left(\\nu\\right)} \\cdot \\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)^{\\nu} \\cdot K_{\\nu}\\left(\\displaystyle\\frac{\\sqrt{2\\nu} \\Vert X-X^{\\prime} \\Vert}{\\ell}\\right)\\)                          Periodic          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\exp\\left[-2 \\sin^2\\left( \\displaystyle\\frac{\\pi \\vert X-X^{\\prime} \\vert}{p} \\right) \\Bigg/ \\ell^2 \\right]\\)                          Rational Quadratic          \\(\\mathcal{K}\\left(X,X^{\\prime}\\right) = \\left( 1 + \\displaystyle\\frac{\\vert X-X^{\\prime} \\vert^2}{2 \\alpha \\ell^2} \\right)^{-\\alpha}\\)                          Mercer’s Theorem          저차원 공간 $L$ 에서 고차원 공간 $H$ 로 관측치들을 매핑하는 커널함수 $K$ 는 $L$ 에서 표현된 관측치들 간 유클리드 거리와 $H$ 에서 표현된 관측치들 간 유클리드 거리를 보존함                      임의의 관측치 $X_a, X_b$ 에 대하여, $2$ 차원 공간에서 해당 관측치를 나타내는 벡터 $\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{\\mathbf{a}}  = \\begin{pmatrix}a_1\\\\a_2\\end{pmatrix},\\quad  \\overrightarrow{\\mathbf{b}}  = \\begin{pmatrix}b_1\\\\b_2\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}$ 을 $3$ 차원상의 벡터 $\\Phi\\left(\\overrightarrow{\\mathbf{a}}\\right),\\Phi\\left(\\overrightarrow{\\mathbf{b}}\\right)$ 로 매핑하는 커널함수 $K\\left(\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}\\right)$ 는 다음의 조건을 만족함\\[\\begin{aligned}  K\\left(\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}\\right)  &amp;= \\left(\\overrightarrow{\\mathbf{a}}^{T} \\overrightarrow{\\mathbf{b}}\\right)^{2} \\\\  &amp;= a_{1}^{2} b_{1}^{2} + 2\\left(a_{1} b_{1} a_{2} b_{2}\\right) + a_{2}^{2}b_{2}^{2} \\\\  &amp;= \\begin{pmatrix}a_{1}^{2}\\\\ \\sqrt{2} a_{1} a_{2}\\\\ a_{2}^{2}\\end{pmatrix} \\cdot \\begin{pmatrix}b_{1}^{2}\\\\ \\sqrt{2}b_{1} b_{2}\\\\ b_{2}^{2}\\end{pmatrix} \\\\  &amp;= \\Phi\\left(\\overrightarrow{\\mathbf{a}}\\right) \\cdot \\Phi\\left(\\overrightarrow{\\mathbf{b}}\\right)  \\end{aligned}\\]            SVR      Optimization\\[\\begin{aligned}  \\hat{\\Theta}  =\\text{arg} \\min{\\left[\\frac{1}{2} \\Vert \\overrightarrow{\\mathbf{w}} \\Vert^{2} + C\\sum_{i=1}^{n}{\\left(\\xi_{i}+\\eta_{i}\\right)}\\right]}  \\end{aligned}\\]        Constraint                      판별 분석 : 마진 범위 이내에 관측치 벡터가 존재하지 않음\\[\\begin{aligned}  \\text{s.t.}\\quad  &amp;y_{i}\\left(\\overrightarrow{\\mathbf{w}}^{T}\\overrightarrow{\\mathbf{x}}_{i}+b\\right) \\ge 1 + \\xi_{i}\\\\  &amp;\\xi_{i} \\ge 0  \\end{aligned}\\]                    회귀 분석 : 마진 범위 이내에 모든 관측치 벡터가 존재함\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp; \\varepsilon + \\xi_{i} + f\\left(\\overrightarrow{\\mathbf{x}}\\right) - y_{i} \\ge 0,\\\\  &amp; \\varepsilon + \\eta_{i} - f\\left(\\overrightarrow{\\mathbf{x}}\\right) + y_{i} \\ge 0,\\\\  &amp; \\xi_{i}, \\eta_{i} \\ge 0  \\end{aligned}\\]            Sourse  https://velog.io/@shlee0125  https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927"
  },
  
  {
    "title": "k-NN",
    "url": "/posts/k_NN/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-03 00:00:00 +0900",
    





    
    "snippet": "k-Nearest Neighbors      k-최근접 이웃(k-Nearest Neighbors): 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]  Distance      맨해튼 거리(Manhattan Distance; L1): 두...",
    "content": "k-Nearest Neighbors      k-최근접 이웃(k-Nearest Neighbors): 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]  Distance      맨해튼 거리(Manhattan Distance; L1): 두 점 사이의 엣지(Edge) 갯수    \\[\\begin{aligned}  d(\\overrightarrow{\\mathbf{a}},\\overrightarrow{\\mathbf{b}})  &amp;= \\Vert \\overrightarrow{\\mathbf{a}} - \\overrightarrow{\\mathbf{b}} \\Vert _{L1}  = \\displaystyle\\sum_{i=1}^{n} \\vert a_i - b_i \\vert  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{i}_{1}}, \\overrightarrow{\\mathbf{i}_{2}}, \\cdots, \\overrightarrow{\\mathbf{i}_{n}}\\) 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리를 합산한 값            유클리드 거리(Euclidean Distance; L2): 두 점 사이의 직선 거리    \\[\\begin{aligned}  d(\\overrightarrow{\\mathbf{a}},\\overrightarrow{\\mathbf{b}})  &amp;= \\Vert \\overrightarrow{\\mathbf{a}} - \\overrightarrow{\\mathbf{b}} \\Vert _{L2}  = \\sqrt{\\displaystyle\\sum_{i=1}^{n} (a_i - b_i)^2}  \\end{aligned}\\]          \\(\\overrightarrow{\\mathbf{i}_{1}}, \\overrightarrow{\\mathbf{i}_{2}}, \\cdots, \\overrightarrow{\\mathbf{i}_{n}}\\) 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 \\(\\overrightarrow{\\mathbf{a}}, \\overrightarrow{\\mathbf{b}}\\) 에 대하여 각 축 방향으로의 기저벡터 단위 거리의 제곱을 합산한 후 제곱근한 값            코사인 거리(Cosine Distance; $\\cos$): 임의의 두 점에 대하여, 원점과 각 점을 잇는 직선의 사이각 $\\theta$ 의 코사인 값    \\[\\begin{aligned}  d(\\overrightarrow{\\mathbf{a}},\\overrightarrow{\\mathbf{b}})  &amp;= \\cos{\\theta}  = \\frac{\\overrightarrow{\\mathbf{a}}^{T}\\overrightarrow{\\mathbf{b}}}{\\Vert \\overrightarrow{\\mathbf{a}} \\Vert \\cdot \\Vert \\overrightarrow{\\mathbf{b}} \\Vert}  = \\frac{\\sum_{i=1}^{n}{a_{i}b_{i}}}{\\sqrt{\\sum_{i=1}^{n}{a_{i}^{2}}} \\cdot \\sqrt{\\sum_{i=1}^{n}{b_{i}^{2}}}}  \\end{aligned}\\]        하버사인 거리(Haversine Distance; $\\text{hav}$): 구 표면상에 존재하는 두 지점에 대하여, 위도($\\varphi$), 경도($\\lambda$) 및 호 중심각($\\Theta$)을 활용하여 측정한 호의 길이                      반지름이 $r$, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta  \\end{aligned}\\]                    점 $A$,$B$ 의 위도가 $\\varphi_{A}$,$\\varphi_{B}$, 경도가 $\\lambda_{A}$,$\\lambda_{B}$ 이고, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호의 길이 $\\text{hav}{\\Theta}$ 는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\text{hav}(\\varphi_{B}-\\varphi_{A})  + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})  \\end{aligned}\\]                    $\\sin$, $\\cos$, $\\text{hav}$ 의 관계는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\sin^{2}{\\frac{\\Theta}{2}}\\\\  &amp;= \\frac{1-\\cos{\\Theta}}{2}  \\end{aligned}\\]                    따라서 반지름, 경도, 위도가 주어졌을 때 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta\\\\  &amp;= r \\cdot \\text{archav}(\\text{hav}{\\Theta})\\\\  &amp;= 2r \\cdot \\arcsin(\\sqrt{\\text{hav}{\\Theta}})\\\\  &amp;= 2r \\cdot \\arcsin\\left(\\sqrt{\\text{hav}(\\varphi_{B}-\\varphi_{A}) + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})}\\right)  \\end{aligned}\\]            Sourse  https://076923.github.io/posts/Python-opencv-43/"
  },
  
  {
    "title": "Supervised Model Selection",
    "url": "/posts/Supervised_Model_Selection/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning, Supervised Learning, Metric, Cross Validation",
    "date": "2024-01-02 00:00:00 +0900",
    





    
    "snippet": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitiv...",
    "content": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitive) 중 잘못 예측한(False) 항목  FN(False Negative) : 부정으로 예측한 것(Negative) 중 잘못 예측한(False) 항목Sensitive to Threshold      정확도(Accuracy) : 전체 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}  \\end{aligned}\\]        민감도(Sensitivity) 혹은 재현율(Recall) : 실제 긍정인 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}  \\end{aligned}\\]          제1종 오류(참을 거짓으로 예측하는 오류; FN)를 강조하는 지표            특이도(Specificity) : 실제 부정인 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}  \\end{aligned}\\]        정밀도(Precision) : 긍정으로 예측한 관측치 대비 옳게 예측한 관측치 비율\\[\\begin{aligned}  \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}  \\end{aligned}\\]          제2종 오류(거짓을 참으로 예측하는 오류; FP)를 강조하는 지표            F1-Score : 재현율과 정밀도의 조화 평균\\[\\begin{aligned}  2 \\times \\frac{\\text{Prec} \\times \\text{Rec}}{\\text{Prec} + \\text{Rec}}  \\end{aligned}\\]  AUROC : Robust to Threshold      ROC Curve(Receiver Operating Characteristic Curve) : $\\text{FPR}$ 값에 따른 $\\text{TPR}$ 의 변화 추이를 나타낸 곡선            AUROC(Area Under ROC) : ROC Curve 아래 면적\\[\\begin{aligned}  0.5 \\le \\text{AUROC} \\le 1  \\end{aligned}\\]                  FNR(False Negative Rate) : 실제 긍정인 관측치(TP+FN) 대비 잘못 예측한 관측치(FN) 비율\\[\\begin{aligned}  \\text{FNR}  &amp;=\\frac{\\text{FN}}{\\text{TP}+\\text{FN}}  \\end{aligned}\\]                    TPR(True Positive Rate) : 실제 긍정인 관측치(TP+FN) 대비 옳게 예측한 관측치(TP) 비율\\[\\begin{aligned}  \\text{TPR}  &amp;=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}} = 1-\\text{FNR}  \\end{aligned}\\]                    FPR(False Possitive Rate) : 실제 부정인 관측치(TN+FP) 대비 잘못 예측한 관측치(FP) 비율\\[\\begin{aligned}  \\text{FPR}  &amp;=\\frac{\\text{FP}}{\\text{TN}+\\text{FP}}  \\end{aligned}\\]                    TNR(True Negative Rate) : 실제 부정인 관측치(TN+FP) 대비 옳게 예측한 관측치(TN) 비율\\[\\begin{aligned}  \\text{TNR}  &amp;=\\frac{\\text{TN}}{\\text{TN}+\\text{FP}} = 1-\\text{FPR}  \\end{aligned}\\]            Regression Metrics      AE(Average Error) : 오차의 합계로서 오차의 방향에 따라 크기가 상쇄되어 계산될 수 있음\\[\\begin{aligned}  \\text{AE}  &amp;=\\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)}  \\end{aligned}\\]        MSE(Mean Squared Error) : 오차 자승의 평균\\[\\begin{aligned}  \\text{MSE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}  \\end{aligned}\\]        RMSE(Root Mean Squared Error) : 오차 자승의 평균의 자승근\\[\\begin{aligned}  \\text{RMSE}  &amp;= \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^2}}  \\end{aligned}\\]        MAE(Mean Absolute Error) : 오차 절대값의 평균\\[\\begin{aligned}  \\text{MAE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\vert y_{i}-\\hat{y}_{i} \\vert}  \\end{aligned}\\]        MAPE(Mean Absolute Percentage Error) : 실제값 대비 오차 비율 절대값의 평균\\[\\begin{aligned}  \\text{MAPE}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\left\\vert \\frac{y_{i}-\\hat{y}_{i}}{y_{i}} \\right\\vert}  \\end{aligned}\\]  SplitGeneralization Problem      일반화(Generalization) : 모델링 목적으로서, 모델이 훈련 관측치에서 학습한 패턴을 사용하여 이전에 보지 못한 관측치에 대하여 예측하는 것        문제점 : 과적합 현상                      과대적합(Overfitting) : 모델이 일반적이지 않은, 즉 훈련 관측치에서만 포착되는 노이즈나 이상치까지 학습하여 신규 관측치에 대해서는 제대로 기능하지 못하는 상태                    과소적합(Underfitting) : 모델이 훈련 관측치에서 나타나는 일반적인 패턴을 충분히 학습하지 못하여 관측치의 다양성과 복잡성을 잡아내지 못하는 상태                  해결 방법 : $E_{\\text{GEN}}$ 최소화                      Training Error : Training Data Set 에 대한 오차\\[\\begin{aligned}  E_{\\text{TRN}}  &amp;= \\sum^{N_{\\text{TRN}}}_{i=1}{\\mathcal{L}\\left(y_{i},\\hat{y}_{i}\\right)}  \\end{aligned}\\]                    Generalization Error : Unseen Data Set 에 대한 오차\\[\\begin{aligned}  E_{\\text{GEN}}  &amp;= \\int{\\mathcal{L}\\left(y_{i},\\hat{y}_{i}\\right)}  \\end{aligned}\\]            Estimation      $E_{\\text{GEN}}$ 측정 상의 문제점 : Unseen Data Set 자체에 대해서 알 수 없으므로 이상적인 개념임        Split Seen Data Set : $E_{\\text{GEN}}$ 를 추정하기 위하여 추정량 $E_{\\text{VAL}}$, $E_{\\text{TST}}$ 를 제시함          Training : 모델 훈련 시 사용하는 표본으로서, 해당 표본으로부터 $E_{val}$ 을 추정함      Validation : 모델 간 성능 비교 시 사용하는 표본으로서, 해당 표본으로부터 $E_{tst}$ 를 추정함      Test : 최종 선택된 모델 성능 측정 시 사용하는 표본으로서, 해당 표본로부터 $E_{gen}$ 를 추정함      Cross Validation      교차 검증(Cross Validation) : 표본을 여러 세트로 나누어 모델을 여러 번 학습하고 평가함으로써 모델의 일반화 성능을 측정하는 절차        LOOCV(Leave-One-Out Cross Validation) : $n$ 개의 표본을 $n-1$ 개의 training 과 $1$ 개의 validation 으로 나누어 $n$ 번 학습하는 방식            k-Fold Cross Validation : $n$ 개의 표본을 $k$ 개의 데이터 세트로 나누고, $k-1$ 개는 training 으로, $1$ 개는 validation 으로 구분하여 $k$ 번 학습하는 방식      "
  },
  
  {
    "title": "What? Data Science",
    "url": "/posts/Data_Science/",
    "categories": "DATA MINING TECHS, 4.machine learning",
    "tags": "Machine Learning",
    "date": "2024-01-01 00:00:00 +0900",
    





    
    "snippet": "Data-Driven Decision MakingData-Driven Decision Making Process  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Expl...",
    "content": "Data-Driven Decision MakingData-Driven Decision Making Process  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend          Ability to Drill Down to the Root-cause      Ability to Isolate All Confounding Information        Predictive : Forcasts What Might Happned          Business Have Remained Fairly Consistent Over Time      Historical Patterns Being Used to Predict Specific Outcomes Using Algorithms      Decisions are Automated Using Algorithms and Tech.        Prescriptive : What Do I Need to Do?          Recommends Action Based On The Forecast      Applying Advanced Analytical Techs to Make Specific Recommendatons      Data-Driven Problem-Solving Process      문제 정의          어떤 문제를 해결할 것인가?이를 위해 필요한 데이터는 무엇인가?            데이터 획득          어떻게 데이터를 수집할 것인가?            데이터 탐색          데이터 전처리탐색적 자료 분석            모델링          문제에 맞는 기계학습 알고리즘 선택모델 구축            배포          제품 배포 및 시스템 유지 보수      Data Science      데이터 과학(Data Science)          정형, 비정형의 다양한 데이터로부터 지식 및 시사점을 도출하는 데 과학적 방법론을 동원하는 융합 분야(출처 : 위키백과)            빅데이터(Bigdata)          통상적으로 사용되는 데이터 수집, 관리, 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터(출처 : 위키백과)              Volume(Data Quantity)      Variety(Data Types)      Velocity(Data Speed)      Value(Data Impact)            데이터 마이닝(Data Mining)          대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 짜임을 분석하여 가치 있는 정보를 빼내는 과정(출처 : 위키백과)            기계학습(Machine Learning)          기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야(출처 : 위키백과)            인공지능(Artificial Intelligence; AI)          인간의 학습, 추론, 지각 능력을 인공적으로 구현하려는 컴퓨터 과학의 세부 분야(출처 : 위키백과)      Type of Machine Learning  지도학습(Supervised Learning) : 정답 세트가 존재하는 데이터를 활용하는 학습 방법                  판별 분석(Classificaiton Analysis) : 범주형 값을 가지는 종속변수를 예측하는 방법론                            회귀 분석(Regression Analysis) : 수치형 값을 가지는 종속변수를 예측하는 방법론                      비지도학습(Unsupervised Learning) : 정답 세트가 존재하지 않는 데이터를 활용하는 학습 방법                  군집화(Clustering) : 유사한 개체들의 집단을 만든 후 새 개체가 어떤 집단과 유사한지 예측하는 방법론                            차원축소(Dimensionality Reduction) : 고차원 데이터를 저차원 데이터로 변환하는 방법론                    Data Preprocessing      데이터 전처리(Data Preprocessing) : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정        데이터 품질에 영향을 끼치는 인자          Noise : 데이터 측정 시 무작위로 발생하여 오류를 발생시키는 문제      Outlier : 대부분의 데이터와 다른 특성을 보이거나 특정 속성의 값이 유별난 데이터      Artifact : 어떤 요인으로 인해 반복적으로 발생하는 왜곡이나 오류      Precision : 동일한 결과물을 반복적으로 측정하였을 때 각 측정값 사이의 일관성 문제      Bias : 측정 장비에 포함된 시스템 상 문제      Accuacy : 측정 장비의 한계로 정확하지 않은 수를 측정함에 따라 발생하는 문제      Inconsistent Value : 데이터 불일치 문제      Duplicate : 데이터 중복 문제      Process      Data Integration : 동일한 단위, 양식으로 데이터를 결합하는 절차    Data Cleansing : 낮은 품질의 데이터를 활용할 수 있도록 하는 절차          중복값 제거      결측치 처리      이상치 처리        Data Transformation : 데이터 형식 및 구조를 학습에 적합하도록 변환하는 절차          표준화(Standardization)      정규화(Normalization)        Data Reduction : 고차원 데이터를 저차원 데이터로 변환하는 절차Sourse  https://www.spotfire.com/glossary/what-is-regression-analysis  https://www.engati.com/glossary/classification-algorithm  https://medium.com/@baharzerenturk/hierarchical-clustering-analysis-dendogram-6b76f5f33fa8  https://www.mlguru.ai/Learn/ai-use-cases-dimensionality-reduction"
  },
  
  {
    "title": "SubTree",
    "url": "/posts/SubTree/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-12 00:00:00 +0900",
    





    
    "snippet": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 ...",
    "content": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 내역을 저장하는 폴더                    Initial Configgit clone &lt;UPSTREAM-URL&gt;cd &lt;UPSTREAM-PATH&gt;git remote add upstream &lt;UPSTREAM-URL&gt;git remote add origin &lt;ORIGIN-URL&gt;Creategit subtree add --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree add : 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 내역을 저장할 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 를 생성함Pull : Update Changes in Origin to Upstreamgit subtree pull --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree pull : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 변경 사항을 병합(pull)함Push : Update Changes in Upstream to Origingit subtree push --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree push : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에서 직접 갱신한 내역을 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 에 추가함Splitgit subtree split --prefix=&lt;SUBTREE-PATH&gt; -b &lt;NEW-BRANCH&gt;  subtree split : 하위 저장소와 연동되어 있는 폴더 &lt;SUBTREE-PATH&gt; 에 관한 커밋을 추출하여 새로운 브랜치를 생성함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Interlock",
    "url": "/posts/Interlock/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-11 00:00:00 +0900",
    





    
    "snippet": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격...",
    "content": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격 저장소의 별명 및 경로를 조회함      Interlockgit remote add &lt;NICKNAME&gt; &lt;REMOTE-REPO-PATH&gt;      remote add : 로컬 저장소에 원격 저장소를 연결함    &lt;NICKNAME&gt; : 호출 시 사용할 원격 저장소 별칭          upstream : 최상위 원격 저장소      origin : 여러 개의 원격 저장소를 위계를 세워 연동하지 않는 한 통상 해당 이름을 사용함      alt        &lt;REMOTE-REPO-PATH&gt; : 연결할 원격 저장소의 경로Renamegit remote rename &lt;EXISITING-NAME&gt; &lt;NEW-NAME&gt;  remote rename : 원격 저장소 별명을 &lt;EXISITING-NAME&gt; 에서 &lt;NEW-NAME&gt; 으로 변경함Changegit remote set-url &lt;NICKNAME&gt; &lt;NEW-PATH&gt;  remote set-url : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소 경로를 변경함Resetgit remote remove &lt;NICKNAME&gt;  remote remove : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소와의 연결을 해제함DownLoad Remote Repository복제하기git clone &lt;OPTION&gt; &lt;REMOTE-REPO-PATH&gt;      clone : 원격 저장소의 커밋 내역을 가져와서 로컬에 새로운 저장소를 생성함        &lt;OPTION&gt;          None      -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제함      --single-branch -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제 후 해당 브랜치만 추적함      --depth &lt;N&gt; : 최신 커밋 HEAD 로부터 특정 깊이까지만 복제함      가져와서 병합하기git pull &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;      pull : 원격 저장소의 커밋 내역을 가져와서 로컬 저장소의 내역과 병합함        &lt;OPTION&gt;          None : fetch + merge      -r : fetch + rebase      가져와서 임시 분기하기git fetch &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;:&lt;NEW-NAME&gt;  fetch : 원격 저장소의 커밋 내역을 가져와서 브랜치명 &lt;NEW-NAME&gt; 으로 임시 분기한 상태로 열람함          &lt;NEW-NAME&gt; 을 별도로 지정하지 않으면 FETCH_HEAD 로 자동 설정함        &lt;OPTION&gt;          None      --dry-run : 원격 저장소의 커밋 내역을 로컬로 가져오지 않고, 가져올 것이 있는지 여부만 확인      --all : 원격 저장소의 모든 브랜치에 대한 내역을 가져옴      Upload Local Changes to RemotePushgit push &lt;OPTION&gt; &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;      push : 로컬 브랜치의 커밋(변경 확정 내역)을 원격 브랜치에 반영함        &lt;OPTION&gt;          None      --all : 모든 로컬 브랜치에 대하여 기능함      --tags : 모든 로컬 태그에 대하여 기능함      --force : 충돌 시 경고를 무시하고 강제로 기능함      --dry-run : 실제로 푸시하지 않고 어떤 변경 사항이 발생할지 미리 확인함      Trackinggit push --set-upstream &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;  push --set-upstream : 현재 체크인한 로컬 브랜치를 원격 저장소 &lt;REMOTE-NICKNAME&gt; 의 브랜치 &lt;REMOTE-BRANCH-NAME&gt; 에 연동함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Branch",
    "url": "/posts/Branch/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-10 00:00:00 +0900",
    





    
    "snippet": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들...",
    "content": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들을 기록하는 브랜치                    최종본 커밋을 기록하는 브랜치에는 최종본 내역 이외의 내역을 남기지 않음                  Main Branch 에는 최종본 커밋만을 기록함          Sub Branch 에는 작업 커밋을 기록함                          방법 : Five Branch Style              Main : 최종본 커밋을 기록하는 브랜치      Develop : Feature 들을 병합하는 브랜치      Feature : Develop 로부터 작업 주제에 따라 추가 분기하는 브랜치      Release : Develop 에서 확정되어 최종본이 된 커밋을 Main 으로 배포하는 브랜치      Hot-Fix : Develop 을 거치지 않고 수정하고 싶을 때 Main 에서 임시 분기하는 브랜치      PruningSearchgit branch &lt;OPTION&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 로컬 저장소에 존재하는 브랜치 목록을 조회함      -vv : 로컬 저장소에 존재하는 브랜치 및 각 브랜치가 추적하는 원격 브랜치 목록을 조회함      Create, Rename, Deletegit branch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 현재 체크인하고 있는 커밋으로부터 분기하는 새로운 브랜치 &lt;BRANCH-NAME&gt; 를 생성함      -m : 현재 체크인하고 있는 브랜치 이름을 &lt;BRANCH-NAME&gt; 으로 변경함      -d : 브랜치 &lt;BRANCH-NAME&gt; 를 삭제함      Check-Ingit switch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      switch : 브랜치 및 커밋의 전환에 대하여 기능함        &lt;OPTION&gt;          -c : 현재 체크인하고 있는 커밋에서 분기하는 새로운 브랜치를 만들고 해당 브랜치로 체크인함      IntegrationMergegit switch &lt;OPTION&gt; &lt;BASE-BRANCH&gt;git merge &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;      merge : 현재 체크인한 브랜치에서 다른 브랜치를 병합하여 새로운 커밋을 생성함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Rebasegit switch &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;git rebase &lt;OPTION&gt; &lt;BASE-BRANCH&gt;      rebase : 현재 체크인한 브랜치 내역을 다른 브랜치와 공통분모가 되는 커밋에 삽입함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit Control",
    "url": "/posts/Commit_Control/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-09 00:00:00 +0900",
    





    
    "snippet": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석...",
    "content": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석 목록 조회      Commitgit show &lt;COMMIT-HASH&gt;      show : 특정 커밋의 정보를 상세 조회함        &lt;COMMIT-HASH&gt;          None : HEAD 커밋      Differencegit diff &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt;      diff : 커밋 간 변경 사항의 차이점을 조회함        &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt; : &lt;COMMIT-1&gt; 에만 존재하는 변경 사항  Move      커밋 전환의 이해              커밋을 이동하는 것은 변수 HEAD 가 가리키는 커밋을 변경하는 작업임            변수 HEAD 의 이해              변수 HEAD 는 현재 체크인하고 있는 브랜치를 가리키고, 각 브랜치는 마지막 커밋을 가리킴      즉, 변수 HEAD 는 현재 체크인하고 있는 브랜치를 참조하여 마지막 커밋을 간접으로 가리키게 됨            DETACHED HEAD                      정의 : HEAD 가 브랜치를 참조하지 않고 커밋을 직접 가리키는 상태                    문제점                  이동한 커밋에서 새로운 커밋을 생성하면 해당 커밋은 브랜치를 벗어나 단독으로 존재하는 상태가 됨          본래 커밋은 직접 지목되지 않고 브랜치를 참조하여 지목되므로 해당 커밋을 가리킬 방법이 없음          이러한 경우 새로운 커밋에서 시작하는 새로운 브랜치를 생성하여 해결함                    refer. Commit Hashgit switch &lt;COMMIT-HASH&gt;refer. Taggit switch tags/&lt;TAG-NAME&gt;Copy &amp; PastePaste# 커밋을 붙여넣을 브랜치로 이동git switch &lt;BRANCH-NAME&gt;# 커밋 붙여넣기git cherry-pick &lt;COMMIT-HASH&gt;  cherry-pick : 현재 위치한 브랜치에 특정 커밋을 기록함If Conflict# 충돌 사항 수정 후 해당 파일들을 스테이지에 올리기git add &lt;conflict files&gt;# 일시중지 작업에 대하여 재개 혹은 중단git cherry-pick &lt;OPTION&gt;  &lt;OPTION&gt; : 일시중지 작업에 대하여 기능함          --continue : 작업 재개      --abort : 작업 중단 및 일시중단 이전 상태로 복원      Cancel커밋 되돌리기git revert &lt;COMMIT-HASH&gt;  revert : 특정 커밋 상태로 되돌리는 새로운 커밋을 생성함커밋 삭제하기git reset &lt;OPTION&gt; &lt;COMMIT-HASH&gt;      reset : 특정 커밋 이후에 추가 기록된 커밋들을 모두 삭제하고 해당 커밋으로 되돌림        &lt;OPTION&gt;              --hard : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 해제하고, 해당 커밋 이후에 기록된 커밋을 삭제함      --mixed : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 유지하되, 해당 커밋 이후에 기록된 커밋을 삭제함      --soft : HEAD 를 해당 커밋으로 되돌리되, 파일의 modified 및 staged 상태를 유지하고, 해당 커밋 이후에 기록된 커밋을 유지함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "File Control",
    "url": "/posts/File_Control/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-08 00:00:00 +0900",
    





    
    "snippet": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&g...",
    "content": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&gt; &lt;OPTION&gt;      stash apply : 임시 저장 항목을 HEAD 커밋에 불러와서 적용함        option          None : 임시 저장 항목을 불러와서 HEAD 커밋과 병합한 후 변경 사항을 스테이지 영역에 추가함      --index : HEAD 커밋과 병합 시 충돌 사항을 조회함      임시 저장 항목 삭제하기git stash drop &lt;STASH-NAME&gt;  stash drop : 특정 임시 저장 항목을 삭제함git stash clear  stash clear : 임시 저장 목록을 초기화함파일 상태 다루기.gitignoreWORKING-DIRECTORY-PATH/.gitignore  .gitignore : 워킹 디렉토리 하위 항목 중 Git 의 추적에서 제외할 항목을 설정하는 파일rmgit rm &lt;OPTION&gt; &lt;FILE-NAME&gt;      rm : 파일을 삭제하거나 추적에서 제외함        &lt;OPTION&gt;          None : 파일을 삭제함      --cached : 파일을 untracked 상태로 전환하고 워킹 디렉토리에서는 삭제하지 않음      -r : 워킹 디렉토리의 하위 항목을 모두 삭제함      --dry-run : 명령어 실행 시 어떤 파일들이 삭제될 것인지 조회함      파일 상태 복원하기git restore &lt;OPTION&gt; &lt;FILE-NAME&gt;  restore : 파일 상태를 특정 시점으로 복원할 때 사용하는 명령어          커밋을 이동하는(변수 HEAD 의 아규먼트를 변경하는) 작업이 아니므로 detached HEAD 를 초래하지 않음      단, restore 상태에서 커밋 생성 시 detached HEAD 발생함        &lt;OPTION&gt;          None : 파일 상태를 HEAD 시점으로 복원함      --worktree : modified 파일의 상태를 HEAD 시점으로 복원함      --staged : staged 파일의 상태를 HEAD 시점으로 복원함      --source=&lt;COMMIT-HASH&gt; : 파일 상태를 특정 커밋 시점으로 복원함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit",
    "url": "/posts/Commit/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-07 00:00:00 +0900",
    





    
    "snippet": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대...",
    "content": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대기하는 상태      Committed : 변경 사항이 확정되어 브랜치에 기록된 상태      Statusgit status  status : 현재 체크인하고 있는 로컬 저장소 브랜치의 상태를 조회함          현재 위치하고 있는 로컬 브랜치      modified 파일 목록      staged 파일 목록      untracked 파일 목록      Differencegit diff &lt;OPTION&gt; &lt;FILE-NAME&gt;      diff : modified 파일의 변경 사항을 조회함        &lt;OPTION&gt;          None : unstaged area 와 stage area 간 변경 사항 조회      HEAD : unstaged area 와 최신 커밋 HEAD 간 변경 사항 조회      --staged : stage area 와 최신 커밋 HEAD 간 변경 사항 조회      Commit ProcessAddgit add &lt;FILE-NAME&gt;  add : modified 파일을 스테이지 영역에 추가함Commitgit commit &lt;OPTION&gt;      commit : staged 파일의 변경 사항을 확정하여 로컬 브랜치에 기록함        &lt;OPTION&gt;          None      -m \"COMMIT MESSAGE\" : 텍스트 에디터를 열지 않고 커멘트 창에서 커밋 메시지를 작성함      --date=\"YYYY-MM-DD HH:MM:SS\" : 커밋한 시각을 명시함      --signoff : 커밋 메시지 끝에 커밋한 사용자의 user.name 과 user.email 을 표기함      --allow-empty : 변경 사항이 없는 빈 커밋을 생성함      --amend : 현재 staged 파일들의 변경 사항을 최신 커밋에 추가 기록하여 새로운 커밋을 생성하고, 기존 커밋을 삭제함      Commit Message Rule  제목(header), 본문(body), 바닥글(footer)은 빈 행(\\n)으로 구분함  본문과 바닥글은 생략해도 무방함  제목은 50글자 이내로 제한함  제목의 첫 글자는 대문자로 작성함  제목 끝에는 마침표를 넣지 않음  제목은 명령문으로 사용하며 과거형을 사용하지 않음  본문에는 HOW 보다는 WHAT, WHY 에 대해서 서술함  본문의 각 행은 72글자 내로 제한함  바닥글에는 참조 정보를 기입함Type            type      설명                  docs      문서 갱신, 주석 추가 또는 데이터의 출처와 처리 방법 등을 문서화              feat      새로운 데이터 분석 기능이나 알고리즘 추가              fix      버그 수정 또는 데이터 정제 과정에서의 오류 수정              perf      성능 향상을 위한 코드 수정              style      코드 스타일 변경 또는 주석의 스타일 수정              refactor      데이터 처리 또는 분석 코드의 구조 변경              data      데이터셋의 추가, 업데이트, 또는 데이터 전처리과정에 관련된 작업              test      새로운 테스트 추가 또는 기존 테스트 수정              chore      빌드 시스템 설정 변경, 라이브러리 업데이트 또는 그 외 기타 작업      TagSearchgit tag -list &lt;OPTION&gt;      tag -list : 로컬 브랜치의 태그 목록을 조회함        &lt;OPTION&gt;          None : 전체 태그 목록      &lt;CONDITION.*&gt; : 키워드 CONDITION 을 포함하는 태그 목록      git show &lt;TAG-NAME&gt;      show : 특정 태그 정보를 상세조회함          태그 주석(Tag Annotation)      태그 작성자(Tagger)      태그 날짜(Date)      해당 태그가 가리키는 커밋      Creategit tag &lt;OPTION&gt; &lt;TAG-NAME&gt; &lt;COMMIT-HASH&gt;      tag : 특정 커밋에 태그를 부착함        &lt;OPTION&gt;          None : 기본 태그(LightWeight Tag)              -a : 주석 태그(Annotated Tag)          git tag -a &lt;TAG-NAME&gt; -m \"Annotation\" &lt;COMMIT-HASH&gt;                    Deletegit tag -d &lt;TAG-NAME&gt;      tag -d : 로컬 저장소의 특정 태그를 삭제함        &lt;TAG-NAME&gt;          $(git tag -l) : 로컬 저장소의 모든 태그를 삭제함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "What? GIT",
    "url": "/posts/Git/",
    "categories": "AI DEV. ENV., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-06 00:00:00 +0900",
    





    
    "snippet": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중...",
    "content": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중앙 집중 방식 : 데이터를 통합 관리하는 중앙 서버에 최종본 한 벌을 두고 로컬에서 서버에 접근하는 방식          분산 저장 방식 : 개별 노드가 네트워크를 통해 개별 노드가 확정본 변경 사항을 동기화하면서 공동으로 관리하는 방식                            버전 관리 시스템                  정의 : 확정본 및 이로부터 분기되어 변경된 사항을 추적/관리하는 시스템                      복사본을 이용한 버전 관리                                            버전 관리 시스템을 이용한 버전 관리                                            기능 및 관련 도구          병렬 작업 : Branch(데이터 형상 변경 내역 흐름)      변경점 관리 : Commit(데이터 형상 변경 내역)      확정본 관리 : Tag(데이터 변경 내역에 다는 꼬리표)      Traking Working DirectoryGit DownLoad  Git DownLoadTrackinggit initEnroll GitHub Accountgit config --global user.name &lt;NAME&gt;git config --global user.email &lt;EMAIL&gt;Configworking-directory-path/.git/config  설정 파일 config 는 워킹 디렉토리의 숨김 폴더 .git 내부에 위치함Searchgit config &lt;SCOPE&gt; &lt;FIELD&gt;      config : config 파일에 대하여 기능함    &lt;SCOPE&gt; : 범위          --system : 시스템 전체 설정      --global : 홈 디렉토리 설정      --local : 워킹 디렉토리 설정        &lt;FIELD&gt; : 아규먼트에 대하여 기능할 속성 파라미터          --list : 모든 속성 파라미터의 아규먼트를 반환함      user.name : 워킹 디렉토리에 연동할 깃허브 계정 닉네임      user.email : 워킹 디렉토리에 연동할 깃허브 계정 이메일      core.editor      color.ui      alias.[alias-name]      Setgit config &lt;SCOPE&gt; &lt;FIELD&gt; &lt;VALUE&gt;  config : config 파일에 대하여 기능함  &lt;VALUE&gt; : 필드에 할당할 아규먼트Resetgit config &lt;SCOPE&gt; &lt;OPTION&gt; &lt;FIELD&gt;  &lt;OPTION&gt;          --unset : 특정 필드의 아규먼트를 초기화함      --unset-all : 모든 필드의 아규먼트를 초기화함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Integration",
    "url": "/posts/Integration/",
    "categories": "MATHEMATICAL TECHS, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-15 00:00:00 +0900",
    





    
    "snippet": "IntegrationIntegration      적분(Integration) : 매우 작은 양을 쌓아가는 방법            미분과의 관계                  미분\\[f(x)  = F(x) \\times \\displaystyle\\frac{1}{\\Delta x}\\]                  $F(x)$ 의 $x$ 에 대한 순간변화율...",
    "content": "IntegrationIntegration      적분(Integration) : 매우 작은 양을 쌓아가는 방법            미분과의 관계                  미분\\[f(x)  = F(x) \\times \\displaystyle\\frac{1}{\\Delta x}\\]                  $F(x)$ 의 $x$ 에 대한 순간변화율 $f(x)$ 를 구하는 방법          $F(x)$ 를 $\\Delta x$ 로 잘게 쪼개는 방법                            적분\\[F(x) + C  = \\displaystyle\\sum{[f(x) \\times \\Delta x]}\\]                  $x$ 축과 피적분함수 $f(x)$ 로 둘러싸인 면적의 너비 $F(x)+C$ 를 구하는 방법          미분소($f(x) \\times \\Delta x$)를 쌓아가는 방법                    Indefinite Integral      부정적분(Indefinite Integral) : 어떤 함수 $f(x)$ 를 도함수로 하는 모든 함수 $F(x)+C$ 를 구하는 연산\\[F(x) + C = \\int{f(x)dx}\\]          $f(x)$ : $F(x)+C$ 의 피적분함수, 도함수 혹은 미분계수      $F(x)+C$ : $f(X)$ 의 부정적분함수      $C$ : 적분상수            성질          $\\displaystyle\\int{\\alpha \\cdot f(x)dx} = \\alpha \\cdot \\displaystyle\\int{f(x)dx}$      $\\displaystyle\\int{[f(x) \\pm g(x)] dx} = \\displaystyle\\int{f(x)dx} \\pm \\displaystyle\\int{g(x)dx}$      $\\displaystyle\\int{x^n dx} = \\displaystyle\\frac{x^{n+1}}{n+1} + C$      $\\displaystyle\\int{\\frac{1}{x}dx} = \\ln{\\vert x \\vert}+C$      $\\displaystyle\\int{e^{x}dx} = e^{x}+C$      $\\displaystyle\\int{\\frac{f^{\\prime}(x)}{f(x)}dx} = \\ln{\\vert f(x) \\vert}+C$      $\\displaystyle\\int{\\sin{x}dx} = -\\cos{x}+C$      $\\displaystyle\\int{\\cos{x}dx} = \\sin{x}+C$      Definite Integral      정적분(Definite Integral) : $x \\in [a,b]$ 과 피적분함수 $f(x)$ 로 둘러싸인 면적의 너비를 구하는 연산\\[\\begin{aligned}  S  &amp;= \\int_{a}^{b}{f(x)dx} \\\\  &amp;= F(b) - F(a)  \\end{aligned}\\]          $a$ : 적분의 아래 한계      $b$ : 적분의 위의 한계            성질          $\\displaystyle\\frac{d}{dx}\\displaystyle\\int_{a}^{x}{f(t)dt} = f(x)$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} = \\alpha \\displaystyle\\int_{a}^{b}{f(x)dx}$      $\\displaystyle\\int_{a}^{b}{f(x) \\pm g(x)dx} = \\displaystyle\\int_{a}^{b}{f(x)dx} \\pm \\displaystyle\\int_{a}^{b}{g(x)dx}$      $\\displaystyle\\int_{a}^{a}{\\alpha f(x)dx} = 0$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} = -\\displaystyle\\int_{b}^{a}{\\alpha f(x)dx}$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} + \\displaystyle\\int_{b}^{c}{\\alpha f(x)dx} = \\displaystyle\\int_{a}^{c}{\\alpha f(x)dx}\\,(a&lt;b&lt;c)$      Multiple Integral      중적분(Multiple Integral) : 영역 $B$ 에서 적분 가능한 다변수함수 $y=f(x_1,x_2,\\cdots,x_n)$ 에 대하여 변수 $x_1,x_2,\\cdots,x_n$ 에 대한 정적분\\[\\begin{aligned}  \\int_{x_n} \\cdots \\int_{x_2} \\int_{x_1} f(x_1,x_2,\\cdots,x_n) dx_1 dx_2 \\cdots dx_n  \\end{aligned}\\]        영역 $B$ 를 다음과 같이 정의하자\\[\\begin{aligned}  B  &amp;= [a,b]\\times[c,d]\\\\  &amp;= \\{(x,y)|a \\leq x \\leq b, c \\leq y \\leq d\\}  \\end{aligned}\\]        2변수함수 $z=f(x,y)$ 는 영역 $B$ 에서 적분 가능한 함수임\\[\\begin{aligned}  \\lim_{x \\rightarrow k-}f(x,y)=\\lim_{x \\rightarrow k+}f(x,y)=f(k,y)\\;(a \\leq k \\leq b)\\\\  \\lim_{y \\rightarrow k-}f(x,y)=\\lim_{y \\rightarrow k+}f(x,y)=f(x,k)\\;(c \\leq k \\leq d)\\\\  \\end{aligned}\\]        피적분함수 $z=f(x,y)$ 를 영역 $B$ 에서 $y$ 에 대하여 적분하면 다음과 같음\\[\\begin{aligned}  g(x)  &amp;= \\int_{c}^{d}{z}dy\\\\  &amp;= \\int_{c}^{d}{f(x,y)}dy\\\\  &amp;= F(x,d)-F(x,c)  \\end{aligned}\\]        $x$ 에 관한 함수 $g(x)$ 를 영역 $B$ 에서 $x$ 에 대하여 적분하면 다음과 같음\\[\\begin{aligned}  \\int_{a}^{b}{g(x)}dx  &amp;= G(b) - G(a)  \\end{aligned}\\]        이상을 요약하면 다음과 같음\\[\\begin{aligned}  \\int_{a}^{b}(\\int_{c}^{d}{z}dy)dx  &amp;= \\int_{a}^{b}\\int_{c}^{d}{f(x,y)}dy\\,dx  \\end{aligned}\\]  특수한 경우의 적분법부분적분: 곱셈의 적분법      $x$ 에 대하여 미분 가능한 함수 $u(x),v(x)$ 의 곱을 $x$ 에 대하여 미분하면 다음과 같음\\[\\begin{aligned}  \\frac{d}{dx}uv  &amp;= u\\frac{dv}{dx} + v\\frac{du}{dx}  \\end{aligned}\\]        양변에 $dx$ 를 곱하면 다음과 같음\\[\\begin{aligned}  d(uv)  &amp;= u \\cdot dv + v \\cdot du  \\end{aligned}\\]        양변의 일부 항목을 이항하면 다음과 같음\\[\\begin{aligned}  u \\cdot dv  &amp;= d(uv) - v \\cdot du  \\end{aligned}\\]        양변을 적분하면 다음과 같음\\[\\begin{aligned}  \\int{u \\cdot dv}  &amp;= uv - \\int{v \\cdot du}  \\end{aligned}\\]  유리함수의 적분법      진분수함수 $\\displaystyle\\frac{f(x)}{g(x)}$ 를 다음과 같이 가정하자\\[\\begin{aligned}  \\frac{f(x)}{g(x)}  &amp;= \\frac{x^3 - x^2 - 2}{x(x-1)}  \\end{aligned}\\]        $f(x)$ 를 $g(x)$ 로 나누면 다음과 같음\\[\\begin{aligned}  f(x) \\div g(x)  &amp;= \\frac{x^3 - x^2 - 2}{x(x-1)} \\\\  &amp;= \\frac{x^2(x - 1) - 2}{x(x-1)} \\\\  &amp;= x - \\frac{2}{x(x-1)}  \\end{aligned}\\]        나머지를 부분분수분해하면 다음과 같음\\[\\begin{aligned}  \\frac{2}{x(x-1)}  &amp;= 2 \\times \\frac{1}{(x-1)-x}(\\frac{1}{x}-\\frac{1}{x-1})\\\\  &amp;= -\\frac{2}{x} + \\frac{2}{x-1}  \\end{aligned}\\]        $\\displaystyle\\frac{f(x)}{g(x)}$ 를 재정의하면 다음과 같음\\[\\begin{aligned}  \\frac{f(x)}{g(x)}  &amp;= x + \\frac{2}{x} - \\frac{2}{x-1}  \\end{aligned}\\]        양변을 적분하면 다음과 같음\\[\\begin{aligned}  \\int\\frac{f(x)}{g(x)}dx  &amp;= \\int{[x + \\frac{2}{x} - \\frac{2}{x-1}]dx}\\\\  &amp;= \\int{x}dx + \\int{\\frac{2}{x}}dx - \\int{\\frac{2}{x-1}}dx  \\end{aligned}\\]  이상적분: 극한치의 적어도 한 개가 무한일 경우의 적분법      피적분함수 $f(x)=\\displaystyle\\frac{1}{x^2}$ 에 대한 정적분을 다음과 같이 가정하자\\[\\int_{1}^{\\infty}{\\frac{1}{x^2}}dx\\]        적분의 위의 한계 $\\infty$ 를 상수 $k$ 로 치환하면 다음과 같음\\[\\lim_{k\\rightarrow\\infty}{\\int_{1}^{k}{\\frac{1}{x^2}}dx}\\]        $f(x)$ 를 $[1,k]$ 에서 정적분하면 다음과 같음\\[\\begin{aligned}  \\int_{1}^{k}{\\frac{1}{x^2}}dx  &amp;= [-x^{-1}]^{k}_{1}\\\\  &amp;= -\\frac{1}{k}+1  \\end{aligned}\\]        $k\\rightarrow\\infty$ 일 때 위 식의 값은 다음과 같음\\[\\begin{aligned}  \\lim_{k\\rightarrow\\infty}{-\\frac{1}{k}+1}  &amp;= 1  \\end{aligned}\\]  "
  },
  
  {
    "title": "Partial Derivative",
    "url": "/posts/Partial_Derivative/",
    "categories": "MATHEMATICAL TECHS, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-14 00:00:00 +0900",
    





    
    "snippet": "Partial DerivativePartial Derivative      편미분(Partial Derivative) : 다변수함수 $y=f(x,\\cdots)$ 에 대하여, 변수 $x$ 를 제외한 모든 변수를 일정한 상수로 고정하였을 때 $x$ 축에 평행한 방향에 대한 $y$ 의 순간변화율        $z$ 에 대한 $x,y$ 의 2변수함수 $f$ ...",
    "content": "Partial DerivativePartial Derivative      편미분(Partial Derivative) : 다변수함수 $y=f(x,\\cdots)$ 에 대하여, 변수 $x$ 를 제외한 모든 변수를 일정한 상수로 고정하였을 때 $x$ 축에 평행한 방향에 대한 $y$ 의 순간변화율        $z$ 에 대한 $x,y$ 의 2변수함수 $f$ 를 상정하자\\[z=f(x,y)\\]        $y=b$ 로서 고정되어 있을 경우, $z$ 는 $x$ 만의 함수라고 볼 수 있음\\[z=f(x,y=b)\\]        $z$ 에 대한 $x$ 만의 함수 $f(x,y=b)$ 가 $x=a$ 에서 미분 가능하다고 하자\\[\\begin{aligned}  \\frac{\\partial}{\\partial x}f(a,b)  &amp;= \\lim_{h\\rightarrow 0}\\frac{f(a+h,b)-f(a,b)}{h}  \\end{aligned}\\]        $(a,b)$ 에서 $x$ 에 관한 편미분계수(Partial Derivatial) 를 다음과 같이 표현함\\[\\begin{aligned}  D_{x}f(x=a,y=b)  &amp;=f_{x}(x=a,y=b)\\\\  &amp;=\\frac{\\partial}{\\partial x} f(x=a,y=b)\\\\  &amp;=\\frac{\\partial z}{\\partial x}  \\end{aligned}\\]  Example      $\\text{temperature} = T(x, time)$            $\\text{temperature} = T(x,time=3)$            $\\text{temperature} = T(x) \\ (\\text{s.t.} \\, time=3)$            $\\displaystyle\\frac{d}{dx}T(x,time=3)$      Partial Derivative Function      고계편도함수 : 다변수함수에 대하여 그 편도함수의 편도함수        $z$ 에 대한 $x,y$ 의 2변수함수 $f$ 를 상정하자\\[z=f(x,y)\\]        $f$ 의 $x,y$ 에 대한 1계편도함수는 다음과 같음\\[\\begin{aligned}  f_{x}(x,y) &amp;= \\frac{\\partial}{\\partial x}f(x,y)\\\\  f_{y}(x,y) &amp;= \\frac{\\partial}{\\partial y}f(x,y)  \\end{aligned}\\]        1계편도함수의 $x,y$ 에 대한 편도함수는 다음과 같음\\[\\begin{aligned}  f_{xx}(x,y)  &amp;= (f_{x})_{x}\\\\  &amp;= \\frac{\\partial^2}{\\partial x^2}f(x,y)\\\\\\\\  f_{xy}(x,y)  &amp;= (f_{x})_{y}\\\\  &amp;= \\frac{\\partial^2}{\\partial y \\partial x}f(x,y)\\\\\\\\  f_{yx}(x,y)  &amp;= (f_{y})_{x}\\\\  &amp;= \\frac{\\partial^2}{\\partial x \\partial y}f(x,y)\\\\\\\\  f_{yy}(x,y)  &amp;= (f_{y})_{y}\\\\  &amp;= \\frac{\\partial^2}{\\partial y^2}f(x,y)  \\end{aligned}\\]  Two-variable function      2변수함수의 그래프              2변수함수 $z=f(x,y)$ 의 그래프 ${(x,y,f(x,y)) \\vert (x,y)\\in D(f)}$ 는 $xyz$-공간에서의 곡면임      Variable Points      임계점(Critical Point) : 함수의 1계편도함수 값이 $0$ 이거나 존재하지 않는 지점\\[f_x = f_y = 0\\]        극점(Local Extremum Point) : 임계점 중에서 극값을 갖는 지점              $f$ 의 임계점 $(a,b)$ 의 모든 열린 근방 $(x,y)$ 에 대하여 다음 중 하나만을 만족하는 경우                  극대점 : $f(a,b) \\leq f(x,y)$          극소점 : $f(a,b) \\ge f(x,y)$                            이는 $x,y$ 에 대한 이계편도함수가 다음을 만족함을 의미함\\[f_{xx} \\cdot f_{yy} - f^{2}_{xy} &gt; 0\\]                  안장점(Saddle Point) : 임계점 중에서 극값을 갖지 않는 점으로서, 어떤 측면에서는 극소값이 되고, 동시에 다른 측면에서는 극대값이 되는 지점              $f$ 의 임계점 $(a,b)$ 의 모든 열린 근방 $(x,y)$ 에 대하여 다음을 동시에 만족하는 경우                  $f(a,b) \\leq f(x,y)$          $f(a,b) \\ge f(x,y)$                            이는 $x,y$ 에 대한 이계편도함수가 다음을 만족함을 의미함\\[f_{xx} \\cdot f_{yy} - f^{2}_{xy} &lt; 0\\]            Hessian Matrix      헤시안 행렬(Hessian Matrix) : 어떤 이변수함수의 이계편도함수를 표현한 행렬로서, 이를 활용하여 2변수함수의 극값을 판별할 수 있음\\[\\begin{pmatrix}  f_{xx}&amp;f_{xy}\\\\  f_{xy}&amp;f_{yy}\\\\   \\end{pmatrix}\\]        헤시안 행렬의 행렬식($D$)\\[\\begin{aligned}  D  &amp;=f_{xx} \\cdot f_{yy} - f^{2}_{xy}\\\\  &amp;=\\begin{vmatrix}  f_{xx}&amp;f_{xy}\\\\  f_{xy}&amp;f_{yy}\\\\   \\end{vmatrix}  \\end{aligned}\\]        헤시안 행렬의 행렬식을 활용한 2변수함수의 극값 판별          $f_x=f_y=0$ 인 점 $(a,b)$ 의 근방에서 함수 $f$ 와 그 일계편도함수가 모두 연속이라고 하자                  $D=0$ : 극값의 존재 여부를 결정할 수 없음          $D&lt;0$ : $f$ 는 $(a,b)$ 에서 안장점을 가짐          $D&gt;0$ : $f$ 는 $(a,b)$ 에서 극값을 가짐                          $f_{xx} &lt; 0$ : 극대값              $f_{xx} &gt; 0$ : 극소값                                          Gradient      그라디언트(Gradient) : $n$ 변수함수 $y=f(x_{1},x_{2},\\cdots,x_{n})$ 에 대하여 각 변수에 대한 일계편도함수로 구성된 벡터\\[\\nabla f  =(\\frac{\\partial f}{\\partial x_{1}}, \\frac{\\partial f}{\\partial x_{2}}, \\cdots, \\frac{\\partial f}{\\partial x_{n}})^{T}\\]        해석 : \\(\\nabla f \\vert _{(x_{1},x_{2},\\cdots,x_{n})}\\) 는 점 \\((x_{1},x_{2},\\cdots,x_{n})\\) 에서 \\(f\\) 의 값이 가장 가파르게 증가하는 방향임      Lagrange Multipliers      라그랑주 승수법(Lagrange Multipliers) : 제약 조건이 주어진 최적화 문제(즉, 제한된 범위 내에서 최대값이나 최소값을 구하는 문제)를 해결하기 위한 수학적 기법으로서, 주로 다변수 함수의 최적화 문제 풀이에 사용됨\\[\\begin{aligned}  \\Theta^{*} =  \\begin{cases}  \\text{arg} \\min{\\mathcal{L}(\\Theta)} \\quad &amp; \\text{minimum}\\\\  \\text{arg} \\max{\\mathcal{L}(\\Theta)} \\quad &amp; \\text{maximun}  \\end{cases}  \\end{aligned}\\]  How to Solve  함수 정의          $f(x,y,\\cdots)$ : 목적 함수      $g_{i}(x,y,\\cdots)=0$ : $i$ 번째 등식 제약 조건      $h_{j}(x,y,\\cdots) \\le 0$ : $j$ 번째 비등식 제약 조건      $\\lambda_{i}$ : $i$ 번째 등식 제약 조건의 라그랑주 승수로서 해당 제약 조건의 영향력      $\\mu_{j}$ : $j$ 번째 비등식 제약 조건의 라그랑주 승수로서 해당 제약 조건의 영향력            라그랑주 함수 도출\\[\\begin{aligned}  &amp;\\mathcal{L}(x,y,\\cdots,\\lambda_{1}, \\cdots, \\mu_{1},\\cdots)\\\\  &amp;= f(x,y,\\cdots) + \\sum_{i}{\\lambda_{i} \\cdot g_{i}(x,y,\\cdots)} + \\sum_{j}{\\mu_{j} \\cdot h_{j}(x,y,\\cdots)}  \\end{aligned}\\]        풀이\\[\\begin{aligned}  \\nabla\\mathcal{L}(x^{*},y^{*},\\cdots,\\lambda^{*}_{1}, \\cdots, \\mu_{1}^{*}, \\cdots) = 0  \\end{aligned}\\]  KKT      KKT 조건(Karush-Kuhn-Tucker Conditions) : 비등식 제약 하 최적화 문제에서 라그랑주 승수법을 적용하기 위한 조건        1차 최적성 조건(Stationarity) : 목적 함수의 기울기와 제약 조건의 기울기가 균형을 이룸\\[\\begin{aligned}  \\nabla f(x^{*}) + \\sum_{i}{\\lambda_{i} \\cdot \\nabla g_{i}(x^{*})} + \\sum_{j}{\\mu_{j} \\cdot \\nabla h_{j}(x^{*})} = 0  \\end{aligned}\\]        제약 조건의 만족(Primal Feasibility) : 최적의 해가 주어진 제약 조건을 만족해야 함\\[\\begin{aligned}  g_{\\forall}(x^{*}) = 0, \\quad h_{\\forall}(x^{*}) \\le 0  \\end{aligned}\\]        이중성 조건 (Dual Feasibility) : 비등식 제약 조건에 대한 라그랑주 승수는 음수가 될 수 없음\\[\\begin{aligned}  \\mu_{\\forall} \\ge 0  \\end{aligned}\\]        슬랙 조건 (Complementary Slackness) : 비등식 제약 조건이 활성(active)일 때만 해당 제약 조건이 최적화 문제에 영향을 미침\\[\\begin{aligned}  \\mu_{\\forall} \\cdot h_{\\forall}(x^{*}) = 0  \\end{aligned}\\]  "
  },
  
  {
    "title": "Taylor Series",
    "url": "/posts/Taylor_Series/",
    "categories": "MATHEMATICAL TECHS, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-13 00:00:00 +0900",
    





    
    "snippet": "극점과 극값  극대점과 극대값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\ge f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극대값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극대점이라고 하고,      ...",
    "content": "극점과 극값  극대점과 극대값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\ge f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극대값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극대점이라고 하고,                          극대점(Local Maximum Point) : 주위 모든 점의 함수값 이상의 함수값을 갖는 점                                이때의 함수값 $f(c)$ 를 $y=f(x)$ 의 극대값이라고 함                          극대값(Local Maximum Value) : 극대점이 갖는 함수값                                          성질                  함수 $y=f(x)$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c(a&lt;c&lt;b)$ 에서 극대값을 가지면 다음을 만족함                          $\\displaystyle\\frac{d}{dx}f(c)=f^\\prime(c)=0$              $\\displaystyle\\frac{d^2}{dx^2}f(c)=f^{\\prime\\prime}(c)&lt;0$                                            극소점과 극소값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\le f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극소값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극소점이라고 하고,                          극대점(Local Minimum Point) : 주위 모든 점의 함수값 이상의 함수값을 갖는 점                                이때의 함수값 $f(c)$ 를 $y=f(x)$ 의 극소값이라고 함                          극대값(Local Minimum Value) : 극대점이 갖는 함수값                                          성질                  함수 $y=f(x)$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c(a&lt;c&lt;b)$ 에서 극소값을 가지면 다음을 만족함                          $\\displaystyle\\frac{d}{dx}f(c)=f^\\prime(c)=0$              $\\displaystyle\\frac{d^2}{dx^2}f(c)=f^{\\prime\\prime}(c)&gt;0$                                          테일러 급수      테일러 다항식(Taylor Polynomial) : $x=a$ 에서 미분 가능한 함수 $y=f(x)$ 에 대하여, $y=f(x)$ 와 $x=a$ 에서 근사하는 $n$ 차 함수\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{n}{\\frac{f^{k}(a)}{k!}(x-a)^{k}}\\\\  &amp;= f(a)  + f^{\\prime}(a)(x-a)  + \\frac{f^{\\prime \\prime}(a)}{2!}(x-a)^{2}  + \\cdots  + \\frac{f^{n}(a)}{n!}(x-a)^{n}  \\end{aligned}\\]        선형 근사(Linear Approximation) : $y=f(x)$ 와 $x=a$ 에서 근사하는 $1$ 차 함수 혹은 그러한 함수를 찾는 방법\\[f(x) \\approx f(a) + f^{\\prime}(a)(x-a)\\]        테일러 급수(Taylor Series) : $n$ 이 무한대로 발산하는 경우 테일러 다항식\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{\\infty}{\\frac{f^{k}(a)}{k!}(x-a)^{k}}\\\\  &amp;= f(a)  + f^{\\prime}(a)(x-a)  + \\frac{f^{\\prime \\prime}(a)}{2!}(x-a)^{2}  + \\cdots  + \\frac{f^{n}(a)}{n!}(x-a)^{n}  + \\cdots  \\end{aligned}\\]        매클로린 급수(Maclaurin’s Series) : $a=0$ 인 경우 테일러 급수\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{\\infty}{\\frac{f^{k}(0)}{k!}x^{k}}\\\\  &amp;= f(0)  + f^{\\prime}(0)x  + \\frac{f^{\\prime \\prime}(0)}{2!}x^{2}  + \\cdots  + \\frac{f^{n}(0)}{n!}x^{n}  + \\cdots  \\end{aligned}\\]  "
  },
  
  {
    "title": "Differentiation",
    "url": "/posts/Differentiation/",
    "categories": "MATHEMATICAL TECHS, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-12 00:00:00 +0900",
    





    
    "snippet": "What? Differentiation  미분(Differentiation)          설명변수 $x$ 에 대한 반응변수 $y$ 의 순간변화율      설명변수 $x$ 가 $\\Delta x$ 만큼 변화할 때 $y$ 는 얼마만큼 변화하는가            평균변화율의 이해              설명변수 $x \\in X$ 에 대한 반응변수 $y...",
    "content": "What? Differentiation  미분(Differentiation)          설명변수 $x$ 에 대한 반응변수 $y$ 의 순간변화율      설명변수 $x$ 가 $\\Delta x$ 만큼 변화할 때 $y$ 는 얼마만큼 변화하는가            평균변화율의 이해              설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여              다음을 구간 $[x,a]$ 에서 $x$ 에 대한 $y$ 의 평균변화율이라고 정의함\\[\\begin{aligned}  \\displaystyle\\frac{\\Delta y}{\\Delta x}  &amp;=\\displaystyle\\frac{f(x)-f(a)}{x-a}\\\\  &amp;=\\displaystyle\\frac{f(x +\\Delta x)-f(x)}{\\Delta x}  \\end{aligned}\\]                  순간변화율의 이해\\[\\begin{aligned}  \\displaystyle\\frac{d y}{d x}  &amp;=\\lim_{x \\rightarrow a}\\displaystyle\\frac{f(x)-f(a)}{x-a}\\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{f(x + \\Delta x)-f(x)}{\\Delta x}  \\end{aligned}\\]          $x \\rightarrow a$ 일 때 구간 $[x,a]$ 에서 $x$ 에 대한 $y$ 의 평균변화율      $\\Delta x \\rightarrow 0$ 일 때 $x$ 에 대한 $y$ 의 평균변화율      즉, $x$ 의 변화폭이 0에 한없이 가까워질 때 $y$ 의 변화폭        미분 가능하다는 말의 의미          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $x=a$ 에서 순간변화율 값이 존재하면 $f$ 는 $x=a$ 에서 미분 가능하다고 말함      모든 정의역에 대하여 미분 가능하다면 $f$ 는 $x$ 에 대하여 미분 가능하다고 말함        성질                  $x$ 에 대하여 미분 가능한 함수 $f(x), g(x)$ 와 상수 $\\alpha$ 에 대하여 다음이 성립함                  $\\displaystyle\\frac{d}{dx}\\alpha=0$          $\\displaystyle\\frac{d}{dx}(\\alpha \\times f(x)) = \\alpha \\times (\\displaystyle\\frac{d}{dx}f(x))$          $\\displaystyle\\frac{d}{dx}x^n=n \\times x^{n-1}$          $\\displaystyle\\frac{d}{dx}(f(x)\\pm g(x))=\\displaystyle\\frac{d}{dx}f(x) \\pm \\frac{d}{dx}g(x)$          $\\displaystyle\\frac{d}{dx}(f(x)\\times g(x))=(\\displaystyle\\frac{d}{dx}f(x))\\times g(x) + f(x) \\times (\\displaystyle\\frac{d}{dx}g(x))$          $\\displaystyle\\frac{d}{dx}\\displaystyle\\frac{f(x)}{g(x)}=\\big( (\\displaystyle\\frac{d}{dx}f(x))\\times g(x) - f(x) \\times (\\displaystyle\\frac{d}{dx}g(x)) \\big) \\times \\displaystyle\\frac{1}{(g(x))^2}$                    합성함수의 미분법  연쇄법칙(Chain Rule)                  $y=f(u)$ 가 $u$ 에 대하여 미분 가능하고, $u=g(x)$ 가 $x$ 에 대하여 미분 가능한 경우 다음이 성립함\\[\\begin{aligned}  \\displaystyle\\frac{dy}{dx}  &amp;=\\displaystyle\\frac{dy}{du}\\times \\displaystyle\\frac{du}{dx} \\\\  &amp;=\\displaystyle\\frac{d}{du}f(u) \\times \\displaystyle\\frac{d}{dx}g(x)  \\end{aligned}\\]              예시                  $y=(3x+2)^5$\\[\\begin{aligned}  y&amp;=u^5,\\\\  u&amp;=3x+2 \\\\\\\\  \\therefore \\displaystyle\\frac{dy}{dx}  &amp;=\\frac{d}{du}u^5 \\times \\displaystyle\\frac{d}{dx}(3x+2) \\\\  &amp;=5u^4 \\times 3 \\\\  &amp;=15(3x+2)^4  \\end{aligned}\\]            자연로그의 밑의 미분법자연로그의 밑의 이해      자연로그함수의 정의 : 기호 $e$ 로 표기되는 특정 상수를 밑으로 하는 로그함수\\[\\begin{aligned}  f(x)  &amp;=\\log_e x \\\\  &amp;=\\ln x\\\\  &amp;=\\displaystyle\\int_{1}^{x}\\displaystyle\\frac{1}{t}dt  \\end{aligned}\\]        자연로그의 밑의 정의 : 자연로그함수 $f(x)$ 에 대하여 $f(x)=1$ 을 만족하는 양의 실수 $x$\\[\\begin{aligned}  f(x)  &amp;=\\displaystyle\\int_{1}^{x}\\displaystyle\\frac{1}{t}dt \\\\  &amp;=\\log_{e} x \\\\  &amp;=1 \\\\\\\\  \\Leftrightarrow x  &amp;=e \\\\  &amp;=\\lim_{n \\rightarrow \\infty} (1+\\displaystyle\\frac{1}{n})^n \\\\  &amp;=2.71828\\cdots,\\;n\\in R  \\end{aligned}\\]  자연로그의 밑의 미분법      자연로그함수의 미분법\\[\\begin{aligned}  \\displaystyle\\frac{d}{dx}\\ln x  &amp;=\\displaystyle\\frac{d}{dx}\\displaystyle\\int_{t=1}^{x}\\displaystyle\\frac{1}{t}dt \\\\  &amp;=\\displaystyle\\frac{1}{x}  \\end{aligned}\\]        자연로그의 밑에 대한 지수함수의 미분법\\[\\begin{aligned}  f(x)  &amp;=e^x\\\\\\\\  \\displaystyle\\frac{d}{dx}f(x)  &amp;=\\displaystyle\\frac{d}{dx}e^x \\\\  &amp;=e^x  \\end{aligned}\\]          증명                              함수 정의\\[f(x)=a^x\\]                                미분 정의\\[\\begin{aligned}  \\displaystyle\\frac{d}{dx}f(x)  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{f(x+\\Delta x) - f(x)}{\\Delta x}\\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{x+\\Delta x} - a^{x}}{\\Delta x} \\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{x}(a^{\\Delta x} - 1)}{\\Delta x} \\\\  &amp;=a^{x}  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $a^x$ 소거\\[\\begin{aligned}  \\lim_{\\Delta x \\rightarrow 0}a^x \\times \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;=a^x \\\\  \\displaystyle\\frac{1}{a^x}\\times a^x \\times \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;= a^x \\times \\displaystyle\\frac{1}{a^x}\\\\  \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;= 1  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{1}{\\Delta x}$ 소거\\[\\begin{aligned}  \\displaystyle\\frac{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)}{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x}  &amp;= 1 \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\times \\frac{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)}{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x}  &amp;= 1 \\times \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $1$ 소거\\[\\begin{aligned}  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}-\\displaystyle\\lim_{\\Delta x \\rightarrow 0}1  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}-\\displaystyle\\lim_{\\Delta x \\rightarrow 0}1 + \\displaystyle\\lim_{\\Delta x \\rightarrow 0}1  &amp;= \\displaystyle\\lim_{\\Delta x \\rightarrow 0}1 + \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)  \\end{aligned}\\]                                극한의 성질에 근거하여 양변에 $\\displaystyle\\frac{1}{\\Delta x}$ 제곱\\[\\begin{aligned}  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x) \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x})^{\\frac{1}{\\Delta x}}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)^{\\frac{1}{\\Delta x}} \\\\  a  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)^{\\displaystyle\\frac{1}{\\Delta x}}  \\end{aligned}\\]                                $\\Delta x$ 를 $\\displaystyle\\frac{1}{n}$ 로 치환\\[\\begin{aligned}  a  &amp;=\\displaystyle\\lim_{n \\rightarrow \\infty}(1+\\displaystyle\\frac{1}{n})^n \\\\  &amp;=e  \\end{aligned}\\]                              삼각함수의 미분법삼각함수의 이해      각도에 대한 대변, 빗변, 이웃변 정의              대변(Homologous Side) : 각 $A$ 와 마주보는 변 $a$      이웃변(Adjoint Side) : 각 $A$ 와 이웃하는 변 $b$      빗변(Hypotenuse) : 직각 $C$ 와 마주보는 변 $c$            삼각함수(Trigonometric Function) : 각도에 대한 삼각비의 함수          삼각비(Trigonometric Ratio) : 직각삼각형 두 변의 비율              사인 함수(Sine Function; $\\sin$) : 각 $\\theta$ 에 대하여 그 빗변 대비 대변의 비율\\[\\sin \\theta = \\frac{a}{c}\\]                    코사인 함수(Cosine Function; $\\cos$) : 각 $\\theta$ 에 대하여 그 빗변 대비 이웃변의 비율\\[\\cos \\theta = \\frac{b}{c}\\]                    탄젠트 함수(Tangent Function; $\\tan$) : 각 $\\theta$ 에 대하여 그 이웃변 대비 대변의 비율\\[\\begin{aligned}  \\tan \\theta &amp;= \\frac{a}{b} \\\\  &amp;= \\frac{\\sin \\theta}{\\cos \\theta}  \\end{aligned}\\]            삼각함수의 미분법      사인 함수의 미분\\[\\frac{d}{dx}\\sin x=\\cos x\\]        코사인 함수의 미분\\[\\frac{d}{dx}\\cos x=-\\sin x\\]        탄젠트 함수의 미분\\[\\frac{d}{dx}\\tan x=\\frac{1}{\\cos^2 x}\\]  "
  },
  
  {
    "title": "Limit and Continuity",
    "url": "/posts/Limit_Continuity/",
    "categories": "MATHEMATICAL TECHS, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-11 00:00:00 +0900",
    





    
    "snippet": "극한      극한(Limiting)\\[\\begin{aligned}  y&amp;=f(x) \\\\  \\displaystyle\\lim_{x  \\rightarrow a}y&amp;=L  \\end{aligned}\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여     ...",
    "content": "극한      극한(Limiting)\\[\\begin{aligned}  y&amp;=f(x) \\\\  \\displaystyle\\lim_{x  \\rightarrow a}y&amp;=L  \\end{aligned}\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $x \\ne a$ 이면서 $x$ 가 $a$ 에 한없이 가까워질 때 $y$ 가 일정한 값 $L$ 에 가까워지는 경우      $y$ 는 $x  \\rightarrow a$ 일 때 $L$ 에 수렴한다(Converge) 라고 정의함      또한 $L$ 를 $x  \\rightarrow a$ 인 경우 $y$ 의 극한(Limiting) 이라고 정의함            좌극한과 우극한\\[\\displaystyle\\lim_{x  \\rightarrow a}f(x)=L \\Rightarrow \\displaystyle\\lim_{x  \\rightarrow a-0}f(x)=\\displaystyle\\lim_{x  \\rightarrow a+0}f(x)=L\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $f$ 가 값 $a$ 에서 극한이 존재하면      그 좌극한 $x  \\rightarrow a-0$ 과 우극한 $x  \\rightarrow a+0$ 이 존재하고, 그 값이 서로 같음            성질                  $\\displaystyle\\lim_{x  \\rightarrow a}f(x), \\displaystyle\\lim_{x  \\rightarrow a}g(x)$ 가 존재하는 경우 다음이 성립함                  $\\displaystyle\\lim_{x  \\rightarrow a}\\alpha f(x)=\\alpha\\displaystyle\\lim_{x  \\rightarrow a}f(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}(f(x)+g(x))=\\displaystyle\\lim_{x  \\rightarrow a}f(x)+\\displaystyle\\lim_{x  \\rightarrow a}g(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}(f(x) \\times g(x))=\\displaystyle\\lim_{x  \\rightarrow a}g(x) \\times \\displaystyle\\lim_{x  \\rightarrow a}f(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}\\frac{f(x)}{g(x)}=\\frac{\\displaystyle\\lim_{x  \\rightarrow a}f(x)}{\\displaystyle\\lim_{x  \\rightarrow a}g(x)}\\;(s.t.\\displaystyle\\lim_{x  \\rightarrow a}g(x) \\ne 0)$                    연속      연속성(Continuity)\\[f(a)=\\displaystyle\\lim_{x  \\rightarrow a}f(x)\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $f$ 가 $x=a$ 에서 함수값과 극한값이 모두 존재하고 그 값이 같을 때      $y=f(x)$ 는 $x=a$ 에서 연속이라고 정의함            연속함수(Continuous Function)\\[f(a)=\\displaystyle\\lim_{x  \\rightarrow a}f(x), \\; a \\in X=R\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      정의역 $X$ 를 모든 실수 $R$ 라고 정의하자      $f$ 가 정의역에 대하여 연속이면 $f$ 를 연속함수라고 정의함      자연로그의 밑      자연로그의 밑 $e$ 의 정의\\[\\begin{aligned}  e&amp;=\\displaystyle\\lim_{n \\rightarrow \\infty}(1+\\frac{1}{n})^n\\\\  &amp;=2.71818\\cdots,\\;n \\in R  \\end{aligned}\\]        자연로그의 정의\\[\\ln x=\\log_e x=a \\Leftrightarrow x=e^a\\]    예시                  $f(x)=\\displaystyle\\lim_{x\\rightarrow 0}(1+3x)^{\\frac{1}{x}}$\\[\\begin{aligned}  n=\\frac{1}{x} \\Rightarrow   f(x)  &amp;=\\displaystyle\\lim_{n\\rightarrow \\infty}(1+\\frac{3}{n})^n\\\\  &amp;=\\displaystyle\\lim_{n\\rightarrow \\infty}(1+\\frac{3}{\\frac{1}{3}n})^{3 \\times \\frac{1}{3}n}\\\\  &amp;=e^3  \\end{aligned}\\]              연속복리와 $e$          복리의 이해                              원금 $a$ 를 연이율 $r$ 로 $n$ 년간 복리예금 시 원리금 $S$ 를 다음과 같이 정의함\\[S=a(1+r)^n\\]                              연속복리 : 가장 짧은 시간 간격으로 취하는 복리                  원금 $a$ 를 연이율 $r$ 로 $n$ 년간 복리예금한다고 하자                      $n$ 년간 $m$ 번 이자를 계산하는 경우 원리금 $S$ 를 다음과 같이 정의함\\[S=a[(1+\\frac{r}{m})^m]^n\\]                                $m$ 이 무한대로 발산한다고 했을 때 원리금 $S$ 를 다음과 같이 정의함\\[\\begin{aligned}  \\lim_{m \\rightarrow \\infty} S  &amp;=\\lim_{m \\rightarrow \\infty} a[(1+\\frac{r}{m})^m]^n \\\\  &amp;=\\lim_{m \\rightarrow \\infty} a[(1+\\frac{1}{\\frac{1}{r}m})^{r \\times \\frac{1}{r}m}]^{n} \\\\  &amp;=a\\times e^{r \\times n}  \\end{aligned}\\]                              "
  },
  
  {
    "title": "Matrix Decomposition",
    "url": "/posts/Matrix_Decomposition/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-09 00:00:00 +0900",
    





    
    "snippet": "Matrix Decomposition      정의 : 하나의 행렬을 특정한 구조를 가진 다른 행렬의 합과 곱으로 나타내는 작업        종류          스펙트럼 분해(Spectral Decomposition) : 대칭행렬에 대한 분해      특이값 분해(Singular Value Decomposition; SVD) : 비대칭행렬에 대한 분...",
    "content": "Matrix Decomposition      정의 : 하나의 행렬을 특정한 구조를 가진 다른 행렬의 합과 곱으로 나타내는 작업        종류          스펙트럼 분해(Spectral Decomposition) : 대칭행렬에 대한 분해      특이값 분해(Singular Value Decomposition; SVD) : 비대칭행렬에 대한 분해      Spectral Decomposition      대칭행렬 $A_{n \\times n}$ 와 그 고유값 $ \\vert \\lambda_{1} \\vert \\ge \\vert \\lambda_{2} \\vert \\ge \\cdots \\ge \\vert \\lambda_{n} \\vert$, 고유벡터 $\\overrightarrow{v_{1}},\\overrightarrow{v_{2}},\\cdots,\\overrightarrow{v_{n}}$ 에 대하여, 직교행렬 $P$ 와 대각행렬 $\\Lambda$ 를 다음과 같이 정의하자\\[\\begin{aligned}  P  &amp;= \\begin{bmatrix} \\overrightarrow{v_{1}} &amp; \\overrightarrow{v_{2}} &amp; \\cdots &amp; \\overrightarrow{v_{n}} \\end{bmatrix} \\\\  \\Lambda  &amp;= diag(\\lambda_1, \\lambda_2, \\cdots, \\lambda_n)  \\end{aligned}\\]        $A_{n \\times n}$ 를 다음과 같이 분해하는 작업을 스펙트럼 분해라고 정의함\\[\\begin{aligned}  A  &amp;= P \\Lambda P^{T} \\\\  &amp;= \\lambda_1 \\overrightarrow{v_{1}} \\overrightarrow{v_{1}^T} + \\lambda_2 \\overrightarrow{v_{2}} \\overrightarrow{v_{2}^T} + \\cdots + \\lambda_n \\overrightarrow{v_{n}} \\overrightarrow{v_{n}^T} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n}\\lambda_i \\overrightarrow{v_{i}} \\overrightarrow{v_{i}^T}  \\end{aligned}\\]  Singular Value DecompositionSVD      비대칭행렬 $A_{m \\times n}$ 에 대하여 다음과 같이 분해하는 작업을 특이값 분해라고 정의함\\[\\begin{aligned}  A_{m \\times n}  =  \\begin{cases}  U_{n \\times m} D_{m \\times m} (V_{n \\times m})^T\\;&amp;if\\;m \\le n \\\\  U_{m \\times n} D_{n \\times n} (V_{n \\times n})^T\\;&amp;if\\;n \\le m \\\\  \\end{cases}  \\end{aligned}\\]        행렬 $U$ 는 행렬 $AA^{T}(=(A^{T}A)^T)$ 의 고유벡터 $\\overrightarrow{u}$ 의 집합임\\[\\begin{aligned}  U &amp;= \\begin{bmatrix} \\overrightarrow{u_1}&amp;\\overrightarrow{u_2}&amp;\\cdots&amp;\\overrightarrow{u_k} \\end{bmatrix}\\\\  k &amp;= \\min (m, n)\\\\  &amp;= rank(A)\\\\  \\overrightarrow{u_i}   &amp;\\in \\{\\overrightarrow{u}\\,|\\,AA^{T}\\overrightarrow{u} = \\lambda \\overrightarrow{u}\\}  \\end{aligned}\\]        행렬 $V$ 는 행렬 $A^{T}A(=(AA^{T})^T)$ 의 고유벡터 $\\overrightarrow{v}$ 의 집합임\\[\\begin{aligned}  U  &amp;= \\begin{bmatrix} \\overrightarrow{v_1}&amp;\\overrightarrow{v_2}&amp;\\cdots&amp;\\overrightarrow{v_k} \\end{bmatrix}\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)\\\\  \\overrightarrow{v_i}  &amp;\\in \\{\\overrightarrow{v}\\,|\\,A^{T}A\\overrightarrow{v} = \\lambda \\overrightarrow{v}\\}  \\end{aligned}\\]        행렬 $D$ 는 행렬 $AA^{T}$ 혹은 그 전치행렬 $A^{T}A$ 의 고유값의 제곱근 $\\sqrt{\\lambda_1} \\ge \\sqrt{\\lambda_2} \\ge \\cdots \\ge \\sqrt{\\lambda_k} &gt; 0$ 을 대각원소로 가지는 대각행렬임\\[\\begin{aligned}  D  &amp;= diag(\\sqrt{\\lambda_1}, \\sqrt{\\lambda_2}, \\cdots, \\sqrt{\\lambda_k}) \\\\  &amp;= \\begin{pmatrix}  \\sqrt{\\lambda_1} &amp; 0 &amp; \\cdots &amp; 0 \\\\  0 &amp; \\sqrt{\\lambda_2} &amp; \\cdots &amp; 0 \\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\  0 &amp; 0 &amp; \\cdots &amp; \\sqrt{\\lambda_k}  \\end{pmatrix} \\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]  Singular Value &amp; Vector      특이값(Singular Value) : 대각행렬 $D$ 의 대각원소로서, 행렬 $AA^{T}$ 혹은 그 전치행렬 $A^{T}A$ 의 고유값의 제곱근\\[\\sqrt{\\lambda_1} \\ge \\sqrt{\\lambda_2} \\ge \\cdots \\ge \\sqrt{\\lambda_k} &gt; 0\\]        왼쪽 특이벡터(Left Singular Vector) : 행렬 $U$ 의 열벡터로서 행렬 $AA^{T}$ 의 고유벡터\\[\\begin{aligned}  \\overrightarrow{u_i}   &amp;\\in \\{\\overrightarrow{u}\\,|\\,AA^{T}\\overrightarrow{u} = \\lambda \\overrightarrow{u}\\},\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]        오른쪽 특이벡터(Right Singular Vector) : 행렬 $V$ 의 열벡터로서 행렬 $AA^{T}$ 의 전치행렬 $A^{T}A$ 의 고유벡터\\[\\begin{aligned}  \\overrightarrow{v_i}  &amp;\\in \\{\\overrightarrow{v}\\,|\\,A^{T}A\\overrightarrow{v} = \\lambda \\overrightarrow{v}\\},\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]        특이값 분해의 전개\\[\\begin{aligned}  A_{m \\times n}  &amp;=  \\begin{cases}  U_{n \\times m} D_{m \\times m} (V_{n \\times m})^T\\;if\\;m \\le n \\\\  U_{m \\times n} D_{n \\times n} (V_{n \\times n})^T\\;if\\;n \\le m \\\\  \\end{cases} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{\\min (m,n)} \\sqrt{\\lambda_i} u_i v_i^T  \\end{aligned}\\]  "
  },
  
  {
    "title": "Eigen",
    "url": "/posts/Eigen/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-08 00:00:00 +0900",
    





    
    "snippet": "고유값과 고유벡터      정의\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n...",
    "content": "고유값과 고유벡터      정의\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]          고유값(Eigen-Value; $\\lambda$) : 정방행렬 $A$ 에 대하여 위 식을 만족하는 상수 $\\lambda$      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A$ 에 대하여 위 식을 만족하는 $\\overrightarrow{0}$ 이 아닌 벡터 $\\overrightarrow{v}$            기하학적 의미                  어떤 벡터 $\\overrightarrow{v}$ 에 대하여 행렬 $A$ 로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 경우                  $\\overrightarrow{v}$ : $A$ 의 고유벡터(Eigen-Vactor)          $\\lambda$ : $A$ 의 고유값(Eigen-Value) 으로서 선형변환 전 크기 대비 선형변환 후 크기의 비율                            Rotation Matrix 와 고유값\\[A  = \\begin{pmatrix} \\cos \\theta &amp; -\\sin \\theta \\\\ \\sin \\theta &amp; \\cos \\theta \\end{pmatrix}\\]                  행렬 $A$ 의 고유벡터는 $A$ 를 통해 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 벡터라고 정의함          행렬 $A$ 가 Rotation Matrix 인 경우, 그 회전변환 각도 $\\theta$ 가 $0^{\\circ}, 180^{\\circ}, 360^{\\circ}$ 인 경우에만 고유벡터가 존재함                      성질                  행렬 $A$ 의 고유값 $\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{n}$ 과 고유벡터 $\\overrightarrow{v_{1}},\\overrightarrow{v_{2}},\\cdots,\\overrightarrow{v_{n}}$ 에 대하여 다음이 성립함                  $tr(A)=\\displaystyle\\sum_{i=1}^{n}\\lambda_{i}$          $det(A)=\\displaystyle\\prod_{i=1}^{n}\\lambda_{i}$          행렬 $A$ 의 고유값 $\\lambda_{i}=0$ 이면 $A$ 는 특이행렬임          행렬 $A$ 의 고유값 $\\lambda_{i} \\ne \\lambda_{j}\\;(i \\ne j)$ 이면 고유벡터들은 선형 독립임          행렬 $A$ 의 고유값과 그 전치행렬 $A^{T}$ 의 고유값은 동일함                      계산 방법                  고유방정식(Eigenvalue Equation) 혹은 특성방정식(Characteristic Equation)\\[\\begin{aligned}  A \\overrightarrow{v}   &amp;= \\lambda \\overrightarrow{v} \\\\  A \\overrightarrow{v} - \\lambda \\overrightarrow{v}   &amp;= \\overrightarrow{0} \\\\  \\therefore (A-\\lambda I)\\overrightarrow{v}   &amp;= \\overrightarrow{0}  \\end{aligned}\\]                  행렬 $A$ 에 대하여 그 고유방정식 $(A-\\lambda I)\\overrightarrow{v} = \\overrightarrow{0}$ 의 해 $\\lambda$ 를 $A$ 의 고유값, $\\overrightarrow{v}$ 를 $A$ 의 고유벡터라고 함                            해가 존재할 조건                              행렬 $A - \\lambda I$ 에 대하여 그 역행렬이 존재하면 고유방정식의 해는 불능임\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= (A - \\lambda I)^{-1} \\overrightarrow{0} \\\\  &amp;= \\overrightarrow{0}  \\end{aligned}\\]                                행렬 $A$ 의 고유방정식 $(A - \\lambda I)\\overrightarrow{v} = \\overrightarrow{0}$ 의 해가 존재하기 위해서는 행렬 $A - \\lambda I$ 의 역행렬이 존재하지 않아야 함\\[\\left\\lvert A - \\lambda I \\right\\rvert = 0\\]                              행렬의 대각화      행렬의 대각화(Diagonalization)\\[\\begin{aligned}  P^{-1}AP   &amp;= \\Lambda \\\\  &amp;= diag(a_{11},a_{22},\\cdots,a_{nn})  \\end{aligned}\\]          정방행렬 $A$ 에 대하여 $P^{-1}AP$ 가 대각행렬 $\\Lambda$ 가 되도록 만드는 정방행렬 $P\\;(\\vert P \\vert \\ne 0)$ 가 존재하는 경우      행렬 $A$ 를 대각화(Diagonalization) 할 수 있는 행렬이라고 함      행렬 $P$ 가 행렬 $A$ 를 대각화시킨다고 표현함            대칭행렬의 대각화                  대칭행렬 $A\\;(a_{ij}=a_{ji})$ 에 대하여 그 고유값이 $\\lambda_1,\\lambda_2,\\cdots,\\lambda_n$ 이고, 고유벡터가 $\\overrightarrow{v_1},\\overrightarrow{v_2},\\cdots,\\overrightarrow{v_n}$ 이라고 하자                    고유벡터 $\\overrightarrow{v_{i^{\\forall}}}, \\overrightarrow{v_{j^{\\forall}}}\\;(i \\ne j)$ 는 직교함\\[\\overrightarrow{v_i} \\perp \\overrightarrow{v_j}\\]                    고유벡터들로 구성된 직교행렬 $P=\\begin{bmatrix}\\overrightarrow{v_1}&amp;\\overrightarrow{v_2}&amp;\\cdots&amp;\\overrightarrow{v_n}\\end{bmatrix}$ 은 $A$ 를 그 고유값들로 구성된 대각행렬 $\\Lambda$ 로 대각화시킴\\[\\begin{aligned}  P^{-1}AP  &amp;= \\Lambda \\\\  &amp;= diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)  \\end{aligned}\\]            "
  },
  
  {
    "title": "Linear Transformation",
    "url": "/posts/Linear_Transformation/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-07 00:00:00 +0900",
    





    
    "snippet": "Linear Transformation선형변환      정의 : 하나의 벡터를 입력하여 다른 벡터를 출력하는 함수            기하학적 의미 : 평면을 휘어트리지 않는 선에서 벡터 공간을 늘리고 뒤틀어서 입력 벡터가 나타내는 직선을 출력 벡터가 나타내는 직선으로 변화하는 과정        성질          $L(\\overrightarrow{...",
    "content": "Linear Transformation선형변환      정의 : 하나의 벡터를 입력하여 다른 벡터를 출력하는 함수            기하학적 의미 : 평면을 휘어트리지 않는 선에서 벡터 공간을 늘리고 뒤틀어서 입력 벡터가 나타내는 직선을 출력 벡터가 나타내는 직선으로 변화하는 과정        성질          $L(\\overrightarrow{v} + \\overrightarrow{w}) = L(\\overrightarrow{v}) + L(\\overrightarrow{w})$      $L(\\alpha \\times \\overrightarrow{v}) = \\alpha L(\\overrightarrow{v})$            선형변환을 통한 행렬과 벡터 곱의 이해          행렬 \\(A = \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\) 과 벡터 \\(\\overrightarrow{v} = \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\) 의 곱은 \\(\\overrightarrow{v}\\) 에 대하여 단위벡터를 기저로 사용하는 직교좌표계에서 \\(A\\) 의 열벡터 \\(\\overrightarrow{a_1}=\\begin{pmatrix} 1\\\\-2 \\end{pmatrix}, \\overrightarrow{a_2}=\\begin{pmatrix} 3\\\\0 \\end{pmatrix}\\) 를 기저로 사용하는 좌표계로의 선형변환으로 이해할 수 있음    \\[\\begin{aligned}  L(\\overrightarrow{v})  &amp;= L(\\begin{pmatrix} 1\\\\-2 \\end{pmatrix}) \\\\  &amp;= L(-1 \\overrightarrow{i} + 2 \\overrightarrow{j}) \\\\  &amp;= -1L(\\overrightarrow{i}) + 2L(\\overrightarrow{j}) \\\\  &amp;= -1 \\begin{pmatrix} 1\\\\-2 \\end{pmatrix} + 2\\begin{pmatrix} 3\\\\0 \\end{pmatrix} \\\\  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\begin{pmatrix} -1\\\\2 \\end{pmatrix} \\\\  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\overrightarrow{v}  \\end{aligned}\\]  기저의 변환과 좌표      벡터 \\(\\overrightarrow{v}=\\begin{pmatrix}-1\\\\2\\end{pmatrix}\\) 는 단위벡터 \\(\\overrightarrow{i}=\\begin{pmatrix}1\\\\0\\end{pmatrix}, \\overrightarrow{j}=\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 직교좌표계의 좌표 \\((x, y) = (-1, 2)\\) 을 의미함\\[\\begin{aligned}  \\begin{pmatrix}  -1\\\\  2  \\end{pmatrix}  &amp;= -1   \\begin{pmatrix}  1\\\\  0  \\end{pmatrix}  + 2  \\begin{pmatrix}  0\\\\  1  \\end{pmatrix}  \\end{aligned}\\]        선형변환 \\(L(\\overrightarrow{v})\\) 를 통해 입력벡터 \\(\\overrightarrow{v}\\) 는 출력벡터 \\(\\begin{pmatrix}5\\\\2\\end{pmatrix}\\) 로 변환되었음\\[\\begin{aligned}  L(\\overrightarrow{v})  &amp;= \\begin{pmatrix}5\\\\2\\end{pmatrix}  \\end{aligned}\\]        출력벡터 \\(\\begin{pmatrix}5\\\\2\\end{pmatrix}\\) 는 벡터 \\(L(\\overrightarrow{i})=\\begin{pmatrix}1\\\\-2\\end{pmatrix}, L(\\overrightarrow{j})=\\begin{pmatrix}3\\\\0\\end{pmatrix}\\) 를 기저로 사용하는 변환된 좌표계의 좌표 \\((x, y) = (-1, 2)\\) 을 의미함\\[\\begin{aligned}  \\begin{pmatrix}5\\\\2\\end{pmatrix}  &amp;= -1 \\begin{pmatrix}1\\\\-2\\end{pmatrix} + 2 \\begin{pmatrix}3\\\\0\\end{pmatrix}  \\end{aligned}\\]  특별한 선형변환      Rotation Matrix : 반시계 방향으로 $\\theta^{\\circ}$ 회전하는 선형변환    \\[\\begin{pmatrix}  \\cos \\theta &amp; -\\sin \\theta \\\\  \\sin \\theta &amp; \\cos \\theta  \\end{pmatrix}\\]        Scaling Matrix : $X$ 축을 $\\alpha$ 배, $Y$ 축을 $\\beta$ 배 늘리는 선형변환    \\[\\begin{pmatrix}  \\alpha &amp; 0 \\\\  0 &amp; \\beta  \\end{pmatrix}\\]        Shearing Matrix : 각 축의 기저벡터를 변형시키는 선형변환                      Horizontal Shearing Matrix(Shear in \\(X\\)) : \\(X\\) 축의 기저벡터는 그대로, \\(Y\\) 축의 단위벡터는 \\(\\begin{pmatrix} s\\\\1 \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;s\\\\0&amp;1 \\end{pmatrix}\\]                    Vertical Shearing Matrix(Shear in \\(Y\\)) : \\(Y\\) 축의 기저벡터는 그대로, \\(X\\) 축의 단위벡터는 \\(\\begin{pmatrix} 1\\\\s \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;0\\\\s&amp;1 \\end{pmatrix}\\]                    Arbitrary Shearing Matrix : \\(X\\) 축의 기저벡터는 \\(\\begin{pmatrix} 1\\\\ t \\end{pmatrix}\\) 으로, \\(Y\\) 축의 단위벡터는 \\(\\begin{pmatrix} s\\\\ 1 \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;s\\\\ t&amp;1 \\end{pmatrix}\\]            Determinant      행렬식(Determinant; $det$) : 행렬로 표현되는 선형변환의 어떤 특성을 표현하는 값\\[\\vert A \\vert  = \\displaystyle\\sum_{\\sigma \\in S_n} (sgn(\\sigma) \\prod_{i=1}^{n}a_{i,\\sigma_{i}})\\]          $S_n$ : ${1,2,\\cdots,n}$ 의 모든 순열      $\\sigma_i$ : $S_n$ 의 원소 중 하나인 $\\sigma$ 의 $i$ 번째 원소      $sgn(\\sigma)$ : 주어진 순열을 연속적으로 짝수만큼 움직였을 때 재정렬되면 $1$, 아니면 $-1$의 값을 가지는 규칙            행렬식의 기하학적 의미 : 행렬 $A$ 에 의한 선형변환이 변화시키는 면적의 비율 $c$            $det(A)=0$ 인 경우의 기하학적 의미\\[\\begin{aligned}  A  &amp;= \\begin{pmatrix} 4&amp;2 \\\\ 2&amp;1 \\end{pmatrix} \\\\  &amp;= \\begin{bmatrix} \\overrightarrow{a_1} &amp; \\overrightarrow{a_2} \\end{bmatrix}  \\end{aligned}\\]                  $det(A)=0$ 이면 행렬 $A$ 의 열벡터는 선형 종속임\\[\\begin{aligned}  \\overrightarrow{a_1}  &amp;= 2 \\times \\overrightarrow{a_2}  \\end{aligned}\\]                    $A$ 에 의한 선형변환은 모든 점을 $1$ 차원 직선에 $mapping$ 하여 그 면적을 $0$ 으로 만듦\\[\\begin{aligned}  \\begin{pmatrix} 4&amp;2 \\\\ 2&amp;1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}  = \\begin{pmatrix} 10 \\\\ 5 \\end{pmatrix}  \\end{aligned}\\]              해석          $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 계수는 $n$ 임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음        성질          $det(\\alpha)=\\alpha$      $det(I)=1$      $det(A)=det(A^T)$      $det(A^{-1})=det(A)^{-1}$      $det(AB)=det(A) \\times det(B)$      $det(\\alpha \\times A_n)=\\alpha^n \\times det(A_n)$      $\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_i} \\cdots \\overrightarrow{a_j} \\end{vmatrix}=-\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_j} \\cdots \\overrightarrow{a_i} \\end{vmatrix}$      $\\begin{vmatrix}\\alpha \\times a &amp; \\alpha \\times b \\ c &amp; d\\end{vmatrix} = \\alpha \\times \\begin{vmatrix}a&amp;b\\ c&amp;d\\end{vmatrix}$        계산 방법          $det(A_2)=a_{11}a_{22}-a_{12}a_{21}$      삼각행렬에 대하여 그 행렬식은 대각항 원소들의 곱으로 구할 수 있음      $3\\times 3$ 이상의 정방행렬에 대하여 그 행렬식은 가우스-조르단 소거법(Gaussian Elimination)으로 구함      "
  },
  
  {
    "title": "Linear Equation",
    "url": "/posts/Linear_Equation/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-06 00:00:00 +0900",
    





    
    "snippet": "Linear Equation선형방정식      정의 : 최고차 항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  &amp; a_1x_1 + a_2x_2 + \\cdots + a_nx_n  = b  \\end{aligned}\\]        선형방정식을 벡터로 표현하면 다음과 같음\\[\\begin{aligne...",
    "content": "Linear Equation선형방정식      정의 : 최고차 항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  &amp; a_1x_1 + a_2x_2 + \\cdots + a_nx_n  = b  \\end{aligned}\\]        선형방정식을 벡터로 표현하면 다음과 같음\\[\\begin{aligned}  \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}  \\begin{pmatrix}x_1\\\\x_2\\\\ \\vdots\\\\ x_n \\end{pmatrix}  = b  \\end{aligned}\\]        이때 벡터 $\\overrightarrow{a}$ 는 방정식의 계수들을 나열하고 있음\\[\\begin{aligned}  \\overrightarrow{a}^T \\overrightarrow{x}  = b  \\end{aligned}\\]  선형연립반정식      정의 : 둘 이상의 선형방정식의 집합\\[\\begin{aligned}  \\begin{matrix}  a_{11}x_1 &amp; + &amp; a_{12}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1 \\\\  a_{21}x_1 &amp; + &amp; a_{22}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2 \\\\  \\vdots &amp; + &amp; \\vdots &amp; + &amp; \\ddots &amp; + &amp; \\vdots &amp; = &amp; \\vdots \\\\  a_{m1}x_1 &amp; + &amp; a_{m2}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m  \\end{matrix}  \\end{aligned}\\]        선형연립방정식을 행렬로 표현하면 다음과 같음\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{m1}&amp;a_{m2}&amp;\\cdots&amp;a_{mn}  \\end{pmatrix}  \\begin{pmatrix}x_1\\\\x_2\\\\\\vdots\\\\ x_n \\end{pmatrix}      &amp;= \\begin{pmatrix}b_1\\\\ b_2\\\\ \\vdots\\\\ b_m \\end{pmatrix}  \\end{aligned}\\]  첨가 행렬      정의 : 선형연립방정식 계수들의 집합으로서 벡터 $\\overrightarrow{x}$ 를 선형변환하는 행렬\\[\\begin{aligned}  A \\overrightarrow{x}  &amp;= \\overrightarrow{b}  \\end{aligned}\\]        첨가 행렬 $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 을 구분하여 표현할 수 있음\\[\\begin{aligned}  \\overrightarrow{a_1} x_1 + \\overrightarrow{a_2} x_2 + \\cdots + \\overrightarrow{a_n} x_n  &amp;= \\overrightarrow{b}  \\end{aligned}\\]  선형방정식의 갯수와 미지수의 갯수가 같은 경우첨가 행렬의 역행렬과 방정식의 해\\[\\begin{aligned}\\begin{pmatrix} a_{11}&amp;a_{12}\\\\ a_{21}&amp;a_{22} \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} b_1\\\\ b_2 \\end{pmatrix}\\Leftrightarrow A \\overrightarrow{x} = \\overrightarrow{b}\\end{aligned}\\]      크기가 $n \\times n$ 인 첨가 행렬 $A$ 에 대하여 그 역행렬 $A^{-1}$ 이 존재할 조건          $Rank(A_n)=n$      $det(A) \\ne 0$      $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 를 $span$ 하여 $n$ 차원 공간을 구성할 수 없음      $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 는 모두 선형 독립임            첨가 행렬 $A$ 에 대하여 그 역행렬이 존재하면 단 하나의 해가 존재함            첨가 행렬 $A$ 에 대하여 그 역행렬이 존재하지 않으면 불능이거나 부정임                  불능(Underdetermined) : 해를 구할 수 없음                            부정(Inconsistent, Impossible) : 해가 무수히 많아 하나로 정할 수 없음                    해가 하나 존재하는 경우의 기하학적 이해\\[\\begin{pmatrix} 7&amp;2\\\\ -7&amp;5 \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} -5\\\\ 12 \\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix} 7\\\\ -7 \\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix} 2\\\\ 5 \\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix} -5\\\\ 12 \\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 있음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 독립임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $2$ 차원 평면에 $\\overrightarrow{b}$ 가 포함됨    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 있음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 종속임      해를 구할 수 없는 경우의 이해\\[\\begin{pmatrix} 5&amp;5\\\\ 5&amp;5 \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} 10\\\\ 20 \\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix} 5\\\\ 5 \\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix} 5\\\\ 5 \\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix} 10\\\\ 20 \\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 없음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 종속임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $1$ 차원 직선에 $\\overrightarrow{b}$ 가 포함되지 않음    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 없음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 독립임      해가 무수히 많은 경우의 이해\\[\\begin{pmatrix}1&amp;1\\\\2&amp;2\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}=\\begin{pmatrix}10\\\\20\\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix}1\\\\2\\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix}1\\\\2\\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix}10\\\\20\\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 없음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 종속임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $1$ 차원 직선에 $\\overrightarrow{b}$ 가 포함됨    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 있음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 종속임      선형방정식의 갯수와 미지수의 갯수가 다른 경우선형방정식의 갯수보다 미지수의 갯수가 더 많은 경우\\[\\begin{pmatrix}1&amp;2&amp;3\\\\1&amp;5&amp;1\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\end{pmatrix}=\\begin{pmatrix}2\\\\1\\end{pmatrix}\\LeftrightarrowA\\overrightarrow{x}= \\overrightarrow{b}\\]  하나의 방정식을 만족하는 벡터 $\\overrightarrow{x}$ 는 $3$ 차원 공간의 $2$ 차원 평면을 구성함  두 방정식을 동시에 만족하는 벡터 $\\overrightarrow{x}$ 는 두 평면이 교차하는 $1$ 차원 직선의 모든 점임미지수의 갯수보다 선형방정식의 갯수가 더 많은 경우\\[\\begin{pmatrix}0&amp;1\\\\-2&amp;1\\\\2&amp;1\\\\ \\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}=\\begin{pmatrix}-1\\\\-4\\\\8\\end{pmatrix}\\LeftrightarrowA\\overrightarrow{x}= \\overrightarrow{b}\\]  하나의 방정식을 만족하는 벡터 $\\overrightarrow{x}$ 는 $2$ 차원 평면의 $1$ 차원 직선을 구성함  세 방정식을 동시에 만족하는 벡터 $\\overrightarrow{x}$ 는 존재하지 않음"
  },
  
  {
    "title": "Matrix",
    "url": "/posts/Matrix/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-05 00:00:00 +0900",
    





    
    "snippet": "What? Matrix\\[\\begin{aligned}A_{n\\times p}&amp;=\\begin{pmatrix}a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1p}\\\\a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2p}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\a_{n1}&amp;...",
    "content": "What? Matrix\\[\\begin{aligned}A_{n\\times p}&amp;=\\begin{pmatrix}a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1p}\\\\a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2p}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{np}\\end{pmatrix}\\\\&amp;=(a_{ij})\\in R^{n\\times p}, \\\\i&amp;=1, 2, \\cdots, n,\\\\j&amp;=1, 2, \\cdots, p\\end{aligned}\\]  행렬(Matrix)          행(row)과 열(column)로 구분된 직사각 모양의 배열      행벡터 혹은 열벡터의 집합        표기법          행렬(Matrix) : $A$      벡터(Vector) : $\\overrightarrow{a}$      스칼라(Scala) : $\\alpha, \\beta, \\gamma, \\cdots$      원소(Element) : $a_{ij}$        크기(Size)          길이(Length; $n$) : 행벡터의 갯수, 관측치의 갯수      차원(Dimention; $p$) : 열벡터의 갯수, 특징의 갯수      크기(Size; $n \\times p$) : 행렬의 크기      특수한 행렬      정방행렬(Square Matrix) : 행벡터의 갯수와 열벡터의 갯수가 동일한 행렬\\[\\begin{aligned}  A_{n}&amp;=\\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2n}\\\\  \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}\\\\  &amp;=(a_{ij})\\in R^{n\\times n}, \\\\  i&amp;=1, 2, \\cdots, n,\\\\  j&amp;=1, 2, \\cdots, n  \\end{aligned}\\]        영행렬(Zero-Matrix) : 그 원소가 모두 0인 행렬\\[0=\\begin{pmatrix}  0&amp;0&amp;0\\\\  0&amp;0&amp;0\\\\  0&amp;0&amp;0  \\end{pmatrix}\\]                  덧셈에 대한 항등원\\[A + 0 = A\\]                  항등행렬(Identify Matrix; $I_n$) : 대각항 원소는 모두 1이고, 비대각항 원소는 모두 0인 정방행렬\\[I_3=\\begin{pmatrix}  1&amp;0&amp;0\\\\  0&amp;1&amp;0\\\\  0&amp;0&amp;1  \\end{pmatrix}\\]                  내적에 대한 항등원\\[A\\cdot I = I \\cdot A = A\\]                    각 차원에 대하여 그 단위벡터들의 모임\\[\\begin{aligned}  I_n&amp;=  \\begin{bmatrix}\\overrightarrow{e_1}&amp;\\overrightarrow{e_2}&amp;\\overrightarrow{e_3}&amp;\\cdots&amp;\\overrightarrow{e_n}\\end{bmatrix}\\\\  &amp;=  \\begin{bmatrix}  \\overrightarrow{e_1}\\\\  \\overrightarrow{e_2}\\\\  \\overrightarrow{e_3}\\\\  \\vdots\\\\  \\overrightarrow{e_n}  \\end{bmatrix}  \\end{aligned}\\]                  대각행렬(Diagonal Matrix; $\\text{diag}$) : 대각항을 제외한 모든 원소가 0인 정방행렬\\[\\text{diag}(1, 2, 3)=\\begin{pmatrix}  1&amp;0&amp;0\\\\  0&amp;2&amp;0\\\\  0&amp;0&amp;3  \\end{pmatrix}\\]        삼각행렬(Triangular Matrix) : 대각항을 기준으로 그 아래 혹은 위에 위치한 원소가 모두 0인 정방행렬\\[\\begin{pmatrix}  1&amp;4&amp;5\\\\  0&amp;2&amp;6\\\\  0&amp;0&amp;3  \\end{pmatrix},  \\begin{pmatrix}  1&amp;0&amp;0\\\\  4&amp;2&amp;0\\\\  5&amp;6&amp;3  \\end{pmatrix}\\]        대칭행렬(Symmetric Matrix) : 그 전치행렬이 자기 자신이 되는 정방행렬\\[\\begin{aligned}  A^T&amp;=A\\\\  a_{ij}&amp;=a_{ji}  \\end{aligned}\\]\\[\\begin{pmatrix}  1&amp;3&amp;0\\\\  3&amp;2&amp;1\\\\  0&amp;1&amp;-1  \\end{pmatrix}^T=  \\begin{pmatrix}  1&amp;3&amp;0\\\\  3&amp;2&amp;1\\\\  0&amp;1&amp;-1  \\end{pmatrix}\\]                  대칭행렬이 가역성을 가지면 그 역행렬 또한 대칭행렬임\\[\\begin{aligned}  if\\;A^T&amp;=A,\\\\  A^{-1}A&amp;=I\\\\  (A^{-1}A)^T&amp;=I \\, (\\because I^T=I)\\\\  A^T(A^{-1})^T&amp;=I\\\\  A(A^{-1})^T&amp;=I\\\\  A^{-1}A(A^{-1})^T&amp;=A^{-1}I\\\\  \\therefore (A^{-1})^T&amp;=A^{-1}  \\end{aligned}\\]                  직교행렬(Orthogonal Matrix) : 모든 행벡터 혹은 열벡터가 직교정규벡터로 구성된 행렬\\[\\overrightarrow{a_{1}}\\perp\\overrightarrow{a_{2}}\\perp\\cdots\\perp\\overrightarrow{a_{n}},\\]\\[A=  \\begin{bmatrix}  \\overrightarrow{a_1}&amp;\\overrightarrow{a_2}&amp;\\cdots&amp;\\overrightarrow{a_n}  \\end{bmatrix}\\]                  직교행렬의 역행렬은 그 전치행렬임\\[A^TA=AA^T=I\\]            Matrix Operation  덧셈과 뺄셈                  크기가 $n\\times p$ 로 동일한 행렬 $A, B$ 의 덧셈 혹은 뺄셈을 대응 원소의 합 혹은 차로 정의함\\[\\begin{aligned}  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix},\\\\  B_{n \\times p}&amp;=\\begin{bmatrix}b_{ij}\\end{bmatrix}\\\\  A+B&amp;=\\begin{bmatrix}a_{ij}+b_{ij}\\end{bmatrix},\\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]              스칼라-행렬 곱셈                  스칼라와 행렬의 곱셈을 행렬의 모든 원소에 대한 스칼라 곱으로 정의함\\[\\begin{aligned}  \\alpha &amp;\\in R, \\\\  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix} \\\\  \\alpha A_{n \\times p}&amp;=\\begin{bmatrix}\\alpha \\times a_{ij}\\end{bmatrix},\\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]              전치(Transpose)                  행렬의 전치는 그 행과 열의 위치를 바꾸는 연산으로 정의함\\[\\begin{aligned}  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix} \\\\  (A_{n \\times p})^T&amp;=\\begin{bmatrix}a_{ji}\\end{bmatrix} \\\\  &amp;=A_{p \\times n}, \\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]                    성질                  $\\alpha^T=\\alpha$          $(A+B)^T=A^T+B^T$          $(\\alpha A)^T=\\alpha(A^T)$          $(AB)^T=B^TA^T$                      대각합(Trace; $\\text{tr}$)                  정방행렬 $A_n$ 의 대각합은 그 대각항의 총합으로 정의함\\[\\text{tr}(A_n)=\\sum_{i=1}^{n}a_{ii}\\]            Matrix Multiplication  적합성 조건(Conformability Condition)          전항의 차원(열벡터 갯수)과 후항의 길이(행벡터 갯수)가 동일함        행렬 곱셈                  적합성 조건을 만족하는 행렬 $A_{n \\times p},B_{p \\times m}\\(을 곱한 값\\)C_{n \\times m}$$ 를 다음과 같이 정의함\\[\\begin{aligned}  C_{n \\times m}&amp;=\\begin{bmatrix}c_{il}\\end{bmatrix}\\\\  c_{il}&amp;=\\sum_{j=1}^{p}(a_{ij}\\times b_{jl}), \\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p, \\\\  l&amp;=1, 2, 3, \\cdots, m  \\end{aligned}\\]                  즉, 전항의 $i$ 번째 행벡터와 후항의 $i$ 번째 열벡터 간 내적의 집합임                            교환법칙이 성립하지 않음\\[A_{n \\times p}B_{p \\times m} \\ne B_{p \\times m}A_{n \\times p}\\]            Inverse Matrix  역행렬(Inverse Matrix)                  정방행렬 $A_n, B_n$ 에 대하여 다음을 만족하는 경우 양자는 서로 역행렬 관계에 있음\\[AB=BA=I \\Rightarrow A^{-1}=B\\,and\\,B^{-1}=A\\]              성질          $I^{-1}=I$      $A_n=diag\\begin{bmatrix}a_{ii}\\end{bmatrix},\\;i=1,2,3,\\cdots,n \\ \\Rightarrow A^{-1}=diag\\begin{bmatrix}\\frac{1}{a_{ii}}\\end{bmatrix}$      $A=\\begin{bmatrix}\\overrightarrow{a_1}&amp;\\overrightarrow{a_2}&amp;\\cdots&amp;\\overrightarrow{a_n}\\end{bmatrix},\\;\\overrightarrow{a_{1}}\\perp\\overrightarrow{a_{2}}\\perp\\cdots\\perp\\overrightarrow{a_{n}} \\ \\Rightarrow A^{-1}=A^T$      $(\\alpha A)^{-1}=\\alpha^{-1}A^{-1}$      $(A^{T})^{-1}=(A^{-1})^T$      $(AB)^{-1}=B^{-1}A^{-1}$        가역성          가역성(Inverible) : 그 역을 계산할 수 있는 성질                  정칙행렬(Non-Singular Matrix) : 가역성을 가지는 행렬          특이행렬(Singular Matrix) : 가역성을 가지지 않는 행렬                    가역성을 가질 조건                  $\\text{det}(A_n) \\ne 0$          $\\text{rank}(A_n)=n$          행렬 $A_n$ 를 구성하는 모든 벡터는 선형 독립임          행렬 $A_n$ 를 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음                      계산 방법                  $2\\times 2$ 정방행렬에 한하여 그 역행렬을 다음과 같이 구할 수 있음\\[\\begin{aligned}  &amp;A_2=  \\begin{pmatrix}  a&amp;b\\\\  c&amp;d  \\end{pmatrix},\\;ad-bc \\ne 0 \\\\  &amp;\\Rightarrow A_{2}^{-1}=\\frac{1}{ad-bc}\\begin{pmatrix}  d&amp;-b\\\\  -c&amp;a  \\end{pmatrix}  \\end{aligned}\\]                    $3\\times 3$ 이상의 정방행렬에 대하여 그 역행렬은 가우스-조르단 소거법(Gaussian Elimination)으로 구함            Determinant      행렬식(Determinant; $\\text{det}$)\\[\\text{det}(A_n)\\; or\\; |A|\\]          정방행렬 $A_n$ 를 실수에 대응시키는 함수      기하학적으로 봤을 때, 정방행렬 $A_n$ 를 구성하는 열벡터에 의해 결정되는 평행사변형의 부피를 의미함        해석          $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 계수는 $n$ 임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음        성질          $\\text{det}(\\alpha)=\\alpha$      $\\text{det}(I)=1$      $\\text{det}(A)=det(A^T)$      $\\text{det}(A^{-1})=\\text{det}(A)^{-1}$      $\\text{det}(AB)=\\text{det}(A) \\times \\text{det}(B)$      $\\text{det}(\\alpha \\times A_n)=\\alpha^n \\times \\text{det}(A_n)$      $\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_i} \\cdots \\overrightarrow{a_j} \\end{vmatrix}=-\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_j} \\cdots \\overrightarrow{a_i} \\end{vmatrix}$      $\\begin{vmatrix}\\alpha \\times a &amp; \\alpha \\times b \\ c &amp; d\\end{vmatrix} = \\alpha \\times \\begin{vmatrix}a&amp;b\\ c&amp;d\\end{vmatrix}$        계산 방법          $\\text{det}(A_2)=a_{11}a_{22}-a_{12}a_{21}$      삼각행렬에 대하여 그 행렬식은 대각항 원소들의 곱으로 구할 수 있음      $3\\times 3$ 이상의 정방행렬에 대하여 그 행렬식은 가우스-조르단 소거법(Gaussian Elimination)으로 구함      Rank      계수(Rank) : 임의의 행렬을 구성하는 벡터 중 선형 독립인 벡터의 갯수\\[\\text{rank}(A)\\]        Full-Rank : 크기가 $n \\times p$ 인 모든 행렬에 대하여 그 계수가 될 수 있는 가장 큰 값\\[\\text{rank}(A_{n \\times p})=\\min{(n,p)}\\]        해석          $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 그 행렬식은 $0$ 이 아님      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음      "
  },
  
  {
    "title": "Vector",
    "url": "/posts/Vector/",
    "categories": "MATHEMATICAL TECHS, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-04 00:00:00 +0900",
    





    
    "snippet": "What? Vector  벡터(Vector) : 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량          원소(Element) : 벡터를 구성하는 요소      차원(Dimension) : 원소의 갯수              부분벡터(Sub-Vector) : 임의의 벡터 $\\overrightarrow{a}$ 에 대하여 그 부분 공...",
    "content": "What? Vector  벡터(Vector) : 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량          원소(Element) : 벡터를 구성하는 요소      차원(Dimension) : 원소의 갯수              부분벡터(Sub-Vector) : 임의의 벡터 $\\overrightarrow{a}$ 에 대하여 그 부분 공간으로 구성된 벡터\\[\\overrightarrow{a_{r:s}}=\\begin{pmatrix}a_r\\\\a_{r+1}\\\\a_{r+2}\\\\\\vdots\\\\a_{s} \\end{pmatrix}\\]              특수한 벡터                  영벡터(Zero Vector) : 벡터 공간에서의 덧셈에 대한 항등원이 되는 벡터\\[\\overrightarrow{0}=\\begin{pmatrix}0\\\\0\\\\\\vdots\\\\0 \\end{pmatrix}\\]                    단위벡터(Unit Vector) : 길이가 1인 벡터\\[(\\overrightarrow{e_{i}})_{j}=\\begin{cases}1,\\;if\\;j=i\\\\0,\\;if\\;j \\ne i\\end{cases}\\]\\[\\overrightarrow{e_{1}}=\\begin{pmatrix}1\\\\0\\\\0\\\\\\vdots\\\\0 \\end{pmatrix},   \\overrightarrow{e_{2}}=\\begin{pmatrix}0\\\\1\\\\0\\\\\\vdots\\\\0 \\end{pmatrix},   \\overrightarrow{e_{3}}=\\begin{pmatrix}0\\\\0\\\\1\\\\\\vdots\\\\0 \\end{pmatrix}\\]              벡터의 기하학적 해석          직각좌표계에 표현된 벡터 공간의 원소                  직각좌표계(Catesian Coordinate System) : 좌표축과 평행한 단위벡터끼리 항상 서로 수직한 모든 좌표계                    좌표평면상 하나의 점      좌표평면상 원점의 위치 이동              좌표평면상 단위벡터의 선형 결합\\[\\begin{pmatrix}3\\\\2 \\end{pmatrix} = 3 \\times \\overrightarrow{e_{1}} + 2 \\times \\overrightarrow{e_{2}}\\]            Vector Operation  스칼라-벡터 곱셈                  스칼라와 벡터의 곱셈은 벡터의 모든 원소에 대한 스칼라 곱으로 정의함\\[\\alpha \\times \\overrightarrow{a} = \\begin{pmatrix}\\alpha \\times a_{1}\\\\\\alpha \\times a_{2}\\\\\\vdots\\\\\\alpha \\times a_{n}\\end{pmatrix}\\]                    기하학적으로 봤을 때 이는 벡터를 스칼라 비율로 확대 혹은 축소하는 작업으로 해석할 수 있음                            벡터에 음수를 곱하면 벡터의 방향이 원점에 대하여 반대가 됨                      덧셈과 뺄셈                  차원이 $n$ 으로 동일한 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 의 덧셈 혹은 뺄셈을 대응 원소의 합 혹은 차로 정의함\\[\\begin{pmatrix}a_{1}\\\\a_{2}\\\\\\vdots\\\\a_{n}\\end{pmatrix} + \\begin{pmatrix}b_{1}\\\\b_{2}\\\\\\vdots\\\\b_{n}\\end{pmatrix} = \\begin{pmatrix}a_{1}+b_{1}\\\\a_{2}+b_{2}\\\\\\vdots\\\\a_{n}+b_{n} \\end{pmatrix}\\]                    기하학적으로 봤을 때 이는 벡터 $\\overrightarrow{a}$ 를 방향 $\\overrightarrow{b}$ 으로 폭 $\\Vert \\overrightarrow{b} \\Vert$ 만큼 평행이동하는 작업으로 해석할 수 있음                              덧셈                                            뺄셈                                          Linear Combination      선형 결합(Linear Combination)\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}}\\]          차원이 $n$ 으로 동일한 임의의 벡터와 스칼라에 대하여, 각 항에 스칼라를 곱하거나 상호 더함으로써 일련의 항으로 구성하는 작업        선형 종속(Linearly Dependent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현 가능한 경우                  좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치는 경우                            $n$ 차원 벡터 $\\overrightarrow{a_{1}}, \\overrightarrow{a_{2}}, \\cdots, \\overrightarrow{a_{p}}$ 와 스칼라 $\\alpha_{1}, \\alpha_{2}, \\cdots, \\alpha_{p}$ 에 대하여 다음을 만족하는 경우\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}} = 0, \\alpha^{\\forall} \\ne 0\\]              선형 독립(Linearly Independent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현될 수 없는 경우                  좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치지 않는 경우                            $n$ 차원 벡터 $\\overrightarrow{a_{1}}, \\overrightarrow{a_{2}}, \\cdots, \\overrightarrow{a_{p}}$ 와 스칼라 $\\alpha_{1}, \\alpha_{2}, \\cdots , \\alpha_{p}$ 에 대하여 다음을 만족하는 경우\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}} = 0 \\Rightarrow \\alpha^{\\forall} = 0\\]              기저(Basis)          $n$ 차원에 대하여 선형 독립인 벡터들의 집합      $n$ 차원 기저벡터의 최대 갯수는 $n$ 개임            $span$\\[\\overrightarrow{x} = \\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{n}\\overrightarrow{a_{n}}\\]          주어진 벡터들의 선형 결합으로 나타낼 수 있는 벡터의 집합, 혹은 그러한 작업      $n$ 차원의 모든 기저벡터들을 $span$ 하면 해당 공간을 모두 나타낼 수 있음      Inner Product and Norm      내적(Inner Product)\\[\\begin{aligned}  \\overrightarrow{a}\\cdot\\overrightarrow{b}&amp;=&lt;\\overrightarrow{a},\\overrightarrow{b}&gt;\\\\  &amp;=\\overrightarrow{a^{T}}\\overrightarrow{b}\\\\  &amp;=\\sum_{i}^{n}a_{i}b_{i}  \\end{aligned}\\]          차원이 $n$ 으로 동일한 두 벡터에 대하여 이를 대표하는 하나의 스칼라로 수렴하는 작업            유클리디안 노름(L-2 Norm)\\[\\Vert \\overrightarrow{a} \\Vert=\\sqrt{\\overrightarrow{a}^T\\cdot\\overrightarrow{a}}\\]                  정의 : 벡터의 규모(Magnitude) 혹은 길이(Length)                    성질                  $\\Vert \\overrightarrow{a} \\Vert \\ge0$          $\\Vert \\overrightarrow{a} \\Vert =0\\Rightarrow\\overrightarrow{a}=\\overrightarrow{0}$          $\\Vert \\alpha\\overrightarrow{a} \\Vert =\\vert \\alpha \\vert \\times \\Vert \\overrightarrow{a}\\Vert$          $\\Vert \\overrightarrow{a}+\\overrightarrow{b}\\Vert\\le\\Vert\\overrightarrow{a}\\Vert+\\Vert\\overrightarrow{b}\\Vert$                          코사인 유사도(Cosine Similarity) : 두 벡터의 사이각 $\\theta$ 의 코사인 값을 이용하여 측정한 벡터 간 유사도\\[cos\\theta=\\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{\\Vert\\overrightarrow{a}\\Vert\\times\\Vert\\overrightarrow{b}\\Vert}\\]          $\\theta$ : 임의의 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 를 좌표평면상에 나타냈을 때, 두 벡터가 이루는 각도              $\\Vert\\overrightarrow{a}\\Vert \\cos{\\theta}$ : $\\overrightarrow{a}$ 를 $\\overrightarrow{b}$ 에 정사영(Projection)하여 얻은 벡터의 길이                    해석                  $-1\\le \\cos{\\theta} \\ge1$          $\\cos{\\theta} = -1$ : 음의 유사도를 가진다고 볼 수 있으며 기하학적으로 상반된 방향성을 가짐          $\\cos{\\theta} = 1$ : 양의 유사도를 가진다고 볼 수 있으며 기하학적으로 동일한 방향성을 가짐          $\\cos{\\theta} = 0$ : 유사하다고 볼 수 없으며 기하학적으로 직교함                          직교정규벡터(Orthonomal Vector) : 임의의 벡터에 대하여 해당 벡터와 직교하면서 그 노름이 1인 벡터          정규벡터(Normal Vector) : 노름이 1인 벡터      상호직교(Mutually Orthonal)                              수학적으로 봤을 때 내적값이 0인 관계\\[\\overrightarrow{a}\\perp\\overrightarrow{b}\\Leftrightarrow\\overrightarrow{a}\\cdot\\overrightarrow{b}=0\\]                                기하학적으로 봤을 때 사잇각이 90도인 관계\\[\\overrightarrow{a}\\perp\\overrightarrow{b}\\Leftrightarrow\\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{||\\overrightarrow{a}||\\times||\\overrightarrow{b}||}=cos90^\\circ\\]                              "
  },
  
  {
    "title": "Welfare Economics (2) Social Choice",
    "url": "/posts/Welfare_Economics_2/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Welfare Economics, Pareto Efficiency, Pareto, Efficiency, Social Welfare, Welfare, Equity, Social Choice",
    "date": "2019-07-23 00:00:00 +0900",
    





    
    "snippet": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : ...",
    "content": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : 사회후생함수(Social Welfare Function)      What? Pareto Efficiency      파레토 효율성(Pareto Efficiency) : 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 어떤 경제주체의 효용수준도 개선할 수 없을 정도로 자원이 배분되었음        예시                            자원 배분 방법          부존자원량          총배분자원량          $A$          $B$          잉여자원량                                      배분1          100          100          30          70          0                          배분2          100          100          70          30          0                          배분3          100          100          50          50          0                          배분4          100          80          20          60          20                          배분5          100          80          60          20          20                          배분6          100          80          40          40          20                            $\\text{배분1},\\text{배분2},\\text{배분3}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서는 다른 경제주체의 자원 보유량을 개선할 수 없는 상태로서 파레토 최적인 상태임(Pareto Optimal)      $\\text{배분4},\\text{배분5},\\text{배분6}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서도 잉여자원 $20$ 으로써 다른 경제주체의 자원 보유량을 개선할 수 있는 상태로서 파레토 개선 가능한 상태임(Pareto Improvement)      따라서 $\\text{배분1},\\text{배분2},\\text{배분3}$ 은 $\\text{배분4},\\text{배분5},\\text{배분6}$ 보다 파레토 우월함(Pareto Superiority)      Condition      생산의 효율성(Productive Efficiency) : 사용 가능한 생산요소 제약 하 경제 전반의 재화 생산량을 극대화하여, 임의의 재화의 생산량을 몇 단위 포기하지 않고서는 다른 재화의 생산량을 개선하지 못하는 상태를 이룸\\[MRTS^{(X)}_{L,K}=\\frac{w}{v}=MRTS^{(Y)}_{L,K}\\]                생산요소 $L,K$ 제약 하 재화 $X,Y$ 에 대한 생산의 계약곡선                  상품 공간 상에 표현된 재화 $X,Y$ 에 대한 생산의 계약곡선으로서생산가능경계(Production Possibility Frontier; PPF)          교환의 효율성(Allocative Efficiency) : 배분 가능한 부존자원 제약 하 경제 전반의 효용을 극대화하여, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 다른 경제주체의 효용수준을 개선하지 못하는 상태를 이룸\\[MRS^{(A)}_{X,Y}=\\frac{P_X}{P_Y}=MRS^{(B)}_{X,Y}\\]                부존자원 $X,Y$ 제약 하 경제주체 $A,B$ 에 대한 교환의 계약곡선          총체적 효율성(Overall Efficiency) : 사용 가능한 생산요소 제약 하 극대화된 재화 생산량을 경제주체들에게 모두 배분하여 경제 전반의 효용수준을 극대화한 상태를 이룸\\[MRPT_{X,Y}=MRS_{X,Y}\\]                총체적 효율성 하에서는 재화 간 한계생산변환율과 경제주체별 재화 간 한계대체율이 일치함                  주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합으로서효용가능경계(Utility Possibility Frontier; UPF)    Social Welfare Function      사회후생함수(Social Welfare Function) : 사회 구성원들의 효용수준($X$)과 사회후생수준($Y$) 간 상관관계를 나타내는 함수\\[SW=F\\left(U_{A},U_{B}\\right)\\]          효율성의 정의가 파레토 효율성으로써 합의된 데 반해, 형평성은 윤리적 관점에 따라 그 해석이 다양함. 이에 따라 파레토 최적 상태 하 형평성 달성도를 나타내는 사회후생함수 역시 어느 하나로 합의되지 않고 다양한 형태를 띰.            (초기) 공리주의 사회후생함수(Utilitarian Social Welfare Function) : 최대 다수의 최대 행복          비록 효용이 주관적 개념이긴 하나, 개인 간에 질적으로는 차이가 없고, 오로지 양적으로만 차이가 있음. 따라서 사회 전체의 효용수준은 그저 그 사회 구성원들이 누리는 효용의 총합에 불과함.    \\[SW=U_{A}+U_{B}\\]            롤스 사회후생함수(Rawlsian Social Welfare Function) : 최소 수혜자의 최대 이익          사회 구성원들에게 무지의 베일을 씌운 원초적 상황 하에서 민주적으로 자원 배분 정책을 수립한다고 하자. 타인의 이익에 무관심하고 오로지 자신의 이익에만 관심이 있음에도 불구하고, 사회 구성원들은 자신이 최악의 상황에 처할 가능성을 고려하여 최소극대화 원칙에 근거한 배분 정책을 수립할 것임.    \\[SW=\\min{\\left[U_{A},U_{B}\\right]}\\]            (실질적) 평등주의 사회후생함수(Egalitarian Social Welfare Function) : 한계효용의 평등          빈자에게 있어서 1원과 부자의 그것이 가지는 실질적 가치가 같다고 볼 수 없음. 따라서 사회 전체의 효용수준을 논함에 있어서 개인의 사정을 고려해야 함.    \\[SW=\\left(U_A\\right)^{\\alpha} \\cdot \\left(U_B\\right)^{1-\\alpha}\\]      Impossibility Theorem  합리성의 공리와 민주성의 공리는 상호위배된다. 따라서 사회후생수준을 평가할 수 있는, 합리적인 동시에 민주적인 사회선호체계란 존재할 수 없다. (케네스 애로우)  합리적 사회선호체계의 공리                  완비성(Completeness); 사회선호체계가 모든 사회적 상태를 비교하고 평가할 수 있어야 한다.\\[X \\neq Y \\implies X \\succeq Y \\;\\text{or}\\; Y \\succeq X \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]                    이행성(Transitivity); 사회적 상태 $X, Y, Z$ 에 대하여 사회선호체계가 $X$ 를 $Y$ 보다 선호하고 $Y$ 를 $Z$ 보다 선호하면 $X$ 를 $Z$ 보다 선호해야 한다.\\[X \\succeq Y \\;\\text{and}\\; Y \\succeq Z \\implies X \\succeq Z \\quad\\text{for}\\quad X, Y, Z \\in \\mathcal{S}\\]                    파레토 원칙(Pareto Principle); 임의의 사회적 상태에 대하여 모든 사회 구성원들이 해당 사회적 상태를 다른 사회적 상태보다 선호한다면, 사회선호체계 역시 해당 사회적 상태를 다른 사회적 상태보다 선호해야 한다.\\[\\begin{aligned} X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ i^{\\forall} &amp;\\in N \\end{aligned}\\]                    독립성(Independence); 사회선호체계가 두 가지 사회적 상태의 선호관계를 평가함에 있어서 이들과 무관한 것으로부터 영향을 받지 말아야 한다.\\[\\begin{aligned} X \\succ Y \\implies X \\succ^{\\prime} Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ Z &amp;\\in \\mathcal{S} \\setminus \\{X, Y\\} \\end{aligned}\\]              민주적 사회선호체계의 공리                  비독재성(Non-dictatorship); 사회선호체계가 사회 구성원 소수의 선호체계에 좌우되지 말아야 한다.\\[\\nexists i \\in N \\; \\text{such that} \\; X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]              이행성과 민주성의 동시 성립 불가능성                  사회 구성원 $A,B,C$ 가 사회적 상태 $X,Y,Z$ 에 대하여 각각 다음과 같이 평가한다고 하자\\[\\begin{aligned}  A:\\quad &amp;X \\succ_A Y \\; \\text{and} \\; Y \\succ_A Z\\\\  B:\\quad &amp;Y \\succ_B Z \\; \\text{and} \\; Z \\succ_B X\\\\  C:\\quad &amp;Z \\succ_C X \\; \\text{and} \\; X \\succ_C Y  \\end{aligned}\\]                    사회선호체계는 파레토 원칙 및 비독재성에 의해 사회적 상태를 다음과 같이 평가함\\[\\begin{aligned}  \\mathcal{S}: X \\succ Y \\; \\text{and} \\; Y \\succ Z \\; \\text{and} \\; Z \\succ X  \\end{aligned}\\]                    따라서 민주성의 공리에 기초하여 도출한 사회선호체계는 이행성을 보장하지 못함            "
  },
  
  {
    "title": "Welfare Economics (1) Theorems of Welfare Economics",
    "url": "/posts/Welfare_Economics_1/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Welfare Economics",
    "date": "2019-07-22 00:00:00 +0900",
    





    
    "snippet": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자...",
    "content": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자원 $X,Y$ 을 보유하고 있고, 두 명의 경제주체 $A,B$ 가 활동하는 가상의 경제를 상정함      Walras Equilibrium  시장에서 모든 경제주체가 동시에 자신의 최적화 문제를 해결하고, 모든 시장이 동시에 균형을 이루는 상태로서, 모든 부존자원에 대하여 모든 경제주체의 주관적 교환 비율과 객관적 교환 비율이 일치하는 상태.Initial Endowment Point      초기부존자원점(Initial Endowment Point)              자원 $X$ 의 부존량 $X=\\overline{X}_A+\\overline{X}_B$      자원 $Y$ 의 부존량 $Y=\\overline{Y}_A+\\overline{Y}_B$            초기부존자원 하 효용 수준              초기부존자원 하 경제주체의 효용 수준을 초기부존자원점에서 서로 교차하는 경제주체 각각의 무차별곡선으로 나타낼 수 있음. 위 그래프는 각각의 무차별곡선이 교차하되 접하지는 않는 상태임. 이때 어느 한 무차별곡선을 원점 가까이 조정하지 않고서도 다른 무차별곡선을 원점에서 더 멀리 이동시킬 수 있음. 즉, 어느 경제주체의 효용 수준을 낮추지 않고서도 다른 경제주체의 효용 수준을 개선할 여지가 있음. 따라서 위 초기부존자원은 이상적인 자원 배분이 아님.      Walras Dis-Equilibrium      교환하기 위한 가격체계 설정              교환(Exchange) : 시장경제체제에서 경제주체들이 각자 효용을 극대화하는 자원조합을 구성하기 위해 상호간에 초기부존자원을 거래하는 행위      가격체계(Price System) : 두 재화 간 객관적 교환 비율로서, (위 그래프의 경우) 부존자원 $X,Y$ 에 대하여 $X$ 의 $Y$ 에 대한 상대가격            가격체계 하 효용 극대화 지점 도출\\[MRS_{X,Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}\\]                $A$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량                  $B$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량          왈라스 불균형\\[MRS^{(A)}_{X,Y} \\ne MRS^{(B)}_{X,Y}\\]                현재 가격체계 하에서는 두 경제주체 간 이해관계가 맞아떨어지지 않음                  $A$ 의 효용 극대점에서 거래를 강제하는 경우$B$ 의 효용수준이 낮아짐                  $B$ 의 효용 극대점에서 거래를 강제하는 경우$A$ 의 효용수준이 낮아짐          왈라스 불균형 하 수요량과 공급량의 불일치        Walras Equilibrium      모색 과정 : 왈라스 균형에 도달하기 위해 가격체계를 조정하는 과정            왈라스 균형\\[MRS^{(A)}_{X,Y} = \\frac{P_X}{P_Y} = MRS^{(B)}_{X,Y}\\]            왈라스 균형 하 수요량과 공급량의 일치            계약곡선(Contract Curve) : 두 경제주체가 교환을 통해 효용을 극대화하는(왈라스 균형을 실현하는) 배분점의 집합      Theorems of Welfare EconomicsThe First Fundamental Theorem  모든 경제주체의 선호체계가 강단조성을 갖고, 하나의 경제에 외부성이 존재하지 않으면, 왈라스 균형 하에서의 배분은 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없을 정도로 자원이 효율적으로 배분된 상태를 실현한다(파레토 최적이다).해석: 경제주체들은 이기적으로 행동함에도 불구하고, 시장에서 보이지 않는 손에 의해 경제주체 간 상충하는 욕망이 조정되어, 사익과 공익이 조화를 이루게 된다.The Second Fundamental Theorem  초기부존지원이 적절하게 분배된 상태에서 모든 경제주체의 선호체계가 연속성, 강단조성, 볼록성을 가진다면, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없는 상태를 실현하는(파레토 효율적인) 배분은 왈라스 균형이 된다.해석: 초기부존자원을 적절한 가격체계 위에 설정한다면, 이상적인(파레토 효율적인) 배분을 왈라스 균형 하 배분으로 만드는 가격체계가 실현될 수 있다."
  },
  
  {
    "title": "Competition Theory",
    "url": "/posts/Competition_Theory/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Equilibrium, Competition Theory, Perfect Competition Theory",
    "date": "2019-07-21 00:00:00 +0900",
    





    
    "snippet": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별...",
    "content": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별생산자는 가격 수용자이다.      하나의 시장에서 거래되는 상품은 모두 동질적이다.      개별생산자는 시장에 자유롭게 진입하거나 퇴출할 수 있다.      시장에 관한 모든 정보는 모든 시장 참여자들에게 있어서 주지사실이다.        시장실패(Market Failure) : 완전 경쟁의 네 가지 조건이 동시에 충족되지 못하여 사회적 후생이 극대화되지 못함          산업조직론(Industrial Organization) : 불완전 경쟁으로 인한 시장실패 현상을 분석함      공공경제학(Public Economics) : 공공재 및 외부효과로 인한 시장실패 현상을 분석함      정보경제학(Information Economics) : 정보의 비대칭성으로 인한 시장실패 현상을 분석함      법경제학(Law and Economics) : 정부의 과도한 경제 간섭과 규제로 인한 시장실패 현상을 분석함      Demand &amp; Supply under Perfect Competition      완전탄력적 수요곡선(Perfectly Elastic Demand Curve) : 개별생산자가 단독으로 직면하는 시장수요곡선              소비자는 가격 수용자로서, 가격의 특정 수준에 대하여 수요량을 조절함으로써 영향력을 행사할 수 없음. 따라서 개별생산자가 단독으로 직면하는 시장수요곡선은 균형가격에서 수평선(완전탄력적인 곡선)이 됨.            평균비용곡선의 극소점을 상회하는 수준의 한계비용곡선(Marginal Cost Curve above the Minimum Point of the Average Cost Curve) : 개별공급곡선              생산자는 가격 수용자로서, 주어진 가격 하 양의 이윤을 보장받을 수 있는 상태에서 이윤을 극대화하는 생산량을 공급함. 따라서 생산자들의 개별공급곡선은 한계비용곡선 중 평균비용곡선의 극소점을 상회하는 수준이 됨.                      주어진 가격 하 양의 이윤을 보장받을 수 있는 생산량 $Q^{*}$\\[\\pi(Q^{*}) \\ge 0 \\Leftrightarrow Q^{*} \\bigg\\vert AR(Q) \\ge AC(Q)\\]                    주어진 가격 하 이윤을 극대화하는 생산량 $Q^{*}$\\[\\max{\\pi(Q^{*})} \\Leftrightarrow Q^{*} \\bigg\\vert MR(Q)=MC(Q)\\]                    주어진 가격 하 평균수익($AR$)과 한계수익($MR$)\\[\\begin{aligned}  TR(Q)&amp;= P \\cdot Q\\\\\\\\  AR(Q)&amp;= \\frac{TR(Q)}{Q}\\\\&amp;= P\\\\\\\\  MR(Q)&amp;= \\frac{\\Delta TR(Q)}{\\Delta Q}\\\\&amp;= P  \\end{aligned}\\]                    종합\\[Q^{*} \\bigg\\vert P=MC(Q) \\quad \\&amp; \\quad P &gt; AC(Q)\\]            Short-Term$P &gt; AC \\Rightarrow \\pi &gt; 0$  균형가격이 평균비용곡선의 극소점을 상회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_A$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_A$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_A)$ 과 균형공급량 $Q_A$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_A)$ 에서 총비용 $TC(Q_A)$ 을 뺀 값임.총수익이 총비용보다 크므로($TR(Q_A)&gt;TC(Q_A)$) 양의 이윤이 발생함($\\pi(Q_A)&gt;0$).        $TR(Q_A)=P \\times Q_A$        $TC(Q_A)=AC(Q_A) \\times Q_A$        $\\pi(Q_A)=TR(Q_A)-TC(Q_A)&gt;0$$P &lt; AC \\Rightarrow \\pi &lt; 0$  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_B$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_B$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_B)$ 과 균형공급량 $Q_B$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_B)$ 에서 총비용 $TC(Q_B)$ 을 뺀 값임.총수익이 총비용보다 작으므로($TR(Q_B)&lt;TC(Q_B)$) 음의 이윤이 발생함($\\pi(Q_B)&lt;0$).        $TR(Q_B)=P \\times Q_B$        $TC(Q_B)=AC(Q_B) \\times Q_B$        $\\pi(Q_B)=TR(Q_B)-TC(Q_B)&lt;0$Negative Profit Analysis  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되어 음의 이윤이 발생하는 경우, 생산을 중단하여 비용을 없애는 것이 합리적인 의사결정임. 그러나 단기에는 공급을 중단하더라도 고정비용이 발생함. 따라서 생산중단을 결정하기 전에 생산을 지속함으로써 고정비용을 회수할 수 있는지 여부를 검토할 필요가 있음.$P&lt;AFC(Q)$  균형가격이 평균고정비용곡선의 극소점을 하회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 작으므로($TR(Q_C)&lt;TFC(Q_C)$) 생산을 지속해도 총고정비용을 회수할 수 없음.따라서 균형가격이 평균고정비용곡선의 극소점을 하회하는 수준에서 형성되는 경우($P&lt;AFC(Q)$) 생산을 중단하는 것이 유리함.        $TR(Q_C)=P \\times Q_C$        $TC(Q_C)=TVC(Q_C)+TFC(Q_C)$        $TR(Q_C)&lt;TFC(Q_C)$$AFC(Q)&lt;P&lt;AVC(Q)$  균형가격이 평균고정비용곡선의 극소점을 상회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 크므로($TR(Q_C)&gt;TFC(Q_C)$) 생산을 지속하면 총고정비용을 회수할 수 있음.따라서 균형가격이 평균고정비용곡선의 극소점을 상회하는 수준에서 형성되는 경우($P&gt;AFC(Q)$) 생산을 중단하는 것이 불리함.        $TR(Q_D)=P \\times Q_D$        $TC(Q_D)=TVC(Q_D)+TFC(Q_D)$        $TR(Q_D)&gt;TFC(Q_D)$Long-Term시장수요곡선의 장기화      $P&gt;\\min{AC} \\Rightarrow \\pi&gt;0$ : 잠재적 생산자가 시장에 진입하여 시장공급곡선이 우측으로 이동함에 따라 균형가격이 하락함            $P&lt;\\min{AC} \\Rightarrow \\pi&lt;0$ : 시장에 진입해 있는 생산자가 퇴출되어 시장공급곡선이 좌측으로 이동함에 따라 균형가격이 상승함            $P=\\min{AC} \\Rightarrow \\pi=0$ : 균형가격은 생산자 진입 및 퇴출에 따라 등락을 반복하다가 점차 이윤이 발생하지 않는 수준으로 수렴함      개별공급곡선의 장기화      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합    \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합    \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]        장기개별공급곡선(Long-Term Individual Supply Curve) : 장기평균비용곡선의 극소점을 상회하는 수준의 장기한계비용곡선      장기 균형      $P(=AR)=LAC \\Rightarrow \\pi=0$          개별생산자의 평균수익 $AR$ 과 장기평균비용 $LAC$ 이 일치함에 따라 이윤 $\\pi$ 이 발생하지 않음. 따라서 잠재적 생산자의 시장 진입 혹은 진입해 있는 생산자의 시장 퇴출 가능성이 제거됨. 즉, 외부교란요인이 발생할 여지가 없음.            $P(=MR)=LMC \\Rightarrow \\max{\\pi}$          개별생산자의 한계수익 $MR$ 과 장기한계비용 $LMC$ 이 일치함에 따라 이윤 $\\pi$ 가 극대화됨.      "
  },
  
  {
    "title": "Producer Theory (3) Joint Production",
    "url": "/posts/Producer_Theory_3/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-20 00:00:00 +0900",
    





    
    "snippet": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합  ...",
    "content": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합            한계생산변환율(Marginal Rate of Product Transformation; MRPT) : 재화 $X,Y$ 에 대하여, 동일한 비용 수준에서 특정 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta x \\cdot MC_X + \\Delta y \\cdot MC_Y = 0\\]\\[\\therefore MRPT_{X,Y}:= -\\frac{\\Delta y}{\\Delta x} = \\frac{MC_X}{MC_Y}\\]          $MC_X = \\displaystyle\\frac{\\partial z}{\\partial x}$ : 재화 $X$ 에 대한 한계비용      $MC_Y = \\displaystyle\\frac{\\partial z}{\\partial y}$ : 재화 $Y$ 에 대한 한계비용            한계생산변환율 체증의 법칙 : 특정 재화의 생산량이 증가할수록 동일한 비용 수준에서 해당 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분이 증가하는 현상\\[\\frac{\\partial MRPT_{X,Y}}{\\partial X} \\succ 0\\]  Revenue Constraint      한계수익불변 하 등수익곡선(Iso-Revenue Curve subject to Constant Marginal Revenue) : 공급 시 동일한 수익을 얻을 수 있는 상품묶음의 조합\\[X \\cdot P_X + Y \\cdot P_Y \\le R\\]                  한계수익불변(Constant Marginal Revenue) : 한계수익이 특정 재화의 공급량 변화에 반응하지 아니하고 일정함\\[\\frac{\\partial R}{\\partial X}=\\overline{\\alpha},\\frac{\\partial R}{\\partial Y}=\\overline{\\beta}\\]                  상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 수익 수준에서 특정 재화를 한 단위 추가 공급하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Cost Minimization under Revenue Constraint\\[\\min{Z} \\quad \\text{s.t.} \\; X \\cdot P_{X} + Y \\cdot P_{Y} \\le R\\]      생산변환곡선의 접선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 한계생산변환율 $MRPT_{X,Y}$\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{MC_X}{MC_Y}\\]        등수익곡선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 상대가격\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{P_X}{P_Y}\\]        생산변환곡선과 등수익곡선의 접점 : 수익 제약 하 비용을 최소화하는 상품묶음\\[\\begin{aligned}  \\frac{MC_X}{MC_Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MC_{X}}{P_X}$ 와 $\\displaystyle\\frac{MC_{Y}}{P_Y}$ 가 일치함\\[\\frac{MC_{X}}{MC_{Y}}=\\frac{P_X}{P_Y} \\Leftrightarrow \\frac{MC_{X}}{P_X}=\\frac{MC_{Y}}{P_Y}\\]          $\\displaystyle\\frac{MC_{X}}{P_X}$ : 화폐 단위당 취득 가능한 $X$ 단위의 한계비용      $\\displaystyle\\frac{MC_{Y}}{P_Y}$ : 화폐 단위당 취득 가능한 $Y$ 단위의 한계비용      "
  },
  
  {
    "title": "Producer Theory (2) Profit Maximization",
    "url": "/posts/Producer_Theory_2/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-19 00:00:00 +0900",
    





    
    "snippet": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{align...",
    "content": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{aligned}\\]          $P=\\alpha - \\beta \\cdot Q$ : 단위당 시장가격      $Q$ : 총 공급량            평균수익(Average Revenue; AR) : 개별생산자가 재화 단위당 취득할 수 있는 수익\\[\\begin{aligned}  AR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{TR(Q \\vert \\alpha, \\beta)}{Q}\\\\  &amp;= P  \\end{aligned}\\]        한계수익(Marginal Revenue; MR) : 개별생산자가 재화를 한 단위 추가 공급했을 때 추가 취득할 수 있는 수익\\[\\begin{aligned}  MR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}\\\\  &amp;= \\alpha - 2 \\beta \\cdot Q  \\end{aligned}\\]  $\\max{TR}$\\[\\begin{aligned}\\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}&amp;= MR(Q)\\\\&amp;= P \\cdot \\left(1 + \\frac{Q / \\Delta Q}{P / \\Delta P}\\right)\\\\&amp;= P \\cdot \\left(1 - \\frac{1}{\\varepsilon_{P}} \\right)\\\\&amp;= 0\\end{aligned}\\]\\[\\therefore \\hat{Q} = \\text{arg}\\max{TR(Q \\vert \\alpha, \\beta)} \\quad \\text{for} \\; \\varepsilon_{P}=1\\]CostShort-Term Cost      단기총비용(Short-Term Total Cost; STC) : 개별생산자가 재화를 총 $Q$ 단위 공급하기 위해 지불해야 하는 비용\\[\\begin{aligned}  STC(Q \\vert K) &amp;= STVC(Q) + STFC\\\\  STVC(Q) &amp;= L \\cdot w\\\\  STFC &amp;= \\overline{K} \\cdot v  \\end{aligned}\\]        단기평균비용(Short-Term Average Cost; SAC) : 개별생산자가 재화 단위당 지불해야 하는 비용\\[\\begin{aligned}  SAC(Q \\vert K)  &amp;= \\frac{STC(Q \\vert K)}{Q}\\\\  &amp;= \\frac{STVC(Q)}{Q} + \\frac{STFC}{Q}  \\end{aligned}\\]        단기한계비용(Short-Term Marginal Cost; SMC) : 개별생산자가 재화 단위를 추가할 때 추가 지불해야 하는 비용\\[\\begin{aligned}  SMC(Q \\vert K)  &amp;= \\frac{\\partial STC(Q \\vert K)}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} + \\frac{\\partial STFC}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} \\quad \\left(\\because \\frac{\\partial STFC}{\\partial Q} = 0 \\right)  \\end{aligned}\\]  Long-Term Cost      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합      \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합      \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]  Profit Maximization      양의 이윤을 극대화하는 생산량 도출\\[Q_{S}^{*}= \\text{arg} \\max{\\pi(Q)}\\]        이윤 함수(Profit Function)\\[\\pi(Q) = TR(Q) - TC(Q)\\]        일계 조건\\[\\begin{aligned}  \\frac{\\partial \\pi(Q)}{\\partial Q}  &amp;= \\frac{\\partial TR(Q)}{\\partial Q} - \\frac{\\partial TC(Q)}{\\partial Q}\\\\  &amp;= MR(Q) - MC(Q)\\\\  &amp;=0\\\\\\\\  \\therefore MR(Q)&amp;=MC(Q)  \\end{aligned}\\]        이계 조건\\[\\begin{aligned}  \\frac{\\partial^2 \\pi(Q)}{\\partial Q^2}  &amp;= \\frac{\\partial}{\\partial Q} \\frac{\\partial \\pi(Q)}{\\partial Q}\\\\  &amp;= \\frac{\\partial MR(Q)}{\\partial Q} - \\frac{\\partial MC(Q)}{\\partial Q}\\\\  &amp;&lt; 0\\\\\\\\  \\therefore \\frac{\\partial MR(Q)}{\\partial Q} &amp;&lt; \\frac{\\partial MC(Q)}{\\partial Q}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Producer Theory (1) Output Maximization under Cost Constraint",
    "url": "/posts/Producer_Theory_1/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-18 00:00:00 +0900",
    





    
    "snippet": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat...",
    "content": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat{K}\\right)$ 도출\\[\\hat{L}, \\hat{K}=\\text{arg} \\min{L \\cdot w + K \\cdot v} \\quad \\text{s.t.} \\; Q^{*}_{S}=F(L,K)\\]            Production      생산 함수(Production Function) : 단기 콥-더글라스 생산 함수임을 가정          가정 : 생산 기간은 단기로 간주하고, 투입되는 생산요소를 노동($L$)과 자본($K$)으로 제한하자. 단기에는 고정투입요소의 투입량을 유동적으로 조정할 수 없으며($\\overline{K}$), 생산기술이 일정한 수준으로 유지된다($\\overline{H}$).    \\[\\begin{aligned}  Q_S  &amp;= F\\left(L,\\overline{K}\\right)\\\\  &amp;= \\overline{H} \\cdot L^{\\alpha} \\cdot \\overline{K}^{\\beta}  \\end{aligned}\\]          $Q_S$ : 개별생산량      $L$ : 노동으로서 가변투입요소      $\\overline{K}$ : 자본으로서 고정투입요소      $\\overline{H}$ : 생산기술            등량 곡선(Isoquant Curve) : 노동 투입량을 X축으로, 자본 투입량을 Y축으로 하는 좌표평면 위에 생산량이 무차별한 요소조합을 이은 곡선    \\[Q_K = F(L, K)\\]          동일한 생산함수의 상이한 생산량수준을 나타내는 두 개의 등량곡선은 교차하지 않는다.      원점에서 비교적 먼 등량곡선은 비교적 높은 생산량수준을 나타낸다.      등량곡선은 우하향한다.      제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 등량곡선이 하나 존재한다.      등량곡선은 원점에 대하여 볼록한 모양을 가진다.      Productivity of Factors of Production      생산요소의 생산력                      노동의 총생산(Total Production of Labor; $TP_L$) : 노동을 $L$ 단위 투입했을 때 가능한 생산량\\[TP_L = f(L,\\overline{K})\\]                    노동의 평균생산(Average Production of Labor; $AP_L$) : 노동 단위당 가능한 생산량\\[AP_L = \\frac{TP_L}{L}\\]                    노동의 한계생산(Marginal Production of Labor; $MP_L$) : 노동 단위 추가 투입 시 가능한 추가 생산량\\[MP_L = \\frac{\\partial TP_L}{\\partial L}\\]                  한계기술대체율(Marginal Rate of Technical Substitution; MRTS) : 동일한 생산량 수준에서 특정 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소 단위\\[\\Delta L \\cdot MP_L + \\Delta K \\cdot MP_K = 0\\]\\[\\therefore MRTS_{L,K}:= -\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        한계기술대체율 체감의 법칙 : 특정 생산요소의 투입량이 증가할수록 동일한 생산량 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분이 감소하는 현상\\[\\frac{\\partial MRTS_{L,K}}{\\partial L} \\prec 0\\]  Cost Constraint      등비용곡선(Iso-Cost Curve) : 주어진 비용($C$)과 요소가격 상황($P_L=w,P_K=v$)에 맞게 취득할 수 있는 요소조합의 집합\\[(L,K) \\quad \\text{s.t.} \\; L \\cdot w + K \\cdot v \\le C\\]        상대가격(Relative Price) : 특정 생산요소에 대하여, 동일한 비용 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분\\[\\Delta L \\cdot w + \\Delta K \\cdot v = 0\\]\\[\\therefore - \\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]  Output Maximization under Cost Constraint\\[\\max{Q_S} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      등량곡선의 접선의 기울기 : 노동의 자본에 대한 한계기술대체율 $MRTS_{L,K}$\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        등비용곡선의 기울기 : 노동의 자본에 대한 상대가격\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]        등비용곡선과 등량곡선의 접점 : 비용 제약 하 생산량을 극대화하는 요소조합\\[\\begin{aligned}  \\frac{MP_L}{MP_K}=-\\frac{\\Delta K}{\\Delta L}=\\frac{w}{v}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MP_{L}}{w}$ 과 $\\displaystyle\\frac{MP_{K}}{v}$ 이 일치함\\[\\frac{MP_{L}}{MP_{K}}=\\frac{w}{v} \\Leftrightarrow \\frac{MP_{L}}{w}=\\frac{MP_{K}}{v}\\]          $\\displaystyle\\frac{MP_{L}}{w}$ : 화폐 단위당 취득 가능한 노동 단위의 한계생산      $\\displaystyle\\frac{MP_{K}}{v}$ : 화폐 단위당 취득 가능한 자본 단위의 한계생산      "
  },
  
  {
    "title": "Consumer Theory (2) Demand Response to Changes in Market Demend Determinants",
    "url": "/posts/Consumer_Theory_2/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Consumer Theory",
    "date": "2019-07-17 00:00:00 +0900",
    





    
    "snippet": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른...",
    "content": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면        소득-수량 평면(Income-Quantity Plane) : 임의의 재화 $X$ 에 대하여 소득수준(혹은 예산제약) $M$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면  Price Changes  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 재 시장가격 $P_{Y}$ 와 소득수준 $M$ 이 일정한 상황에서 $X$ 재 시장가격 $P_{X}$ 는 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $\\displaystyle\\frac{P_{X}}{P_{Y}}$ 이 감소함      예산선의 기울기가 점차 완만해짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Q_{X}^{*}$ 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격소비곡선(Price Consumption Curve; PCC) : 상품 공간에서 시장가격의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            개별수요곡선(Individual Demand Curve) : 가격-수량 평면에서 시장가격의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      개별수요곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta P_X}{\\Delta Q_X}\\right)$ 와 개별수요의 가격 탄력성 $\\varepsilon_{P}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{P}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta P_X/P_X}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta P_X} \\cdot \\frac{P_X}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta P_{X}}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{P_X}{Q_X}  \\end{aligned}\\]            Income Changes  가정 : 정상재 $X,Y$ 에 대하여, 그 시장가격 $P_{X},P_{Y}$ 이 일정한 상황에서 소득수준 $M$ 이 지속적으로 상승하는 추세에 있다.            현상      상품 공간 상의 표현                  예산규모 $M$ 이 증가함      예산선이 원점에서 점차 멀어짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Y$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{Y}}$ 이 증가함      예산선의 $Y$ 절편이 점차 원점에서 멀어짐              \\(Q_{X}^{*}, Q_{Y}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 우상향함            소득소비곡선(Income Consumption Curve; ICC) : 상품 공간에서 소득수준의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            엥겔곡선(Engel Curve; EC) : 소득-수량 평면에서 소득수준의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      엥겔곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta M}{\\Delta Q_X}\\right)$ 와 개별수요의 소득 탄력성 $\\varepsilon_{M}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{M}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta M/M}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta M} \\cdot \\frac{M}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta M}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{M}{Q_X}  \\end{aligned}\\]            Price Effect  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 의 시장가격 $P_Y$ 가 일정한 상태에서 $X$ 의 시장가격 $P_{X}$ 이 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함      예산선의 기울기가 점차 완만해짐              \\(Q_{X}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격 효과(Price Effect) : 특정 재화의 가격 변동이 해당 재화의 수요량에 미치는 총 효과            $\\text{Price Effect} = \\text{Substitution Effect} + \\text{Income Effect}$                      $E_1 \\rightarrow E_3$ : 대체 효과                  대체 관계에 있는 재화 $X,Y$ 에 대하여, 동일한 효용수준을 유지하는 경우, $Y$ 에 대한 $X$ 의 상대가격 $-\\displaystyle\\frac{\\Delta Y}{\\Delta X}=\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함에 따라 $Y$ 단위당 기회비용이 증가하므로 $Y$ 의 개별수요량 $Q_Y$ 일부가 $X$ 의 개별수요량 $Q_X$ 으로 대체될 수 있음                            $E_3 \\rightarrow E_2$ : 소득 효과                  정상재 $X$ 에 대하여, $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함에 따라 $X$ 의 개별수요량 $Q_X$ 이 증가할 수 있음                    Price Effect Analysis      대체 효과(Substitution Effect; $E_1 \\rightarrow E_3$) : 특정 재화의 가격이 감소했을 때, 동일한 효용 수준을 유지하면서 상대적으로 더 저렴해진 재화를 더 많이 소비하고, 더 비싸진 재화를 덜 소비하는 효과              동일한 효용 수준을 유지하므로 무차별곡선에 변화가 없음      상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하므로 예산선의 기울기가 완만해짐      최적 선택 하 $Q_Y$ 일부가 $Q_X$ 으로 대체되므로 예산선과 무차별곡선의 접점이 우하향함            소득 효과(Income Effect; $E_3 \\rightarrow E_2$) : 특정 재화의 가격이 감소했을 때, 소비자가 동일한 예산 제약 하에서 취득 가능한 수량(구매력)이 증가하여 효용 수준이 변화하는 효과              상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 대체 효과 이후와 동일하므로 예산선은 대체 효과로 인해 완만해진 예산선과 평행함      실질 소득 수준이 증가하므로 예산선은 원점에서 멀어짐                  $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하므로 $X$ 절편이 우측으로 이동함          $Y$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_Y}$ 에는 변화가 없으므로 $Y$ 절편은 대체 효과 이전으로 회귀함                    VariationCompensating Variation      보상 변화(Compensating Variation; CV) : 특정 재화의 가격이 변화했을 때, 이전과 동일한 효용 수준을 누리기 위해 보상 받아야 하는 추가 소득              $P_X$ 가 감소함에 따라 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하였음. 가격체계를 임의로 조정할 수 없는 상태에서 이전과 동일한 효용 수준으로 회귀하기 위해서는, 가격 변화 이전에 누렸던 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기가 완만해진 상태에서 기울기를 임의로 조정할 수 없는 경우, 가격 변화 이전의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 보상 변화가 됨.            보상수요곡선(Compensated Demand Curve) : 가격 효과를 반영한 개별수요곡선에서 소득 효과를 제외한 대체 효과, 혹은 보상 변화만을 반영한 개별수요곡선      Equivalent Variation      대등 변화(Equivalent Variation; EV) : 특정 재화의 가격이 변화했다고 가정했을 때 누릴 수 있는 효용 수준과 대등한 효용 수준을 누리기 위해 필요한 추가 소득              $P_X$ 가 감소한다고 가정한다면, 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가할 것임. 이에 따라 누릴 수 있는 효용 수준이 상승할 것임. 실제로는 가격체계에 변함이 없는 상태에서 가정과 대등한 효용 수준을 누리기 위해서는, 가격 변화 이후 누릴 수 있는 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기에 변함이 없는 경우, 가격 변화 이후의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 대등 변화가 됨.      "
  },
  
  {
    "title": "Consumer Theory (1) Utility Maximization under Budget Constraint",
    "url": "/posts/Consumer_Theory_1/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Consumer Theory",
    "date": "2019-07-16 00:00:00 +0900",
    





    
    "snippet": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Pr...",
    "content": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Preference Relation) : 임의의 상품묶음과 다른 상품묶음 간 선호의 우열관계\\[(x,y) \\succ (x', y')\\]              선호체계의 공리                  완비성(Completeness); 동일한 품목의 수량을 나타내는 상품묶음 사이의 선호관계를 비교할 수 있다.\\[A \\succ B \\; \\text{or} \\; B \\succ A \\; \\text{or} \\; A \\sim B \\quad \\text{for}\\;(A, B)^{\\forall} \\in X\\]                    이행성(Transitivity); 동일한 품목의 수량을 나타내는 상품묶음 A, B, C에 대하여 A보다 B를 선호하고, B보다 C를 선호하면 A보다 C를 선호한다.\\[A \\succ B \\; \\text{and} \\; B \\succ C \\implies A \\succ C \\quad \\text{for}\\; (A, B, C)^{\\forall} \\in X\\]                    강단조성(Strong Monotonicity); 상품묶음이 나타내는 두 가지 재화 중에서 임의의 재화에 대하여 다른 재화의 수량이 일정하다면 해당 상품의 수량이 더 높은 상품묶음을 선호한다.\\[x_i \\ge y_i \\; \\text{for all} \\; i \\; \\text{and} \\; x_i &gt; y_i \\; \\text{for some} \\; i \\implies A \\succ B \\quad \\text{for} \\; (A, B)^{\\forall} \\in X\\]                    연속성(Continuity); 두 상품묶음에 대한 선호도의 차이는 두 상품묶음이 나타내는 수량의 차이에 비례한다.\\[A \\succ B \\; \\text{and} \\; C \\approx A \\implies C \\succ B \\quad \\text{for}\\;(A, B, C)^{\\forall} \\in X\\]                    볼록성(Convexity); 극단적인 수량의 조합을 나타내는 상품묶음보다는 두 가지 재화의 수량이 고루 섞여 있는 상품묶음을 선호한다.\\[\\begin{aligned} \\lambda A + (1 - \\lambda)B \\succ A \\quad \\text{for} \\quad &amp;\\lambda^{\\forall} \\in (0, 1)\\\\ &amp;(A, B)^{\\forall} \\in X \\end{aligned}\\]            Utility      효용함수(Utility Function) : 상품묶음과 선호도 값 사이의 상관관계를 나타내는 함수\\[\\begin{aligned}  U^{(1)}:&amp; \\quad U(A)=10, U(B)=20, U(C)=30\\\\  U^{(2)}:&amp; \\quad U(A)=40, U(B)=60, U(C)=80  \\end{aligned}\\]          $U^{(1)}$ 과 $U^{(2)}$ 는 재화에 대하여 선호도 값을 다르게 매겼으나, 선호관계를 동일하게 평가하였음. 따라서 두 효용함수는 실질적으로는 무차별함. 이처럼 효용함수는 선호도 값의 기수성이 아니라 서수성이 중요함.            무차별곡선(Indifference curve) : 재화 $X,Y$ 에 대하여, 동일한(무차별한) 효용 수준을 누릴 수 있는 상품묶음 $(X, Y)$ 의 집합    \\[U(x,y)=u_{i}\\]          완비성(Completeness); 동일한 효용함수의 상이한 효용수준을 나타내는 두 개의 무차별곡선은 교차하지 않는다.      이행성(Transitivity); 무차별곡선은 원점에서 멀수록 더 높은 효용수준을 나타낸다.      강단조성(Strong Monotonicity); 무차별곡선은 우하향한다.      연속성(Continuity); 제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 무차별곡선이 하나 존재한다.      볼록성(Convexity); 무차별곡선은 원점에 대하여 볼록한 모양을 가진다.      Subjective Rate of Substitution      한계효용(Marginal Utility; MU) : 임의의 재화를 한 단위 추가 소비함으로써 추가로 누릴 수 있는 효용 수준\\[MU_{X}:= \\frac{\\partial U}{\\partial X}\\]        한계대체율(Marginal Rate of Substitution; MRS) : 재화 $X,Y$ 에 대하여, 동일한 효용 수준에서 해당 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot MU_{X} + \\Delta Y \\cdot MU_{Y} = 0\\]\\[\\therefore MRS_{X,Y}:= -\\frac{\\Delta Y}{\\Delta X} = \\frac{MU_{X}}{MU_{Y}}\\]        한계대체율 체감의 법칙 : 임의의 상품에 대하여, 해당 상품의 보유량이 증가할수록 동일한 효용수준에서 해당 상품을 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분이 감소하는 현상\\[\\frac{\\partial MRS_{X,Y}}{\\partial X} \\prec 0\\]  Budget Constraint      예산선(Budget Line) : 주어진 예산($M$)과 가격 상황($P_{X}, P_{Y}$)에 맞게 취득할 수 있는 상품묶음들의 집합\\[\\begin{aligned}  (x,y) \\quad \\text{s.t.}\\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M  \\end{aligned}\\]        상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 예산 수준에서 특정 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Utility Maximization under Budget Constraint\\[\\max{U(x,y)} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      무차별곡선의 접선의 기울기 : X재의 Y재에 대한 주관적 교환비율로서 한계대체율\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{MU_{X}}{MU_{Y}}\\]        예산선의 기울기 : X재의 Y재에 대한 객관적 교환비율로서 상대가격\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}\\]        예산선과 무차별곡선의 접점 : 예산 제약 하 효용을 극대화하는 상품묶음\\[\\begin{aligned}  \\frac{MU_{X}}{MU_{Y}}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MU_{X}}{P_{X}}$ 과 $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ 이 일치함\\[\\frac{MU_{X}}{MU_{Y}}=\\frac{P_{X}}{P_{Y}} \\Leftrightarrow \\frac{MU_{X}}{P_{X}}=\\frac{MU_{Y}}{P_{Y}}\\]          $\\displaystyle\\frac{MU_{X}}{P_{X}}$ : 화폐 단위당 취득 가능한 X재 단위의 한계효용      $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ : 화폐 단위당 취득 가능한 Y재 단위의 한계효용      Sourse  https://enotesworld.com/price-budget-line-or-budget-constraint/"
  },
  
  {
    "title": "What? Microeconomics",
    "url": "/posts/What_Micro/",
    "categories": "ECONOMICS, 2.microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Equilibrium",
    "date": "2019-07-15 00:00:00 +0900",
    





    
    "snippet": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원...",
    "content": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득할 수 있도록 마련한 절차          시장경제체제(Market Economy) : 한 사회의 자원 배분이 그 구성원들의 경제 활동으로써(혹은 시장 수요와 공급에 의해) 결정되는 제도      계획경제체제(Command Economy) : 한 사회의 자원 배분 및 그 구성원들의 경제 활동이 정부에 의해 결정되는 제도        시장경제체제의 운용 원리          모든 선택에는 대가가 있다.      선택의 대가는 그것을 얻기 위해 포기한 것이다.      합리적 판단은 한계적으로 이루어진다.      경제주체는 경제적 유인에 반응한다.      자유거래는 모든 경제주체를 이롭게 한다.      일반적으로 시장이 경제활동을 조직하는 좋은 수단이다.      경우에 따라 정부가 시장의 성과를 개선할 수 있다.      한 나라의 생활수준은 그 나라의 생산 능력에 달려 있다.      통화량이 지나치게 증가하면 물가는 상승한다.      단기적으로는 인플레이션과 실업 사이에 상충관계가 있다.      Equilibrium      보이지 않는 손(Invisible Hand)          시장 참여자들이 자신의 이익을 추구하는 과정에서 가격 메커니즘을 통해 사회 전체의 자원 배분이 효율적으로 이루어지는 현상, 혹은 이러한 현상을 가능케 하는 메커니즘              교환(Exchange) : 이상적인 자원 조합을 구성하기 위해 상대가격이 낮은 자원을 지불하여 상대가격이 높은 자원을 구입하는 행위      상대가격(Relative Price) : 다른 자원의 단위로 측정한 어떤 자원의 가치로서, 시장 참여자 상호간에 합의된 자원 간 상대적 교환 비율      가격(Price) : 화폐로써 수량화된 자원의 가치로서, 화폐 단위당 자원의 절대적 교환 비율            최적화(Optimization) : 시장 참여자들이 제약 하에서 목표를 최대화하거나 최소화하는 과정으로서, 경제 활동 혹은 경제 활동의 결과 실현된 상태    수요자의 최적 의사결정          쾌락의 최대화 : 동일한 가치를 지불함으로써 취득 가능한 자원 단위를 최대화함      고통의 최소화 : 동일한 자원 단위를 취득하기 위해 지불해야 하는 가치를 최소화함      최대지불의사(Willingness to Pay; WTP) : 어떤 시장 참여자가 특정 자원을 취득하기 위해 포기할 수 있는 최대 가치        공급자의 최적 의사결정          쾌락의 극대화 : 동일한 자원 단위를 지불함으로써 취득 가능한 가치를 최대화함      고통의 최소화 : 동일한 가치를 취득하기 위해 교환해야 하는 자원 단위를 최소화함      유보가격(Reservation Price) : 어떤 시장 참여자가 특정 자원을 포기하는 대신 취득하고자 하는 최소 가치            균형(Equilibrium) : 자원의 교환 가치를 낮추려는 힘과 높이려는 힘이 맞아떨어져서 외부 교란 요인이 없는 한 유지되는 상태              존재성 : 균형이 존재하는 성질      유용성 : 균형이 적을수록 유용한 성질      안정성 : 다수의 균형이 존재하는 경우 안정적인 균형이 선호되는 성질      Market DemandDeterminants      시장수요결정변수(Market Demand Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장수요($Y$)를 결정하는 요인($X$)\\[f_{D}:P;M,P_{R},N \\rightarrow Q_{D}\\]        가격(Price; $P$) : 수요자가 자원을 취득하기 위해 지불해야 할 가치                  수요의 법칙(Law of Demand; LOD) : 가격과 수요량 간 음의 상관관계\\[\\frac{\\Delta Q_{D}}{\\Delta P} &lt; 0\\]                  소득수준(Income; $M$) : 수요자가 자원을 취득하기 위해 지불 가능한 예산 규모        관련재의 가격(Prices of Substitutes and Complements; $P_{R}$)        수요자 수(Population; $N$)  Elasticity  수요의 탄력성(Elasticity of Demand) : 시장수요결정변수의 변화에 따른 시장수요의 변동성          $\\varepsilon &gt; 1$ : 시장수요결정변수에 대하여 탄력적      $\\varepsilon = 1$ : 시장수요결정변수에 대하여 단위탄력적      $\\varepsilon &lt; 1$ : 시장수요결정변수에 대하여 비탄력적            수요량의 가격 탄력성(Price Elasticity of Demand; PED) : 가격의 단위 변화에 따른 시장수요량의 변동성\\[\\varepsilon_{P}:= -\\frac{\\Delta Q_{D}/Q_D}{\\Delta P/P} \\quad (\\because \\text{LOD})\\]        수요의 소득 탄력성(Income Elasticity of Demand; IED) : 소득수준의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{M}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta M/M}\\]                  정상재(Normal Goods) : 소득수준의 변동성과 시장수요의 변동성이 비례하는 자원\\[\\varepsilon_{M} &gt; 0\\]                              사치재(Luxury Goods) : 소득수준의 단위 변화에 따른 수요의 변동성이 탄력적인 자원\\[\\varepsilon_{M} &gt; 1\\]                                필수재(Necessities) : 소득수준의 단위 변화에 따른 수요의 변동성이 비탄력적인 자원\\[0 &lt; \\varepsilon_{M} &lt; 1\\]                                      열등재(Inferior Goods) : 소득수준의 변동성과 시장수요의 변동성이 반비례하는 자원\\[\\varepsilon_{M} &lt; 0\\]                  수요의 교차 탄력성(Cross-Price Elasticity of Demand; XED) : 관련재 가격의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{C}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta P_{R}/P_R}\\]                  대체재(Substitutes) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 증가하는 경우\\[\\varepsilon_{C} &gt; 0\\]                    보완재(Complements) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 감소하는 경우\\[\\varepsilon_{C} &lt; 0\\]                    독립재(Unrelated Goods) : 어떤 자원의 가격 변동성이 다른 자원의 시장수요 변동성에 영향을 미치지 않는 경우\\[\\varepsilon_{C} = 0\\]            Market SupplyDeterminants      시장공급결정변수(Market Supply Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장공급($Y$)을 결정하는 요인($X$)\\[f_{S}:P;w,v,H,C \\rightarrow Q_{D}\\]        가격(Price; $P$) : 공급자가 자원 단위를 공급함으로써 취득하는 가치                  공급의 법칙(Law of Supply; LOS) : 가격과 공급량 간 양의 상관관계\\[\\frac{\\Delta Q_{S}}{\\Delta P} &gt; 0\\]              자원 생산 시 투입되는 생산요소의 단위당 가격          임금(Wage; $w$) : 노동의 단위당 가격      임대료(Rent; $v$) : 자본의 단위당 가격            기술수준(Hechnics; $H$)    공급자 수(Population; $C$)Elasticity  공급의 탄력성(Elasticity of Supply) : 시장공급결정변수의 변화에 따른 시장공급의 변동성          $\\epsilon &gt; 1$ : 시장공급결정변수에 대하여 탄력적      $\\epsilon = 1$ : 시장공급결정변수에 대하여 단위탄력적      $\\epsilon &lt; 1$ : 시장공급결정변수에 대하여 비탄력적            공급량의 가격 탄력성(Price Elasticity of Supply) : 가격의 단위 변화에 따른 시장공급량의 변동성\\[\\epsilon_{P}:= \\frac{\\Delta Q_{S}/Q_S}{\\Delta P/P} \\quad (\\because \\text{LOS})\\]  Sourse  https://policonomics.com/supply-and-demand/  https://thismatter.com/economics/supply.htm"
  }
  
]


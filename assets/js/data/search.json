[
  
  {
    "title": "BDNet",
    "url": "/posts/BDNet/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Deep Learning, BNN, Bayesian",
    "date": "2024-08-07 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Language Model",
    "url": "/posts/Langs_Model/",
    "categories": "AI & Data Mining, Text Analytics",
    "tags": "Data Mining, Text Mining",
    "date": "2024-08-02 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Text Representation",
    "url": "/posts/Text_Representation/",
    "categories": "AI & Data Mining, Text Analytics",
    "tags": "Data Mining, Text Mining",
    "date": "2024-08-01 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Statistical Modeling Methods",
    "url": "/posts/Statistical_Modeling_Methods/",
    "categories": "AI & Data Mining, Text Analytics",
    "tags": "Data Mining, Text Mining",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "Text RepresentationWord Representation      원 핫 인코딩(One Hot Encoding) : 단어를 전체 Voca Set 크기를 차원으로 하는 벡터로 표현하는 방법      Document Representation      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법           ...",
    "content": "Text RepresentationWord Representation      원 핫 인코딩(One Hot Encoding) : 단어를 전체 Voca Set 크기를 차원으로 하는 벡터로 표현하는 방법      Document Representation      BoW(Bag of Words) : 문서를 단어 빈도 수로 표현하는 방법            DTM(Document Term Matrix) : 여러 개의 문서를 BoW 로 표현하는 방법            TF-IDF(Term Frequency-Inverse Document Frequency) : DTM 내 단어들에 대하여 각 단어의 중요도에 따라 가중치를 부여하여 표현하는 방법\\[\\text{TF-IDF}(d,t)=\\text{TF}(d,t) \\cdot \\text{IDF}(t)\\]                  TF(Term Frequency) : 문서 $d$ 에서 단어 $t$ 가 등장하는 횟수\\[\\text{TF}(d,t)\\]                    IDF(Inverse Document Frequency) : 단어 $t$ 가 등장하는 문서의 수에 반비례하는 수\\[\\text{IDF}(t)=\\ln{\\frac{n}{1+\\text{DF}(t)}}\\]                  $n$ : 문서의 수          $\\text{DF}(t)$ : 단어 $t$ 가 등장하는 문서의 수                    Language Model  언어 모형(Language Model) : Word Sequence(문장)에 확률을 할당하여 가장 자연스러운 문장을 탐색하는 모형SLM      Statistical Language Model(SLM) : 조건부 확률을 활용하여 Word Sequence 발생 확률을 부여하는 모형\\[\\begin{aligned}  P(W)  &amp;= P(w_1, w_2, \\cdots, w_n)\\\\  &amp;= \\cancel{P(w_1)} \\cdot \\frac{\\cancel{P(w_1,w_2)}}{\\cancel{P(w_1)}} \\cdot \\frac{\\cancel{P(w_1, w_2, w_3)}}{\\cancel{P(w_1, w_2)}} \\cdots \\frac{P(w_1, w_2, \\cdots, w_n)}{\\cancel{P(w_1, w_2, \\cdots, w_{n-1})}}\\\\  &amp;= P(w_1) \\cdot P(w_2 \\mid w_1) \\cdot P(w_3 \\mid w_1, w_2) \\cdots P(w_n \\mid w_1, w_2, \\cdots, w_{n-1})\\\\  &amp;= \\prod_{i=1}^{n}{P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]        확률 부여 방법\\[\\begin{aligned}  P(w_i \\mid w_1, w_2, \\cdots, w_{i-1})  &amp;= \\frac{\\text{Count}(w_1, w_2, \\cdots, w_i)}{\\text{Count}(w_1, w_2, \\cdots, w_{i-1})}  \\end{aligned}\\]          $\\text{Count}(w_1, w_2, \\cdots, w_i)$ : 말뭉치에서 Word Sequence $(w_1, w_2, \\cdots, w_i)$ 가 등장한 횟수      n-Gram      n-Gram : $i$ 번째 단어를 예측함에 있어 $N-1$ 개의 단어만을 활용하는 모형\\[\\begin{aligned}  P(W)  &amp;= \\prod_{i=1}^{n}{P(w_{i} \\mid w_{i-(n-1)}, w_{i-(n-2)}, \\cdots, w_{i-1})}  \\end{aligned}\\]        How to Select $n$ : 통상 $n \\le 5$ 권장                            Problem          Small $n$          Large $n$                                      Sparsity Problem          $\\downarrow$          $\\uparrow$                          Long-term Dependency          $\\uparrow$          $\\downarrow$                            희소성 문제(Sparsity Problem) : 충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제      장기 의존성 문제(Long-term Dependency) : 문맥 내에서 멀리 떨어져 있는 단어들 간의 관계를 처리하는 문제      PPL      Perplexity(PPL) : 언어 모형의 성능 평가 지표\\[\\begin{aligned}  PPL(W)  &amp;= P(W)^{-\\frac{1}{N}}\\\\  &amp;= P(w_1, w_2, \\cdots, w_N)^{-\\frac{1}{N}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{P(w_1, w_2, \\cdots, w_N)}}\\\\  &amp;= \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  \\end{aligned}\\]        해석 : 선택 가능한 경우의 수를 의미하는 분기 계수(Branching Factor)로서, 특정 시점마다 평균적으로 고민하는 선택지 수\\[\\begin{aligned}  PPL(W)  &amp;=10\\\\  \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}}}  &amp;= 10\\\\  \\prod_{i=1}^{n}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}\\\\  \\underset{\\frac{1}{10}}{P(w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_2 \\mid w_1)} \\cdot \\underset{\\frac{1}{10}}{P(w_3 \\mid w_1, w_2)} \\cdots \\underset{\\frac{1}{10}}{P(w_N \\mid w_1, w_2, \\cdots, w_{N-1})}  &amp;= \\left(\\frac{1}{10}\\right)^{N}  \\end{aligned}\\]  Topic Model  토픽 모형(Topic Model) : 관측 가능한 단어(Word) 및 문서(Document)로부터 말뭉치(Corpus)에 내재되어 있는(Latent) 토픽(Topic)을 탐색하는 방법          문서(Document)는 토픽(Topic)으로 어떻게 표현할 수 있을까?      단어(Word)sms 토픽(Topic) 별로 어떻게 등장하는가?      탐색된 Something(Topic)의 정체를 무엇이라 정의하면 좋을까?      LSA      잠재 의미 분석(Latent Semantic Analysis; LSA) : 특이값 분해(Singular Value Decomposition; SVD)를 활용하여 Document-Term Matrix 를 분해하는 방법                            Dimension          Interpretation                                                 $n$          Number of Document                                     $d$          Number of Term                                     $k$          Number of Topic          Hyper-Parameter                            $\\mathbb{A}_{n \\times d}$ : Document-Term Matrix      \\(\\mathbb{U}_{n \\times k} \\cdot \\Sigma_{k \\times k}\\) : Document-Topic Matrix      $\\Sigma_{k \\times k} \\cdot \\mathbb{V}_{d \\times k}^{T}$ : Term-Topic Matrix            특이값 분해(Singular Value Decomposition; SVD) : 차원의 크기가 $n \\times d$ 인 임의의 행렬 $\\mathbb{A}$ 를 세 개의 행렬의 곱으로 분해하는 방법    \\[\\mathbb{A} = \\mathbb{U} \\cdot \\Sigma \\cdot \\mathbb{V}^{T}\\]          $\\mathbb{U}_{n \\times k}$ : 직교 정규 행렬(Ortho-normal Matrix)                              열벡터 $\\overrightarrow{u}_{i} \\in \\mathbb{U}$ 는 행렬 $\\mathbb{A} \\cdot \\mathbb{A}^{T}$ 의 고유벡터(Eigen Vector)임\\[\\mathbb{A}\\mathbb{A}^{T} \\cdot \\overrightarrow{u}_i = \\lambda_i \\overrightarrow{u}_i\\]                                열벡터 $\\overrightarrow{u}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\overrightarrow{u}_{i} \\Vert = 1\\]                                열벡터 \\(\\overrightarrow{u}_{i}, \\overrightarrow{u}_{j}\\) 은 직교함\\[\\overrightarrow{u}_{i} \\perp \\overrightarrow{u}_{j} \\Leftrightarrow \\langle \\overrightarrow{u}_{i}, \\overrightarrow{u}_{j} \\rangle = 0\\]                              $\\mathbb{V}_{d \\times k}^{T}$ : 직교 정규 행렬(Ortho-normal Matrix)                              열벡터 $\\overrightarrow{v}_{i} \\in \\mathbb{V}$ 는 행렬 $\\mathbb{A}^{T} \\cdot \\mathbb{A}$ 의 고유벡터(Eigen Vector)임\\[\\mathbb{A}^{T}\\mathbb{A} \\cdot \\overrightarrow{v}_i = \\lambda_i \\overrightarrow{v}_i\\]                                열벡터 $\\overrightarrow{v}_{i}$ 의 길이는 $1$ 임\\[\\Vert \\overrightarrow{v}_{i} \\Vert = 1\\]                                열벡터 \\(\\overrightarrow{v}_{i}, \\overrightarrow{v}_{j}\\) 은 직교함\\[\\overrightarrow{v}_{i} \\perp \\overrightarrow{v}_{j} \\Leftrightarrow \\langle \\overrightarrow{v}_{i}, \\overrightarrow{v}_{j} \\rangle = 0\\]                                      $\\Sigma_{k \\times k}$ : 대각 행렬(Diagonal Matrix)\\[\\Sigma_{k \\times k}  = \\begin{pmatrix}  \\sigma_{1} &amp; 0 &amp; \\cdots &amp; 0 \\\\  0 &amp; \\sigma_{2} &amp; \\cdots &amp; 0 \\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\  0 &amp; 0 &amp; \\cdots &amp; \\sigma_{k}  \\end{pmatrix}\\]                              대각항의 원소 $\\sigma_{i}$ 는 행렬 $\\mathbb{A} \\cdot \\mathbb{A}^{T}$ 혹은 $\\mathbb{A}^{T} \\cdot \\mathbb{A}$ 의 고유값(Eigen Value) $\\lambda_{i}$ 의 자승근임\\[\\sigma_{i} = \\sqrt{\\lambda_i}\\]                              LDA      잠재 디리클레 할당(Latent Dirichlet Allocation; LDA) : 베이지안 프레임워크를 활용하여 문서에 내재된 잠재적인 토픽 구조를 탐색하는 방법\\[\\begin{aligned}  &amp;\\hat{\\theta}, \\hat{\\psi}\\\\  &amp;=\\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{P(\\theta_d \\mid z(d,n)) \\times P(\\psi_{z(d,n)} \\mid w(d,n))}}}\\\\  &amp;\\propto \\text{arg} \\max_{\\theta, \\psi}{\\prod_{d=1}^{D}{\\prod_{n=1}^{N_d}{\\underbrace{P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)}_{\\begin{array}{c} \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\begin{array}{c} \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}}}}  \\end{aligned}\\]          $P(\\theta_d \\mid z(d,n)) \\propto P(\\theta_d) \\cdot P(z(d,n) \\mid \\theta_d)$ : Posterior Probability of Document-Topic Allocation      $P(\\psi_{z(d,n)} \\mid w(d,n)) \\propto P(\\psi_{z(d,n)}) \\cdot P(w(d,n) \\mid \\psi_{z(d,n)})$ : Posterior Probability of Topic-Word Allocation            Posterior Probability $P(\\theta, \\psi ; z \\mid w)$          각 문서는 여러 토픽의 혼합으로 구성되어 있고, 각 토픽은 특정 단어들의 혼합으로 구성되어 있다고 가정하자. 특정 문서를 구성하고 있는 단어들로부터, 해당 단어들을 발생시킨 토픽들의 비중을 추론할 수 있음.                      문서 $d$ 에는 여러 토픽들이 담겨 있으며, 각 토픽 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} k \\mid \\theta_d &amp;\\sim \\text{Multinomial}(\\theta_{d})\\\\ \\theta_{d} &amp;\\sim \\text{Dirichlet}(\\alpha) \\end{aligned}\\]                  $k \\mid \\theta_d$ : 문서 $d$ 에서 토픽 $k$ 가 발생할 확률          $\\theta_d$ : $d$ 번째 문서에서 각 토픽들이 발생할 확률                            토픽 $k$ 에서는 여러 단어들이 발생할 수 있으며, 각 단어 발생 확률은 디리클레 분포를 따름\\[\\begin{aligned} w \\mid \\psi_{k} &amp;\\sim \\text{Multinomial}(\\psi_{k})\\\\ \\psi_{k} &amp;\\sim \\text{Dirichlet}(\\beta) \\end{aligned}\\]                  $w \\mid \\psi_{k}$ : 토픽 $k$ 에서 단어 $w$ 가 발생할 확률          $\\psi_{k}$ : 토픽 $k$ 에서 각 단어들이 발생할 확률                            따라서 단어 $w(d,n)$ 이 발생했을 때, $\\theta_d$ 및 $\\psi_{z(d,n)}$ 의 사후 확률 분포는 다음과 같음\\[\\begin{aligned} &amp;P(\\theta_d, \\psi_{z(d,n)}; z(d,n) \\mid w(d,n))\\\\ &amp;\\propto \\underbrace{P(\\theta_d \\mid z(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Document-Topic} \\\\ \\text{Allocation} \\end{array}} \\times \\underbrace{P(\\psi_{z(d,n)} \\mid w(d,n))}_{\\begin{array}{c} \\text{Posterior of} \\\\ \\text{Topic-Word} \\\\ \\text{Allocation} \\end{array}}\\\\ &amp;\\propto \\left[\\underbrace{P(\\theta_d)}_{\\text{Prior}} \\cdot \\underbrace{P(z(d,n) \\mid \\theta_d)}_{\\text{Likelihood}}\\right] \\times \\left[\\underbrace{P(\\psi_{z(d,n)})}_{\\text{Prior}} \\cdot \\underbrace{P(w(d,n) \\mid \\psi_{z(d,n)})}_{\\text{Likelihood}}\\right] \\end{aligned}\\]                  $w(d,n)$ : 문서 $d$ 의 $n$ 번째 단어          $z(d,n)$ : 단어 $w(d,n)$ 에 대하여 해당 단어가 할당된 토픽          $\\theta_d$ : 문서 $d$ 의 토픽 분포          $\\psi_{z(d,n)}$ : 토픽 $z(d,n)$ 의 단어 분포                    이미지 출처  https://velog.io/@growthmindset/%EC%9B%90-%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9One-Hot-Encoding"
  },
  
  {
    "title": "NVMF",
    "url": "/posts/NVMF/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Deep Learning, Autoencoder, Bayesian",
    "date": "2024-07-31 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Text Data Preprocessing",
    "url": "/posts/Text_Data_Preprocessing/",
    "categories": "AI & Data Mining, Text Analytics",
    "tags": "Data Mining, Text Mining",
    "date": "2024-07-30 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Regular Expression",
    "url": "/posts/Regular-Expression/",
    "categories": "AI & Data Mining, Text Analytics",
    "tags": "Data Mining, Text Mining",
    "date": "2024-07-29 00:00:00 +0900",
    





    
    "snippet": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                   ...",
    "content": "Regular Expression  정규표현식(Regular Expression) : 특정 문자 패턴을 정의하는 방식          Practice      Meta-Character      검사 범위 자동 지정                            패턴          설명                                      .          개행 문자(\\n) 를 제외하고 공백을 포함한 모든 문자                          \\s          탭(\\t), 개행 문자(\\n)                          \\d          숫자                          \\D          \\d 의 검사 범위를 제외한 모든 문자                          \\w          알파벳 대소문자와 언더바(_)                          \\W          \\w 의 검사 범위를 제외한 모든 문자                          검사 범위 수동 지정                            패턴          설명                                      [xyz]          x, y, z 중 하나                          [^xyz]          x, y, z 를 제외한 모든 문자 중 하나                          (xyz)          xyz 매칭                          (?:xyz)          xyz 매칭                          x|yz          x 또는 yz                          검사 위치 지정                            패턴          설명                                      ^          첫 번째 줄의 시작                          $          마지막 줄의 끝                          \\b          경계 문자                          \\B          경계 문자                          (?=)          긍정형 전방 탐색                          (?!)          부정형 전방 탐색                          (?&lt;=)          긍정형 후방 탐색                          (?&lt;!)          부정형 후방 탐색                          수량 지정                            패턴          설명                                      *          $0$ 개 이상                          +          $1$ 개 이상                          ?          $0$ 또는 $1$                          {n}          $n$ 개                          {n,}          $n$ 개 이상                          {,n}          $n$ 개 이하                          {m,n}          $m$ 개 이상 $n$ 개 이하                    Escape Sequence  백슬래시를 활용하여 특정 문자들을 탈출(Escape) 시켜서 원래의 기능을 무효화하거나 특별한 기능을 수행하게 만드는 문자 조합            예약 문자      설명                  \\      Escape Sequence              \\n      개행              \\t      현재 시간              \\u      사용자 이름              \\w      현재 작업 중인 로컬 디렉토리 절대 경로              \\[      비출력문자열 시작              \\]      비출력문자열 종료      Python Package re      re.compile(pattern)      import re  pattern = ...  p = re.compile(pattern, option)              option                  None          re.DOTALL : 개행 문자(\\n)를 무시하고 매칭함          re.IGNORECASE : 대소문자 구분 없이 매칭함          re.MULTILINE : 문자열의 각 줄마다 매칭함                          p.match(my_str) : 문자열 처음부터 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.match(my_str)              result.group() : 매칭된 문자열을 반환함      result.start() : 매칭된 문자열의 시작 위치를 반환함      result.end() : 매칭된 문자열의 끝 위치를 반환함      result.span() : 매칭된 문자열의 (시작 위치, 끝 위치) 를 튜플로 반환함            p.search(my_str) : 문자열 전체를 탐색하여 정규표현식과 매칭되는지 조회함      my_str = ...  result = p.search(my_str)            p.findall(my_str) : 정규표현식과 매칭되는 모든 문자열을 반환함      my_str = ...  result = p.findall(my_str)            p.finditer(my_str) : 정규표현식과 매칭되는 모든 문자열을 반복 가능한 객체(iterator)로 반환함      my_str = ...  result = p.finditer(my_str)            p.sub(re_str, my_str) : 정규표현식과 매칭되는 모든 문자열을 다른 문자열로 수정함      my_str = ...  re_str = ...  result = p.sub(re_str, my_str)      Matching Rule of PythonForward Orderpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            1efG 매칭            추가 매칭되는 문자열 없음      Excluding the Prior Matchedpattern = '[a-zA-Z0-9]ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efCefGH\"results = p.finditer(my_str)for result in results:    print(result)      2efC 매칭            먼저 매칭된 문자열을 제외하고 탐색하므로 CefG 는 포함되지 않음      Greedypattern = '[a-zA-Z0-9]+ef[a-zA-Z0-9]'p = re.complile(pattern)my_str = \"AB12efC1efGH\"results = p.finditer(my_str)for result in results:    print(result)      If Python is not Greedy            But Python is Greedy      Exploration이미지 출처  https://zephyrus1111.tistory.com/310"
  },
  
  {
    "title": "BPMF",
    "url": "/posts/BPMF/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Bayesian",
    "date": "2024-07-24 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Bayesian Neural Networks",
    "url": "/posts/Bayesian_Neural_Networks/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, Deep Learning, BNN",
    "date": "2024-07-22 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Bayesian Regression",
    "url": "/posts/Bayesian_Regression/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, Regression",
    "date": "2024-07-21 00:00:00 +0900",
    





    
    "snippet": "        Bayesian Regression ModelFrequentist Estimation      다중선형회귀모형(Multiple Linear Regression Model)\\[\\begin{aligned}  \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\beta} + \\overrightarr...",
    "content": "        Bayesian Regression ModelFrequentist Estimation      다중선형회귀모형(Multiple Linear Regression Model)\\[\\begin{aligned}  \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\beta} + \\overrightarrow{\\varepsilon}  \\quad \\text{for} \\quad \\overrightarrow{\\varepsilon} \\sim N(0, \\sigma^2\\mathbf{I})\\\\  \\therefore \\overrightarrow{y}  &amp;= \\mathbf{X}\\overrightarrow{\\hat{\\beta}}  \\end{aligned}\\]  MLE      최우추정법(Maximum Liklihood Estimation; MLE) : 우도를 최대화하는 회귀계수를 탐색하는 방법\\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}_{MLE}  &amp;= \\text{arg}\\max{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}  \\end{aligned}\\]        우도(Liklihood) : 파라미터 $\\theta$ 가 주어졌을 때, 관측치 $y$ 가 발생할 확률\\[\\begin{aligned}  \\overrightarrow{y}  &amp;\\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}) \\quad (\\because \\overrightarrow{\\varepsilon} \\sim N(0, \\sigma^2\\mathbf{I}))\\\\  \\\\  \\therefore \\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)  &amp;= P(\\overrightarrow{y} \\,\\mid\\, \\overrightarrow{\\beta}, \\sigma^2)\\\\  &amp;= \\frac{1}{(2\\pi\\sigma^2)^{n/2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\right]}  \\end{aligned}\\]  OLS      최소자승법(Least Square Estimation; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 탐색하는 방법\\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}_{OLS}  &amp;= \\text{arg}\\min_{\\beta}{RSS}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]        Residual Sum of Square(RSS) : 잔차 자승의 합\\[\\begin{aligned}  RSS  &amp;= \\sum_{i}{(y_{i}-\\hat{y}_{i})^2}\\\\  &amp;= \\mid \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\mid^{2}\\\\  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})  \\end{aligned}\\]  \\(\\hat{\\beta}_{MLE}=\\hat{\\beta}_{OLS}\\)      우도 $\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)$ 는 잔차 $RSS$ 에 반비례함\\[\\begin{aligned}  \\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)  &amp;\\propto \\log{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}\\\\  &amp;= -\\frac{n}{2}\\cdot\\log{2\\pi\\sigma^2}-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\propto -\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\propto -(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;= -RSS  \\end{aligned}\\]        따라서 \\(\\hat{\\beta}_{MLE}\\) 과 \\(\\hat{\\beta}_{OLS}\\) 는 동일함\\[\\begin{aligned}  \\therefore \\text{arg}\\max_{\\beta}{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}  &amp;= \\text{arg}\\max_{\\beta}{\\log{\\mathcal{L}(\\overrightarrow{\\beta}, \\sigma^2)}}\\\\  &amp;= \\text{arg}\\max_{\\beta}{-(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})}\\\\  &amp;= \\text{arg}\\min_{\\beta}{(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})}\\\\  &amp;= \\text{arg}\\min_{\\beta}{RSS}  \\end{aligned}\\]          \\(\\hat{\\beta}_{MLE}\\) : 최우추정량으로서 우도를 최대화하는 모수      \\(\\hat{\\beta}_{OLS}\\) : 최소자승추정량으로서 잔차를 최소화하는 모수      Non-informative Prior DeterminationLiklihood Function Transformation      다중선형회귀모형의 우도 함수\\[\\begin{aligned}  \\mathcal{L}(\\beta, \\sigma^2)  &amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]} \\quad (\\because \\overrightarrow{y} \\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}))\\\\  &amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}  \\end{aligned}\\]        $(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})$ 변형\\[\\begin{aligned}  (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= \\left[(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\right]^{T}\\left[(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\right]\\\\  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\\\  &amp;\\quad + (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;\\quad + 2 \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})\\\\  \\\\  (\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\\\  2 \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}\\overrightarrow{\\hat{\\beta}}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;=0\\\\  \\\\  \\therefore (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})  &amp;= (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}}) + (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\\\  \\end{aligned}\\]        우도 함수에 대입\\[\\begin{aligned}  \\mathcal{L}(\\beta, \\sigma^2)  &amp;\\propto (\\sigma^2)^{-n/2}\\\\  &amp;\\quad \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\right]}\\\\  &amp;\\quad \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\  \\end{aligned}\\]        잔차 분산 및 자유도 정의\\[\\begin{aligned}  s^{2}  &amp;= \\frac{1}{\\nu} \\cdot RSS\\\\  &amp;= \\frac{1}{\\nu} \\cdot (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\hat{\\beta}})\\\\  \\nu  &amp;= n-k  \\end{aligned}\\]        우도 함수에 대입\\[\\begin{aligned}  \\therefore \\mathcal{L}(\\beta, \\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\  &amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}  \\end{aligned}\\]  Prior Determination of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2)&amp;= P(\\beta ; \\sigma^2) \\cdot P(\\sigma^2)\\\\&amp;= P(\\beta) \\cdot P(\\sigma^2) \\quad (\\because \\text{i.i.d})\\\\&amp;= 1 \\times \\frac{1}{\\sigma^2}\\end{aligned}\\]      Jacobian Change of $\\sigma^2$ for Relaxing Range Constraints\\[\\begin{aligned}  \\psi  &amp;= \\log{\\sigma^2}\\\\  \\therefore P(\\sigma^2)  &amp;= P(\\psi) \\cdot \\frac{1}{\\sigma^2}  \\end{aligned}\\]        Non-informative Prior Determination of $\\beta, \\psi$\\[\\beta, \\psi \\sim \\text{Uniform}(0,1)\\]        Jeffreys Prior of $\\sigma^2$\\[\\begin{aligned}  P(\\sigma^2)  &amp;= P(\\psi) \\cdot \\frac{1}{\\sigma^2}\\\\  &amp;= \\frac{1}{\\sigma^2}  \\end{aligned}\\]  Posterior Estimation of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2 \\mid \\mathcal{D})&amp;\\propto P(\\mathcal{D} \\mid \\beta, \\sigma^2) \\cdot P(\\beta, \\sigma^2)\\\\\\\\&amp;\\propto (\\sigma^2)^{-\\nu/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2} \\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\&amp;\\quad \\times \\frac{1}{\\sigma^2}\\\\\\\\&amp;= (\\sigma^2)^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2} \\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\end{aligned}\\]      Marginal Posterior of $\\sigma^2$ is Inverse Chi-Squared Distribution\\[\\begin{aligned}  f(\\sigma^2 \\mid \\nu,s^2)  &amp;=(\\sigma^2)^{-\\nu/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu s^2\\right]}\\\\  \\therefore \\sigma^2 \\mid \\mathcal{D}  &amp;\\sim \\text{Inv-}\\chi^2(\\nu,s^2)  \\end{aligned}\\]        Conditional Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  f(\\beta \\mid \\hat{\\beta}, \\mathbf{V}_{\\beta})  &amp;= (\\sigma^2)^{-(n-\\nu)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot (\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})^{T}(\\mathbf{X}^{T}\\mathbf{X})(\\overrightarrow{\\beta} - \\overrightarrow{\\hat{\\beta}})\\right]}\\\\  \\therefore \\beta ; \\sigma^2 \\mid \\mathcal{D}  &amp;\\sim N(\\overrightarrow{\\hat{\\beta}}, \\sigma^2\\mathbf{V}_{\\beta})  \\end{aligned}\\]          $\\overrightarrow{\\hat{\\beta}}=(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}$ : $\\overrightarrow{\\beta}$ 의 최우추정량      $\\sigma^2\\mathbf{V}_{\\beta}=\\sigma^2(\\mathbf{X}^{T}\\mathbf{X})^{-1}$ : $\\overrightarrow{\\beta}$ 의 공분산 행렬      Informative Prior DeterminationLiklihood Function\\[\\begin{aligned}\\mathcal{L}(\\beta, \\sigma^2)&amp;= (2\\pi\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]} \\quad (\\because \\overrightarrow{y} \\sim N(\\mathbf{X}\\overrightarrow{\\beta}, \\sigma^2\\mathbf{I}))\\\\&amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}\\end{aligned}\\]Setting Conjugate Prior of $\\beta, \\sigma^2$\\[P(\\beta, \\sigma^2) = P(\\beta ; \\sigma^2) \\cdot P(\\sigma^2)\\]      Conjugate Prior of $\\sigma^2$ is Scaled Inverse Chi-Squared Distribution\\[\\begin{aligned}  P(\\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\nu_{0}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu_{0} s_{0}^{2}\\right]}\\\\  &amp;\\propto \\text{Scaled Inv-}\\chi^2(\\nu_{0}, s_{0}^{2})  \\end{aligned}\\]          $\\nu_{0}$ : 사전 자유도      $s_{0}^{2}$ : 사전 잔차 분산            Conjugate Prior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  P(\\beta;\\sigma^2)  &amp;\\propto (\\sigma^2)^{-(n-\\nu_0)/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_0)^{T}\\Lambda_{0}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_0)\\right]}\\\\  &amp;\\propto N(\\overrightarrow{\\mu}_0, \\sigma^2\\Lambda_{0}^{-1})  \\end{aligned}\\]          $\\overrightarrow{\\mu}_0$ : $\\overrightarrow{\\beta}$ 의 사전 평균      $\\sigma^2\\Lambda_{0}^{-1}$ : $\\overrightarrow{\\beta}$ 의 사전 공분산 행렬      Posterior Estimation of $\\beta, \\sigma^2$\\[\\begin{aligned}P(\\beta, \\sigma^2 \\mid \\mathcal{D})&amp;\\propto P(\\mathcal{D} \\mid \\beta, \\sigma^2) \\cdot P(\\beta, \\sigma^2)\\\\\\\\&amp;\\propto (\\sigma^2)^{-n/2} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\nu_{n}/2-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot \\nu_{n} s_{n}^{2}\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\\\\\\\&amp;= (\\sigma^2)^{-\\frac{n+\\nu_n}{2}-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\left(\\nu_n s^{2}_{n} + (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right)\\right]}\\\\&amp;\\quad \\times (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\end{aligned}\\]      Posterior of $\\sigma^2$ is Inverse-Gamma Distribution\\[\\begin{aligned}  P(\\sigma^2 \\mid \\mathcal{D})  &amp;\\propto (\\sigma^2)^{-\\frac{n+\\nu_n}{2}-1} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\left(\\nu_n s^{2}_{n} + (\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y}-\\mathbf{X}\\overrightarrow{\\beta})\\right)\\right]}\\\\  &amp;\\propto \\text{Inv-Gamma}\\left(\\frac{n + \\nu_n}{2}, \\frac{1}{2} \\left[\\nu_n s_n^2 + (\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})^{T}(\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})\\right]\\right)  \\end{aligned}\\]          $\\nu_{n}$ : 사후 자유도      $s_{n}^{2}$ : 사후 잔차 분산            Posterior of $\\beta$ given $\\sigma^2$ is Normal Distribution\\[\\begin{aligned}  P(\\beta;\\sigma^2)  &amp;\\propto (\\sigma^2)^{-\\frac{n-\\nu_n}{2}} \\cdot \\exp{\\left[-\\frac{1}{2\\sigma^2}\\cdot(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)^{T}\\Lambda_{n}(\\overrightarrow{\\beta}-\\overrightarrow{\\mu}_n)\\right]}\\\\  &amp;\\propto N(\\overrightarrow{\\mu}_n, \\sigma^2\\Lambda_{n}^{-1})  \\end{aligned}\\]          $\\overrightarrow{\\mu}_n$ : $\\overrightarrow{\\beta}$ 의 사후 평균      $\\sigma^2\\Lambda_{n}^{-1}$ : $\\overrightarrow{\\beta}$ 의 사후 공분산 행렬      "
  },
  
  {
    "title": "Multi Armed Bandits",
    "url": "/posts/Multi_Armed_Bandits/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, MAB, Multi Armed Bandits",
    "date": "2024-07-20 00:00:00 +0900",
    





    
    "snippet": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. ...",
    "content": "What? Multi-Armed Bandits      Multi-Armed Bandits Problem : 보상 확률을 알 수 없는 여러 선택지 중 하나를 선택하는 문제              $n$ 개의 슬롯 머신이 각각 특정한 확률분포를 따르는 보상을 돌려준다고 하자. 즉, 슬롯 머신이 돌려주는 보상 금액은 동일하되, 보상 받을 확률은 다르다. 단, 슬롯 머신의 보상 확률은 알려져 있지 않다. 어떤 슬롯 머신을 고르는 것이 이득일까?            A/B Test vs. MAB                      A/B Test : 탐색 후 그 결과를 100% 활용하는 불연속적인(Discrete) 방법                  $n$ 개의 집단에 $n$ 개의 선택지를 노출하여 순수하게 새로운 가능성을 탐색(Exploration)한 후, 의사결정이 완료된 후에는 채택된 선택지를 모든 집단에 노출하여 활용함(Exploitation)                            MAB : 탐색과 활용을 동시에 수행하는 연속적인(Continuous) 방법                  고객의 피드백을 실시간으로 반영하며 각 선택지의 보상 확률을 갱신함으로써 열등한 선택지는 비교적 적게 노출하고 우월한 선택지는 비교적 많이 노출함                          Selection Issue : Exploration-Exploitation Trade-off              만약 적당히 좋은 결과를 돌려주는 슬롯 머신을 찾아냈다면, 그 결과를 유지하기 위해 그 슬롯 머신을 활용할 것인가(Exploitation) 아니면 더 좋은 결과를 얻을 수 있다는 희망으로 다른 슬롯 머신을 탐색할 것인가(Exploration)?              탐색(Exploration) : 다양한 슬롯 머신들을 선택하면서 보상이 어느 정도 도출되는지 탐색하는 과정      활용(Exploitation) : 수집된 정보를 바탕으로 보상 확률이 높은 슬롯 머신을 선택하는 과정      Selection Algorithms      Loss Function for MAB is Total Regret\\[\\begin{aligned}  \\mathcal{R}(T)  &amp;= \\sum_{t=1}^{T}{\\left[\\theta_{opt}-\\theta_{B(t)}\\right]}\\\\  &amp;= T \\cdot \\theta_{opt} - \\sum_{t=1}^{T}{\\theta_{B(t)}}  \\end{aligned}\\]          $B(t)$ : $t$ 번째 시점에서 선택한 슬롯 머신      $P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률 분포      $\\theta_{B(t)} \\sim P_{B(t)}$ : $t$ 번째 시점에서 선택한 슬롯 머신의 보상 확률      $\\theta_{opt}$ : 최적 슬롯 머신의 보상 확률      Bayes Selection; Thompson Sampling      모든 슬롯 머신의 보상 확률에 대하여 사전 확률 분포 설정\\[\\begin{aligned} X \\mid \\theta &amp;\\sim \\text{Bin}(n,\\theta)\\\\ \\therefore \\theta &amp;\\sim \\text{Beta}(\\alpha_0,\\beta_0) \\end{aligned}\\]        보상 확률이 가장 높은 슬롯 머신 선택\\[B(t)=\\text{arg}\\max_{a}{\\theta_{a}}\\]        보상 관찰 후 해당 슬롯 머신의 사후 확률 분포 갱신\\[\\begin{aligned} \\theta_{B(t)} \\mid X &amp;\\sim \\text{Beta}(\\alpha, \\beta)\\\\ \\alpha &amp;= \\alpha_0 + X\\\\ \\beta &amp;= \\beta_0 - n + X \\end{aligned}\\]  Extra Selection Algorithms      Greedy : $t-1$ 번째 시점까지 탐색한 정보를 토대로 기대 보상이 가장 큰 슬롯 머신만을 활용하는 전략\\[\\begin{aligned}  B(t)  &amp;= \\text{arg}\\max_{a}{Q(a;t)}\\\\  &amp;= \\text{arg}\\max_{a}{\\frac{\\sum_{i=1}^{t-1}{\\tau_{i} \\cdot \\mathbb{I}\\left[B(i)=a\\right]}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}  \\end{aligned}\\]          $\\tau_{i}$ : $i$ 번째 시점에서 받은 보상      $\\mathbb{I}\\left[B(i)=a\\right]$ : Indicate Function            $\\varepsilon$-Greedy : $\\varepsilon$ 의 확률로 새로운 슬롯 머신을 탐색하는 전략\\[B(t)  = \\begin{cases}\\begin{aligned}  Q(a;t) \\quad &amp; \\text{with probability} \\; 1-\\varepsilon\\\\  \\text{random} \\quad &amp; \\text{with probability} \\; \\varepsilon  \\end{aligned}\\end{cases}\\]          $Q(a;t)$ : Exploitation Term      $\\text{random}$ : Exploration Term            UCB(Upper Confidence Bound) : 승률이 높은 슬롯 머신을 활용하면서, 승률의 불확실성이 높은 슬롯 머신을 탐색하는 전략\\[B(t)  =\\text{arg}\\max_{a}{\\left[Q(a;t) + c \\cdot \\sqrt{\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}\\right]}\\]          $Q(a;t)$ : Exploitation Term      $\\sqrt{\\displaystyle\\frac{\\ln{t}}{\\sum_{i=1}^{t-1}{\\mathbb{I}\\left[B(i)=a\\right]}}}$ : Exploration Term      $c$ : Exploration Constant      이미지 출처  https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/  https://link.springer.com/article/10.1007/s10489-023-04955-0?fromPaywallRec=false"
  },
  
  {
    "title": "Bayesian A/B Test",
    "url": "/posts/Bayesian_A_B_Test/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, A/B Test",
    "date": "2024-07-19 00:00:00 +0900",
    





    
    "snippet": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 ...",
    "content": "  Question  프론트엔드 웹 개발자는 전환율(Conversion Rate)을 개선하기 위해 웹사이트 디자인을 기존 $A$ 안에서 $B$ 안으로 개편하고자 한다. 변경 전, 개발자는 개편이 성공적이었는지 확인하기 위해 A/B Test 를 실시하였다. 구체적으로 방문객 일부에게는 $A$ 를, 나머지는 $B$ 를 제공한 후, 전환 수를 아래와 같이 기록하였다. $A,B$ 전환율 간에 유의한 차이가 있다고 볼 수 있는가? (단, \\(\\sigma^2_{A}=\\sigma^2_{B}\\) 임이 알려져 있다고 가정한다.)            디자인      방문자 수      전환 수                  A      1,300      120              B      1,275      125      Frequentist A/B Test  Point Estimator          Interest Parameter : $\\pi_A-\\pi_B$      Point Estimator : $p_A-p_B$        Hypothesis          $H_{0}:\\quad p_A-p_B = D_{0}$      $H_{1}:\\quad p_A-p_B \\ne D_{0}$            Parametric Test Assumptions\\[\\begin{aligned}  n_A \\cdot p_A &amp;\\ge 5\\\\  n_A \\cdot (1-p_A) &amp;\\ge 5\\\\  n_B \\cdot p_B &amp;\\ge 5\\\\  n_B \\cdot (1-p_B) &amp;\\ge 5  \\end{aligned}\\]        Test Statistic\\[\\begin{aligned}  Z  &amp;= \\frac{(p_A-p_B) - D_0}{\\sqrt{s^2_p(1-s^2_p)\\left(\\displaystyle\\frac{1}{n_A}+\\displaystyle\\frac{1}{n_B}\\right)}}  \\sim N(0,1)  \\end{aligned}\\]                  $s^{2}_p$ : Pooled Estimator\\[s^{2}_p = \\frac{n_A \\cdot p_A + n_B \\cdot p_B }{n_A + n_B}\\]            Bayesian A/B Test      Prior of $\\pi$ Determination                  전환율 $\\pi$ 은 $n$ 번의 실험에 따른 성공 횟수 $X \\mid \\pi$ 에 대한 성공 확률임\\[X \\mid \\pi \\sim \\text{Bin}(n,\\pi)\\]                    Binomial Dist. 의 성공 확률 $\\pi$ 에 대한 Conjugate Prior Dist. 로서 Beta Dist. 가 적합함\\[\\pi \\sim \\text{Beta}(\\alpha_0,\\beta_0)\\]                  Posterior of $\\pi \\mid X$ Estimation\\[\\pi \\mid X \\sim \\text{Beta}(\\alpha_0 + X, \\beta_0 + n - X)\\]        Beyes Action\\[\\hat{p} = \\text{arg}\\min{\\mathcal{R}(p)}\\]                  $\\mathcal{R}(p)$ : Bayes Risk\\[\\begin{aligned}  \\mathcal{R}(p)  &amp;= \\mathbb{E}_{\\pi \\mid X}\\left[\\text{Loss}(\\pi, p)\\right]\\\\  &amp;\\approx \\frac{1}{k}\\sum_{i=1}^{k}{\\text{Loss}(p^{(i)}, p)}  \\end{aligned}\\]                  Compare $\\hat{p}_A$ and $\\hat{p}_B$  "
  },
  
  {
    "title": "Bayes Action",
    "url": "/posts/Bayes_Action/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, Optimization, Loss Function",
    "date": "2024-07-18 00:00:00 +0900",
    





    
    "snippet": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출...",
    "content": "Bayes Action  사후확률 $\\theta \\mid X$ 을 추정하기 위해, 확률분포 $P(\\theta \\mid X) \\propto \\mathcal{L}(\\theta) \\cdot \\pi(\\theta)$ 로부터 $n$ 번의 샘플링을 통해 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)}$ 을 도출했다고 하자. 그렇다면 이들 중 무엇을 모수 $\\theta \\mid X$ 의 추정치 $\\hat{\\theta}$ 로 사용하는 것이 적절할까?      Bayes’ Risk : 사후확률분포 $P(\\theta \\mid X)$ 를 사용하여 계산된, 모수 $\\theta$ 에 대하여 추정치 $\\hat{\\theta}$ 를 선택할 때의 기대 손실(Expected Loss)\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;= \\int{\\text{Loss}(\\theta, \\hat{\\theta}) \\cdot P(\\theta \\mid X)}\\text{d}\\theta  \\end{aligned}\\]                  모수 $\\theta \\mid X$ 를 알 수 없으므로, $n$ 번의 샘플링을 통해 도출한 $n$ 개의 샘플 $\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(n)} \\sim P(\\theta \\mid X)$ 를 사용하여 근사함\\[\\begin{aligned}  \\mathcal{R}(\\hat{\\theta})  &amp;= \\mathbb{E}_{\\theta \\mid X}\\left[\\text{Loss}(\\theta, \\hat{\\theta})\\right]\\\\  &amp;\\approx \\frac{1}{N}\\sum_{i=1}^{N}{\\text{Loss}(\\theta^{(i)}, \\hat{\\theta})}  \\end{aligned}\\]                  Bayes Estimator : 모수 $\\theta$ 에 대하여, Bayes’ Risk 를 최소화시키는 추정치 $\\hat{\\theta}$\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathcal{R}(\\hat{\\theta})}  \\end{aligned}\\]                  Posterior Mean : Bayes’ Least Square (BLS) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[(\\theta-\\hat{\\theta})^2\\right]}\\\\  &amp;= \\mathbb{E}_{\\theta \\mid X}(\\theta)  \\end{aligned}\\]                    Posterior Median\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[ \\vert \\theta-\\hat{\\theta} \\vert \\right]}\\\\  &amp;= \\tilde{\\theta}  \\end{aligned}\\]                    Posterior mode : Maximum a posteriori (MAP) Estimator\\[\\begin{aligned}  \\hat{\\theta}  &amp;= \\text{arg} \\min_{\\hat{\\theta}}{\\mathbb{E}_{\\theta \\mid X}\\left[1_{\\hat{\\theta} \\ne \\theta}\\right]}\\\\  &amp;= \\text{arg} \\max_{\\theta}{P(\\theta \\mid X)}  \\end{aligned}\\]            Loss FunctionContinuous Prob. Variable      Squared Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= (\\theta - \\hat{\\theta})^2  \\end{aligned}\\]        Asymmetric Squared Error Loss\\[\\text{Loss}(\\theta, \\hat{\\theta})  = \\begin{cases}\\begin{aligned}  &amp;(\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} &lt; \\theta&amp;\\\\  &amp;c \\cdot (\\theta - \\hat{\\theta})^2 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ge \\theta&amp;,\\;0&lt;c&lt;1  \\end{aligned}\\end{cases}\\]        Absolute Error Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  =  \\vert \\theta - \\hat{\\theta} \\vert   \\end{aligned}\\]  Discrete Prob. Variable      Zero-One Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  &amp;= 1_{\\hat{\\theta} \\ne \\theta}\\\\  &amp;= \\begin{cases}\\begin{aligned}  &amp;0 \\quad &amp;\\text{if}\\;\\hat{\\theta} = \\theta\\\\  &amp;1 \\quad &amp;\\text{if}\\;\\hat{\\theta} \\ne \\theta  \\end{aligned}\\end{cases}  \\end{aligned}\\]        Binary Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\left[\\hat{\\theta} \\cdot \\log{\\theta}+(1-\\hat{\\theta})\\cdot\\log{(1-\\theta)}\\right] \\quad \\text{for}\\;&amp;\\hat{\\theta}\\in\\{0,1\\},\\\\&amp;\\theta\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 베르누이 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Bernoulli}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\theta^{\\hat{\\theta}} \\cdot (1-\\theta)^{1-\\hat{\\theta}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\left[\\hat{\\theta} \\cdot \\log{\\theta} + (1-\\hat{\\theta}) \\cdot \\log{(1-\\theta)}\\right]  \\end{aligned}\\]                  Categorical Cross Entropy Loss\\[\\begin{aligned}  \\text{Loss}(\\theta, \\hat{\\theta})  = -\\sum_{i=1}^{K}{\\hat{\\theta}_{i}\\cdot\\log{\\theta_{i}}} \\quad \\text{for}\\;&amp;\\hat{\\theta}_{i}\\in\\{0,1\\},\\\\&amp;\\theta_{i}\\in[0,1]  \\end{aligned}\\]                  관측치 $\\hat{\\theta}$ 가 $\\theta$ 를 확률로 가지는 카테고리 분포로부터 생성된다고 하자\\[\\begin{aligned}  \\hat{\\theta} \\sim \\text{Categorical}(\\theta)  \\end{aligned}\\]                    $\\hat{\\theta}$ 에 대한 확률질량함수는 다음과 같음\\[P(\\hat{\\theta};\\theta)=\\prod_{i=1}^{K}{\\theta_{i}^{\\hat{\\theta}_{i}}}\\]                    이를 $\\theta$ 에 대한 로그 우도 함수로 해석할 수 있음\\[\\begin{aligned}  \\log{\\mathcal{L}(\\theta)}  &amp;= \\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]                    $\\theta$ 를 모수, $\\hat{\\theta}$ 를 추정치에 대응하여 손실함수를 구성하면 다음과 같음\\[\\begin{aligned}  \\text{Loss}(\\theta,\\hat{\\theta})  &amp;= -\\log{\\mathcal{L}(\\theta)}\\\\  &amp;= -\\log{P(\\hat{\\theta} \\mid \\theta)}\\\\  &amp;= - \\sum_{i=1}^{K}{\\hat{\\theta}_{i} \\cdot \\log{\\theta_{i}}}  \\end{aligned}\\]            "
  },
  
  {
    "title": "BERT4REC",
    "url": "/posts/BERT4REC/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Sequential RecSys, Deep Learning, BERT",
    "date": "2024-07-17 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Posterior Estimation",
    "url": "/posts/Posterior/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, Markov Chain",
    "date": "2024-07-17 00:00:00 +0900",
    





    
    "snippet": "Monte Carlo Simulation      정의 : 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법        절차 : 무작위 샘플을 반복 생성하여 문제의 수치적 근사치를 얻음          문제 정의 : 해결하려는 문제를 수학적 모형으로 정의함      확률분포 설정 : 변수들에 대한 무작위 샘플을 생성...",
    "content": "Monte Carlo Simulation      정의 : 복잡한 시스템이나 수학적 문제의 결과를 예측하기 위해 확률적 샘플링을 사용하는 방법        절차 : 무작위 샘플을 반복 생성하여 문제의 수치적 근사치를 얻음          문제 정의 : 해결하려는 문제를 수학적 모형으로 정의함      확률분포 설정 : 변수들에 대한 무작위 샘플을 생성하기 위해 각 변수들의 확률분포를 설정함      샘플링 : 설정된 확률분포에서 무작위 샘플을 반복하여 추출함      모형 계산 : 각 샘플을 모형에 투입하여 결과를 계산함      결과 분석      example 원주율 구하기  한 변의 길이가 2인 정사각형 내부에 점을 무작위로 찍었을 때, 그 점이 정사각형에 내접하는 원의 내부에 위치할 확률 실험을 전개하여, 원주율 $\\pi$ 를 추론하시오.  좌표평면 상에서 주어진 조건을 만족하는 원          정의 : \\(C = \\{ (x, y) \\mid x^2 + y^2 = r^2 \\}\\)      면적 : $\\pi r^2 = \\pi \\quad (\\because 2r=2)$        좌표평면 상에서 주어진 조건을 만족하는 정사각형          정의 : $R = { (x, y) \\mid -1 \\le x \\le 1, -1 \\le y \\le 1} $      면적 : $(2r)^2=4$            정사각형 내부에 점을 무작위로 찍었을 때, 점이 원 내부에 위치할 가능성\\[\\begin{aligned}  P((x,y) \\in C)  &amp;=\\displaystyle\\frac{N_{circle}}{N}\\\\  &amp;=\\displaystyle\\frac{\\pi r^2}{(2r)^2}\\\\  &amp;=\\displaystyle\\frac{\\pi}{4}  \\end{aligned}\\]          $N$ : 실행 횟수      $N_{circle}$ : 성공 횟수(원 내부에 위치한 횟수)            Monte Carlo Simulation 을 통한 $\\pi$ 추론값 도출              실행 횟수(num)가 증가할수록 $\\pi$ 의 추론값이 $3.141592\\cdots$ 에 근접해감      Rejection Sampling      정의 : 제안 분포로부터 추출한 관측치를 적절하게 거절하는 과정을 반복하여 표본 분포를 목표 분포와 유사한 형태로 만드는 방법    절차          제안 분포 $q(\\psi)$ 로부터 파라미터 $\\psi$ 샘플링              목표 분포 $p(\\theta \\mid \\mathcal{D})$, 제안 분포 $q(\\psi)$, 스케일링 팩터 $M$ 에 대하여, 다음 조건을 만족하지 않으면 $\\psi$ 를 샘플로 채택하지 않음\\[u \\le \\displaystyle\\frac{p(\\psi \\mid \\mathcal{D})}{M \\cdot q(\\psi)} \\quad \\text{s.t.} \\quad u \\sim \\text{Uniform}(0,1)\\]                  목표 분포(Target Dist.) : 파라미터 $\\theta$ 의 사후 확률 분포\\[p(\\theta \\mid \\mathcal{D}) \\propto p(\\mathcal{D} \\mid \\theta) \\cdot p(\\theta)\\]          $\\theta$ : 파라미터      $p(\\mathcal{D} \\mid \\theta)$ : 파라미터 $\\theta$ 의 우도 함수      $p(\\theta)$ : 파라미터 $\\theta$ 의 사전 확률 분포            제안 분포(Proposal Dist.)\\[q(\\psi)\\]          $\\psi$ : 파라미터로서 고려되는 샘플      $q(\\psi)$ 는 $p(\\psi \\mid \\mathcal{D})$ 와 위치 및 분포가 비슷해야 함      상수 $M$ 에 대하여, $p(\\psi \\mid \\mathcal{D}) \\le M \\cdot q(\\psi)$ 를 만족해야 함            거절 확률(Rejection Prob.)\\[\\frac{p(\\psi \\mid \\mathcal{D})}{M \\cdot q(\\psi)} \\propto \\frac{p(\\mathcal{D} \\mid \\psi) \\cdot p(\\psi)}{M \\cdot q(\\psi)}\\]  Markov Chain Monte Carlo  Markov Chain Monte Carlo(MCMC)          정의 : 이전 단계에서 추출한 표본을 기반으로 다음 단계의 표본을 순차로 추출하는 방법      장점 : 차원이 높아질수록 표본 분포가 목표 분포로 수렴하는 속도가 지연되는 문제를 완화함      단점 : 모든 표본($x^{(t)}$)이 이전 단계에서 추출한 표본($x^{(t-1)}$)에 의존함      종류                  Metropolis Hastings Method          Gibbs Sampling                    Markov Chain      정의 : 어떤 시스템에 대하여 해당 시스템이 상태 공간 $S$ 에서 이산적인 시점($t=0,1,2,\\cdots$)에서만 상태 전이가 발생한다고 했을 때, 이 시스템이 마르코프 성질을 만족한다면, 이 시스템은 마르코프 체인이라고 볼 수 있음                  마르코프 성질 : 미래의 상태가 현재 상태에만 의존하며 과거의 상태는 고려하지 않는 성질\\[\\begin{aligned}  P(X_{n+1}=j \\mid X_{n}=i,X_{n-1}=i_{n-1},\\cdots,X_{0}=i_{0}) = P(X_{n+1}=j \\mid X_{n}=i)  \\end{aligned}\\]                  $X_{n}$ : 시점 $n$ 에서 시스템이 취하는 상태          $i,j \\in S$ : 특정 상태                          전이확률행렬(Transition Probability Matrix) : 각 상태에서 다른 상태로의 전이 확률을 나타내는 행렬\\[\\mathbf{P}_{n \\times n} = \\{p_{i,j} \\mid i,j \\in n, p_{i,j} \\in S\\}\\]                  $p_{i,j} \\in S$ : 상태 $i$ 에서 $j$ 로의 전이확률                  $0 \\le p_{i,j} \\le 1$          $\\sum_{j}{p_{i,j}}=1$ : 상태 $i$ 에서 다른 상태로 전이될 확률의 합은 1임                          정상확률(Steady-State Probability; $\\pi_{j}$) : 마르코프 체인이 장기적으로 상태 $j$ 를 취할 확률\\[\\pi_{j}=\\sum_{i}{\\pi_{i}\\cdot p_{i,j}}\\]          상태 $j$ 의 정상확률 $\\pi_{j}$ 는 상태 $i$ 에서 $j$ 로 전이할 확률의 기대값($E(x)=\\sum{x\\cdot P(x)}$)임            정상확률분포(Steady-State Probability Distribution; $\\overrightarrow{\\pi}$) : 마르코프 체인이 각 상태를 취할 확률이 시간에 따라 변하지 않고 일정하게 유지되는, 장기적인 확률 분포\\[\\overrightarrow{\\pi}=\\overrightarrow{\\pi}\\cdot\\mathbf{P}\\]  Metropolis Hastings Method      정의 : 목표 분포의 산 모양을 추정하기 위하여, 확률 밀도가 높은 지역일수록(봉우리가 높은 지역일수록) 그 근방에서 더 많은 조약돌을 모으는 방법    절차                  특정 위치에서 샘플링 시작하기\\[\\theta^{(t=0)}\\]                    근방의 조약돌 분포를 조사하여 새로 이동할 위치 $\\psi$ 탐색하기\\[\\psi=\\theta^{(t)}+\\varepsilon \\quad \\text{s.t.} \\quad \\varepsilon \\sim N(0, \\sigma^2)\\]                    새로운 조약돌이 해당 위치 $\\psi$ 에서 발견될 가능성을 조사하여 해당 위치를 수락할지 판단하기\\[\\theta^{(t+1)}  =\\begin{cases}\\begin{aligned}  \\psi, \\quad &amp;\\text{if} \\; u&lt;\\alpha(\\theta^{(t)},\\psi) \\quad \\text{for} \\quad u \\sim \\text{Uniform}(0,1)\\\\  \\theta^{(t)}, \\quad &amp;\\text{otherwise}  \\end{aligned}\\end{cases}\\]                  목표 분포(Target Dist.) : 파라미터 $\\theta^{(t)}$ 의 사후 확률 분포\\[p(\\theta^{(t)}\\mid \\mathcal{D}) \\propto p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})\\]          $\\theta^{(t)}$ : $t$ 번째 파라미터      $p(\\theta^{(t)})$ : 파라미터 $\\theta^{(t)}$ 의 사전 확률 분포      $p(\\mathcal{D} \\mid \\theta^{(t)})$ : 파라미터 $\\theta^{(t)}$ 의 우도 함수            제안 분포(Proposal Dist.) : 시점 $t$ 에서 수락된 파라미터 샘플 $\\theta^{(t)}$ 에 기반하여 다음 시점 $t+1$ 에서 샘플링 위치 $\\psi$ 를 제안하는 분포\\[q(\\psi \\mid \\theta^{(t)}) = N(\\psi;\\theta^{(t)},\\sigma^2)\\]                  제안 분포가 $\\theta^{(t)}$ 을 중심으로 하는 종형 분포인 경우, 다음을 만족함\\[q(\\psi \\mid \\theta^{(t)}) = q(\\theta^{(t)} \\mid \\psi)\\]                  $q(\\psi \\mid \\theta^{(t)})$ : 시점 $t$ 에서 조약돌을 수집한 위치가 $\\theta^{(t)}$ 일 때, 다음 시점 $t+1$ 에서 조약돌을 수집할 위치가 $y$ 일 가능성          $q(\\theta^{(t)} \\mid \\psi)$ : 시점 $t-1$ 에서 조약돌을 수집한 위치가 $\\psi$ 일 때, 다음 시점 $t$ 에서 조약돌을 수집할 위치가 $\\theta^{(t)}$ 일 가능성                            $\\sigma^2$ 의 크기와 샘플링 수렴 여부의 관계                          수락 확률(Acception Prob.) : $\\psi$ 를 다음 시점 $t+1$ 에서 조약돌을 수집할 위치 $\\theta^{(t+1)}$ 로 수락할 확률\\[\\begin{aligned}  \\alpha(\\theta^{(t)}, \\psi)  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})} \\cdot \\frac{q(\\theta^{(t)} \\mid \\psi)}{q(\\psi \\mid \\theta^{(t)})}\\right]}\\\\  &amp;= \\min{\\left[1, \\frac{p(\\psi \\mid \\mathcal{D})}{p(\\theta^{(t)} \\mid \\mathcal{D})}\\right]} \\quad \\text{s.t.} \\quad \\psi \\mid \\theta^{(t)} \\sim N(\\theta^{(t)},\\sigma^2)\\\\  &amp;\\propto \\min{\\left[1, \\frac{p(\\psi) \\cdot p(\\mathcal{D} \\mid \\psi)}{p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})}\\right]}  \\end{aligned}\\]          $p(\\psi \\mid \\mathcal{D}) \\propto p(\\psi) \\cdot p(\\mathcal{D} \\mid \\psi)$ : 목표 분포 $p$ 에 대하여 샘플 $\\psi$ 의 사후 확률로서, 다음 시점에서 조약돌을 수집할 위치가 $\\psi$ 일 가능성      $p(\\theta^{(t)} \\mid \\mathcal{D}) \\propto p(\\theta^{(t)}) \\cdot p(\\mathcal{D} \\mid \\theta^{(t)})$ : 목표 분포 $p$ 에 대하여 $t$ 번째 파라미터 $\\theta^{(t)}$ 의 사후 확률로서, 다음 시점에서 조약돌을 수집할 위치가 $\\theta^{(t)}$ 일 가능성      Auto-Correlation      자기상관(Auto-Correlation) : 순차로 발생한 일련의 관측치 ${x^{(t)} \\mid t\\text{ is time point}}$ 간에 존재하는 상관관계              $x^{(t)} \\sim N(0,1) \\quad \\text{for} \\quad x^{(0)} = 0$      $y^{(t)} \\sim N(y^{(t-1)},1) \\quad \\text{for} \\quad y^{(0)} = 0$            자기상관계수(Auto-Correlation Coefficient) : 순서에 의미가 있는 데이터에서, 현재 시점의 값 $x^{(t)}$ 과 그 과거 또는 미래의 값 $x^{(t-k)}$ 간의 상관관계를 측정하는 지표\\[R(k)=\\text{Corr}(x^{(t)},x^{(t-k)})\\]                  $k$ : 시간 간격(Lag)                          솎아내기(Thinning) : 매 $k$ 번째 표본을 선택함으로써 자기상관을 줄이는 방법              통상 $k \\le 10$ 으로 설정함            선행 구간(Burn-in Period) : 수렴 상태에 도달하기 전, 초기값 $x^{(t=0)}$ 의 영향력을 최소화하기 위해 일부 반복을 무시하는 구간      이미지 출처  https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo"
  },
  
  {
    "title": "Prior Determination",
    "url": "/posts/Prior/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian",
    "date": "2024-07-16 00:00:00 +0900",
    





    
    "snippet": "Prior Determination      사전확률분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후확률분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후확률분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전확률분포의 가정에 위배된다는 것을 ...",
    "content": "Prior Determination      사전확률분포의 결정은 모델링의 일부임          모형이 적합한 이후에는 사후확률분포를 살펴보아야 하고, 이치에 맞는지 확인해야 한다. 만일 사후확률분포가 이치에 맞지 않는다면 모형에 포함되지 않은 사전 정보가 추가로 필요하다는 것을 의미한다. 그리고 이전에 사용한 사전확률분포의 가정에 위배된다는 것을 의미한다. 그래서 이전으로 돌아가 사전확률분포가 외부 정보와 조화되도록 변경하는 것이 적절하다. (Andrew Gelman)            관측치 갯수($N$)가 많아질수록 사전확률분포의 영향력이 약화됨      Objective/Non-Informative Dist.      Principle of Indifference : 가능한 모수 공간에서 특별히 어떤 값을 선호하지 않는 원칙에 따라, 관측치가 사후분포에 미치는 영향력을 최대화하는 방법\\[\\begin{aligned}  X \\mid \\theta &amp;\\sim \\text{Binomial}(n,\\theta)\\\\  \\theta &amp;\\sim \\text{Uniform}(0,1)  \\end{aligned}\\]  Transformation Variant of Flat Prior Dist.      모수 $\\theta$ 가 균등 분포 $\\text{Uniform}(0,1)$ 를 따르는 객관적인 사전확률이라고 하자\\[\\theta \\sim \\text{Uniform}(0,1)\\]        모수 $\\theta$ 를 $\\log{\\displaystyle\\frac{\\theta}{1-\\theta}}$ 로 변수 변환한 $\\psi$ 는 로지스틱 분포 $\\text{Logistic}(0,1)$ 을 따르게 됨\\[\\begin{aligned}  \\psi  &amp;= g(\\theta)\\\\  &amp;= \\log{\\frac{\\theta}{1-\\theta}}\\\\ \\\\  \\theta  &amp;= g^{-1}(\\psi)\\\\  &amp;= \\frac{\\text{exp}(\\psi)}{1+\\text{exp}(\\psi)}\\\\ \\\\  f_{\\psi}(\\psi)  &amp;= f_{\\theta}(g^{-1}(\\psi)) \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi)\\right\\vert \\\\  &amp;= 1 \\times \\left\\vert \\frac{\\text{d}}{\\text{d} \\psi}g^{-1}(\\psi) \\right\\vert \\quad (\\because \\theta \\sim \\text{Uniform}(0,1))\\\\  &amp;= \\frac{\\text{exp}(\\psi)}{(1+\\text{exp}(\\psi))^{2}}\\\\  \\\\  \\therefore \\psi &amp;\\sim \\text{Logistic}(0,1)  \\end{aligned}\\]        즉, 모수 $\\theta$ 의 변수 변환에 의하여 사전분포의 객관성이 상실되었음                  변환 전 : $\\theta \\sim \\text{Uniform}(0,1)$                            변환 후 : $\\psi \\sim \\text{Logistic}(0,1)$                    Jacobian Change of Variables      자코비안 변수 변환(Jacobian Change of Variables) : 기본 변수 $\\overrightarrow{\\theta}$, 변환 변수 $\\overrightarrow{\\psi}=g(\\overrightarrow{\\theta})$ 및 그 밀도 함수 $f$ 에 대하여, 다음을 만족하는 변수 변환 방법\\[\\begin{aligned}  f_{\\psi}\\left(\\psi\\right)  &amp;=f_{\\theta}\\left(\\theta\\right) \\cdot \\left\\vert \\frac{1}{\\text{det}\\left(\\mathbb{J}\\right)} \\right\\vert\\\\  \\overrightarrow{\\theta}  &amp;= \\begin{pmatrix} \\theta_{1} &amp; \\theta_{2} &amp; \\cdots &amp; \\theta_{n} \\end{pmatrix}\\\\  \\overrightarrow{\\psi}  &amp;= \\begin{pmatrix} \\psi_{1} &amp; \\psi_{2} &amp; \\cdots &amp; \\psi_{m} \\end{pmatrix}  \\end{aligned}\\]                  자코비안 행렬(Jacobian Matrix; $\\mathbb{J}$) : 다변수 벡터 값 함수의 모든 편미분을 모아 만든 행렬\\[\\begin{aligned}  \\mathbb{J}  &amp;= \\frac{\\partial \\psi}{\\partial \\theta}\\\\  &amp;= \\begin{pmatrix}  \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_1}{\\partial \\theta_n}\\\\  \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_2}{\\partial \\theta_n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_1} &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_2} &amp; \\cdots &amp; \\displaystyle\\frac{\\partial \\psi_m}{\\partial \\theta_n}  \\end{pmatrix}  \\end{aligned}\\]                  자코비안 변수 변환은 밀도의 불변성을 보장하는 변수 변환 방법임                  변환 변수 $\\psi=g(\\theta)$ 가 기본 변수에 대하여 (확률) 밀도의 불변성을 보장한다고 하자\\[\\begin{aligned}  P(a \\le \\theta \\le b)  &amp;= P(g(a) \\le \\psi \\le g(b))\\\\  \\int_{a}^{b}{f_{\\theta}(\\theta)d\\theta}  &amp;= \\int_{g(a)}^{g(b)}{f_{\\psi}(\\psi)d\\psi}  \\end{aligned}\\]                    기본 변수의 단위당 밀도와 변환 변수의 단위당 밀도가 동일함\\[f_{\\theta}(\\theta) \\cdot \\Delta\\theta  =f_{\\psi}(\\psi) \\cdot \\Delta\\psi\\]                    $\\because \\Delta\\psi=\\displaystyle\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta$\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\Delta\\psi  &amp;= f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)\\\\  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta  \\end{aligned}\\]                    따라서 자코비안 변수 변환은 밀도의 불변성을 보장함\\[\\begin{aligned}  f_{\\psi}(\\psi) \\cdot \\left(\\frac{\\Delta\\psi}{\\Delta\\theta} \\cdot \\Delta\\theta\\right)  &amp;= f_{\\theta}(\\theta) \\cdot \\Delta\\theta\\\\  f_{\\psi}(\\psi) \\cdot \\left\\vert \\frac{\\Delta\\psi}{\\Delta\\theta} \\right\\vert  &amp;= f_{\\theta}(\\theta)\\\\  \\therefore f_{\\psi}(\\psi)  &amp;= f_{\\theta}(\\theta) \\cdot \\left\\vert \\frac{\\Delta\\theta}{\\Delta\\psi} \\right\\vert  \\end{aligned}\\]            Jeffreys Priors      Jeffreys Priors : 모수 공간에 대해 불변성을 보장함으로써 변수 변환 후에도 객관성을 보존하는 사전분포\\[\\pi_{J}(\\theta) \\propto \\sqrt{\\mathbf{I}(\\theta)}\\]                  $\\sqrt{\\mathbf{I}(\\theta)}$ : Fisher Information\\[\\begin{aligned}  \\mathbf{I}(\\theta)  &amp;= \\mathbb{E}\\left[\\frac{\\text{d}^{2}}{\\text{d}\\theta^{2}}\\log{\\mathcal{L}(\\theta)}\\right]  \\end{aligned}\\]                  Transformation Invariance of Jeffreys Priors                  변수 $\\theta$ 에 대한 확률분포가 그 피셔 정보의 자승근에 비례하도록 정의되었다고 하자\\[p(\\theta) \\propto \\sqrt{I(\\theta)}\\]                    변수 $\\theta$ 의 피셔 정보 $I(\\theta)$ 는 다음과 같음\\[I(\\theta) = \\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta}\\right)^{2}\\right]\\]                    함수 $g$ 를 통해 변수 $\\theta$ 를 변수 $\\psi$ 로 변환한다고 하자\\[\\psi = g(\\theta)\\]                    변환 변수 $\\psi$ 의 확률분포 또한 그 피셔 정보의 자승근에 비례하게 됨\\[p(\\psi) \\propto \\sqrt{I(\\psi)}\\]                    미분 법칙에 의해 다음이 성립함\\[\\frac{\\partial \\log{\\mathcal{L}(\\psi)}}{\\partial \\psi}  =\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi}\\]                    변환 변수 $\\psi$ 의 피셔 정보 $I(\\psi)$ 는 다음과 같음\\[\\begin{aligned}  I(\\psi)  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\partial \\theta} \\cdot \\frac{\\partial \\theta}{\\partial \\psi} \\right)^{2}\\right]\\\\  &amp;=\\mathbb{E}\\left[\\left(\\frac{\\partial \\log{\\mathcal{L}(\\theta)}}{\\theta}\\right)^{2}\\right] \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}\\\\  &amp;=I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}  \\end{aligned}\\]                    따라서 변환 변수 $\\psi$ 의 확률분포는 기본 변수 $\\theta$ 의 확률분포의 형태를 유지하되, 자코비안 행렬식 $\\left\\vert \\displaystyle\\frac{d\\theta}{d\\psi} \\right\\vert$ 로 보정된 양상을 띠게 됨\\[\\begin{aligned}  p(\\psi) &amp;\\propto \\sqrt{I(\\psi)}\\\\  &amp;= \\sqrt{I(\\theta) \\cdot \\left(\\frac{d\\theta}{d\\psi}\\right)^{2}}\\\\  &amp;= \\sqrt{I(\\theta)} \\cdot \\left\\vert \\frac{d\\theta}{d\\psi} \\right\\vert  \\end{aligned}\\]            Subjective/Informative Dist.  Principle of Subjectivity : 주관적 판단을 반영하여 특정한 영역을 선호하는 원칙에 따라, 사전 지식이나 경험, 믿음 등의 영향력을 개입시킴으로써 특정 영역에 편향된 추론 결과를 도출하는 방법Empirical Bayes Method  Empirical Bayes Method : 사전확률분포에 설정되는 하이퍼파라미터를 빈도주의적으로 접근하여 추정하는 방법          사전 정보가 많지 않지만 관측치가 풍부한 경우 유용함      관측하기 이전에 사전분포가 정의되어야 한다는 베이지안 추론 원칙에 위배됨            example General Model\\[\\begin{aligned}  X_{i} \\mid \\theta &amp;\\sim N(\\theta, 5^2)\\\\  \\theta &amp;\\sim N(\\mu, \\sigma^2)  \\end{aligned}\\]                  객관적 사전확률분포 설정을 통한 접근\\[\\theta \\sim N(0, 100^2)\\]                    주관적 사전확률분포 설정을 통한 접근\\[\\theta \\sim N(\\mu_{0}, \\sigma_{0}^{2})\\]                  $\\mu=\\mu_{0}$ : 연구자가 보유하고 있는 사전 정보를 활용하여 설정          $\\sigma=\\sigma_{0}$ : 연구자가 보유하고 있는 불확실성을 수량화하여 설정                            Empirical Bayes\\[\\theta \\sim N\\left(\\frac{1}{N}\\sum_{i=1}^{N}{X_i}, \\frac{1}{N-1}\\sum_{i=1}^{N}{(X_i-\\mu)^2}\\right)\\]            Conjugate Priors      켤레사전분포(Conjugate Priors) : 관측치 $X$ 와 그 확률분포 \\(\\mathcal{L}_{\\alpha}\\) 에 대하여, 다음의 조건을 만족하는 사전확률분포 \\(\\pi_{\\beta}\\) 가 존재하는 경우, \\(\\pi_{\\beta}\\) 를 \\(\\mathcal{L}_{\\alpha}\\) 의 켤레사전분포(Conjugate Prior Prob. Dist.)라고 함\\[\\begin{aligned}  \\pi_{\\beta^{\\prime}}(\\theta \\mid X) \\propto \\mathcal{L}_{\\alpha}(\\theta) \\cdot \\pi_{\\beta}(\\theta)  \\end{aligned}\\]          $\\mathcal{L}_{\\alpha}(\\theta)$ : 모수 $\\theta$ 의 우도 함수      $\\pi_{\\beta}(\\theta)$ : 모수 $\\theta$ 의 사전 확률      $\\pi_{\\beta^{\\prime}}(\\theta \\mid X)$ : 모수 $\\theta$ 의 사후 확률      $\\alpha,\\beta,\\beta^{\\prime}$ : 모수들의 집합            예시                            Likelihood          Prior          Posterior                                      $\\text{Bernoulli}(\\theta)$          $\\text{Beta}(\\alpha, \\beta)$          $\\text{Beta}\\Big(\\alpha + n \\cdot \\bar{x}, \\beta + n\\cdot(1-\\bar{x})\\Big)$                          $\\text{Poisson}(\\lambda)$          $\\text{Gamma}(\\alpha, \\beta)$          $\\text{Gamma}(\\alpha+ n \\cdot \\bar{x}, \\beta+n)$                          $\\text{Multinomial}(\\theta)$          $\\text{Dirichlet}(\\alpha)$          $\\text{Dirichlet}(\\alpha+n \\cdot \\bar{x})$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\sigma^2$          $N(\\mu_0, \\sigma_0^2)$          $N\\Bigg( \\displaystyle\\frac{\\displaystyle\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n \\cdot \\bar{x}}{\\sigma^2}}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\displaystyle\\frac{n}{\\sigma^2}}, \\displaystyle\\frac{1}{\\displaystyle\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}} \\Bigg)$                          $N(\\mu, \\sigma^2)$  $\\text{known} \\; \\mu$          $\\text{Inv-Gamma}(\\alpha, \\beta)$          $\\text{Inv-Gamma}\\Bigg(\\alpha + \\displaystyle\\frac{n}{2}, \\beta + \\displaystyle\\frac{n \\cdot (\\bar{x} -\\mu)^2}{2}\\Bigg)$                          $N(\\mu, \\Sigma)$  $\\text{known} \\; \\mu$          $\\text{Inv-Wishart}(\\nu_{0}, S_{0})$          $\\text{Inv-Wishart}(\\nu_{0}+n, S_{0} + n \\cdot \\bar{S})$                    "
  },
  
  {
    "title": "What? Bayesian",
    "url": "/posts/Bayesian/",
    "categories": "Statistical Techs, Bayesian Modeling",
    "tags": "Statistics, Bayesian, Optimization, MLE",
    "date": "2024-07-15 00:00:00 +0900",
    





    
    "snippet": "Compare Frequentist and Bayesian빈도주의자 vs. 베이지안  사건 $X$ 가 발생할 확률 $P(X)$ 의 정의                  빈도주의자(Frequentist) : 어떤 사건이 발생하는 장기적인 빈도\\[P(X)\\]                    베이지안(Bayesian) : 어떤 사건이 발생할 것이라는 믿음 ...",
    "content": "Compare Frequentist and Bayesian빈도주의자 vs. 베이지안  사건 $X$ 가 발생할 확률 $P(X)$ 의 정의                  빈도주의자(Frequentist) : 어떤 사건이 발생하는 장기적인 빈도\\[P(X)\\]                    베이지안(Bayesian) : 어떤 사건이 발생할 것이라는 믿음 혹은 확신의 척도\\[P(X \\mid \\theta)\\]              모수 $\\theta$ 의 이해                  빈도주의자(Frequentist) : 사건 발생 빈도를 묘사하는 상수\\[\\theta=\\mu, \\sigma^2, p, \\cdots\\]                    베이지안(Bayesian) : 사건 발생에 대한 믿음의 분포를 묘사하는 확률변수\\[\\theta \\sim F\\]            표본의 크기가 충분하다면      빈도주의자의 결론과 베이지안의 결론은 일치함\\[\\lim_{n \\rightarrow \\infty}{P(\\theta \\mid X_{1},X_{2},\\cdots,X_{n})} \\approx \\mu, \\sigma^2, p, \\cdots\\]          사건 발생에 대한 믿음은 신규 관측치에 의해 끊임없이 갱신되어 사건 발생에 대한 장기적인 빈도로 수렴함      표본의 크기가 충분하지 않다면  표본의 크기는 결코 크지 않다. 만일 N이 충분한 추정을 얻기에 부족하다면 더 많은 데이터(또는 더 많은 가정)을 확보해야 한다. 그러나 일단 N이 충분히 크다면 데이터를 나눠 더 많은 것(가령 여론조사에서 전국적으로 훌륭한 추정을 얻었다면 남과 여, 지역별, 연령대별 그룹 등으로 나눠 추정할 수 있다)을 얻을 수 있다. N은 충분하지 않다. 만약 충분하더라도 여러분은 이미 더 많은 데이터가 필요한 다음 문제에 직면하기 때문이다. (Andrew Gelman)      빈도주의자(Frequentist) : 모수(미지의 상수)에 대한 신뢰구간을 확대함으로써 모수 추정 과정 상의 불확실성을 최소화함\\[\\text{CI}_{\\theta}=\\bar{X}\\pm Z\\cdot\\frac{\\sigma}{\\sqrt{n}}\\]        베이지안(Bayesian) : 모수(확률변수)에 대한 사전확률을 도입함으로써 모수 자체의 불확실성을 모형화함\\[P(\\theta \\mid X)=\\frac{P(X \\mid \\theta)\\cdot P(\\theta)}{P(X)}\\]  Bayesian FrameworkBayes’ Theorem      베이즈 정리(Bayes’ Theorem)          사상 $A_{1},A_{2},\\cdots,A_{n}$ 이 표본공간 $S$ 의 분할이고, $P(A_{i})&gt;0,P(X)&gt;0$ 이면 $X$ 에 대한 $A_{k}$ 의 조건부 확률은 다음과 같음    \\[\\begin{aligned}  P(A_{k} \\mid X)  &amp;=\\frac{P(A_{k} \\cap X)}{P(X)}\\\\  &amp;=\\frac{P(A_{k})\\cdot P(X \\mid A_{k})}{P(X)}\\\\  &amp;=\\frac{P(A_{k})\\cdot P(X \\mid A_{k})}{\\sum_{i=1}^{n}{P(A_{i}) \\cdot P(X \\mid A_{i})}} \\propto P(A_{k})\\cdot P(X \\mid A_{k})  \\end{aligned}\\]          $P(A_{k} \\mid X)$ : 사건 $X$ 발생 조건부 $A_k$ 가 발생할 확률      $P(A_{k})$ : 사건 $A_{k}$ 가 발생할 확률      $P(X \\mid A_{k})$ : 사건 $A_{k}$ 발생 조건부 $X$ 가 발생할 확률      $P(X)$ : 사건 $X$ 가 발생할 확률            확률분포함수로 표현한 베이즈 정리\\[P(\\theta \\mid \\mathcal{D})=\\frac{P(\\theta) \\cdot P(\\mathcal{D} \\mid \\theta)}{P(\\mathcal{D})} \\propto \\pi(\\theta) \\cdot \\mathcal{L}(\\theta)\\]          $\\theta$ : 모수      $\\mathcal{D}$ : 관측된 데이터      $P(\\theta \\mid \\mathcal{D})$ : $\\theta$ 의 사후확률분포      $\\pi(\\theta)=P(\\theta)$ : $\\theta$ 의 사전확률분포      $\\mathcal{L}(\\theta)=P(\\mathcal{D} \\mid \\theta)$ : $\\theta$ 에 대한 $\\mathcal{D}$ 의 우도함수      $P(\\mathcal{D})$ : $\\mathcal{D}$ 의 주변확률      Component      사전확률분포(Prior Probability Distribution) : 사건 발생 전, 가지고 있는 정보를 기초로 하여 설정된 초기 믿음\\[\\theta \\sim P\\]        사후확률분포(Posterior Probability Distribution) : 사건 발생 후, 추가된 정보를 고려하여 갱신된 믿음\\[\\theta \\mid \\mathcal{D} \\sim P\\]        우도(Likelihood or Likelihood Function) : 모수의 특정 값이 $\\theta$ 로 주어졌을 때, 관측치 $\\mathcal{D}$ 가 실현될 가능성\\[\\begin{aligned}  \\mathcal{L}(\\theta)  &amp;=P(\\mathcal{D} \\mid \\theta)\\\\  &amp;=\\prod_{i=1}^{n}{f(X_{i} \\mid \\theta)}  \\end{aligned}\\]  [example] 동전 던지기  동전을 던졌을 때 앞면이 나올 확률을 $\\theta$ 라고 하자. $\\theta$ 에 대한 정보가 아무것도 없다고 가정하자. 즉, $\\theta$ 는 0과 1 사이의 무작위수일 것이라고 믿어지고 있다. 동전을 두 번 던졌는데 두 번 다 앞면이 나왔다. 그렇다면 $\\theta$ 에 대한 믿음은 어떻게 변화할까?      문제에서 주어진 정보\\[\\begin{aligned}  X \\mid \\theta &amp;\\sim \\text{Bin}(n,\\theta)\\\\  \\theta &amp;\\sim \\text{Uniform}(0,1)  \\end{aligned}\\]        목적 함수 정의\\[P(\\theta \\mid X)=\\frac{\\pi(\\theta)P(X \\mid \\theta)}{P(X)} \\propto \\pi(\\theta)P(X \\mid \\theta)\\]                  $\\pi(\\theta)$ : $\\theta$ 에 대한 사전확률\\[\\pi(\\theta)=1 \\quad \\because \\theta \\sim \\text{Uniform}(0,1)\\]                    $P(X \\mid \\theta)$ : $\\theta$ 에 대한 $X$ 의 우도함수 혹은 확률질량함수\\[P(X \\mid \\theta)=\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X} \\quad \\because X \\mid \\theta \\sim \\text{Bin}(n,\\theta)\\]                    $P(X)$ : $X$ 의 주변확률로서 정규화 상수($\\theta$ 에 대한 함수가 아니므로 이후 생략)\\[\\begin{aligned}  P(X)  &amp;= \\int_{0}^{1}{\\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\int_{0}^{1}{\\theta^{X} \\cdot (1-\\theta)^{n-X}}\\text{d}\\theta\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\text{B}(X+1,n-X+1)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{\\Gamma(X+1)\\Gamma(n-X+1)}{\\Gamma(n+2)} \\quad \\because (X+1),(n-X+1) \\in \\mathbf{R}^{+}\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\frac{X!(n-X)!}{(n+1)!} \\quad \\because (X+1),(n-X+1) \\in \\mathbf{Z}^{+}\\\\  &amp;= \\frac{1}{n+1}  \\end{aligned}\\]                              $\\text{B}(\\alpha,\\beta)$ : 베타함수\\[\\begin{aligned}  \\text{B}(\\alpha,\\beta)  &amp;= \\int_{0}^{1}{t^{\\alpha-1}(1-t)^{\\beta-1}}\\text{d}t\\\\  &amp;= \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)} \\quad \\text{where}\\; \\alpha,\\beta \\in \\mathbf{R}^{+}  \\end{aligned}\\]                                $\\Gamma(n)$ : 감마함수\\[\\begin{aligned}  \\Gamma(n)  &amp;= \\int_{0}^{\\infty}{t^{(n-1)}e^{-t}}\\text{d}t\\\\  &amp;= (n-1)! \\quad \\text{where}\\; n \\in \\mathbf{Z}^{+}  \\end{aligned}\\]                                    결론 : $\\theta$ 의 사후확률은 베타분포 $\\text{Beta}(3,1)$ 을 따름\\[\\begin{aligned}  P(\\theta \\mid X)  &amp;\\propto \\pi(\\theta)P(X \\mid \\theta)\\\\  &amp;= \\frac{n!}{X!(n-X)!} \\cdot \\theta^{X} \\cdot (1-\\theta)^{n-X}\\\\  \\\\  \\therefore P(\\theta \\mid X)  &amp;\\sim \\text{Beta}(X+1,n-X+1)  \\end{aligned}\\]                  $\\text{Beta}(\\alpha,\\beta)$ : 베타분포\\[f(x)  = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\text{B}(\\alpha,\\beta)}  \\sim \\text{Beta}(\\alpha,\\beta)\\]            "
  },
  
  {
    "title": "Multiple Linear Regression Analysis",
    "url": "/posts/Multiple_Linear_Regression_Analysis/",
    "categories": "Statistical Techs, Regression Analysis",
    "tags": "Statistics, Regression, f Test",
    "date": "2024-07-10 00:00:00 +0900",
    





    
    "snippet": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+...",
    "content": "What? Multiple Linear Regression      정의 : 설명변수가 여러 개인(Multi-Variate) 선형 회귀 모형(Linear Regression Model)    \\[y^{(k)}=\\beta_{0}+\\beta_{1}x_{1}^{(k)}+\\beta_{2}x_{2}^{(k)}+\\cdots+\\beta_{p}x_{p}^{(k)}+\\varepsilon^{(k)}\\]        VS. Simple Linear Regression                      Simple Linear Regression\\[\\begin{aligned}  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\varepsilon^{(k)}\\\\  \\text{Sales}^{(k)}  &amp;=\\beta_{0}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}  \\end{aligned}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제하지 않은 상태에서 추정되었다. 때문에 해당 요인($X_{i}$)과 다른 요인들 간 상관관계가 있을 경우, $\\beta_{i}$ 은 다른 요인들의 변화가 매출에 미치는 영향력을 포함하게 된다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 없다.                            Multiple Linear Regression\\[\\text{Sales}^{(k)}=\\beta_{0}+\\beta_{1} \\cdot \\text{TV}^{(k)}+\\beta_{2} \\cdot \\text{Radio}^{(k)}+\\beta_{3} \\cdot \\text{News}^{(k)}+\\varepsilon^{(k)}\\]                  회귀계수 $\\beta_{i}$ 은 다른 요인($X_{j \\ne i}$)들의 변화에 따른 매출($\\text{Sales}$)의 변동성을 통제한 상태에서 추정되었다. 따라서 $\\beta_{i}$ 은 $X_{i}$ 가 $\\text{Sales}$ 에 미치는 순수한 영향력이라 볼 수 있다.                    Normal Equation      정규방정식(Normal Equation) : 최소자승법에 기초하여 추정한 가중치 벡터\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{RSS}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]    정규방정식 도출 과정                  변수 갯수가 $P$ 이고 관측치 갯수가 $N$ 인 다중 선형 회귀 모형을 선형대수로 표현하면 다음과 같음\\[\\overrightarrow{\\hat{y}} = \\mathbf{X}\\hat{\\overrightarrow{\\beta}}\\]                  $\\mathbf{X}_{N \\times P}$ : Design Matrix                            $RSS$ 도출\\[\\begin{aligned}  RSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\right\\Vert^2\\\\  &amp;= (\\overrightarrow{y}^T - \\overrightarrow{\\beta}^T \\mathbf{X}^T)(\\overrightarrow{y} - \\mathbf{X}\\overrightarrow{\\beta})\\\\  &amp;= \\overrightarrow{y}^T \\overrightarrow{y} - \\overrightarrow{y}^T \\mathbf{X} \\overrightarrow{\\beta} - \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y} + \\overrightarrow{\\beta}^T \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}  \\end{aligned}\\]                    $\\because \\overrightarrow{y}^T \\mathbf{X} \\overrightarrow{\\beta} = \\left(\\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y}\\right)^T = \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y}$\\[RSS = \\overrightarrow{y}^T \\overrightarrow{y} - 2 \\overrightarrow{\\beta}^T \\mathbf{X}^T \\overrightarrow{y} + \\overrightarrow{\\beta}^T \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}\\]                    $RSS$ 를 $\\overrightarrow{\\beta}$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial}{\\partial \\overrightarrow{\\beta}} RSS  &amp;= -2 \\mathbf{X}^T \\overrightarrow{y} + 2 \\mathbf{X}^T \\mathbf{X} \\overrightarrow{\\beta}\\\\  &amp;= 0 \\quad (\\because \\min_{\\overrightarrow{\\beta}}{RSS})  \\end{aligned}\\]                    $\\overrightarrow{\\beta}$ 에 대하여 정리\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}\\\\  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{RSS}  \\end{aligned}\\]                  회귀계수의 해석          설명변수 $X_{i}$ 의 회귀계수 $\\beta_{i}$ 는 다른 모든 설명변수가 일정할 때 $X_{i}$ 가 $1$ 단위 변화함에 따른 $Y$ 변화 단위의 추정치이다. 즉, 다른 모든 설명변수에 대하여 변동이 없는 상태에서, $X_{i}$ 가 $1$ 단위 변화했을 때 $Y$ 가 $\\beta_{i}$ 만큼 변화할 것이라 추정된다.      회귀계수의 유의성 검정: F-검정      정의 : 반응변수에 대한 설명변수들의 설명력이 통계적으로 유의한가에 관한 검정    귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_1=\\beta_2 =\\cdots =\\beta_p=0$      $H_{1}: \\quad$ 적어도 하나의 $i$ 에 대하여 $\\beta_{i} \\ne 0$            검정통계량 도출\\[F  = \\frac{ESS/p}{RSS/(n-p-1)} \\sim F(p, n-p-1)\\]                  회귀변동(Explained Sum of Square; ESS) : 모형에 의해 설명되는 반응변수의 변동성\\[ESS=TSS-RSS\\]                    총변동(Total Sum of Square; TSS) : 반응변수의 총 변동성\\[\\begin{aligned}  TSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overline{y} \\right\\Vert^2\\\\  &amp;= \\sum{\\left(y^{(i)}-\\overline{y} \\right)^2}  \\end{aligned}\\]                    잔차변동(Residual Sum of Square) : 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;= \\left\\Vert \\overrightarrow{y} - \\overrightarrow{\\hat{y}} \\right\\Vert^2\\\\  &amp;= \\sum{\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2}  \\end{aligned}\\]            부분 유의성 검정  Occam’s Razor  Entities should not be multiplied beyond necessity.      정의 : 설명변수 추가에 따른 부분적 효과의 통계적 유의성에 관한 검정    모형 예시          $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon$      $y=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\varepsilon$        귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_3=\\beta_4=0$      $H_{1}: \\quad \\beta_{3} \\ne 0 \\quad \\text{or} \\quad \\beta_{4} \\ne 0$            검정통계량 도출\\[F  = \\frac{(RSS_{0}-RSS)/q}{RSS/(n-p-1)} \\sim F(q, n-p-1)\\]                  $RSS$ : 설명변수 $X_{3}, X_{4}$ 를 추가한 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 + \\beta_3 x^{(i)}_3 + \\beta_4 x^{(i)}_4 \\right) \\right]^2}  \\end{aligned}\\]                    $RSS_{0}$ : 설명변수 $X_{3}, X_{4}$ 를 추가하지 않은 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS_{0}  &amp;= \\sum{\\left[y^{(i)}-\\left(\\beta_0 + \\beta_1 x^{(i)}_1 + \\beta_2 x^{(i)}_2 \\right) \\right]^2}  \\end{aligned}\\]            $n$ : 관측치 갯수      $p$ : 총 설명변수 갯수      $q$ : 검정 대상 설명변수($X_{3}, X_{4}$) 를 제외한 설명변수의 갯수      이미지 출처  https://www.linkedin.com/pulse/understanding-linear-regression-basics-divyesh-sonar-snv4c/"
  },
  
  {
    "title": "SASREC",
    "url": "/posts/SASREC/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Sequential RecSys, Deep Learning, Attention Mechanism",
    "date": "2024-07-10 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Estimate Regression Coefficient",
    "url": "/posts/Estimate_Regression_Coefficient/",
    "categories": "Statistical Techs, Regression Analysis",
    "tags": "Statistics, Regression, Estimation, OLS",
    "date": "2024-07-09 00:00:00 +0900",
    





    
    "snippet": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\va...",
    "content": "Ordinary Least Squares      최소자승법(Ordinary Least Squares; OLS) : 잔차 자승의 합을 최소화하는 회귀계수를 추정하는 방법\\[\\begin{aligned}  \\hat{\\beta}_{0}, \\hat{\\beta}_{1}  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left(y_{i} - \\hat{y}_{i} \\right)^{2}}}\\\\  &amp;= \\text{arg} \\min_{\\theta}{\\sum_{i=1}^{n}{\\left[ y_{i} - \\left(\\beta_{0} + \\beta_{1} x_{i} \\right) \\right]^2}}  \\end{aligned}\\]        최소자승추정량(OLS Estimator)          편향 \\(\\beta_{0}\\) 의 최소자승추정량 \\(\\hat{\\beta}_{0} = \\overline{Y} - \\hat{\\beta}_{1} \\overline{X}\\)      가중치 \\(\\beta_{1}\\) 의 최소자승추정량 \\(\\hat{\\beta}_{1} = \\displaystyle\\frac{Cov(X,Y)}{Var(X)}\\)      OLS Estimator      $Loss(\\beta_0, \\beta_1)=\\displaystyle\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}$ 을 $\\beta_0$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_0}Loss(\\beta_0, \\beta_1)\\\\  &amp;= -2 \\times \\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_0 + \\beta_1 x_{i}\\right)\\right]} \\\\  &amp;= -2 \\times \\left[\\sum_{i=1}^{n}{y_{i}} - n \\beta_{0}-\\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\right] \\cdots ①\\\\  &amp;= -2n \\times (\\overline{Y} - \\beta_0 - \\beta_1 \\overline{X}) \\\\  &amp;= 0  \\end{aligned}\\]        편향 $\\beta_0$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 도출\\[\\therefore  \\hat{\\beta_0}  = \\overline{Y} - \\hat{\\beta_1}\\overline{X} \\quad (\\text{s.t.} \\; n \\ne 0)\\]        $Loss(\\beta_0, \\beta_1)=\\displaystyle\\sum_{i=1}^{n}{e_{i}^{2}}$ 을 $\\beta_0$ 으로 편미분\\[\\begin{aligned}  &amp;\\frac{\\partial}{\\partial \\beta_1} Loss(\\beta_0, \\beta_1)\\\\  &amp;= -2\\times\\sum_{i=1}^{n}{\\left[y_{i}-\\left(\\beta_0+\\beta_1 x_{i}\\right)\\right] \\times x_{i}}\\\\  &amp;= -2\\times\\left[\\sum_{i=1}^{n}{y_{i}x_{i}}-\\beta_0\\sum_{i=1}^{n}{x_{i}}-\\beta_1\\sum_{i=1}^{n}{x_{i}^2}\\right] \\cdots ② \\\\  &amp;= 0  \\end{aligned}\\]        식 $①$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ① \\times \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}} - n \\beta_{0} \\sum_{i=1}^{n}{x_{i}} - \\beta_{1} \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{x_{i}}\\\\  &amp;= n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{0}\\overline{X}-n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\\\  &amp;= 0  \\end{aligned}\\]        식 $②$ 변형\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\times ② \\times n \\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_0 \\sum_{i=1}^{n}{x_{i}} - n \\beta_1 \\sum_{i=1}^{n}{(x_{i})^2}\\\\  &amp;= n \\sum_{i=1}^{n}{y_{i}x_{i}} - n^{2} \\beta_0 \\overline{X} - n \\beta_1 \\sum_{i=1}^{n}{x_{i}^2}\\\\  &amp;= 0  \\end{aligned}\\]        식 ①, ② 의 변형을 뺄셈\\[\\begin{aligned}  &amp; -\\frac{1}{2} \\left(① \\times \\displaystyle\\sum_{i=1}^{n}X_i - ② \\times n \\right)\\\\  &amp;= \\left[n^{2}\\overline{Y}\\overline{X} - n^{2}\\beta_{1}\\left(\\overline{X}\\right)^{2}\\right] -  \\left[n \\sum_{i=1}^{n}{y_{i}x_{i}} - n \\beta_1 \\sum_{i=1}^{n}{(x_{i})^2}\\right]\\\\  &amp;= \\beta_1 \\times n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{x_{i}^2}-\\left(\\overline{X}\\right)^{2}\\right] - n^{2}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}x_{i}}-\\overline{Y}\\overline{X}\\right]\\\\  &amp;= \\beta_1 \\times n^{2} Var\\left[X\\right] - n^{2} Cov\\left[Y,X\\right]\\\\  &amp;= 0  \\end{aligned}\\]        가중치 $\\beta_1$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 도출\\[\\hat{\\beta}_{1}  = \\frac{Cov\\left[Y,X\\right]}{Var\\left[X\\right]}\\]  Gauss-Markov Theorem  고전적 선형 회귀 가정(Classical Linear Regression Assumptions) 하 최소자승추정량은 선형 불편 추정량 중 분산이 가장 작은 추정량(Best Linear Unbiased Estimator; BLUE)이다.      가중치 $\\beta_{1}$ 의 최소자승추정량 $\\hat{\\beta}_{1}$ 의 확률분포\\[\\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\sigma^2\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]\\right)\\]        편향 $\\beta_{0}$ 의 최소자승추정량 $\\hat{\\beta}_{0}$ 의 확률분포\\[\\hat{\\beta}_{0} \\sim N\\left(\\beta_{0}, \\sigma^{2} \\left[\\displaystyle\\frac{1}{n} + \\displaystyle\\frac{\\overline{x}^{2}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]\\right)\\]        오차항 $\\varepsilon$ 의 모분산 $\\sigma^2$ 을 그 표본분산으로 추정함\\[\\sigma^2 \\xrightarrow{\\text{P}} \\displaystyle\\frac{\\text{RSS}}{n-2}\\]  OLS Estimator is Unbiasedness Estimator\\[\\mathbb{Bias}\\left[\\hat{\\beta}\\right]=\\mathbb{E}\\left[\\hat{\\beta}-\\beta\\right]=0\\]$\\hat{\\beta}_{1}$\\[\\begin{aligned}\\hat{\\beta}_{1}&amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})(y_{i}-\\overline{y})}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\\\\\y_{i}&amp;= \\beta_{0}+\\beta_{1}x_{i}+\\varepsilon_{i}\\\\\\overline{y}&amp;= \\beta_{0}+\\beta_{1}\\overline{x}+\\overline{\\varepsilon}\\\\\\\\\\therefore(y_{i}-\\overline{y})&amp;= \\beta_{1}(x_{i}-\\overline{x}) + (\\varepsilon_{i}-\\overline{\\varepsilon})\\\\\\\\\\therefore(x_{i}-\\overline{x})(y_{i}-\\overline{y})&amp;= \\beta_{1}(x_{i}-\\overline{x})^{2} + \\varepsilon_{i}(x_{i}-\\overline{x}) = \\overline{\\varepsilon}(x_{i}-\\overline{x})\\\\\\\\\\therefore\\hat{\\beta}_{1}&amp;= \\beta_{1}+\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i-\\overline{x}})^2}}+\\overline{\\varepsilon} \\cdot \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\\\&amp;= \\beta_{1}+\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i-\\overline{x}})^2}} \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0,\\sigma^2)\\\\\\\\\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]&amp;= \\beta_{1} + \\mathbb{E}\\left[\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]\\\\&amp;= \\beta_{1} + \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x}) \\mathbb{E}\\left[\\varepsilon_{i}\\right]}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}} \\quad \\text{s.t.}\\;\\mathbb{E}\\left[\\varepsilon_{i}\\vert x_{i}\\right]=\\mathbb{E}\\left[\\varepsilon_{i}\\right]\\\\&amp;= \\beta_{1} \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0,\\sigma^2)\\end{aligned}\\]$\\hat{\\beta}_{0}$\\[\\begin{aligned}\\hat{\\beta}_{0}&amp;= \\overline{y} - \\hat{\\beta}_{1}\\overline{x}\\\\\\\\\\overline{y}&amp;= \\beta_{0} + \\beta_{1}\\overline{x}\\\\\\\\\\therefore\\hat{\\beta}_{0}&amp;= \\beta_{0} + \\beta_{1}\\overline{x} - \\hat{\\beta}_{1}\\overline{x}\\\\\\\\\\mathbb{E}\\left[\\hat{\\beta}_{0}\\right]&amp;= \\beta_{0} + \\mathbb{E}\\left[\\beta_{1}\\overline{x}\\right] - \\mathbb{E}\\left[\\hat{\\beta}_{1}\\overline{x}\\right]\\\\&amp;= \\beta_{0} + \\overline{x}\\cdot\\mathbb{E}\\left[\\beta_{1}\\right] - \\overline{x}\\cdot\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]\\\\&amp;= \\beta_{0} + \\overline{x} \\cdot \\beta_{1} - \\overline{x} \\cdot \\beta_{1} \\quad \\left(\\because \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] = \\beta_{1} \\right)\\\\&amp;= \\beta_{0}\\end{aligned}\\]OLS Estimator is Efficiency Estimator\\[\\hat{\\beta}_{OLS}=\\text{arg} \\min{\\mathbb{Var}\\left[\\hat{\\beta}\\right]}\\]$\\hat{\\beta}_{1}$\\[\\begin{aligned}\\hat{\\beta}_{1}&amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})(y_{i}-\\overline{y})}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\&amp;= \\beta_{1}+\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}} \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0,\\sigma^2)\\\\\\\\\\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]&amp;= \\mathbb{Var}\\left[\\beta_{1}+\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right]\\\\&amp;= \\mathbb{Var}\\left[\\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right]\\\\&amp;= \\left(\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right)^{2} \\cdot \\mathbb{Var}\\left[\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}\\right] \\quad \\text{s.t.}\\;\\mathbb{E}\\left[\\varepsilon_{i} \\vert x_{i}\\right] = \\mathbb{E}\\left[\\varepsilon_{i}\\right]\\\\\\\\\\mathbb{Var}\\left[\\sum_{i=1}^{n}{(x_{i}-\\overline{x})\\varepsilon_{i}}\\right]&amp;= \\sum_{i=1}^{n}{\\mathbb{Var}\\left[(x_{i}-\\overline{x})\\varepsilon_{i}\\right]} \\quad \\text{s.t.} \\; \\mathbb{Cov}\\left[\\varepsilon_{i},\\varepsilon_{j}\\right]=0\\\\&amp;= \\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}\\mathbb{Var}\\left[\\varepsilon_{i}\\right]} \\quad \\text{s.t.} \\; \\mathbb{E}\\left[\\varepsilon_{i} \\vert x_{i}\\right]=\\mathbb{E}\\left[\\varepsilon_{i}\\right]\\\\&amp;= \\sigma^{2}\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}} \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0, \\sigma^2)\\\\\\\\\\therefore\\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]&amp;= \\left(\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\right)^{2} \\cdot \\sigma^{2}\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}\\\\&amp;= \\sigma^2 \\cdot \\left[\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}} \\right]\\end{aligned}\\]$\\hat{\\beta}_{0}$\\[\\begin{aligned}\\hat{\\beta}_{0}&amp;= \\overline{y} - \\hat{\\beta}_{1}\\overline{x}\\\\\\\\\\mathbb{Var}\\left[\\hat{\\beta}_{0}\\right]&amp;= \\mathbb{Var}\\left[\\overline{y} - \\hat{\\beta}_{1}\\overline{x}\\right]\\\\&amp;= \\mathbb{Var}\\left[\\overline{y}\\right] + \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\overline{x}\\right] - \\mathbb{Cov}\\left[\\overline{y}, \\hat{\\beta}_{1}\\overline{x}\\right]\\end{aligned}\\]      $\\mathbb{Var}\\left[\\overline{y}\\right]$\\[\\begin{aligned}  \\mathbb{Var}\\left[\\overline{y}\\right]  &amp;= \\mathbb{Var}\\left[\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}}\\right]\\\\  &amp;= \\left(\\frac{1}{n}\\right)^{2} \\cdot \\mathbb{Var}\\left[\\sum_{i=1}^{n}{y_{i}}\\right]\\\\  &amp;= \\left(\\frac{1}{n}\\right)^{2} \\cdot \\sum_{i=1}^{n}{\\mathbb{Var}\\left[y_{i}\\right]} \\quad \\text{s.t.}\\;\\mathbb{Cov}\\left[\\varepsilon_{i},\\varepsilon_{j}\\right]=0\\\\  &amp;= \\left(\\frac{1}{n}\\right)^{2} \\cdot \\sum_{i=1}^{n}{\\mathbb{Var}\\left[\\varepsilon_{i}\\right]} \\quad \\left(\\because y_{i}=\\beta_{0} + \\beta_{1}x_{i} + \\varepsilon_{i} \\right)\\\\  &amp;= \\frac{\\sigma^2}{n} \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0, \\sigma^2)  \\end{aligned}\\]        $\\mathbb{Var}\\left[\\hat{\\beta}_{1}\\overline{x}\\right]$\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\overline{x}\\right]  &amp;= \\overline{x}^{2} \\cdot \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\right]\\\\  &amp;= \\overline{x}^{2} \\cdot \\frac{\\sigma^2}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}  \\end{aligned}\\]        $\\mathbb{Cov}\\left[\\overline{y}, \\hat{\\beta}_{1}\\overline{x}\\right]$\\[\\begin{aligned}  \\mathbb{Cov}\\left[\\overline{y}, \\hat{\\beta}_{1}\\overline{x}\\right]  &amp;= \\mathbb{Cov}\\left[\\beta_{0}+\\beta_{1}\\overline{x}+\\overline{\\varepsilon}, \\hat{\\beta}_{1}\\overline{x}\\right]\\\\  &amp;= \\overline{x} \\cdot \\mathbb{Cov}\\left[\\overline{\\varepsilon},\\hat{\\beta}_{1}\\right]\\\\  &amp;= \\overline{x} \\cdot \\mathbb{E}\\left[\\left(\\hat{\\beta}_{1}-\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right]\\right)\\cdot\\left(\\overline{\\varepsilon}-\\mathbb{E}\\left[\\overline{\\varepsilon}\\right]\\right)\\right]\\\\  &amp;= \\overline{x} \\cdot \\mathbb{E}\\left[\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right)\\cdot\\left(\\overline{\\varepsilon}-\\mathbb{E}\\left[\\overline{\\varepsilon}\\right]\\right)\\right] \\quad (\\because \\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] = \\beta_{1})\\\\  &amp;= \\overline{x} \\cdot \\mathbb{E}\\left[\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right)\\cdot\\left(0-0\\right)\\right] \\quad \\text{s.t.} \\; \\varepsilon \\sim N(0, \\sigma^2)\\\\  &amp;= 0  \\end{aligned}\\]        $\\mathbb{Var}\\left[\\hat{\\beta}_{0}\\right]$\\[\\begin{aligned}  \\mathbb{Var}\\left[\\hat{\\beta}_{0}\\right]  &amp;= \\mathbb{Var}\\left[\\overline{y}\\right] + \\mathbb{Var}\\left[\\hat{\\beta}_{1}\\overline{x}\\right] - \\mathbb{Cov}\\left[\\overline{y}, \\hat{\\beta}_{1}\\overline{x}\\right]\\\\  &amp;= \\frac{\\sigma^2}{n} + \\overline{x}^{2} \\cdot \\frac{\\sigma^2}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}} + 0\\\\  &amp;= \\sigma^2 \\cdot \\left[\\frac{1}{n} + \\frac{\\overline{x}^{2}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right]  \\end{aligned}\\]  이미지 출처  https://medium.com/@luvvaggarwal2002/linear-regression-in-machine-learning-9e8af948d3eb"
  },
  
  {
    "title": "Simple Linear Regression Analysis",
    "url": "/posts/Simple_Linear_Regression_Analysis/",
    "categories": "Statistical Techs, Regression Analysis",
    "tags": "Statistics, Regression, t Test, Goodness of Fit Test, R2",
    "date": "2024-07-08 00:00:00 +0900",
    





    
    "snippet": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들...",
    "content": "What? Linear Regression Analysis  선형 회귀 분석(Linear Regression Analysis) : 관찰된 연속형 변수들에 대하여 한 변수($Y$)를 다른 변수들($X$)의 선형 결합으로써 설명하는 모형을 탐색하는 방법          광고지출비용이 증가할 때 매출액은 어떻게 변하는가?      소득이 높은 국가의 국민들이 더 행복한가?      소득이 증가할 때 소비는 얼마나 증가하는가?      교육수준이 높을수록 임금이 증가하는가?        변수(Variable)          예측 대상이 되는 변수($Y$)                  반응변수(Response Variable)          종속변수(Dependent Variable)          내생변수(Endogenous Variable)                    예측에 활용되는 변수($X$)                  설명변수(Explanatory Variable)          독립변수(Independent Variable)          외생변수(Exogenous Variable)                    Simple Linear Regression Model      단순 선형 회귀 모형(Simple Linear Regression Model) : 반응변수와 단일 설명변수 간 선형 상관관계를 모델링하는 모형\\[\\begin{aligned}  Y  &amp;=\\beta_0+\\beta_1X+\\varepsilon\\\\  y_{i}  &amp;=\\beta_0+\\beta_1 x_{i}+\\varepsilon_{i}  \\end{aligned}\\]    회귀계수(Regression Coefficient) : 모형이 추론하고자 하는 모수(Parameter)로서 상수          편향(Bias; $\\beta_0$) : 설명변수의 값이 $0$ 일 때 종속변수의 값      가중치(Weight; $\\beta_1$) : 설명변수가 종속변수에 미치는 영향력의 방향과 강도            오차항(Error Term; $\\varepsilon$) : 확률변수\\[\\begin{aligned}  \\varepsilon = y-\\left(\\beta_{0} + \\beta_{1} x \\right) \\sim N(0, \\sigma^2)  \\end{aligned}\\]                  잔차(Residual; $\\epsilon$) : 최적 회귀계수 하 오차항의 추정치\\[\\epsilon=y-\\left(\\hat{\\beta}_{0} + \\hat{\\beta}_{1} x \\right)\\]            회귀계수의 유의성 검정: T-검정  반응변수와 설명변수가 통계적으로 유의한(Statistically Significant) 관계를 가지는가에 관한 가설검정임. 단, 검정 결과 두 변수 간 관계가 통계적으로 유의하다는 결론이 도출되더라도, 이 결론은 두 변수 간 상관관계(Correlation)의 유의성을 보장할 뿐, 두 변수 간 선형관계(Linear Relationship) 혹은 인과관계(Causation)의 유의성을 보장하지는 않음.  관심 모수에 대한 점 추정량 도출          관심 모수 : $\\beta_{1}$      점 추정량 : \\(\\hat{\\beta}_{1} \\sim N(\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right], \\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]^2) \\quad \\text{s.t.}\\;n&gt;30\\)                  최소자승추정량의 평균 : \\(\\mathbb{E}\\left[\\hat{\\beta}_{1}\\right] = \\beta_{1}\\)          최소자승추정량의 분산 : \\(\\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]^2 = \\sigma^2\\left[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^2}}\\right] \\quad \\text{s.t.}\\;\\varepsilon \\sim N(0,\\sigma^2)\\)                      귀무가설과 대립가설 설정          $H_{0}: \\quad \\beta_{1} = 0$      $H_{1}: \\quad \\beta_{1} \\ne 0$            검정통계량 도출\\[\\begin{aligned}  T = \\frac{\\hat{\\beta}_{1}-0}{\\mathbb{SE}\\left[\\hat{\\beta}_{1}\\right]} \\sim t(n-2)  \\end{aligned}\\]  Goodness of Fit      적합도(Goodness of Fit) : 모형이 반응변수의 변동을 얼마나 잘 설명하고 있는가        반응변수(Response Variable)          $y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\varepsilon_{i}$      $\\hat{y}=\\beta_{0}+\\beta_{1}x$      $\\overline{y}=\\beta_{0}+\\beta_{1}\\overline{x} \\quad \\text{s.t.}\\; \\varepsilon \\sim N(0, \\sigma^2)$      Variation of the Response Variable\\[\\begin{aligned}\\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}&amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} + \\varepsilon_{i}\\right) -\\overline{y}\\right]^{2}} \\\\&amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right) + \\varepsilon_i \\right]^{2}} \\\\&amp;= \\sum_{i=1}^{n}{\\left[\\left(\\hat{y}_{i} -\\overline{y}\\right)^2 + \\varepsilon_{i}^{2} + 2 \\times \\varepsilon_{i} \\times \\left(\\hat{y}_{i}-\\overline{y}\\right)\\right]} \\\\&amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^{2}} + \\sum_{i=1}^{n}{\\varepsilon_{i}^2} + 2\\times\\sum_{i=1}^{n}{\\varepsilon_{i}\\left(\\hat{y}_{i}-\\overline{y}\\right)} \\\\&amp;= \\sum_{i=1}^{n}{\\left(\\hat{y}_{i} -\\overline{y}\\right)^2} + \\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}\\quad(\\because \\sum_{i=1}^{n}{\\hat{y}_{i}-\\overline{y}} = 0)\\end{aligned}\\]      총변동(Total Sum of Square; TSS) : 반응변수의 총 변동성\\[TSS=\\sum_{i=1}^{n}{\\left(y_{i}-\\overline{y}\\right)^2}\\]        회귀변동(Explained Sum of Square; ESS) : 모형에 의해 설명되는 반응변수의 변동성\\[ESS=\\sum_{i=1}^{n}{\\left(\\hat{y}_{i}-\\overline{y}\\right)^2}\\]        잔차변동(Residual Sum of Square; RSS) : 모형에 의해 설명되지 않는 반응변수의 변동성\\[\\begin{aligned}  RSS  &amp;=\\sum_{i=1}^{n}{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}\\\\  &amp;=\\sum_{i=1}^{n}{\\varepsilon_{i}^{2}}  \\end{aligned}\\]  Coefficient of Determination      결정계수(Coefficient of Determination; $R^2$) : 총변동 대비 회귀변동의 비율로 측정된 적합도\\[\\begin{aligned}  R^2  &amp;= \\frac{ESS}{TSS} \\\\  &amp;= \\frac{ESS}{ESS + RSS} \\\\  &amp;= 1 - \\frac{RSS}{TSS}  \\end{aligned}\\]        Adjusted Coefficient of Determination($\\text{Adj.}R^2$) : 설명변수의 갯수 $p$ 가 많을수록 적합도가 높게 측정되는 경향을 조정한 결정계수\\[\\text{Adj.}R^2 = \\frac{(n-1)R^2-p}{n-p-1}\\]  "
  },
  
  {
    "title": "Summarize Statistical Method",
    "url": "/posts/Summarize_Statistical_Methods/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics, Normality Test, Shapiro-Wilk Test, Homogeneity of Variance Test, Levene’s Test, ANOVA",
    "date": "2024-07-07 00:00:00 +0900",
    





    
    "snippet": "수치형 변수의 평균에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 평균      $\\mu$      $\\bar{X}$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu...",
    "content": "수치형 변수의 평균에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 평균      $\\mu$      $\\bar{X}$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu=\\mu_0$      One Sample t-Test      statsmodels.stats.ttest_mean              두 집단 간 평균 비교  (독립표본)      $\\mu_1-\\mu_2$      \\(\\bar{X}_{1} - \\bar{X}_{2}\\)      $(n_1 + n_2)&gt;30$ or $X_{1}\\sim N, X_{2} \\sim N$      $H_0: \\mu_1 - \\mu_2 = 0$      Two Sample t-Test      statsmodels.stats.weightstats.ttest_ind              두 집단 간 평균 비교  (쌍체표본)      $\\mu_d$      $\\bar{X}_d$      $n&gt;30$ or $X \\sim N$      $H_0: \\mu_d=0$      Paired t-Test      statsmodels.stats.ttest_mean              셋 이상 그룹 간 평균 비교      $\\mu_1, \\cdots, \\mu_m$      $\\bar{X}_1, \\cdots, \\bar{X}_m$      $n_i&gt;30$ or $X_{i} \\sim N$  $\\sigma_{i}^{2}=\\sigma_{j}^{2}$      $H_0: \\mu_1 = \\cdots = \\mu_m$      ANOVA      statsmodels.stats.anova.AnovaRM              양적변수 간의 상관관계      $\\beta_0, \\beta_1$  $(y=\\beta_0+\\beta_1 x + \\epsilon)$      $\\hat{\\beta}_0, \\hat{\\beta}_1$      반응변수와 설명변수 간 선형성  설명변수 간 독립성  오차의 등분산성  오차의 정규성      $H_0: \\beta_i=0$      Regression      statsmodels.api.OLS      범주형 변수의 비율에 대한 추론            문제      관심모수      점추정량      가정체크      검정가설      검정방법      Python Module                  단일 집단의 비율      $\\pi$      $p$      $np&gt;5$  $n(1-p)&gt;5$      $H_0: \\pi=\\pi_0$      One Sample z-Test      statsmodels.stats.proportion.proportions_ztest              두 집단 간 비율 비교      $\\pi_1 - \\pi_2$      $p_1 - p_2$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1-\\pi_2=0$      Two Sample z-Test      statsmodels.stats.proportion.proportions_ztest              적합성 검정      $\\pi_1, \\cdots, \\pi_m$      $p_1, \\cdots, p_m$      $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0: \\pi_1=p_{0}^{(1)}, \\cdots, \\pi_m=p_{0}^{(m)}$      Chi-square test      scipy.stats.chisquare              독립성 검정                    $n_i p_i &gt; 5$  $n_i (1-p_i)&gt;5$      $H_0:$ 두 범주형 변수가 독립      Chi-square test      scipy.stats.chi2_contingency              양적변수와의 상관관계      $\\beta_0, \\beta_1$  $(\\pi=\\beta_0+\\beta_1 x)$      $\\hat{\\beta}_0, \\hat{\\beta}_1$      $Y \\sim B$      $H_0: \\beta_i=0$      Logistic regression      sklearn.linear_models.LogisticRegression      refer.정규성 검정(Shapiro-Wilk Test)  귀무가설과 대립가설 설정          $H_{0}:\\quad X \\sim N(\\mu, \\sigma^2)$      $H_{1}:\\quad X \\not\\sim N(\\mu, \\sigma^2)$            검정통계량 도출\\[W=\\frac{\\left(\\sum_{i=1}^{n} \\alpha_{i} X_{i}\\right)^2}{\\sum_{i=1}^{n}\\left(X_{i} - \\overline{X}\\right)^2}\\]                  $\\overrightarrow{X}$ : 표본의 관측치 $X_{i}$ 를 크기에 따라 오름차순 정렬한 순위 통계량 벡터\\[\\begin{aligned}  \\overrightarrow{X}  =\\begin{pmatrix} X_{1}&amp;X_{2}&amp;\\cdots&amp;X_{n} \\end{pmatrix}^{T}  \\end{aligned}\\]                  $\\overline{X}=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}$ : 표본평균                            $\\overrightarrow{\\alpha}$ : 순위 통계량 벡터 $\\overrightarrow{X}$ 의 계수 벡터\\[\\overrightarrow{\\alpha}=\\displaystyle\\frac{\\overrightarrow{m}^{T}\\mathbb{V}^{-1}}{\\Vert \\mathbb{V}^{-1}\\overrightarrow{m} \\Vert}\\]                              $\\overrightarrow{m}$ : 기대 순위 통계량 벡터\\[\\overrightarrow{m}=\\begin{pmatrix} E\\left[X_{1}\\right]&amp;E\\left[X_{2}\\right]&amp;\\cdots&amp;E\\left[X_{n} \\right]\\end{pmatrix}^{T}\\]                                $\\mathbb{V}$ : 기대 순위 통계량의 공분산 행렬\\[\\mathbb{V}_{i,j}=\\text{Cov}\\Big[E\\left[X_{i}\\right],E\\left[X_{j}\\right]\\Big]\\]                    $\\overrightarrow{m}^{T}\\mathbb{V}^{-1}$ : $\\mathbb{V}^{-1}$ 에 의해 선형 변환되어 상호 독립된 기대 순위 통계량 벡터          $\\Vert \\mathbb{V}^{-1}\\overrightarrow{m} \\Vert$ : 정규화 항                      표본 $Y \\sim N(0,1)$ 를 활용한 경험적 분포 생성                  표준정규분포로부터 $n$ 개의 관측치로 구성된 표본을 반복적으로 생성\\[\\begin{aligned} \\overrightarrow{Y}^{(k)} =\\begin{pmatrix} Y_{1}^{(k)}&amp;Y_{2}^{(k)}&amp;\\cdots&amp;Y_{k}^{(k)} \\end{pmatrix}^{T} \\quad \\text{for}\\; Y^{(k)}_{i} \\sim N(0,1) \\end{aligned}\\]                    각 표본에 대하여 검정통계량 도출\\[W^{(k)}=\\frac{\\left(\\sum_{i=1}^{k} \\alpha_{i} Y_{i}\\right)^2}{\\sum_{i=1}^{k}\\left(Y_{i} - \\overline{Y}\\right)^2}\\]                    $n$ 의 크기에 따른 $W$ 의 경험적 분포 도출\\[f_{W}:n \\rightarrow W\\]                    $W$ 의 경험적 분포에서 특정 $w$ 값보다 작거나 같은 값을 가질 확률 도출\\[\\begin{aligned} \\text{p-value} &amp;=F_{W}(w)\\\\ &amp;=P(W \\le w) \\end{aligned}\\]              표본 $X$ 에 대한 검정통계량 $W$ 의 $\\text{p-value}$ 와 유의수준 $\\alpha$ 비교                  $F_{W}(W) \\le \\alpha$ : $X \\not\\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 현저히 낮다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각한다.                            $\\alpha &lt; F_{W}(W)$ : $X \\sim N(\\mu, \\sigma^2)$                  귀무가설이 참이라는 가정 하에 도출된 검정통계량보다 극단적인 실현값이 발생할 가능성이 어느 정도 존재한다. 이는 귀무가설이 참이라는 가정 하에 표본이 실현될 가능성이 현저히 낮다고 볼 수 없음을 의미한다. 따라서 유의수준 $\\alpha$ 하 귀무가설을 기각하지 않는다.                    등분산 검정(Levene’s Test)  관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\sigma_{1}^{2},\\sigma_{2}^{2},\\cdots,\\sigma_{k}^{2}\\)      점 추정량 : \\(S_{1}^{2},S_{2}^{2},\\cdots,S_{k}^{2}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad$ 모든 $i$ 에 대하여 $\\displaystyle\\frac{\\sigma_{i}^{2}}{\\sigma_{j \\ne i}^{2}}=1$      $H_{1}:\\quad$ 어떤 $i$ 에 대하여 $\\displaystyle\\frac{\\sigma_{i}^{2}}{\\sigma_{j \\ne i}^{2}} \\ne 1$            검정통계량 도출\\[F=\\frac{\\text{SSB} / (k-1)}{\\text{SSW} / (N-k)} \\sim F(k-1, N-k)\\]                  SSB(Sum of Square Between) : 집단 간 편차 자승의 합\\[\\text{SSB}=\\sum_{i=1}^{k}{N_{i}\\left(\\overline{Z}^{(i)}-\\overline{Z}\\right)^2} \\sim \\chi^2(k-1)\\]                  $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}_{\\forall}\\) 의 평균          $\\overline{Z}$ : 모든 관측치 $X^{(\\forall)}_{\\forall}$ 에 대하여 그 절대편차 \\(Z^{(\\forall)}_{\\forall}\\) 의 평균          $k$ : 표본 내 집단 갯수                            SSW(Sum of Within) : 집단 내 편차 자승의 합\\[\\text{SSW}=\\sum_{i=1}^{k}\\sum_{j=1}^{N_{i}}{\\left(Z^{(i)}_{j}-\\overline{Z}^{(i)}\\right)^2} \\sim \\chi^2(N-k)\\]                              \\(Z^{(i)}_{j}\\) : \\(i\\) 번째 집단의 \\(j\\) 번째 관측치 \\(X^{(i)}_{j}\\) 의 절대편차\\[Z^{(i)}_{j}=\\left\\vert X^{(i)}_{j}-\\overline{X}^{(i)} \\right\\vert\\]                    $\\overline{Z}^{(i)}$ : $i$ 번째 집단에 대하여 그 절대편차 \\(Z^{(i)}_{\\forall}\\) 의 평균          $N$ : 표본 내 관측치 갯수                            F-Dist.($F(\\nu_1, \\nu_2)$) : 서로 독립인 확률변수 $V_{1}\\sim\\chi^2(\\nu_1),V_{2}\\sim\\chi^2(\\nu_2)$ 간 비율로 구성되는 확률변수의 분포\\[F=\\frac{V_1/\\nu_1}{V_2/\\nu_2} \\sim F(\\nu_1,\\nu_2)\\]            "
  },
  
  {
    "title": "A/B Test",
    "url": "/posts/A_B_Test/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics, A/B Test, Two Sample t Test, Paired Sample t Test, Goodness of Fit Test, Test of Independence",
    "date": "2024-07-06 00:00:00 +0900",
    





    
    "snippet": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더...",
    "content": "What? A/B Test      A/B Test : 서로 다른 두 방법 간 효과의 차이를 밝히기 위한 대조 실험          상관관계(Correlation) 를 파악하고자 하는 변수 $Y,X$ 외에 다른 요인들을 직접 통제할 수 없을 때 사용되는 통계적 디자인 패턴으로서, 임의로 나눈 두 집단에 대하여 서로 다른 방법을 적용하고 어떤 집단이 더 높은 성과를 보이는지 판단함. 이때 두 집단을 무작위로 추출함으로써, 두 집단이 제3의 요인들에 대하여 완전히 동질적일 수는 없지만 확률적으로 유사한 분포를 가지도록 함.      refer. Correlation VS. Causality  Example: 아이스크림 판매량과 물놀이 사고 간 관계성  한 지자체에서 물놀이 사고를 줄이는 것을 목표로 하고 있다. 조사 결과 아이스크림 판매량과 물놀이 사고 빈도 간의 상관관계가 높음을 알 수 있었다. 즉, 아이스크림 판매량이 증가하면 물놀이 사고가 증가하는 것이 데이터로부터 파악되었다. 이를 근거로 아이스크림 판매량 증가가 물놀이 사고 증가의 원인이라고 판단하였고, 물놀이 사고를 줄이기 위해 아이스크림 가격을 올려 판매량을 줄이는 정책을 입안하였다.  아이스크림 판매량과 물놀이 사고를 동시에 증가시키는 제3의 요인이 존재한다면?  Example: 웹사이트 디자인 개편과 매출 증가 간 관계성  어떤 쇼핑몰 웹 사이트에서 3개월에 걸쳐 디자인 개편 프로젝트를 진행하였고, 지난주에 성공적으로 새 디자인을 적용하였다. 그랬더니 갑자기 그 전에 비해 일 매출이 $10\\%$ 증가했다. 매출 증가는 웹사이트 디자인 개편 덕분이라고 판단할 수 있는가?  새 디자인이 적용된 날 갑자기 경쟁 쇼핑몰이 문을 닫았다면?  새 디자인이 적용된 날 갑자기 인기 상품이 입고되었다면?  새 디자인이 적용된 날 갑자기 경기가 좋아졌다면?Two Sample t-Test      2표본 t 검정(Two Sample t-Test) : 두 독립표본의 평균이 통계적으로 유의한 차이가 있는지 검정하는 방법          한 메이저 리그 야구경기를 마무리하는 데 걸리는 시간에 대한 우려가 팬과 구단주 사이에서 점차 더 커지고 있다. 이 문제의 심각성을 평가하기 위해서, 한 통계 전문가는 5년 전과 금년에 임의표본을 구성하는 경기들을 마무리하는데 걸린 시간을 기록하였다. 한 경기를 마무리하는 데 걸리는 시간이 5년 전보다 금년이 더 길다고 결론을 내릴 수 있는가?        관심 모수에 대한 점 추정량 도출          관심 모수 : $\\mu_1-\\mu_2$      점 추정량 : $\\overline{X}_1-\\overline{X}_2$        귀무가설과 대립가설 설정          $H_{0}:\\quad \\mu_1-\\mu_2=D_{0}$      $H_{1}:\\quad \\mu_1-\\mu_2 \\ne D_{0}$      Independent Samples t-Test      독립표본 t 검정(Independent Samples t-Test) : 등분산 가정이 성립하는 경우($\\sigma^2_1=\\sigma^2_2$)의 2표본 t 검정        합동분산(Pooled Variance; $S_p^2$) : 모분산이 동일한 것으로 간주되는 두 독립표본의 분산을 각각의 자유도로 가중평균한 값\\[\\begin{aligned}  S_p^2  &amp;= \\frac{\\nu_1 \\cdot S_{1}^2 + \\nu_2 \\cdot S_{2}^2}{\\nu_1+\\nu_2}  \\end{aligned}\\]        합동분산이 적용된 검정통계량 도출\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{\\displaystyle\\frac{S_p^2}{n_1}+\\displaystyle\\frac{S_p^2}{n_2}}}  \\sim t(\\nu_1+\\nu_2)  \\end{aligned}\\]                  $\\overline{X}_1-\\overline{X}_2$ 의 기대값 도출\\[\\begin{aligned}  E\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= E\\left[\\overline{X}_1\\right]-E\\left[\\overline{X}_2\\right]\\\\  &amp;=\\mu_1 - \\mu_2  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= Var\\left[\\overline{X}_1\\right] + Var\\left[\\overline{X}_2\\right] - 2\\times Cov\\left[\\overline{X}_1,\\overline{X}_2\\right] \\\\  &amp;= \\frac{S_p^2}{n_1} + \\frac{S_p^2}{n_2}\\quad (\\because Cov\\left[\\overline{X}_1,\\overline{X}_2\\right]=0)  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\displaystyle\\frac{S_p^2}{n_1}+\\displaystyle\\frac{S_p^2}{n_2}}}  \\sim t(\\nu_1+\\nu_2)  \\end{aligned}\\]            Welch’s t-Test      Welch’s t 검정(Welch’s t-Test) : 등분산 가정이 성립하지 않는 경우($\\sigma^2_1 \\ne \\sigma^2_2$)의 2표본 t 검정        Welch-Satterthwaite 자유도(Welch-Satterthwaite Degree of Freedom; $\\nu_W$) : 표준오차로써 측정된 종합적인 변동성을 각 표본들이 변동성에 대하여 기여한 정도를 가중평균한 값\\[\\begin{aligned}  \\nu_W  &amp;= \\left(\\frac{S_{1}^{2}}{n_{1}}+\\frac{S_{2}^{2}}{n_{2}}\\right)^2 \\bigg/ \\left[\\frac{(S_{1}^2/n_1)^2}{\\nu_1} + \\frac{(S_{2}^2/n_2)^2}{\\nu_2} \\right]  \\end{aligned}\\]          $\\left(\\displaystyle\\frac{S_{1}^{2}}{n_{1}}+\\displaystyle\\frac{S_{2}^{2}}{n_{2}}\\right)^2$ : 표준오차로써 측정된 확률변수 $\\overline{X}_1-\\overline{X}_2$ 의 종합적인 변동성      $\\displaystyle\\frac{(S_{1}^2/n_1)^2}{\\nu_1} + \\displaystyle\\frac{(S_{2}^2/n_2)^2}{\\nu_2}$ : 표본들이 확률변수 $\\overline{X}_1-\\overline{X}_2$ 의 종합적인 변동성에 대하여 각각 기여한 정도            Welch-Satterthwaite 자유도를 따르는 검정통계량 도출\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-D_{0}}{\\sqrt{\\displaystyle\\frac{S_1^2}{n_1}+\\displaystyle\\frac{S_2^2}{n_2}}}  \\sim t(\\nu_W)  \\end{aligned}\\]                  $\\overline{X}_1-\\overline{X}_2$ 의 기대값 도출\\[\\begin{aligned}  E\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= E\\left[\\overline{X}_1\\right]-E\\left[\\overline{X}_2\\right]\\\\  &amp;=\\mu_1 - \\mu_2  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}_1-\\overline{X}_2\\right]  &amp;= Var\\left[\\overline{X}_1\\right] + Var\\left[\\overline{X}_2\\right] - 2\\times Cov\\left[\\overline{X}_1,\\overline{X}_2\\right] \\\\  &amp;= \\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\quad (\\because Cov\\left[\\overline{X}_1,\\overline{X}_2\\right]=0)  \\end{aligned}\\]                    $\\overline{X}_1-\\overline{X}_2$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\displaystyle\\frac{S_1^2}{n_1}+\\displaystyle\\frac{S_2^2}{n_2}}}  \\sim t(\\nu_{W})  \\end{aligned}\\]            Paired Sample t-Test      쌍체표본 t 검정(Paired Sample t-Test) : 쌍을 이루는 두 변수 간 차이의 평균이 기대되는 값($\\mu_0$)과 통계적으로 유의한 차이가 있는지 검정하는 방법          주식시장의 변동은 일부 투자자들로 하여금 주식을 팔고 그들의 자금을 더 안전한 투자로 이동시키게 만든다. 최근 주식시장의 변동이 주식 보유에 어느 정도 영향을 미쳤는지를 결정하기 위해 주식을 소유하고 있는 170 명을 대상으로 서베이를 실시하였다. 실험 대상자들의 재작년 말과 작년 말 주식 보유액을 기록하였다. 주식 보유액이 감소했다고 추론할 수 있는가?              쌍체표본(Paired Sample) : 동일한 대상에 대하여 두 번의 측정을 통해 얻은 표본 혹은 변수 간 상관관계가 존재하는 두 대상에 대하여 측정을 통해 얻은 표본        관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\mu=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\)      점 추정량 : \\(\\overline{X}=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad \\mu=\\mu_{0}$      $H_{1}:\\quad \\mu \\ne \\mu_{0}$            검정통계량\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{\\overline{X}-\\mu_{0}}{\\displaystyle\\frac{S}{\\sqrt{n}}}  \\sim t(\\nu)  \\end{aligned}\\]                  $\\overline{X}$ 의 기대값 도출\\[\\begin{aligned}  E\\left[ \\overline{X} \\right]  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\left(X^{(A)}_{i}-X^{(B)}_{i}\\right)}\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\left(\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right)\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(B)}_{i}}\\right]\\\\  &amp;= E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(A)}_{i}}\\right]-E\\left[\\frac{1}{n}\\sum_{i=1}^{n}{\\overline{X}^{(B)}_{i}}\\right]\\\\  &amp;= E\\left[\\overline{X}_{A}\\right]-E\\left[\\overline{X}_{B}\\right]\\\\  &amp;=\\mu_A - \\mu_B  \\end{aligned}\\]                    $\\overline{X}$ 의 분산 도출\\[\\begin{aligned}  Var\\left[\\overline{X}\\right]  &amp;=Var\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}-X^{(B)}_{i}}\\right]\\\\  &amp;=Var\\left[\\frac{1}{n}\\sum_{i=1}^{n}{X^{(A)}_{i}}-\\frac{1}{n}\\sum_{i=1}^{n}{X^{(B)}_{i}}\\right]\\\\  &amp;=Var\\left[\\overline{X}_{A}-\\overline{X}_{B}\\right]\\\\  &amp;=Var\\left[\\overline{X}_{A}\\right] + Var\\left[\\overline{X}_{B}\\right] - 2 \\times Cov \\left[\\overline{X}_{A}, \\overline{X}_{B}\\right]\\\\  &amp;=\\frac{S_{A}^{2}}{n}+\\frac{S_{B}^{2}}{n}-2\\times\\frac{r_{A,B}}{n}\\quad(\\because Cov \\left[\\overline{X}_{A}, \\overline{X}_{B}\\right] \\ne 0)\\\\  &amp;=\\frac{S^2}{n}  \\end{aligned}\\]                    $\\overline{X}$ 표준화\\[\\begin{aligned}  T  &amp;= \\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{S}{\\sqrt{n}}}  \\sim t(\\nu)  \\end{aligned}\\]            Goodness-of-Fit Test      적합성 검정(Goodness-of-Fit Test) : 범주형 자료에 대하여 관찰된 비율이 기대되는 비율과 통계적으로 유의한 차이가 있는지 검정하는 방법          마케팅 조사 기관 Scott 가 수행한 시장 점유율에 대한 조사에서, 몇 년동안 시장점유율은 A사 $30\\%$, B사 $50\\%$, C사 $20\\%$ 수준을 보이며 안정적이었다. 최근에 C사는 기능이 향상된 제품을 출시하였다. 이에 신제품의 출시가 시장점유율의 변화에 영향을 미치고 있는지 파악하고자 한다. Scott 가 $200$ 명의 고객을 소비자 패널로 활용하여 조사를 수행한 결과, 아래의 표와 같은 구매 선호도를 얻었다. 신제품 출시에 따라 시장점유율이 변화했다고 볼 수 있는가?        관심 모수에 대한 점 추정량 도출          관심 모수 : \\(\\pi_{A},\\quad \\pi_{B},\\quad \\pi_{C}\\)      점 추정량 : \\(p_{A},\\quad p_{B},\\quad p_{C}\\)        귀무가설과 대립가설 설정          $H_{0}:\\quad \\pi_{A}=0.3 \\; \\text{and} \\; \\pi_{B}=0.5 \\; \\text{and} \\; \\pi_{C}=0.2$      $H_{1}:\\quad \\pi_{A} \\ne 0.3 \\; \\text{or} \\; \\pi_{B} \\ne 0.5 \\; \\text{or} \\; \\pi_{C} \\ne 0.2$            검정통계량\\[\\begin{aligned}  X  &amp;= \\sum_{i=1}^{k}{Z_{i}^2} \\quad \\text{for} \\quad Z_{i} \\sim N(0,1)\\\\  &amp;= \\sum_{i=1}^{k}{\\left(\\frac{\\Omega_{i} - e_{i}}{\\sqrt{e_{i}}}\\right)^2} \\sim \\chi^2{(\\nu)}  \\end{aligned}\\]                  $Z_{i}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[Z_{i}=\\frac{\\Omega_{i} - e_{i}}{\\sqrt{e_{i}}} \\sim N(0,1)\\]                    $\\Omega_{i}$ : $i$ 번째 카테고리에 해당하는 관측치의 관측 빈도                                            회사              A              B              C              계                                                          관측 빈도              48              98              54              200                                                  $e_{i}$ : $\\Omega_{i}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                                            회사              A              B              C                                                          기대 빈도              60              100              40                              \\[\\begin{aligned}  e_{i}  &amp;=E\\left[\\Omega_{i} \\right]\\\\  &amp;= n \\cdot p_{i}  \\end{aligned}\\]                    $\\sqrt{e_{i}}$ : $\\Omega_{i}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  Var\\left[\\Omega_{i}\\right]  &amp;= n \\cdot p_{i} \\cdot (1-p_{i})\\\\  &amp;= e_{i} \\cdot (1-p_{i})\\\\  &amp;\\approx e_{i} \\cdot 1  \\end{aligned}\\]                    $\\chi^2{(\\nu)}$ : 자유도가 $\\nu$ 인 카이제곱 분포                  $\\nu=k-1$          $k$ : 카테고리 갯수                    Test of Independence      독립성 검정(Test of Independence) : 두 범주형 자료가 통계적으로 독립인지 검정하는 방법          맥주 회사 Alber’s 에서는 라이트 맥주, 일반 맥주, 흑 맥주를 생산하여 유통한다. 이 기업의 시장조사팀은 성별에 따라 선호하는 맥주에 차이가 있는지 알아보고자 한다. 만약 맥주의 품종별 선호도가 성별에 독립적이라면 맥주광고는 모든 고객에 대해 획일적으로 이루어질 것이다. 반면, 품종별 선호도가 성별에 의존적이라면 세분 시장의 목표 고객에 따라 상이한 촉진 전략을 수행해야 할 것이다. 아래 분할표는 무작위 추출된 $150$ 명이 각 맥주에 대해 시음한 후 응답한 품종별 선호도이다. 맥주의 품종별 선호도는 성별에 대하여 독립적이라 볼 수 있는가?        귀무가설과 대립가설 설정          $H_{0}:\\quad$ 품종별 선호도(열 변수; $Y$)는 성별 선호도(행 변수; $X$)에 대하여 독립적이다.      $H_{1}:\\quad$ 품종별 선호도(열 변수; $Y$)는 성별 선호도(행 변수; $X$)에 대하여 독립적이라 볼 수 없다.            검정통계량 도출\\[\\begin{aligned}  X  &amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{l}{Z_{i,j}^2} \\quad \\text{for} \\quad Z_{i,j} \\sim N(0,1)\\\\  &amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{l}{\\left(\\frac{\\Omega_{i,j} - e_{i,j}}{\\sqrt{e_{i,j}}}\\right)^2} \\sim \\chi^2{(\\nu)}  \\end{aligned}\\]                  $Z_{i,j}$ : 각 셀에 대하여 관측 빈도와 기대 빈도의 표준화된 차이\\[Z_{i,j}=\\frac{\\Omega_{i,j} - e_{i,j}}{\\sqrt{e_{i,j}}} \\sim N(0,1)\\]                    $\\Omega_{i,j}$ : 변수 $X$ 의 $i$ 번째 카테고리와 변수 $Y$ 의 $j$ 번째 카테고리에 해당하는 관측치의 관측 빈도                                            품종              라이트              일반              흑              계                                                          남성              20              40              20              80                                      여성              30              30              10              70                                      계              50              70              10              150                                                  $e_{i,j}$ : $\\Omega_{i,j}$ 의 기대값으로서 귀무가설이 참일 때 기대되는 빈도                                            품종              라이트              일반              흑                                                          남성              26.67              37.33              16.00                                      여성              23.33              32.67              14.00                              \\[\\begin{aligned}  e_{i,j}  &amp;= E\\left[\\Omega_{i,j} \\right]\\\\  &amp;=n \\cdot p_{i,j}\\\\  &amp;=n \\cdot P(X_{i} \\cap Y_{j})\\\\  &amp;=n \\cdot P(X_{i})P(Y_{j}) \\quad \\left(\\because P(Y_{j} \\vert X_{i})=P(Y_{j})\\right)  \\end{aligned}\\]                    $\\sqrt{e_{i,j}}$ : $\\Omega_{i,j}$ 에 대한 표준편차의 근사값\\[\\begin{aligned}  Var\\left[\\Omega_{i,j}\\right]  &amp;= n \\cdot p_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;= e_{i,j} \\cdot (1-p_{i,j})\\\\  &amp;\\approx e_{i,j} \\cdot 1  \\end{aligned}\\]                    $\\chi^2{(\\nu)}$ : 자유도가 $\\nu$ 인 카이제곱 분포                  $\\nu=(k-1)(l-1)$          $k$ : 변수 $X$ 의 카테고리 갯수          $l$ : 변수 $Y$ 의 카테고리 갯수                    이미지 출처  https://varify.io/en/blog/ab-testing/"
  },
  
  {
    "title": "Statistical Inference",
    "url": "/posts/Statistical_Inference/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics, Estimation, z Test, t Test",
    "date": "2024-07-05 00:00:00 +0900",
    





    
    "snippet": "EstimationPoint Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                    ...",
    "content": "EstimationPoint Estimator      점 추정량(Point Estimator) : 모수를 추정하는 하나의 값(Single Value)                                       표기          평균          분산          비율                                      모수          $\\theta$          $\\mu$          $\\sigma^2$          $\\pi$                          점 추정량          $\\hat{\\theta}$          $\\overline{X}$          $S^2$          $P$                          좋은 점 추정량의 성질          불편성(Unbiasedness) : 기대값이 모수와 같아 모수로부터 음이나 양으로 편향되지 아니함      효율성(Efficiency) : 모수의 불편 추정량 가운데에서 분산이 최소임      일치성(Consistency) : 표본의 크기 $n$ 이 커질수록 평균자승오차가 $0$ 에 수렴함      불편 추정량(Unbiased Estimator)      정의 : 기대값이 모수와 같아 모수로부터 음이나 양으로 편향되지 아니한 추정량          불편 추정량은 평균적으로 모수를 음으로 편향되게 평가하거나(과소평가), 양으로 편향되게 평가(과대평가)하지 않음. 단, 불편 추정량에 대하여 특정 표본에서 도출된 일부 실현값에는 오차가 존재할 수 있음.    \\[\\begin{aligned}  Bias(\\hat{\\theta})  &amp;= E(\\hat{\\theta}) - \\theta \\\\  &amp;= 0  \\end{aligned}\\]          $Bias(\\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 편향(Bias)      $E(\\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 기대값            예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 불편 추정량임      표본분산 $S^2$ 은 모분산 $\\sigma^2$ 의 불편 추정량임      효율적 추정량(Efficient Estimator)      정의 : 모수의 불편 추정량 가운데에서 분산이 최소인 불편 추정량\\[\\begin{aligned}  \\min{MSE(\\theta, \\hat{\\theta})}  &amp;= \\min{E\\left[(\\hat{\\theta}-\\theta)^2\\right]}\\\\  &amp;= \\min{\\bigg[Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\\bigg]}  \\end{aligned}\\]          $MSE(\\theta, \\hat{\\theta})$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대한 평균자승오차(Mean Squared Error)      $E[(\\hat{\\theta}-\\theta)^2]$ : 모수 $\\theta$ 의 추정량 $\\hat{\\theta}$ 에 대하여 그 오차 자승의 기대값            예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 불편 선형 추정량(Unbiased Linear Estimator) 중 가장 효율적인 추정량(Best Linear Unbiased Estimator; BLUE) 임                  선형 추정량 : \\(w_1x_1 + w_2x_2+\\cdots+e\\)          비선형 추정량 : \\(x_1^2,\\quad x_1 \\times x_2,\\quad \\displaystyle\\frac{x_1}{x_2}\\)                    일치 추정량(Consistent Estimator)      정의 : 표본의 크기 $n$ 이 커질수록 평균자승오차가 $0$ 에 수렴하는 추정량\\[\\begin{aligned}  \\displaystyle\\lim_{n \\rightarrow \\infty}{MSE(\\hat{\\theta})}  &amp;= \\displaystyle\\lim_{n \\rightarrow \\infty}{Var(\\hat{\\theta})} + \\displaystyle\\lim_{n \\rightarrow \\infty}{Bias(\\hat{\\theta})}^2\\\\  &amp;= 0  \\end{aligned}\\]        예시          표본평균 $\\overline{X}$ 은 모평균 $\\mu$ 의 일치 추정량임      Confidence Intervals      정의 : 신뢰 가능한 수준 하에서 모수를 포함할 수 있다고 추정되는 구간으로서 신뢰수준을 담보한 구간 추정량(Interval Estimator)          표본평균 $\\overline{X}$ 이 모평균 $\\mu$ 의 좋은 점 추정량이라고 해서 항상 그 실현값 $\\overline{x}_i$ 가 $\\mu$ 와 일치하지는 않음. 때문에 특정 표본에서 구한 추정치 $\\overline{x}_i$ 를 활용하여 $\\mu$ 를 포함할 가능성이 있는 구간을 만들어서 $\\mu$ 을 추정함. 신뢰구간은 이러한 구간 추정량에 대하여 $\\mu$ 를 포함할 가능성을 담보하고 있음.            구성\\[\\text{CI}=\\left(\\overline{X}-z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}, \\overline{X}+z_{\\alpha/2}\\times \\frac{\\sigma}{\\sqrt{n}}\\right)\\]                  신뢰수준(Confidence Level; $1-\\alpha$) : 신뢰구간이 담보하는, 해당 구간이 모수 $\\mu$ 를 포함할 가능성\\[P(\\mu \\in \\text{CI})=1-\\alpha\\]                    오차한계(Margin of Error; \\(z_{\\alpha / 2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}\\)) : 모수 $\\mu$ 와 그 점 추정량 $\\overline{X}$ 에 대하여 신뢰구간의 끝(한계)과 $\\mu$ 사이의 최대 차이로서, $\\mu$ 와 $\\overline{X}$ 의 차이(오차)를 수용할 수 있는 범위를 결정하는 값                  길이\\[\\text{Length}(\\text{CI}) = 2 \\times z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]          $(1-\\alpha)\\uparrow \\; \\Rightarrow L\\uparrow$ : 신뢰수준이 높을수록 신뢰구간의 길이가 증가함      $\\sigma\\uparrow \\; \\Rightarrow L\\uparrow$ : 모집단의 분포가 널리 퍼져 있을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함      $n\\downarrow \\; \\Rightarrow L\\uparrow$ : 표본의 크기가 작을수록 정확한 추정이 어려워 신뢰구간의 길이가 증가함            도출                  중심극한정리에 의해 $n$ 이 충분히 크면 다음이 성립함\\[\\begin{aligned}  \\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})  \\end{aligned}\\]                    확률변수 $\\overline{X}$ 를 다음과 같이 표준화할 수 있음\\[\\begin{aligned}  Z=\\displaystyle\\frac{\\overline{X} - \\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1)  \\end{aligned}\\]                    $100(1-\\alpha)\\%$ 신뢰수준 하 신뢰구간은 다음과 같음\\[\\begin{aligned}  P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})  &amp;=P(-z_{\\alpha/2}&lt;\\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}&lt;z_{\\alpha/2})\\\\  &amp;=P(-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\overline{X}-\\mu&lt;z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(-\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;-\\mu&lt;-\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=P(\\overline{X}-z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}}&lt;\\mu&lt;\\overline{X}+z_{\\alpha/2}\\times \\displaystyle\\frac{\\sigma}{\\sqrt{n}})\\\\  &amp;=1-\\alpha  \\end{aligned}\\]            Hypothesis Testing  통계적 가설(Statistical Hypothesis) : 모집단의 모수에 대한 주장          귀무가설(Null-Hypothesis; $H_0$) : 사실이 아니라는 충분한 근거를 얻기 전에는 사실이라고 믿어지는 가설      대립가설(Alternative Hypothesis; $H_1$) : 연구자의 주장으로서 귀무가설이 기각될 때 채택되는 가설        가설검정(Hypothesis Testing) : 귀무가설을 기각할 충분한 증거가 있는지 살핌으로써 대립가설을 우회로 증명하는 절차          귀무가설과 대립가설 설정      유의수준 설정      모수 추정법 적용 가능 여부 검토      검정통계량과 p-value 도출      귀무가설 기각 여부 결정      검정 결과 해석      종류      양측검정(Two-Sided Test) : 귀무가설에 대한 기각역을 양측에 설정하는 검정    \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu\\ne70  \\end{aligned}\\]        단측검정(One-Sided Test) : 귀무가설에 대한 기각역을 단측에만 설정하는 검정                  우측검정 : 기각역을 우측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu \\le 70,\\\\  H_1&amp;:\\;\\mu &gt; 70  \\end{aligned}\\]                    좌측검정 : 기각역을 좌측에만 설정하는 검정        \\[\\begin{aligned}  H_0&amp;:\\;\\mu=70,\\\\  H_1&amp;:\\;\\mu&lt;70  \\end{aligned}\\]            오류와 신뢰성      오류(Error) : 사실과 다르게 판단함              제1종 오류(Type 1 Error) : 귀무가설이 참일 때 귀무가설을 기각하는 오류      제1종 오류(Type 2 Error) : 귀무가설이 거짓일 때 귀무가설을 기각하지 않는 오류            검정의 유의수준(Significance Level) : 제1종 오류를 범할 확률\\[\\alpha\\]          통계학에서는 보수적 태도(귀무가설을 기각하지 않으려는 태도)를 취하므로 제1종 오류에 민감함            검정의 신뢰수준(Confidence Level) : 제1종 오류를 범할 확률 $\\alpha$ 에 대하여, 귀무가설이 참일 때 귀무가설을 기각하지 않을 확률\\[1-\\alpha\\]        검정의 검정력(Power) : 제2종 오류를 범할 확률 $\\beta$ 에 대하여, 귀무가설이 거짓일 때 귀무가설을 기각할 확률\\[1-\\beta\\]  검정통계량과 유의확률 도출      검정통계량(Test Statistic) : 귀무가설이 참이라고 가정했을 때 얻은 결과    \\[\\begin{aligned}  Z  &amp;=\\displaystyle\\frac{\\overline{X}-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\\\  &amp;=\\displaystyle\\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} + \\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\\\  &amp;=0 + \\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}  \\end{aligned}\\]                  귀무가설이 참인 경우 검정통계량의 분포 : 평균이 $0$ 이고 분산이 $1$ 인 가우시안 분포를 따름\\[\\begin{aligned}  Z \\sim N(0,1)  \\end{aligned}\\]                    귀무가설이 참이 아닌 경우 검정통계량의 분포 : 평균이 $\\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}}$ 이고 분산이 $1$ 인 가우시안 분포를 따름\\[\\begin{aligned}  Z \\sim N(\\displaystyle\\frac{\\mu-\\mu_0}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}},1)  \\end{aligned}\\]                  유의확률(Significance Probability Value; $\\text{p-value}$) : 검정통계량($Z$)보다 극단적인 결과($Y$)가 관측될 확률로서, 표본이 귀무가설과 양립하는 정도    \\[\\begin{aligned}  \\text{p-value}  &amp;= P\\left(\\vert Y \\vert \\ge \\vert Z \\vert \\Big\\vert H_{0}\\right) \\quad \\text{for}\\; Y \\sim N(0,1)  \\end{aligned}\\]  귀무가설 기각 여부 결정      검정통계량 $Z$ 의 실현값 $z$ 가 $0$ 과 차이가 많이 나면 기각함\\[\\vert z \\vert &gt;z_{\\alpha/2}\\]          기각치(Reject Value; $z_{\\alpha/2}$) : 차이가 많이 나는 기준이 되는 값으로서, 유의수준 $\\alpha$ 에 따라 결정됨            귀무가설이 참일 때 표본이 발생할 확률 $\\text{p-value}$ 이 현저하게 낮으면 기각함\\[\\text{p-value} &lt; \\alpha\\]          유의수준(Significance Level; $\\alpha$) : 현저하게 낮은 기준이 되는 값으로서, 제1종 오류 수용 정도      검정 결과 해석      통계적 유의성(Statistically Significant) : 유의함이 실제로는 존재하지 않을 수도 있지만, 주어진 정보를 활용하여 판단했을 때는 존재하였음        귀무가설을 기각할 수 없을 때는 귀무가설이 제한적으로 사실이라고 받아들임          귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각하지 않는다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_{0}$ 과 통계적으로 유의한 차이가 있다고 볼 수 없다.            귀무가설을 기각할 때는 대립가설이 사실이라고 잠정적으로 결론을 내림          귀무가설을 $\\alpha \\times 100 \\%$ 유의수준에서 기각한다. 즉, $\\alpha \\times 100 \\%$ 유의수준에서 모평균 $\\mu$ 는 $\\mu_0$ 과 통계적으로 유의한 차이가 있다.      Student t-Dist.  모분산 $\\sigma^2$ 을 모르는 경우 표본평균 $\\overline{X}$ 에 대하여 가설검정 시 우선 표본분산 $S^2$ 을 활용하여 모분산 $\\sigma^2$ 을 추정해야 함. 추정된 모분산으로 도출된 검정통계량은 자유도 $\\nu$ 에 따라 그 폭이 상이한 분포를 따르게 됨. 이처럼 자유도에 따라 변화하는 분산의 변동성을 반영하기 위해 표준정규분포 $Z \\sim N(0,1)$ 대신 스튜던트 t 분포 $T \\sim t(\\nu)$ 를 사용함.      스튜던트 t 분포($t(\\nu)$) : 표준정규분포를 따르는 확률변수 $Z$ 와 자유도가 $\\nu$ 인 카이제곱분포를 따르는 확률변수 $V$ 로 구성되는 확률변수의 분포    \\[T=\\frac{Z}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}} \\quad \\text{for}\\;Z \\sim N(0,1),\\; V \\sim \\chi^2(\\nu)\\]                  카이제곱분포($\\chi^2(\\nu)$) : 자유도가 $\\nu$ 로 주어졌을 때 표준정규분포를 따르는 독립적인 확률변수 $Z_{i}\\left(=\\displaystyle\\frac{X_{i}-\\overline{X}}{\\sigma}\\right)$ 들의 자승의 합의 분포로서, 모분산을 추정하는 데 사용됨\\[\\begin{aligned}  V  &amp;=\\sum_{i=1}^{k}{Z_{i}^2} \\quad \\text{for}\\; Z_{\\forall} \\sim N(0,1)\\\\  &amp;=\\sum_{i=1}^{k}{\\left(\\frac{X_{i}-\\overline{X}}{\\sigma}\\right)^2}\\\\  &amp;=\\frac{1}{\\sigma^2} \\times \\sum_{i=1}^{k}{\\left(X_{i}-\\overline{X}\\right)^2}\\\\  &amp;=\\frac{1}{\\sigma^2} \\times \\nu \\cdot \\frac{1}{\\nu} \\sum_{i=1}^{k}{\\left(X_{i}-\\overline{X}\\right)^2}\\\\  &amp;=\\nu \\times \\frac{S^2}{\\sigma^2} \\sim \\chi^2(\\nu)  \\end{aligned}\\]                  스튜던트 t 분포를 활용한 표본 $X \\sim N(\\mu, \\sigma^2)$ 의 검정통계량 $T$ 도출\\[\\begin{aligned}  T  &amp;= Z \\times \\frac{1}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}}\\\\  &amp;= \\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{\\sigma}{\\sqrt{n}}} \\times \\frac{1}{\\sqrt{\\displaystyle\\frac{\\sigma^2}{S^2}}}\\\\  &amp;= \\frac{\\overline{X}-\\mu}{\\displaystyle\\frac{S}{\\sqrt{n}}} \\sim t(\\nu)  \\end{aligned}\\]  이미지 출처  https://u5man.medium.com/to-err-is-human-what-the-heck-is-type-i-and-type-ii-error-b2c78190a45c  https://wikidocs.net/163986"
  },
  
  {
    "title": "Sample Dist.",
    "url": "/posts/Sample_Dist/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics",
    "date": "2024-07-04 00:00:00 +0900",
    





    
    "snippet": "Random SampleStatistical Inference  통계적 추론(Statistical Inference)          정의 : 표본을 사용하여 모집단의 성격을 추정하는 작업                  표본의 측정치를 모집단의 측정치에 대한 추정치로 간주함                    목표 : 표본오차의 크기 최소화       ...",
    "content": "Random SampleStatistical Inference  통계적 추론(Statistical Inference)          정의 : 표본을 사용하여 모집단의 성격을 추정하는 작업                  표본의 측정치를 모집단의 측정치에 대한 추정치로 간주함                    목표 : 표본오차의 크기 최소화                  표본은 모집단의 부분집합일 뿐이지, 모집단은 아니므로 모수와 통계량은 완전히 일치할 수 없음                      표본오차(Sampling Error) : 응답오차, 측정오차, 표본선택편향이 해결되었음에도 발생하는 실제값과 예측값의 차이          응답오차(Response Error) : 응답자의 응답 거부 혹은 잘못된 응답으로 인해 발생하는 오차      측정오차(Measurement Error) : 데이터의 틀린 측정이나 기입으로 인해 발생하는 오차      표본선택편향(Sample Selection Bias) : 모집단의 각 관측치들이 표본에 포함될 확률이 서로 다른 경우      Population &amp; Sample  모수는 그 값이 알려져 있지 않은 고정된 수이다. 이 값을 추정하기 위하여 표본의 통계량을 사용하므로, 통계량은 모수의 추정량이라 할 수 있다. 그런데 모집단에서 어떤 표본을 추출하느냐에 따라 통계량의 실현값이 달라진다. 따라서 모수는 상수(Constant), 통계량은 확률변수(Random Variable)라고 볼 수 있다.  모집단(Population)의 모수(Parameter)          모평균 : $\\mu$      모분산 : $\\sigma^2$        표본(Sample)의 통계량(Statistic)                  표본평균 : $\\overline{X}$\\[\\begin{aligned}  \\overline{X}  &amp;= \\frac{1}{n}(X_{1}+X_{2}+\\cdots+X_{n}) \\quad \\text{for}\\; X_{\\forall} \\in \\Omega\\\\  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{X_{i}}  \\end{aligned}\\]                    표본분산 : $S^2$\\[\\begin{aligned}  S^2  &amp;= \\frac{1}{\\nu}\\left[\\vert X_{1} - \\overline{X}\\vert^2 + \\vert X_{2} - \\overline{X}\\vert^2 + \\cdots + \\vert X_{n} - \\overline{X}\\vert^2 \\right]\\\\  &amp;= \\frac{1}{\\nu}\\sum_{i=1}^{n}(X_{i}-\\overline{X})^2  \\end{aligned}\\]                    note 자유도(Degree of Freedom; $\\nu$) : 주어진 자료 내에서 독립적으로 변할 수 있는 확률변수의 수                  어떠한 자료에 대하여 그 기술통계량이 주어지는 경우, 특정 관측치의 정보가 불분명하더라도 해당 관측치가 취할 수 있는 값은 제한되어 있음          표본분산 $S^2$ 을 계산하기 위해서는 표본평균 $\\overline{X}$ 을 먼저 계산해야 하므로, 분산 계산 시 동원되는 관측치 중 독립적으로 변할 수 있는 관측치의 수는 $n-1$ 임          이 경우 관측치 수 $n$ 이 아니라 자유도 $\\nu=n-1$ 로 나눈 값이 모분산 $\\sigma^2$ 의 비편향 추정량임                    Random Sample      모집단으로부터 관측치 $X_1, X_2, X_3, \\cdots, X_n$ 를 추출하여 구성한 표본에 대하여\\[\\begin{aligned}  \\{X_1, X_2, X_3, \\cdots, X_N\\}  \\end{aligned}\\]        모집단의 각 개체가 표본의 원소로서 선택될 확률이 모두 같고,\\[P(X_{i}=x_{i})=\\frac{1}{N} \\quad \\text{for}\\;i=1,2,\\cdots,N\\]        원소 $X_1, X_2, X_3, \\cdots, X_n$ 이 모두 모집단의 분포를 따르는 확률변수이고,\\[\\begin{aligned}  E\\left[X_{i^{\\forall}}\\right]&amp;=\\mu \\\\  Var\\left[X_{i^{\\forall}}\\right]&amp;=\\sigma^2  \\end{aligned}\\]        원소 $X_1, X_2, X_3, \\cdots, X_n$ 이 모두 통계적으로 독립인 경우\\[P(X_{j^{\\forall}} \\vert X_{i^{\\forall}}) = P(X_{j^{\\forall}})\\]  Sample DistributionWhat? Sample Dist.  표본분석의 목적 : 모수 추정          표본의 평균 $\\overline{X}$ 가 모집단의 평균 $\\mu$ 를 얼마나 잘 추정하는가      확률변수 $\\overline{X}$ 의 기대값 $E(\\overline{X})$ 은 상수 $\\mu$ 에 가까운가      추정량 $\\overline{X}$ 의 기대값 $E(\\overline{X})$ 과 모수 $\\mu$ 사이에는 얼마나 큰 추정오차가 존재하는가        추정량과 추정치의 정의          추정량(Estimator) : 모수를 추정하는 값으로서 통계량(Statistics)                  모평균 $\\mu$ 의 추정량 : 표본평균 $\\overline{X}$          모분산 $\\sigma^2$ 의 추정량 : 표본분산 $S^2$          모표준편차 $\\sigma$ 의 추정량 : 표본표준편차 $S$                    추정치(Estimate) : 특정 표본에서 얻어진 추정량의 실현값(Realized Value)        표본분포(Sampling Distribution) : 모수에 대한 추정량의 확률분포                  모집단의 평균을 추정하기 위해 여러 표본을 뽑을 때 표본 평균의 추정치들의 분포\\[\\overline{X} \\sim N(\\mu, \\displaystyle\\frac{\\sigma^2}{n}) \\quad (\\text{s.t.}\\;n&gt;30)\\]                    모집단의 평균을 추정하기 위해 여러 표본을 뽑을 때 표본 비율의 추정치들의 분포\\[P \\sim N(\\pi, \\displaystyle\\frac{\\pi(1-\\pi)}{n}) \\quad (\\text{s.t.}\\;n&gt;30)\\]            Statistics      $\\overline{X}$ 의 기대값 : $E\\left[\\overline{X}\\right]=\\mu$\\[\\begin{aligned}  E\\left[\\overline{X}\\right]  &amp;= E\\left[\\frac{1}{n}(\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n)\\right]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[\\overline{x}_1\\right]+E\\left[\\overline{x}_2\\right]+\\cdots+E\\left[\\overline{x}_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}(\\mu + \\cdots + \\mu)\\\\  &amp;=\\mu  \\end{aligned}\\]        $\\overline{X}$ 의 분산 : $Var\\left[\\overline{X}\\right]=\\displaystyle\\frac{\\sigma^2}{n}$\\[\\begin{aligned}  Var\\left[\\overline{X}\\right]  &amp;= Var\\left[\\frac{1}{n}(\\overline{x}_1+\\overline{x}_2+\\cdots+\\overline{x}_n)\\right]\\\\  &amp;=Var\\left[\\frac{1}{n}\\overline{x}_1\\right]+Var\\left[\\frac{1}{n}\\overline{x}_2\\right]+\\cdots+Var\\left[\\frac{1}{n}\\overline{x}_n\\right]\\\\  &amp;(\\because Cov\\left[\\overline{x}_i, \\overline{x}_j\\right]=0)\\\\  &amp;=\\frac{1}{n^2}Var\\left[\\overline{x}_1\\right]+\\frac{1}{n^2}Var\\left[\\overline{x}_2\\right]+\\cdots+\\frac{1}{n^2}Var\\left[\\overline{x}_n\\right]\\\\  &amp;=\\frac{1}{n^2}\\sigma^2 + \\frac{1}{n^2}\\sigma^2 + \\cdots + \\frac{1}{n^2}\\sigma^2\\\\  &amp;=\\frac{1}{n^2}(\\sigma^2 + \\cdots + \\sigma^2)\\\\  &amp;=\\frac{\\sigma^2}{n}  \\end{aligned}\\]        표준오차(Standard Error; $SE$) : $\\overline{X}$ 의 표준편차          표본 $sample1, sample2, \\cdots$ 에 의해 얻어진 추정량 $\\overline{X}$ 의 실현값 $\\overline{x}_1, \\overline{x}_2, \\cdots$ 은 $\\mu$ 를 기준으로 얼마나 널리 퍼져 있는가    \\[\\begin{aligned}  SE  &amp;=\\sqrt{\\frac{\\sigma^2}{n}}\\\\  &amp;=E\\left[\\vert\\overline{x}_{i}-\\mu\\vert\\right]  \\end{aligned}\\]          $\\overline{X}$ 의 표준편차는 모수 $\\mu$ 와 그 추정치 $\\overline{x}_{i}$ 의 차이의 평균임      $Var(\\overline{X})$ 가 작을수록 모수 $\\mu$ 에 근사하는 추정량 $\\overline{X}$ 가 실현될 가능성이 높음      Central Limit Theorem      중심극한정리(Central Limit Theorem; $CLT$)          평균이 $\\mu$ 이고, 분산이 $\\sigma^2$ 인 모집단에서 크기가 $n$ 인 표본을 추출하는 경우 $n$ 이 증가할수록 표본평균 $\\overline{X}$ 의 분포는 평균이 $\\mu$ 이고, 분산이 $\\sigma^2$ 일 때의 가우시안 분포에 근사함    \\[\\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n}),\\quad \\text{s.t.}\\,n &gt; 30\\]          $n \\le 30$ 인 경우에는 모집단의 분포에 의존함      $n &gt; 30$ 인 경우에는 모집단의 분포와 상관 없이 성립함      ProportionPopulation Proportion      모비율(Population Proportion; $\\pi$) : 모집단 중 특정 성질을 가지는 관측치 비율\\[\\pi \\times 100\\%\\]        모비율에 대한 확률변수 정의 : 베르누이 확률변수\\[X \\sim Bernoulli(\\pi)\\]                  관측치 $X_i$ 가 성질을 만족하면 $1$, 만족하지 않으면 $0$ 이라고 하자\\[X=  \\begin{cases}  1\\quad \\text{with probability}\\;\\pi\\\\  0\\quad \\text{with probability}\\;1-\\pi  \\end{cases}\\]                    확률변수 $X$ 의 기대값\\[\\begin{aligned}  E\\left[X\\right]  &amp;=1\\times\\pi + 0\\times(1-\\pi) \\\\  &amp;=\\pi  \\end{aligned}\\]                    확률변수 $X$ 의 분산\\[\\begin{aligned}  Var\\left[X\\right]  &amp;=(1-\\pi)^2\\times\\pi + (0-\\pi)^2\\times(1-\\pi) \\\\  &amp;=\\pi(1-\\pi)  \\end{aligned}\\]            Sample Proportion      표본비율(Sample Proportion; $P$) : 모비율에 대한 표본평균          크기가 $n$ 인 표본을 추출할 때 모비율 $\\pi$ 에 대한 표본평균 $P$ 는 다음과 같음    \\[\\begin{aligned}  P  &amp;= \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}{p_i}  \\end{aligned}\\]        $P$ 의 기대값 : $E\\left[P\\right]=\\pi$\\[\\begin{aligned}  E\\left[P\\right]  &amp;= E\\left[\\frac{1}{n}(p_1+p_2+\\cdots+p_n)\\right]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[p_1+p_2+\\cdots+p_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}\\bigg[E\\left[p_1\\right]+E\\left[p_2\\right]+\\cdots+E\\left[p_n\\right]\\bigg]\\\\  &amp;=\\frac{1}{n}(\\pi + \\cdots + \\pi)\\\\  &amp;=\\pi  \\end{aligned}\\]        $P$ 의 분산 : $Var\\left[P\\right]=\\displaystyle\\frac{\\pi(1-\\pi)}{n}$\\[\\begin{aligned}  Var\\left[P\\right]  &amp;= Var\\left[\\frac{1}{n}(p_1+p_2+\\cdots+p_n)\\right]\\\\  &amp;= Var\\left[\\frac{1}{n}p_1\\right]+Var\\left[\\frac{1}{n}p_2\\right]+\\cdots+Var\\left[\\frac{1}{n}p_n\\right]\\\\  &amp;= \\frac{1}{n^2}Var\\left[p_1\\right]+\\frac{1}{n^2}Var\\left[p_2\\right]+\\cdots+\\frac{1}{n^2}Var\\left[p_n\\right]\\\\  &amp;= \\frac{1}{n^2}\\Big[\\pi(1-\\pi)+\\cdots+\\pi(1-\\pi)\\Big]\\\\  &amp;= \\frac{\\pi(1-\\pi)}{n}  \\end{aligned}\\]        표본비율에 대한 중심극한정리          표본의 크기 $n$ 이 충분히 크면 표본비율 $P$ 는 다음과 같은 분포를 따르게 됨    \\[P \\sim N(\\pi, \\frac{\\pi(1-\\pi)}{n})\\]  "
  },
  
  {
    "title": "Prob. Dist. Functions",
    "url": "/posts/Prob_Dist_Functions/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "Discrete Prob. Dist.이산 균등 분포(Discrete Uniform Dist.)      정의 : 실현 가능한 각각의 결과가 동일한 확률로 발생하는 분포\\[X \\sim \\text{DiscreteUniform}(a,b)\\]          $1,2,3,4,5,6$ 까지 눈금이 있는 주사위를 굴릴 때, 각 눈금이 나올 확률의 분포      ...",
    "content": "Discrete Prob. Dist.이산 균등 분포(Discrete Uniform Dist.)      정의 : 실현 가능한 각각의 결과가 동일한 확률로 발생하는 분포\\[X \\sim \\text{DiscreteUniform}(a,b)\\]          $1,2,3,4,5,6$ 까지 눈금이 있는 주사위를 굴릴 때, 각 눈금이 나올 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)=\\frac{1}{n}\\]          $X$ : 이산 균등 분포를 따르는 확률변수      $k=a,\\cdots,b$ : 발생 가능한 결과      $n$ : 발생 가능한 결과의 갯수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{a+b}{2}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{(b-a+1)^2-1}{12}\\]  이항 분포(Bi-Nomial Dist.)      정의 : 고정된 횟수($n$)의 독립적인 베르누이 시행에서 성공 횟수를 나타내는 분포\\[X \\sim \\text{Bin}(n,p)\\]          열 번의 동전 던지기 실험에서 앞면이 나오는 횟수가 특정 값일 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)  = \\begin{pmatrix}n\\\\ k\\\\ \\end{pmatrix} p^{k} \\cdot (1-p)^{n-k}\\]          $X$ : 이항 분포를 따르는 확률변수      $k=0,1,2,\\cdots,n$ : 성공 횟수      $p$ : 성공 가능성      $n$ : 베르누이 시행 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=n \\cdot p\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=n \\cdot p \\cdot (1-p)\\]  포아송 분포(Poisson Dist.)      정의 : 단위 시간 혹은 공간 안에서 사건 발생 횟수를 나타내는 분포\\[X \\sim \\text{Poi}(\\lambda)\\]          한 시간 동안 특정 웹사이트에 접속하는 사용자 수가 특정 값일 확률의 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X=k)  = \\frac{\\lambda^{k}}{k!}\\text{exp}(-\\lambda)\\]          $X$ : 포아송 분포를 따르는 확률변수      $k=0,1,2,\\cdots,n$ : 단위 시간 혹은 공간 안에서 사건 발생 횟수      $\\lambda$ : 단위 시간 혹은 공간 안에서 평균 사건 발생 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\lambda\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\lambda\\]  다항 분포(Multi-Nomial Dist.)      정의 : 여러 카테고리의 결과가 있는 일련의 실험에서 각 카테고리 결과의 횟수를 나타내는 분포\\[X \\sim \\text{Multin}(n;p_1, \\cdots, p_k)\\]          설문조사에서 예, 아니오, 무응답 응답자 수가 특정 값일 확률을 나타내는 분포            확률 질량 함수(Prob. Mass Function, PMF)\\[P(X_1=x_1, \\cdots, X_k=x_k)  = {n \\choose x_{1} ~ \\cdots ~ x_{k}} p_{1}^{x_{1}} \\cdots p_{k}^{x_{k}}\\]          $X$ : 다항 분포를 따르는 확률변수      $x_i=0,1,2,\\cdots,n$ : $i$ 번째 카테고리의 성공 횟수      $p_{i}$ : $i$ 번째 카테고리의 성공 가능성      $\\sum_{i}{x_{i}}=n$ : 시행 횟수            기대값(Expected Value)\\[\\mathbb{E}\\big[X_{i}\\big]=n \\cdot p_{i}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{i}\\big]=n \\cdot p_{i} \\cdot (1-p_{i})\\]        공분산(Covariance)\\[\\mathbb{Cov}\\big[X_{i},X_{j}\\big]=-n \\cdot p_{i} \\cdot p_{j}\\]  Continuous Prob. Dist.균등 분포(Uniform Dist.)      정의 : 주어진 구간에서 모든 값이 일정한 확률을 가지는 분포\\[X \\sim \\text{Uniform}(a,b)\\]          $0$ 과 $1$ 사이의 수를 무작위로 선택할 때, 특정 값이 선택될 확률의 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{b-a} \\quad \\text{for}\\;a&lt;x&lt;b\\]        기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{a+b}{2}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{(b-a)^2}{12}\\]  베타 분포(Beta Dist.)      정의 : 두 매개변수 $\\alpha$ 와 $\\beta$ 에 의해 모양이 결정되는, $0$ 과 $1$ 사이의 값에 대한 확률 분포\\[X \\sim \\text{Beta}(\\alpha,\\beta)\\]          어떤 사건의 성공 횟수($\\alpha$)와 실패 횟수($\\beta$)가 주어졌을 때, 해당 사건의 성공 가능성이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\\]          $X$ : 베타 분포를 따르는 확률 변수      $x$ : 주로 성공 가능성      $\\alpha$ : 주로 성공 횟수로서, 클수록 우편향된 형태의 분포가 됨      $\\beta$ : 주로 실패 횟수로서, 클수록 좌편향된 형태의 분포가 됨              $\\Gamma(\\cdot)$ : 감마 함수\\[\\begin{aligned}  \\Gamma(n)  &amp;= \\int_{0}^{\\infty}{t^{n-1}e^{-t}}\\text{d}t\\\\  &amp;= (n-1)! \\quad \\text{s.t.}\\;n \\in \\mathbf{Z}^{+}  \\end{aligned}\\]                  기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{\\alpha}{\\alpha+\\beta}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{\\alpha \\cdot \\beta}{(\\alpha+\\beta)^2 \\cdot (\\alpha+\\beta+1)}\\]  지수 분포(Exponential Dist.)      정의 : 단일 사건의 대기 시간을 나타내는 분포\\[X \\sim \\text{Exp}(\\lambda)\\]          특정 버스 정류장에서 버스가 도착할 때까지 대기 시간이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\lambda \\cdot \\text{exp}(-\\lambda \\cdot x)\\]          $X$ : 지수 분포를 따르는 확률 변수      $x$ : 대기 시간      $\\lambda$ : 단위 시간 당 사건 발생률            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{1}{\\lambda}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{1}{\\lambda^{2}}\\]  감마 분포(Gamma Dist.)      정의 : 여러 지수적 사건의 총 대기 시간을 나타내는 분포\\[X \\sim \\text{Gamma}(k, \\theta)\\]          (여러 부품이 결합된) 특정 기계가 고장 나기 전까지 작동하는 시간이 특정 값일 확률 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{x^{k-1}\\exp\\left(-\\frac{x}{\\theta}\\right)}{\\theta^{k} \\cdot \\Gamma(k)}\\]          $X$ : 감마 분포를 따르는 확률 변수      $x &gt; 0$ : 총 대기 시간      $k$ : 형태 매개변수로서, 지수적 사건 발생 횟수      $\\theta$ : 스케일 매개변수로서, 지수적 사건의 평균 대기 시간      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=k \\cdot \\theta\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=k \\cdot \\theta^{2}\\]  역감마 분포(Inverse-Gamma Dist.)      정의 : 감마 분포의 역수를 따르는 확률 분포\\[\\begin{aligned}  X &amp;\\sim \\text{Gamma}(k, \\theta)\\\\  \\frac{1}{X} &amp;\\sim \\text{Inv-Gamma}(k, \\theta)  \\end{aligned}\\]          정규 분포 $N(\\mu, \\sigma^2)$ 의 분산 $\\sigma^2$ 에 대한 사전확률분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(Y=y) = \\frac{\\theta^{k} \\cdot y^{-k-1} \\cdot \\exp\\left(-\\frac{\\theta}{y}\\right)}{\\Gamma(k)}\\]          $Y=\\displaystyle\\frac{1}{X}$ : 역감마 분포를 따르는 확률 변수      $k$ : 형태 매개변수      $\\theta$ : 스케일 매개변수      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[Y\\big]=\\frac{\\theta}{k-1} \\quad \\text{s.t.}\\; k&gt;1\\]        분산(Variance)\\[\\mathbb{V}\\big[Y\\big]=\\frac{\\theta^2}{(k-1)^2(k-2)} \\quad \\text{s.t.}\\; k&gt;2\\]  정규 분포(Normal Dist.)      정의 : 자연 및 사회 과학에서 발생하는 대부분의 현상을 설명하는 대표적인 분포\\[X \\sim N(\\mu, \\sigma^2)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\exp\\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2}\\right)\\]          $\\mu$ : 평균      $\\sigma$ : 표준편차            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\mu\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\sigma^2\\]  비중심 T-분포(Non-central T-Dist.)      정의 : 평균이 $0$ 이 아닌 정규 분포에 기반한 표본 평균의 분포\\[X \\sim t_{\\nu}(\\delta)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x)  = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\nu \\pi}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1 + \\frac{1}{\\nu}\\left(\\frac{x-\\delta}{\\sigma}\\right)^{2}\\right)^{-\\frac{\\nu+1}{2}}\\]          $\\nu$ : 자유도(Degree of Freedom)      $\\delta$ : 비중심 매개변수(Non-Centrality Parameter)로서, 분포의 중심      $\\sigma$ : 스케일 매개변수로서, 표준편차      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]  =  \\begin{cases}\\begin{aligned}  &amp;\\delta \\cdot \\frac{\\Gamma\\left(\\frac{\\nu-1}{2}\\right)}{\\sqrt{\\frac{\\nu}{2}}\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\quad &amp;\\text{if}\\; \\nu &gt; 1\\\\  &amp;\\text{undefined} \\quad &amp;\\text{if}\\; \\nu \\le 1  \\end{aligned}\\end{cases}\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]  =  \\begin{cases}\\begin{aligned}  &amp;\\frac{\\nu(1+\\delta^2)}{\\nu-2}-\\left(\\delta \\cdot \\frac{\\Gamma\\left(\\frac{\\nu-1}{2}\\right)}{\\sqrt{\\frac{\\nu}{2}}\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\right)^2 \\quad &amp;\\text{if}\\; \\nu &gt; 2\\\\  &amp;\\infty \\quad &amp;\\text{if}\\; \\nu \\le 2  \\end{aligned}\\end{cases}\\]  카이제곱 분포(Chi-Squared Dist.)      정의 : 표준 정규 분포를 따르는 독립적인 확률변수들의 자승의 합이 특정 값일 확률에 대한 분포\\[X \\sim \\chi^{2}(k)\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(X=x) = \\frac{1}{2^{\\frac{k}{2}}\\cdot \\Gamma\\left(\\frac{k}{2}\\right)}x^{\\frac{k}{2}-1}\\exp(-\\frac{x}{2})\\]          $X$ : 카이제곱 분포를 따르는 확률변수              $x &gt; 0$ : $k$ 개의 독립적인 표준 정규 분포 $N(0,1)$ 를 따르는 확률변수 $Z_{i}$ 의 자승의 합\\[x = \\sum_{i=1}^{k}{Z_{i}^{2}} \\quad \\text{for} \\; Z_{i} \\sim N(0,1)\\]            $k$ : 자유도로서 확률변수 $z_{i}$ 의 갯수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=k\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=2k\\]  스케일된 역 카이제곱 분포(Scaled Inverse-Chi-Squared Dist.)      정의 : 카이제곱 분포의 역수를 따르는 확률 분포\\[\\begin{aligned}  X &amp;\\sim \\chi^{2}(k)\\\\  \\frac{\\sigma^2}{X} &amp;\\sim \\text{Scaled-Inv-}\\chi^{2}(k,\\sigma^2)  \\end{aligned}\\]        확률 밀도 함수(Prob. Density Function, PDF)\\[P(Y=y) = \\frac{1}{\\Gamma\\left(\\frac{k}{2}\\right)}\\left(\\frac{k}{2\\sigma^2}\\right)^{\\frac{k}{2}}y^{-\\frac{k}{2}-1}\\exp\\left(-\\frac{k}{2\\sigma^2y}\\right)\\]          $Y=\\displaystyle\\frac{\\sigma^2}{X}$ : 스케일된 역카이제곱 분포를 따르는 확률변수      $y &gt; 0$      $k$ : 자유도      $\\sigma^2$ : 스케일 매개변수      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=\\frac{k \\cdot \\sigma^2}{k-2} \\quad \\text{s.t.}\\; k&gt;2\\]        분산(Variance)\\[\\mathbb{V}\\big[X\\big]=\\frac{2 \\cdot k^2 \\cdot \\sigma^4}{(k-2)^2(k-4)} \\quad \\text{s.t.}\\; k&gt;4\\]  위샤트 분포(Wishart Dist.)      정의 : 양정치 행렬(Positive Definite Matrix)에 대한 확률 분포\\[X \\sim W_{p}(\\mathbf{V},n)\\]          다변량 정규 분포(Multi-variat Normal Distribution) $N(\\mu, \\Sigma)$ 의 공분산 행렬 $\\Sigma$ 에 대한 사전확률분포            확률 밀도 함수(Prob. Density Function, PDF)\\[\\begin{aligned}  P(X=\\mathbf{X})   &amp;= \\frac{1}{2^{\\frac{np}{2}} \\vert \\mathbf{V} \\vert ^{\\frac{n}{2}}\\Gamma_{p}(\\frac{n}{2})} \\vert \\mathbf{X} \\vert ^{\\frac{n-p-1}{2}}\\exp\\left(-\\frac{1}{2}\\text{tr}(\\mathbf{V}^{-1}\\mathbf{X})\\right)\\\\  \\Gamma_{p}\\left(\\displaystyle\\frac{n}{2}\\right)  &amp;=\\pi^{\\frac{p(p-1)}{4}}\\prod_{i=1}^{p}{\\Gamma\\left(\\displaystyle\\frac{n-(i-1)}{2}\\right)}\\\\  \\text{tr}(\\mathbf{V}^{-1}\\mathbf{X})  &amp;=\\sum_{i}{(\\mathbf{V}^{-1}\\mathbf{X})_{ii}}  \\end{aligned}\\]          $X$ : 위샤트 분포를 따른 확률변수      \\(\\mathbf{X}=\\sum_{i=1}^{n}{\\overrightarrow{z}_{i} \\cdot \\overrightarrow{z}_{i}^{T}}\\) : $p \\times p$ 양정치 행렬(Positive Definite Matrix)                  표준 정규 분포 \\(N(0,1)\\) 를 따르는 \\(p\\) 차원 벡터 \\(\\overrightarrow{z}_{1},\\overrightarrow{z}_{2},\\cdots,\\overrightarrow{z}_{n}\\) 생성          외적 \\(\\overrightarrow{z}_{i} \\cdot \\overrightarrow{z}_{i}^{T}\\) 을 통해 \\(p \\times p\\) 양정치 행렬 \\(n\\) 개 생성          $n$ 개의 $p \\times p$ 양정치 행렬을 덧셈하여 $\\mathbf{X}$ 생성                    $n&gt;p-1$ : 자유도로서 $\\overrightarrow{z}_{i} \\sim N(0,1)$ 갯수              $\\mathbf{V}&gt;0$ : 양정치 행렬로서, 벡터 $\\overrightarrow{z}_{i} \\sim N(0,1)$ 간 공분산을 조정함으로써 분포의 형태와 스케일을 결정            $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X\\big]=n \\cdot \\mathbf{V}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{ij}\\big]=n(\\mathbf{V}_{ij}^{2}+\\mathbf{V}_{ii}\\mathbf{V}_{jj})\\]  디리클레 분포(Dirichlet Dist.)      정의 : 베타분포의 다변수 확장으로서, 여러 카테고리의 비율에 대한 확률 분포\\[X \\sim \\text{Dirichlet}(\\alpha_{1}, \\cdots, \\alpha_{k})\\]          각 정당에 대한 투표 비율이 특정 값일 확률에 대한 분포            확률 밀도 함수(Prob. Density Function, PDF)\\[P(X_1=x_1, \\cdots, X_k=x_k) = \\frac{\\Gamma(\\alpha_{1}+\\cdots+\\alpha_{k})}{\\Gamma(\\alpha_{1}) \\cdots \\Gamma(\\alpha_{k})}x_{1}^{\\alpha_{1}-1} \\cdots x_{k}^{\\alpha_{k}-1}\\]          $0 \\le x_{i} \\le 1$ : 전체 카테고리 대비 $i$ 번째 카테고리가 차지하는 비중      $\\alpha_{i}$ : $i$ 번째 카테고리의 강도      $\\Gamma(\\cdot)$ : 감마 함수            기대값(Expected Value)\\[\\mathbb{E}\\big[X_{i}\\big]=\\frac{\\alpha_{i}}{\\sum_{i}{\\alpha_{i}}}\\]        분산(Variance)\\[\\mathbb{V}\\big[X_{i}\\big]=\\frac{\\alpha_{i}(\\sum_{i}{\\alpha_{i}}-\\alpha_{i})}{\\left(\\sum_{i}{\\alpha_{i}}\\right)^{2}(\\sum_{i}{\\alpha_{i}}+1)}\\]        공분산(Covariance)\\[\\mathbb{V}\\big[X_{i},X_{j}\\big]=-\\frac{\\alpha_{i} \\cdot \\alpha_{j}}{\\left(\\sum_{i}{\\alpha_{i}}\\right)^{2}(\\sum_{i}{\\alpha_{i}}+1)}\\]  "
  },
  
  {
    "title": "GRU4REC",
    "url": "/posts/GRU4REC/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Sequential RecSys, Deep Learning, RNN",
    "date": "2024-07-03 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Probability",
    "url": "/posts/Probability/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics",
    "date": "2024-07-02 00:00:00 +0900",
    





    
    "snippet": "ProbabilityRandom Experiment  확률실험(Random Experiment) : 사건의 불확실성을 가진 프로세스          사건의 불확실성 : 결과(Outcome)를 사전에 알 수 없는 성질        표본공간(Sample Space) : 확률실험에서 발생 가능한 모든 결과의 집합                  동전 던지기\\...",
    "content": "ProbabilityRandom Experiment  확률실험(Random Experiment) : 사건의 불확실성을 가진 프로세스          사건의 불확실성 : 결과(Outcome)를 사전에 알 수 없는 성질        표본공간(Sample Space) : 확률실험에서 발생 가능한 모든 결과의 집합                  동전 던지기\\[S = \\{H, T\\}\\]                    주사위 던지기\\[S = \\{1, 2, 3, 4, 5, 6\\}\\]                    전구의 수명\\[S = \\{x \\in R \\,|\\, x \\ge 0\\}\\]                    올해 순 이익\\[S = R\\]              사건(Event) : 표본공간의 부분집합으로서 발생 가능한 결과의 일부          단순 사건(Simple Event) : 어떤 결과 하나만으로 이루어진 사건                              동전을 한 번 던졌을 때 앞면이 나오는 사건\\[E=\\{H\\}\\]                                주사위를 한 번 던졌을 때 3이 나오는 사건\\[E=\\{3\\}\\]                              복합 사건(Compound Event) : 두 개 이상의 결과로 이루어진 사건                              동전을 두 번 던졌을 때 서로 다른 면이 나오는 사건\\[E=\\{HT, TH\\}\\]                                주사위를 한 번 던졌을 때 짝수가 나오는 사건\\[E=\\{2,4,6\\}\\]                              Probability      확률(Probability) : 주어진 표본공간 $S$ 에 대하여 그 사건 $A$ 가 발생할 상대적 가능성\\[P(A),\\quad \\text{s.t.}\\;0 \\le P(A) \\le 1\\]    확률 부여 방법          고전적 접근법 : 확률실험의 대칭성(Symmetric Nature)을 이용하여 각 결과가 발생할 가능성을 논리적으로 추론하는 방법                  어떤 확률실험이 발생 가능성이 동일한(Equally Likely) $n$ 개의 결과를 가질 때, 단순 사건이 발생할 확률은 $\\displaystyle\\frac{1}{n}$ 임          $n$ 개의 결과 중 $n_A$ 개 결과를 취하는 복합 사건이 발생할 확률은 $\\displaystyle\\frac{n_A}{n}$ 임                    상대 빈도 접근법 : 반복되는 경험에 따라 확률을 부여하는 방법으로서 경험적 접근법                  어떤 확률실험을 $n$ 번 반복했을 때, 어떤 결과가 $k \\le n$ 번 발생했다면 그 결과가 발생할 확률은 $\\displaystyle\\frac{k}{n}$ 임          실험 횟수가 증가할수록 정확도가 높아짐          실험 횟수가 매우 크고, 모든 실험이 동일한 환경에서 이루어졌을 때 정당성을 가짐                    주관적 접근법 : 고전적 접근법, 상대 빈도 접근법에 의해 확률을 부여하는 것이 불가능한 경우 개인적인 판단에 의해 확률을 부여하는 방법            확률의 공리(Axioms of Probability)          주어진 표본공간 $S$ 에 대하여 그 사건 $A_i\\,(i=1,2,\\cdots n)$ 는 다음을 만족해야 함              $P(S)=1$      $0 \\le P(A_i) \\le 1$      $A_1, A_2, \\cdots, A_n$ 이 상호배타적이라면 $P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+P(A_3)+\\cdots +P(A_n)$                              상호배타성(Mutually Exclusive or Disjoint)\\[A_i \\cap A_j = \\phi\\]                                    확률 법칙          주어진 표본공간 $S$ 에 대하여 그 사건 $A_i\\,(i=1,2,\\cdots n)$ 는 다음을 만족함              $P(\\phi)=0$      \\(P(A_i')=1-P(A_i)\\), \\(A_i'=\\{x \\in S \\vert x \\notin A_i \\}\\)      $A_i\\subseteq A_j \\Rightarrow P(A_i) \\le P(A_j)$      $P(A_i \\cup A_j)=P(A_i) + P(A_j) - P(A_i \\cap A_j)$      $A_1, A_2, \\cdots, A_n$ 이 집단전체적이라면 $P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n)=1$                              집단전체성(Collectively Exhaustive)\\[A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n = S\\]                              Joint Probability      결합 확률(Joint Probability) : 확률변수 $A, B$ 에 대하여 그 값 $A_i \\in A$ 와 $B_j \\in B$ 가 동시에 발생할 확률\\[P(A_i \\cap B_j)\\]        결합확률표          표본공간 $S$ 에 대하여 확률변수 $A={A_1, A_2, A_3, \\cdots, A_i, \\cdots, A_n}$ 를 상호배타적이고 집단전체적인 사건들의 집합이라고 하자. 또한 확률변수 $B={B_1, B_2, B_3, \\cdots, B_j, \\cdots, B_m}$ 를 또 다른 상호배타적이고 집단전체적인 사건들의 집합이라고 하자. 이때 사건 $A_i, B_j$ 가 동시에 발생할 결합 확률 $P(A_i \\cap B_j)$ 는 다음의 표와 같다.                                           $B_1$          $B_2$          $\\cdots$          $B_m$          $\\sum_{j=1}^{m}P(A_i \\cap B_j)$                                      $A_1$          $P(A_1 \\cap B_1)$          $P(A_1 \\cap B_2)$          $\\cdots$          $P(A_1 \\cap B_m)$          $P(A_1)$                          $A_2$          $P(A_2 \\cap B_1)$          $P(A_2 \\cap B_2)$          $\\cdots$          $P(A_2 \\cap B_m)$          $P(A_2)$                          $\\vdots$          $\\vdots$          $\\vdots$          $\\ddots$          $\\vdots$          $\\vdots$                          $A_n$          $P(A_n \\cap B_1)$          $P(A_n \\cap B_2)$          $\\cdots$          $P(A_n \\cap B_m)$          $P(A_n)$                          $\\sum_{i=1}^{n}P(A_i \\cap B_j)$          $P(B_1)$          $P(B_2)$          $\\cdots$          $P(B_m)$          $1$                    Statistical Independence      조건부 확률(Conditional Probability) : 사건 $A_1$ 이 발생했을 때 사건 $A_2$ 가 발생할 확률\\[P(A_2 \\vert A_1) = \\frac{P(A_2 \\cap A_1)}{P(A_1)} \\quad (\\text{s.t.}\\, P(A_1)&gt;0)\\]        베이즈 정리(Bayes Theorem)\\[\\begin{aligned}  P(B \\vert A)  &amp;= \\frac{P(B)P(A \\vert B)}{P(A)}\\\\  &amp;= \\frac{P(B) \\times \\frac{P(A \\cap B)}{P(B)}}{P(A)}\\\\  &amp;= \\frac{P(B \\cap A)}{P(A)}  \\end{aligned}\\]                  일반화                  사건 $B_1, B_2, B_3, \\cdots, B_m$ 이 상호배타적이고 집단전체적이라면, 사건 $A$ 와 $B_j\\,(j=1,2,3,\\cdots,m)$ 에 대하여 다음이 성립함        \\[\\begin{aligned}  P(B_j \\vert A)  &amp;= \\frac{P(A \\vert B_j) \\times P(B_j)}{\\displaystyle\\sum_{i=1}^{m}P(A \\vert B_i)P(B_i)}  \\end{aligned}\\]                  통계적 독립성(Statistical Independence) : 한 사건의 발생 여부가 다른 사건이 발생할 가능성에 아무런 영향을 끼치지 못하는 경우\\[P(A_2 \\vert A_1) = P(A_2) \\quad \\text{or} \\quad P(A_1 \\vert A_2) = P(A_1)\\]                  사건 $A_1$ 과 $A_2$ 가 통계적으로 독립적이면 다음을 만족함\\[P(A_1 \\cap A_2) = P(A_1)P(A_2)\\]                    사건 $A_1$ 과 $A_2$ 가 상호배타적이라고 해서 통계적으로 독립이라고 볼 수는 없음                              사건 $A_1$ 과 $A_2$ 가 상호배타적인 경우\\[P(A_1 \\cap A_2) = 0 \\quad (\\text{s.t.} \\, P(A_1)&gt;0, P(A_2)&gt;0)\\]                                사건 $A_1$ 과 $A_2$ 가 통계적으로 독립인 경우\\[\\begin{aligned}  P(A_2 \\vert A_1)  &amp;=\\frac{P(A_2 \\cap A_1)}{P(A_1)} \\\\  &amp;=P(A_2) \\quad (\\text{s.t.} \\, P(A_1)&gt;0, P(A_2)&gt;0)  \\end{aligned}\\]                              Random VariablesWhat? Random Variable      확률변수(Random Variable) : 표본공간 $S$ 에 대하여 그 결과에 숫자를 배정하는 규칙으로서, 그 값이 확률실험 결과에 의해 결정되는 변수        확률 분포(Probability Distribution) : 확률변수의 값 $x \\in X$ 에 대하여 각각에 대응하는 확률 값 $P(x)$ 의 분포        확률분포함수 : 확률변수를 정의역으로, 그 분포를 치역으로 가지는 함수\\[\\begin{aligned}  f(x)=P(X=x)  \\end{aligned}\\]        누적분포함수(Cumulative Distribution Function) : 확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k)  \\end{aligned}\\]  ExampleProbability Experiment of Tossing a Coin Twice      표본공간 $S$ 정의\\[S=\\{HH,HT,TH,TT\\}\\]        결과 $outcome \\in S$ 의 확률 정의                            $outcome \\in S$          $P(outcome)$                                      $HH$          $0.25$                          $HT$          $0.25$                          $TH$          $0.25$                          $TT$          $0.25$                    규칙1 같은 면이면 1, 다른 면이면 0      확률변수 $X$ 정의 : $X = {0, 1}$                            $outcome \\in S$          $x \\in X$                                      $HH$          $1$                          $HT$          $0$                          $TH$          $0$                          $TT$          $1$                          확률변수 $x \\in X$ 의 확률분포                            $x \\in X_1$          $P(x)$                                      $1$          $0.5$                          $0$          $0.5$                    규칙2 앞면의 갯수      확률변수 $X$ 정의 : $X = {0, 1, 2}$                            $outcome \\in S$          $x \\in X$                                      $HH$          $2$                          $HT$          $1$                          $TH$          $1$                          $TT$          $0$                          확률변수 $x \\in X$ 의 확률분포                            $x \\in X$          $P(x)$                                      $2$          $0.25$                          $1$          $0.5$                          $0$          $0.25$                    Discrete Random VariableWhat? Discrete Random Variable      이산확률변수(Discrete Random Variable) : 변수가 취할 수 있는 값의 수를 셀 수 있는 확률변수\\[X=\\{x_i\\,|\\,i=1,2,3,\\cdots,n\\}\\]          동전 앞면의 수      주사위 눈의 수      자녀의 수      한 시간 동안 방문한 고객의 수            이산확률분포(Discrete Probability Distribution) : 이산확률변수 $X$ 가 취할 수 있는 값 $x \\in X$ 에 대하여 그 값이 발생할 확률 $P(x)$ 의 분포\\[P(X)\\]        확률질량함수(Probability Mass Function; $pmf$) : 이산확률변수를 정의역으로, 그 확률분포를 치역으로 가지는 함수\\[\\begin{aligned}  f:\\,X\\rightarrow P(X)  \\end{aligned}\\]          이산확률변수 $X={x_1, x_2, x_3, \\cdots, x_n}$ 에 대하여 그 확률질량함수는 다음의 조건을 만족해야 함                  $0 \\le P(x) \\le 1, \\; x^{\\forall} \\in X$          $\\displaystyle\\sum_{i=1}^{n}P(x_i)=1$                          누적분포함수(Cumulative Distribution Function; $cdf$) : 이산확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k) \\\\  &amp;=\\sum_{x=1}^{k}f(x)  \\end{aligned}\\]  Descriptive Statistic      기대값(Expected Value; $E$) : 각 값이 발생할 확률에 따라 가중평균된 값          이산확률변수 $X$ 가 값 $x_i (i=1,2,3,\\cdots,n)$ 을 가질 확률이 $P(x_i)$ 일 때, $X$ 의 기대값 $E\\left[X\\right]$ 를 다음과 같이 정의함    \\[\\begin{aligned}  E\\left[X\\right]  &amp;= \\mu \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n}x_iP(x_i)  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $E\\left[\\alpha \\right]=\\alpha$          $E\\left[\\alpha X \\right]=\\alpha E\\left[X \\right]$          $E\\left[\\alpha X \\pm \\beta Y \\right] = \\alpha E\\left[X \\right] \\pm \\beta E\\left[Y \\right]$          $X, Y$ 가 독립이면 $E \\left[XY \\right]=E \\left[X \\right]E \\left[Y \\right]$                          분산(Variance; $Var$)          이산확률변수 $X$ 가 값 $x_i (i=1,2,3,\\cdots,n)$ 을 가질 확률이 $P(x_i)$ 일 때, $X$ 의 분산 $Var(X)$ 를 다음과 같이 정의함    \\[\\begin{aligned}  Var \\left[X \\right]  &amp;=\\sigma^2\\\\  &amp;=\\displaystyle\\sum_{i=1}^{n}(x_i-\\mu)^2P(x_i)\\\\  &amp;=E \\left[(X-\\mu)^2 \\right]\\\\  &amp;=E \\left[X^2 \\right]-E \\left[X \\right]^2  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $Var\\left[\\alpha \\right]=0$          $Var\\left[\\alpha X \\right]=\\alpha^2Var\\left[X \\right]$          $Var\\left[\\alpha + X \\right]=Var\\left[X \\right]$          $Var\\left[\\alpha X \\pm \\beta Y \\right] = \\alpha^2Var\\left[X \\right] + \\beta^2Var\\left[Y \\right] \\pm 2\\alpha\\beta Cov\\left[X, Y \\right]$                    Statistical Independence      이산확률변수의 결합확률분포(Joint Probability Distribution)          이산확률변수 $x \\in X, y \\in Y$ 에 대하여 그 결합확률분포 $P(x, y)$ 는 $X=x, Y=y$ 일 확률을 추정한 분포로 정의함    \\[P(X=x_i, Y=y_j)=P(x_i \\cap y_j)\\]\\[\\begin{aligned}  for\\; X&amp;=\\{x_i\\,|\\,i=1,2,\\cdots,n\\},\\\\  Y&amp;=\\{y_j\\,|\\,j=1,2,\\cdots,m\\}  \\end{aligned}\\]          공리                  $0 \\le P(x_i,y_j) \\le 1$          $\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)=1$                    규칙                  $P_X(x_i)=\\displaystyle\\sum_{j=1}^{m}P(x_i,y_j)$          $P_Y(y_j)=\\displaystyle\\sum_{i=1}^{n}P(x_i,y_j)$                          이산확률변수의 공분산\\[\\begin{aligned}  Cov\\left[X,Y\\right]  &amp;=\\sigma_{XY}\\\\  &amp;=E\\left[(X-\\mu_{X})(Y-\\mu_{Y})\\right]\\\\  &amp;=E\\left[XY\\right]-\\mu_{X}\\mu_{Y}\\\\  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)-\\mu_{X}\\mu_{Y}  \\end{aligned}\\]                  성질                  이산확률변수 $X, Y, Z$ 와 상수 $\\alpha, \\beta$ 에 대하여 다음이 성립함                          $Cov\\left[X, \\alpha \\right]=0$          $Cov\\left[X+\\alpha, Y+\\beta \\right]=Cov\\left[X,Y \\right]$          $Cov\\left[\\alpha X, \\beta Y \\right]=\\alpha\\beta Cov\\left[X,Y \\right]$          $Cov\\left[X+Y,Z \\right]=Cov\\left[X,Z \\right]+Cov\\left[Y,Z \\right]$                          이산확률변수 간 통계적 독립                  모든 $(x_i, y_j)$ 에 대하여 다음을 만족하는 경우 이산확률변수 $X, Y$ 는 통계적으로 독립임\\[P(x_i \\vert y_j)=P_X(x_i) \\quad \\text{or} \\quad P(y_j \\vert x_i)=P_Y(y_j)\\]            이산확률변수 $X, Y$ 가 통계적으로 독립이면 다음이 성립함                  $ P(x_{i}, y_{j})=P_X(x_{i})P_Y(y_{j}) $          $ Cov\\left[X,Y \\right]=0 $                            위 명제에 근거하여 다음이 성립함\\[\\begin{aligned}  Cov\\left[X,Y \\right]  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} P(x_i,y_j)-\\mu_{X}\\mu_{Y}\\\\  &amp;=0\\\\  \\therefore \\mu_{X}\\mu_{Y}  &amp;=\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{m} x_iy_jP_X(x_i)P_Y(y_j)  \\end{aligned}\\]            Continuous Random VariableWhat? Continuous Random Variable      연속확률변수(Continuous Random Variable) : 변수가 취할 수 있는 값이 연속적이어서 그 수를 셀 수 없는 확률변수\\[X=(l,u) \\quad \\text{or} \\quad X=[l,u]\\]          길이      무게      시간      기온            연속확률분포(Continuous Probability Distribution) : 연속확률변수 $X$ 가 취할 수 있는 값 $x \\in X$ 에 대하여 그 값이 발생할 확률 $P(x)$ 의 분포\\[P(X)\\]        확률밀도함수(Probability Density Function; $pdf$) : 연속확률변수를 정의역으로, 그 확률분포를 치역으로 가지는 함수\\[\\begin{aligned}  f:\\,X\\rightarrow P(X)  \\end{aligned}\\]          구간 $X=(l, u)$ 혹은 $X=[l,u]$ 에서 정의된 연속확률변수 $x \\in X$ 에 대하여 그 확률밀도함수는 다음의 조건을 만족해야 함                  $\\displaystyle\\int_{l}^{u}f(x)dx=1$                          $f(x \\in [a, b])=P(a \\le x \\le b)=\\displaystyle\\int_{a}^{b}f(x)dx$              $f(k)=P(k \\le x \\le k)=\\displaystyle\\int_{k}^{k}f(x)dx=0$                                $f(x) \\ge 0 \\quad \\text{for} \\; x^{\\forall} \\in X$                          누적분포함수(Cumulative Distribution Function; $cdf$) : 연속확률변수 $X$ 에 대하여 그 값이 특정한 값 $k$ 이하일 확률에 대한 함수\\[\\begin{aligned}  F(k)  &amp;=P(X \\le k) \\\\  &amp;=\\displaystyle\\int_{x=1}^{k}f(x)dx  \\end{aligned}\\]  Continuous Statistic      기대값(Expected Value; $E$)\\[\\begin{aligned}  E \\left[X \\right]  &amp;=\\mu\\\\  &amp;=\\displaystyle\\int_{x=l}^{u}xf(x)dx  \\end{aligned}\\]        분산(Variance; $Var$)\\[\\begin{aligned}  Var \\left[X \\right]  &amp;=\\sigma^2\\\\  &amp;=E \\left[(X-\\mu)^2 \\right]\\\\  &amp;=\\displaystyle\\int_{x=l}^{u}(x-\\mu)^2f(x)dx  \\end{aligned}\\]  "
  },
  
  {
    "title": "What? Statistics",
    "url": "/posts/Statistics/",
    "categories": "Statistical Techs, Statistics",
    "tags": "Statistics",
    "date": "2024-07-01 00:00:00 +0900",
    





    
    "snippet": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : ...",
    "content": "What? Statistics      통계학(Statistics)          의사결정에 필요한 정보를 얻기 위하여 데이터를 수집(Collect), 정리(Summarize), 분석(Analyze), 해석(Interpret)하는 방법을 연구하는 학문            종류          기술통계학(Descriptive Statistics) : 데이터를 수집, 정리, 제시, 요약하는 방법을 연구함      추론통계학(Inferential Statistics) : 표본으로부터 모집단의 성격을 추정하는 방법을 연구함      What? Descriptive StatisticData Set  구성          관측치(Observation) : 분석하려는 집합에 속한 하나의 개체      변수(Variable) : 개체의 특징        Data Type          정량적 자료(Quantitative Data) : 수로 표현되는 자료로서 숫자 자체가 의미를 가지는 자료                  이산형 자료(Discrete Data) : 셀 수 있는 정수 형태의 자료          연속형 자료(Continuous Data) : 셀 수 없는 실수 형태의 자료                    정성적 자료(Qualitative Data) : 범주(Category)에 따라 나뉘는 자료      Descriptive Statistic      기술통계량(Descriptive Statistic) : 숫자로 측정한 데이터 세트의 특징    명목 척도(Nominal Scale)                  고유한 값(Unique Value)만을 구분하는 척도                  전공 : 경영학, 경제학, 통계학                      순서 척도(Ordinal Scale)                  값들 사이에 분명한 순위가 있는 척도                  직급 : 사원, 대리, 팀장, 과장, 차장, 부장                            값의 간격은 의미를 갖지 않음              구간 척도(Interval Scale)                  값의 간격이 산술적 의미를 갖는 척도                  기온 $0^{\\circ}C$ 와 $10^{\\circ}C$ 의 간격은 기온 $20^{\\circ}C$ 와 $30^{\\circ}C$ 의 간격과 동일함                            값 사이의 비율은 산술적 의미를 갖지 않음                  기온 $30^{\\circ}C$ 가 $20^{\\circ}C$ 보다 $50%$ 더 따뜻하다고 볼 수 없음                      비율 척도(Ratio Scale)                  값 사이의 비율이 산술적 의미를 갖는 척도                  순익 $2,000,000$ 원은 순익 $1,000,000$ 원 보다 순익 두 배라고 볼 수 있음                            $0$ 이 절대영점으로서 의미를 가짐                  매출 $0$ 원은 매출이 하나도 없음을 의미함                    Summary Quantitative Data      중심 위치 측도 : 대표값으로서 값의 대부분이 어디쯤 위치하는지 측정하는 지표        변이 측도 : 관측치들이 얼마나 퍼져 있는가를 나타내는 측도  중심 위치 측도      평균(Mean; $\\mu$) : 관측치들의 합을 그 갯수로 나눈 값\\[\\mu = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}\\]        중위수(Median; $Q_2$) : 모든 관측치를 크기에 따라 오름차순 정렬했을 때 중앙에 오는 값                  평균 vs. 중위수 : 관측치에 이상치가 포함되어 있거나, 분포가 지나치게 비대칭일 경우, 중위수가 대표값으로서 선호됨                          사분위수(Quartile; $Q_i$) : 모든 관측치를 크기에 따라 오름차순으로 정렬했을 때, 하위 25%($Q_1$), 하위 50%($Q_2$), 하위 75%($Q_3$)에 해당하는 값      변이 측도      범위(Range) : 최대값과 최소값의 차이\\[\\text{R}=X_{max}-X_{min}\\]        사분위범위(Interquartile Range) : 관측치를 크기를 기준으로 오름차순 정렬했을 때 제3사분위수와 제1사분위수의 차이\\[\\text{IQR}=Q_{3}-Q_{1}\\]        평균절대편차(Mean Absolute Deviation; MAD) : 관측치와 평균 사이 거리의 평균\\[\\text{MAD} = \\frac{1}{N}\\sum_{i=1}^{N} \\vert X_{i}-\\mu \\vert\\]        분산(Variance; $\\sigma^2$) : 관측치와 평균 간 편차 자승의 평균\\[\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2\\]        표준편차(Standard Deviation; $\\sigma$) : 분산의 자승근\\[\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu)^2}\\]          자료에서 사용된 단위와 동일한 단위로 측정되므로 해석에 용이함      변이 측도를 활용한 이상치 판별      경험 법칙(Empirical Rule) : 관측치 분포가 종 모양의 대칭 형태를 띠는 경우, 실증적으로 획득된 분포에 대한 일반적인 원칙이 성립함              $(\\mu - 1\\sigma, \\mu + 1\\sigma)$ 에는 관측치의 약 68%가 존재함      $(\\mu - 2\\sigma, \\mu + 2\\sigma)$ 에는 관측치의 약 95%가 존재함      $(\\mu - 3\\sigma, \\mu + 3\\sigma)$ 에는 관측치의 약 99%가 존재함            사분위수 범위를 활용한 이상치 판별              이상치 판단 기준으로서 상한선 및 하한선 설정                  상한선 : $Q_{3}+1.5\\cdot\\text{IQR}$          하한선 : $Q_{1}-1.5\\cdot\\text{IQR}$                            내부 범위 설정\\[\\text{Outlier} \\notin [Q_{1}-1.5\\cdot\\text{IQR}, Q_{3}+1.5\\cdot\\text{IQR}]\\]            변수 간 관계      공분산(Covariance) : 두 변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]          $\\sigma_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\sigma_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\sigma_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음            피어슨 상관계수(Pearson Correlation Coefficient; PCC) : 공분산의 단위 의존적(Unit-Dependent)인 문제를 완화한 지표로서, 공분산을 두 변수의 편차의 곱으로 나눈 값\\[\\rho_{XY} = \\frac{\\sigma_{XY}}{\\sigma_{X}\\sigma_{Y}}\\]          $-1\\le\\rho_{XY}\\le1$      $\\rho_{XY} &gt; 0$ : 변수 $X, Y$ 가 양의 상관관계를 가짐      $\\rho_{XY} &lt; 0$ : 변수 $X, Y$ 가 음의 상관관계를 가짐      $\\rho_{XY} = 0$ : 변수 $X, Y$ 간에 상관관계가 유의미하다고 볼 수 없음      Summary with Graphs수치형 변수      Box Plot : 사분위수를 기준으로 데이터의 대략적인 분포를 나타낸 그래프            Histogram : 데이터 범위를 동일 간격 구간으로 나누어 해당 구간에 위치한 데이터 갯수를 나타낸 그래프                      Density Estimate : 커널밀도추정법을 통해 히스토그램을 연속된 곡선으로 나타낸 그래프                          Q-Q Normality Plot : 데이터 분포 형태가 정규 분포에 얼마나 근접한지 나타내는 그래프      수치형 변수 간 관계      히트 맵(Heatmap) : 두 변수 간 상관관계가 강할수록 채도를 짙게 나타낸 그래프            산점도(Scatter Plot)      범주형 변수      도수분포표(Frequency Table) : 각 범주에 해당하는 관측치 갯수를 요약한 표            Bar Plot : 도수분포표의 값을 막대 높이로 나타낸 그래프            Pie Chart : 도수분포표의 빈도 비율을 부채꼴 모양으로 나타낸 그래프      범주형 변수 간 관계      분할표(Cross Table) : 두 범주형 변수에 의해 생성되는 범주별 빈도수를 요약한 표            Mosaic Plot : 분할표에서 각 범주의 비율을 상자의 너비와 높이로 나타낸 그래프      이미지 출처  https://thirdspacelearning.com/gcse-maths/statistics/frequency-table/  https://www.jaspersoft.com/articles/what-is-a-bar-chart  https://proclusacademy.com/blog/customize_matplotlib_piechart/  https://www.questionpro.com/cross-tabulation.html"
  },
  
  {
    "title": "Mult-VAE",
    "url": "/posts/Mult-VAE/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Deep Learning, Autoencoder, Bayesian",
    "date": "2024-06-05 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "CDAE",
    "url": "/posts/CDAE/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Deep Learning, Autoencoder",
    "date": "2024-05-22 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "DeepFM",
    "url": "/posts/DeepFM/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Deep Learning",
    "date": "2024-05-01 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Wide & Deep Learning",
    "url": "/posts/Wide_Deep_Learning/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Deep Learning",
    "date": "2024-04-03 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "FM",
    "url": "/posts/FM/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model",
    "date": "2024-03-20 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "NCF",
    "url": "/posts/NCF/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Deep Learning",
    "date": "2024-03-06 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "FISM",
    "url": "/posts/FISM/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, User Free Model",
    "date": "2024-02-29 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "SLIM",
    "url": "/posts/SLIM/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, User Free Model",
    "date": "2024-02-22 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "FPMC",
    "url": "/posts/FPMC/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Sequential RecSys, Latent Factor Model",
    "date": "2024-02-15 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "TimeSVD++",
    "url": "/posts/TimeSVD++/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Temporal RecSys, Latent Factor Model",
    "date": "2024-02-08 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "SubGroup",
    "url": "/posts/Subgroup/",
    "categories": "AI & Data Mining, Social Media Analytics",
    "tags": "Data Mining, Social Media, Social Network, Graph",
    "date": "2024-02-02 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Structural Hole and Broker",
    "url": "/posts/Structural_Hole_Broker/",
    "categories": "AI & Data Mining, Social Media Analytics",
    "tags": "Data Mining, Social Media, Social Network, Graph",
    "date": "2024-02-01 00:00:00 +0900",
    





    
    "snippet": "구조적 공백네트워크가 액터에게 주는 효익  정보효익(Information Benefit)          정보 획득 기회      정보 획득의 신속성      보유 정보의 다양성        통제효익(Control Benefit)          교섭력      통제력      구조적 공백(Structure Hole)      정의 : 네트워크에서 액...",
    "content": "구조적 공백네트워크가 액터에게 주는 효익  정보효익(Information Benefit)          정보 획득 기회      정보 획득의 신속성      보유 정보의 다양성        통제효익(Control Benefit)          교섭력      통제력      구조적 공백(Structure Hole)      정의 : 네트워크에서 액터 간 연결관계가 성립되지 않은 지점    목적 : 정보효익과 통제효익을 에고 네트워크의 구조 관점에서 이해하기 위함          구조적 공백과 정보효익 : 양의 상관관계                  에고 네트워크에서 알터 간 연결관계가 성립되어 있을 경우          에고가 획득하는 정보 출처의 다양성이 감소함          에고가 획득하는 정보에 중복이 발생함                    구조적 공백과 통제효익 : 양의 상관관계                  에고 네트워크에서 알터 간 연결관계가 성립되어 있을 경우          알터들은 에고를 매개하지 않고서도 상호간에 정보를 교환할 수 있음          즉, 에고가 다른 알터와의 연결관계를 기반으로 알터를 교섭 및 통제하기 어려움                      에고 네트워크에서 구조적 공백의 대리변수          에고의 매개 중심성 : 구조적 공백과 양의 상관관계      밀도(알터 간 연결 정도) : 구조적 공백과 음의 상관관계      중개자(Broker)      정의 : 에고 네트워크에서 연결관계가 성립되지 아니한 두 알터에 대한 에고의 위치적 우위를 유형화하기 위해 고안된 개념    동일 그룹에 속한 알터들을 중개하는 경우          조정자 : 에고가 알터들과 동일 그룹에 속해 있는 경우      컨설턴트 : 에고가 알터들과 다른 그룹에 속해 있는 경우        다른 그룹에 속한 알터들을 중개하는 경우          연락자 : 에고가 제3의 그룹에 속해 있는 경우      대표자 : 에고가 하나의 알터와 동일 그룹에 속해 있고, 해당 알터를 대리하는 경우      문지기 : 에고가 하나의 알터와 동일 그룹에 속해 있고, 알터 간에 접촉하기 위해서는 에고의 허락이 필요한 경우      효율성과 제약성유효규모와 효율성      목적 : 에고 네트워크에서 구조적 공백에 따른 에고의 위치적 우위 정도를 파악하기 위함        유효규모 : 에고 $N_i$ 가 알터들과 중복되지 아니하고 연결된 갯수\\[\\begin{aligned}  ES(N_i)  &amp;=\\displaystyle\\sum_{j=1}^{g}{(1-R_{i,j})}\\\\  &amp;=g-R(N_i)  \\end{aligned}\\]          $R(N_{i})$ : 에고 $N_i$ 의 중복성      $R_{i,j}$ : 에고 $N_i$ 와 알터 $N_j$ 의 중복 정도      $g$ : 에고 네트워크의 크기            효율성 : 유효규모를 실제규모로 표준화한 값\\[EF(N_i)  =\\frac{ES(N_i)}{g}\\]  중복성      정의 : 에고 네트워크에서 알터 간 연결관계 성립 여부 및 그 강도        계산\\[\\begin{aligned}  R(N_{i})  &amp;=\\displaystyle\\sum_{j=1}^{g}{R_{i,j}}\\\\  &amp;=\\displaystyle\\sum_{j=1}^{g}{\\displaystyle\\sum_{q=1}^{g-1}{p_{i,q}m_{j,q}}}  \\end{aligned}\\]          $R(N_{i})$ : 에고 $N_i$ 의 중복성      $R_{i,j}$ : 에고 $N_i$ 와 알터 $N_j$ 의 중복 정도      $p_{i,q}$ : 에고 $N_i$ 의 연결 정도 대비 알터 $N_{j}$ 와 직접 접촉하기 위해 투자된 연결 정도      $m_{j,q}$ : 알터 $N_j$ 의 알터 $N_q$ 에 대한 한계 강도                  $N_j$ 의 연결관계 중 최대 강도 대비 $N_q$ 와의 연결 강도          이진 네트워크의 경우 $0$ 또는 $1$ 임                    $g$ : 에고 네트워크의 크기      제약성      목적 : 에고 네트워크에서 에고가 알터의 영향에 얼마나 취약한지를 파악하기 위함        정의 : 에고 네트워크에서 알터들의 연결관계 성립 및 그 강도가 에고의 위치적 우위를 제약하는 정도        계산\\[\\begin{aligned}  C(N_i)  &amp;=\\displaystyle\\sum_{j=1}^{g}{C_{i,j}}\\\\  &amp;=\\displaystyle\\sum_{j=1}^{g}{(p_{i,j} + \\displaystyle\\sum_{q=1}^{g-1}{p_{i,q}p_{q,j}})}  \\end{aligned}\\]          $C(N_{i})$ : 에고 $N_i$ 의 제약성      $C_{i,j}$ : 에고 $N_i$ 에 대한 알터 $N_j$ 의 제약 정도      $p_{i,j}$ : 에고 $N_i$ 의 연결 정도 대비 알터 $N_{j}$ 와 직접 접촉하기 위해 투자된 연결 정도      $p_{i,q}\\times p_{q,j}$ : 에고 $N_i$ 가 알터 $N_q$ 를 매개로 알터 $N_j$ 에 간접 접촉하기 위해 투자된 연결 정도      $g$ : 에고 네트워크의 크기      "
  },
  
  {
    "title": "BPR",
    "url": "/posts/BPR/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model, Pairewise Learning, Ranking Prediction",
    "date": "2024-02-01 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Centrality and Power",
    "url": "/posts/Centrality_Power/",
    "categories": "AI & Data Mining, Social Media Analytics",
    "tags": "Data Mining, Social Media, Social Network, Graph",
    "date": "2024-01-31 00:00:00 +0900",
    





    
    "snippet": "What? Centrality      정의 : 네트워크에서 액터의 중요도를 해당 액터가 차지하는 구조적 위치를 통해 측정한 개념        종류          연결 정도 중심성(Degree) : 액터의 활동성      근접 중심성(Closeness) : 액터의 다른 액터에 대한 경로 길이      매개 중심성(Betweenness) : 액터가 다...",
    "content": "What? Centrality      정의 : 네트워크에서 액터의 중요도를 해당 액터가 차지하는 구조적 위치를 통해 측정한 개념        종류          연결 정도 중심성(Degree) : 액터의 활동성      근접 중심성(Closeness) : 액터의 다른 액터에 대한 경로 길이      매개 중심성(Betweenness) : 액터가 다른 두 액터 간 최단경로 상에 위치하는 횟수      고유벡터 중심성(Eigenvector) : 연결된 알터들의 연결 정도      베타 중심성(Beta) : 네트워크의 구조      연결 정도 중심성액터의 연결 정도 중심성(Actor Degree Centrality)      정의 : 연결 정도로써 측정한 액터의 중심성    해석          액터가 얼마나 많은 관계에 관여하고 있는가                  친구의 수          보유한 정서 자원의 양          각종 사교 모임 참여 기회          타인에게 영향을 미칠 수 있는 위치          긍정적, 부정적 대상에 대한 노출 기회 및 위험                    방향 네트워크의 내향 연결 정도 중심성                  중요성(Prominent)          명망(Prestige)          인기(Popularity)                    방향 네트워크의 외향 연결 정도 중심성                  영향력(Influential)          개방성(Expansiveness)          사교성(Gregariousness)                          계산 : 액터의 성립 가능한 연결관계 갯수\\[C_{D}(N_i) = \\frac{\\sum_{j=1}^{g}(x_{i})_{j}}{g-1}\\]          $(x_{i})_{j}$ : 노드 $N_i$ 의 노드 $N_j$ 에 대한 연결 성립 여부 및 연결 강도      $g-1$ : 이론상으로 성립 가능한 연결관계 갯수 최대값      네트워크의 연결 정도 중심성(Network Degree Centrality)      정의 : 연결 정도로 측정한 액터 간 중요도의 불균등성        계산 : 액터 연결 정도 중심성 최대값과 그 외 액터 연결 정도 중심성 간 격차의 합\\[\\begin{aligned}  C_{D}  &amp;=\\frac{\\sum_{i=1}^{g}{C_{D}(N_{*})-C_{D}(N_i)}}{(g-1)(g-2)}  \\end{aligned}\\]                  $C_{D}(N_{*})$ : 액터 연결 정도 중심성 최대값                    $C_{D}(N_i)$ : 노드 $N_i$ 의 연결 정도 중심성                    $(g-1)(g-2)$                  $\\sum_{i=1}^{g}{[(g-1)-1]}$          $\\max(\\sum_{i=1}^{g}{C_{D}(N_{*})-C_{D}(N_i)})$          이론상으로 성립 가능한 네트워크 연결 정도 중심성 최대값          즉, 액터 갯수가 $g$ 인 스타 네트워크의 연결 정도 중심성~                    한계점  간접적인 연결관계를 간과함          연결 정도 중심성은 직접적인 연결관계만을 고려하기 때문에 그 의미가 지역에 한정될 수 있음      즉, 지역에서는 중심적이지만 전역에서는 중심적이지 않은 경우 중요도가 왜곡될 수 있음                  예컨대 액터의 연결 정도는 높지만, 그 알터들의 연결 정도는 낮은 경우                    전역에서의 구조적 위치를 파악하기 위해서는 간접적인 연결관계까지 고려할 필요가 있음        네트워크 구조의 영향력을 간과함          네트워크 구조에 따른 액터의 구조적 위치와 파워 간 불일치 현상      Positive Network                  연결관계가 보완적 성격을 가지는 네트워크          커뮤니케이션 네트워크 등          중요도가 높은 액터와 연결관계를 가질수록 파워가 높아짐                    Negative Network                  연결관계가 경쟁적 성격을 가지는 네트워크          Zero-Sum 원칙에 기초하는 자원 교환 네트워크, 협상 네트워크 등          중요도가 낮은 액터와 연결관계를 가질수록 파워가 높아짐                    근접 중심성액터의 근접 중심성(Actor Closeness Centrality)      정의 : 다른 액터와의 접근성으로써 측정한 액터의 중심성    해석 : 액터의 독립성(Independence)          액터의 근접 중심성이 높을수록 사교 과정에서 개별 알터의 영향력이 감소함      액터의 근접 중심성이 높을수록 다양한 출처로부터 정보를 획득할 수 있음      액터의 근접 중심성이 높을수록 정보를 획득하기까지 소요되는 시간이 감소함            계산 : 다른 액터들과의 직경의 합의 역수\\[\\begin{aligned}  C_{C}(N_{i})  &amp;=\\displaystyle\\frac{(\\displaystyle\\frac{1}{\\sum_{j=1}^{g}{d(N_i, N_j)}})}{(\\displaystyle\\frac{1}{g-1})}\\\\  &amp;=\\frac{g-1}{\\sum_{j=1}^{g}{d(N_i, N_j)}}  \\end{aligned}\\]          $d(N_i, N_j)$ : 노드 $N_i$ 와 노드 $N_j$ 의 직경      $g-1$ : 이론상으로 성립 가능한 직경 최대값      네트워크의 근접 중심성(Network Closeness Centrality)      정의 : 다른 액터에 대한 접근성을 중심으로 측정한 액터 간 중요도의 불균등성        계산 : 액터 근접 중심성 최대값과 그 외 액터 근접 중심성 간 격차의 합\\[C_{C}  =\\frac{\\sum_{i=1}^{g}(C_{C}(N_{*})-C_{C}(N_{i}))}{\\displaystyle\\frac{(g-2)(g-1)}{2g-3}}\\]                  $C_{C}(N_{*})$ : 액터 근접 중심성 최대값                    $C_{C}(N_i)$ : 노드 $N_i$ 의 근접 중심성                    $\\displaystyle\\frac{(g-2)(g-1)}{2g-3}$                  이론상으로 성립 가능한 네트워크 근접 중심성 최대값          즉, 액터 갯수가 $g$ 인 스타 네트워크의 근접 중심성                    매개 중심성액터의 매개 중심성(Actor Betweenness Centrality)      정의 : 사교 과정에 관여하는 빈도로써 측정한 액터의 중심성        해석 : 네트워크에서 이루어지는 사교 활동에 대한 통제 능력        계산 : 임의의 액터에 대하여, 네트워크에서 존재하는 모든 액터쌍의 최단경로 중 해당 액터가 포함된 최단경로의 비율\\[\\begin{aligned}  C_{B}(N_i)  &amp;=\\frac{\\sum_{j&lt;k}{\\displaystyle\\frac{g_{j,k}(N_i)}{g_{j,k}}}}{\\displaystyle\\frac{(g-1)(g-2)}{2}}  \\end{aligned}\\]          $g_{j,k}$ : 노드 $N_j$ 와 노드 $N_k$ 의 최단경로 갯수      $g_{j,k}(N_i)$ : 노드 $N_j$ 와 노드 $N_k$ 의 최단경로 갯수 중 노드 $N_i$ 가 포함된 최단경로 갯수      $\\displaystyle\\frac{(g-1)(g-2)}{2}$ : 이론상으로 성립 가능한 액터 매개 중심성 최대값      네트워크의 매개 중심성(Network Betweenness Centrality)      정의 : 사교 과정에 관여하는 빈도로써 측정한 액터 간 중요도의 불균등성        계산 : 액터 매개 중심성 최대값과 그 외 액터 매개 중심성 간 격차의 합\\[C_{B}  =\\frac{\\sum_{i=1}^{g}(C_{B}(N_{*}-C_{B}(N_{i})))}{g-1}\\]                  $C_{B}(N_{*})$ : 액터 매개 중심성 최대값                    $C_{B}(N_i)$ : 노드 $N_i$ 의 매개 중심성                    $g-1$                  이론상으로 성립 가능한 네트워크 매개 중심성 최대값          즉, 액터 갯수가 $g$ 인 스타 네트워크의 매개 중심성                    고유벡터 중심성      정의 : 알터들의 연결 정도를 가중하여 계산한 연결 정도 중심성    해석 : 중요도가 높은 액터들과의 연결 정도          인기도(Population)      지위(Status)            계산 : 노드 $N_{i}$ 의 고유벡터 중심성 $C_{E}(N_{i})$ 은 좌변의 수렴값임\\[C_{E}(N_{i})  =\\lambda\\sum_{j=1}^{g}{[x_{i,j} \\times C_{E}(N_{j})]}\\]          $\\lambda$ : 고유값      $g$ : 액터 갯수      $x_{i,j}$ : 노드 $N_{i}$ 와 노드 $N_{j}$ 의 연결 여부 및 그 강도      $C_{E}(N_{j})$ : 노드 $N_{j}$ 의 고유벡터 중심성        연결 정도 중심성과의 관계          다음의 경우 고유벡터 중심성 값이 민감하게 변화함                  연결 정도 중심성이 낮은 액터가 연결 정도 중심성이 높은 액터와 연결관계를 가지게 되는 경우          연결 정도 중심성이 높은 액터가 연결 정도 중심성이 낮은 액터와 연결관계를 가지게 되는 경우                    다음의 경우 스패머(Spammer)일 가능성이 있다고 판단함                  연결 정도 중심성은 높지만 고유벡터 중심성은 낮은 경우                    베타 중심성      정의 : 네트워크 구조 및 다른 액터에 대한 접근성을 고려하여 측정한 중심성        계산\\[\\begin{aligned}  C_{B}  &amp;=\\alpha (\\beta^{1-1} X^1 \\overrightarrow{1} + \\beta^{2-1} X^2 \\overrightarrow{1} + \\beta^{3-1} X^3 \\overrightarrow{1} + \\cdots)\\\\  &amp;=\\displaystyle\\sum_{k=1}^{\\infty}{\\beta^{k-1}X^{k}\\overrightarrow{1}}\\\\  &amp;=  \\begin{pmatrix}  C_{B}(N_1)\\\\  C_{B}(N_2)\\\\  \\vdots\\\\  C_{B}(N_i)\\\\  \\vdots\\\\  C_{B}(N_g)\\\\  \\end{pmatrix}  \\end{aligned}\\]          $C_{B}$ : 액터 베타 중심성 $C_{B}(N_i)$ 를 원소로 가지는 열벡터      $X$ : $x_{i,j}$ 를 원소로 가지는 인접 행렬      $x_{i,j}$ : 노드 $N_i$ 와 노드 $N_j$ 의 연결관계 성립 여부 및 그 강도      $X^k$ : 워크 길이가 $k$ 일 때 노드 $N_i$ 와 노드 $N_j$ 간 성립 가능한 워크      $\\overrightarrow{1}$ : $1$ 로 구성된 열벡터      $\\alpha$ : 베타 중심성 표준화 파라미터      $\\beta$ : 액터 간 거리에 대한 가중치 파라미터로서 연구자가 설정함      $\\beta$ 의 이해      $\\beta$ 의 범위\\[\\vert \\beta \\vert  \\leq \\frac{1}{\\lambda}\\]          $\\lambda$ : 인접 행렬 $X$ 의 고유값        $\\beta$ 값과 워크 길이의 관계          워크 길이가 긴 액터의 영향력을 얼마나 고려할 것인가      $ \\vert \\beta \\vert $ 가 클수록 간접적인 연결관계를 고려함      $ \\vert \\beta \\vert $ 가 $0$ 에 가까울수록 연결 정도 중심성에 가까워짐        최적의 $\\beta$ 값 구하기          시점 $t$ 일 때의 네트워크를 도출함      시점 $t+1$ 일 때 액터가 획득한 정보량을 측정함      다양한 $\\beta$ 값에 따른 베타 중심성을 측정함      베타 중심성과 정보량 간 상관관계를 분석함      상관관계가 가장 높은 $\\beta$ 값을 최적값으로서 채택함        $\\beta$ 최적값에 따른 네트워크 구조 해석          $\\beta &gt; 0$ : Positive Network      $\\beta &lt; 0$ : Negative Network      "
  },
  
  {
    "title": "Connection and Density",
    "url": "/posts/Connection_Density/",
    "categories": "AI & Data Mining, Social Media Analytics",
    "tags": "Data Mining, Social Media, Social Network, Graph",
    "date": "2024-01-30 00:00:00 +0900",
    





    
    "snippet": "연결 정도  액터의 연결 정도(Actor Connection Degree)          정의 : 액터의 활동성(Activity)              계산 : 노드의 라인 갯수\\[0 \\leq D(N_i) \\leq g-1\\]                  $D(N_i)$ : 노드 $i$ 의 연결 정도          $g$ : 네트워크에 존재하는 ...",
    "content": "연결 정도  액터의 연결 정도(Actor Connection Degree)          정의 : 액터의 활동성(Activity)              계산 : 노드의 라인 갯수\\[0 \\leq D(N_i) \\leq g-1\\]                  $D(N_i)$ : 노드 $i$ 의 연결 정도          $g$ : 네트워크에 존재하는 노드 갯수                      네트워크의 연결 정도(Network Connection Degree)          정의 : 네트워크에 존재하는 액터들의 평균적인 활동성              계산 : 네트워크에 존재하는 노드의 평균 라인 갯수\\[\\begin{aligned}  \\overline{d}  &amp;=\\frac{\\sum_{i=1}^{g}{D(N_i)}}{g}\\\\  &amp;=\\frac{2L}{g}  \\end{aligned}\\]                  $L$ : 네트워크에 존재하는 라인 갯수                      연결 정도의 분산          정의 : 네트워크의 집중도 혹은 네트워크의 액터들 간 불균등성(Uniformity)              계산 : 액터 간 활동성 편차\\[S_{d}^{2}=\\frac{\\sum_{i=1}^{g}{D(N_i)-\\overline{d}}}{g}\\]            밀도와 포괄성밀도(Density)  정의 : 응집력(Cohesion)을 라인을 중심으로 측정한 개념          이진 네트워크의 경우 연결관계 성립률을 의미함      계량 네트워크의 경우 연결관계 평균 강도를 의미함        계산 : 네트워크에서 성립 가능한 라인 갯수 대비 실제 성립되어 있는 라인 갯수                  비방향 네트워크\\[D=\\frac{\\sum_{j=1}^{g}(x_{i})_{j}}{_{g}C_{2}}\\]                  $(x_{i})_{j}$ : 노드 $N_i$ 의 노드 $N_j$ 에 대한 연결 성립 여부 및 연결 강도          \\(_{g}C_{2}\\) : 성립 가능한 라인 갯수                            방향 네트워크\\[D=\\frac{\\sum_{j=1}^{g}(x_{i})_{j}}{_{g}P_{2}}\\]                  $(x_{i})_{j}$ : 노드 $N_i$ 의 노드 $N_j$ 에 대한 연결 성립 여부 및 연결 강도          \\(_{g}P_{2}\\) : 성립 가능한 라인 갯수                    포괄성(Inclusiveness)      정의 : 응집력(Cohesion)을 노드를 중심으로 측정한 개념        계산 : 네트워크에 존재하는 노드 갯수 대비 다른 노드와 연결관계를 맺고 있는 노드 갯수\\[I=\\frac{g_c}{g}\\]          $g_c$ : 다른 노드와 연결관계를 맺고 있는 노드 갯수      호혜성과 이행성호혜성(Reciprocity)      정의 : 방향 네트워크에서, $N_i$ 의 $N_j$ 에 대한 연결관계가 존재하고 동시에 $N_j$ 의 $N_i$ 에 대한 연결관계가 존재하는 경우        계산          양자관계(dyad) : 연결관계가 성립되어 있는 액터쌍 대비 호혜적 액터쌍      선택관계(arc) : 연결관계가 성립될 수 있는 액터쌍 대비 호혜적 액터쌍      이행성 조건(Transitivity Condition)  정의 : 액터 $A$, $B$, $C$ 로 구성되어 있는 삼자관계에서 다음의 연결관계가 모두 성립되어 있는 경우          $A\\rightarrow B$      $B\\rightarrow C$      $A\\rightarrow C$            해석 : 이행성 조건을 충족하는 삼자관계가 많을수록 군집화된 구조를 가지는 경향이 있음    계산 : 성립될 수 있는 삼자관계 갯수 대비 이행성 조건을 충족하는 삼자관계 갯수삼자관계(Trid Relationship)      정의 : 방향 이진 네트워크에서, 세 액터 및 그 액터들 간 관계    삼자관계 센서스(Trid Census)                  정의 : 삼자관계의 16가지 유형 중 각 유형이 어느 정도 출현하는지 파악하는 절차                    MAN 표기법                  M(mutual) : 호혜적 연결관계 갯수          A(asymmetric) : 비호혜적 연결관계 갯수                          U(up)              D(down)              T(transitive)              C(cyclic)                                N(null) : 고립 노드 갯수                      삼자관계의 이행성          불완전 이행적(Vacuous or Vacuously Transitive) : 삼자관계의 트리플이 모두 불완전 이행적일 경우      비이행적(Intransitive) : 삼자관계의 불완전 이행적인 트리플을 제외한 트리플 중 하나라도 비이행적일 경우      이행적(Transitive) : 삼자관계의 불완전 이행적인 트리플을 제외한 트리플이 모두 이행적일 경우      트리플(Triple)  정의 : 삼자관계에서 존재하는 액터들의 중복되지 않는 배열          $(A,B,C)$      $(A,C,B)$      $(B,A,C)$      $(B,C,A)$      $(C,A,B)$      $(C,B,A)$        트리플의 이행성 조건 : 이하 조건을 모두 충족하는 경우          $N_1\\rightarrow N_2$ : 첫 번째 노드의 두 번째 노드에 대한 연결관계가 존재함      $N_2\\rightarrow N_3$ : 두 번째 노드의 세 번째 노드에 대한 연결관계가 존재함      $N_1\\rightarrow N_3$ : 첫 번째 노드의 세 번째 노드에 대한 연결관계가 존재함        트리플의 이행성 분류          이행적(Transitive) : 세 조건이 모두 충족되는 경우                  $N_1\\rightarrow N_2$          $N_2\\rightarrow N_3$          $N_1\\rightarrow N_3$                    비이행적(Intransitive) : 세 번째 조건이 충족되지 않는 경우                  $N_1\\rightarrow N_2$          $N_2\\rightarrow N_3$          $N_1\\not\\rightarrow N_3$                    불완전 이행적(Vacuous or Vacuously Transitive) : 이행성 여부를 판단하기 위해 필요한 연결관계 갯수가 부족하여 판단할 수 없는 경우                  $N_1\\not\\rightarrow N_2$ or $N_2\\not\\rightarrow N_3$                    클러스터링 계수(Clustering Coefficient)      정의 : 비방향 네트워크에 대한 이행성 판단 지표    로컬 클러스터링 계수(Local Clustering Coefficient)                  정의 : 비방향 네트워크에서 액터의 이행성 정도                    계산 : 액터의 에고 네트워크 밀도\\[D=\\frac{\\sum_{j=1}^{g}(x_{i})_{j}}{_{g}C_{2}}\\]                  $(x_{i})_{j}$ : 노드 $N_i$ 의 노드 $N_j$ 에 대한 연결 성립 여부 및 연결 강도          \\(_{g}C_{2}\\) : 성립 가능한 라인 갯수                      글로벌 클러스터링 계수(Global Clustering Coefficient)          정의 : 비방향 네트워크에서 네트워크의 군집화 정도      계산 : 로컬 클러스터링 계수에 대하여 로컬 네트워크의 크기에 대한 가중 평균      거리  거리(Distance) : 임의의 두 노드에 대하여 상호간에 멀리 위치하는 정도  워크(Walk) : 임의의 두 노드에 대하여 상호간에 성립 가능한 직, 간접적인 연결 방법의 가짓수  워크 길이(Walk Length) : 워크에 포함된 라인 갯수  경로(Path) : 노드와 라인의 중복이 없는 워크  경로 길이(Path Length) : 경로에 포함된 라인 갯수  도달 가능성(Reachable) : 임의의 두 노드에 대하여, 상호간에 하나 이상의 경로가 존재하는 경우  최단 경로(Geodesic) : 길이가 가장 짧은 경로  직경(Diameter) : 최단 경로 중 가장 긴 거리  플로우(Flow) : 상호간에 라인이 중복되지 않는 경로들의 집합  라인 연결성(Line Connectivity or Edge Connectivity) : 경로를 없애기 위해 제거해야 하는 최소 라인 갯수"
  },
  
  {
    "title": "What? Network",
    "url": "/posts/Network/",
    "categories": "AI & Data Mining, Social Media Analytics",
    "tags": "Data Mining, Social Media, Social Network, Graph",
    "date": "2024-01-29 00:00:00 +0900",
    





    
    "snippet": "정의  네트워크(Network) : 사회 연결망으로서 액터 및 그들 간 관계          네트워크의 규모 혹은 크기를 네트워크에 존재하는 액터의 수로 측정함            액터(Actor) : 사회 구성원으로서 노드(Node)로 표현함    연결관계(Relationship) : 액터 간 관계로서 라인(Line)으로 표현함종류Directed  ...",
    "content": "정의  네트워크(Network) : 사회 연결망으로서 액터 및 그들 간 관계          네트워크의 규모 혹은 크기를 네트워크에 존재하는 액터의 수로 측정함            액터(Actor) : 사회 구성원으로서 노드(Node)로 표현함    연결관계(Relationship) : 액터 간 관계로서 라인(Line)으로 표현함종류Directed      비방향 네트워크(Undirected Network) : 방향성이 존재하지 않는 네트워크        방향 네트워크(Directed Network) : 방향성이 존재하는 네트워크          액터의 내향 연결 정도(Introvert Connection Degree) : 액터가 연결 객체가 되는 연결관계 갯수      액터의 외향 연결 정도(Outrovert Connection Degree) : 액터가 연결 주체가 되는 연결관계 갯수      Weighted  이진 네트워크(Binary Network) : 연결 강도가 존재하지 않는 네트워크  가중 혹은 계량 네트워크(Weighted Network) : 연결 강도가 존재하는 네트워크Focus      전역 네트워크(Global Network) : 네트워크 전반에 대하여 초점을 맞추는 네트워크        에고 네트워크(Ego Network) : 특정 노드에 대하여 초점을 맞추는 네트워크          에고(Ego) : 초점 노드      알터(Alter) : 에고와 연결관계를 맺고 있는 노드      에고 네트워크 분석 시 알터와 에고의 연결관계는 고려하지 않음      표현그래프  방향 네트워크의 경우 연결 방향을 화살표로 표기함  계량 네트워크의 경우 연결 강도를 숫자로 표기함행렬      $(i, j)$ 는 $N_i$ 의 $N_j$ 에 대한 연결 여부 및 강도를 나타냄        비방향 네트워크의 경우 $(i, j)=(j, i)$ 인 대칭 행렬임\\[\\begin{bmatrix}  -&amp;1&amp;1&amp;1&amp;1\\\\  1&amp;-&amp;1&amp;0&amp;1\\\\   1&amp;1&amp;-&amp;1&amp;0\\\\  1&amp;0&amp;1&amp;-&amp;1\\\\  1&amp;1&amp;0&amp;1&amp;-  \\end{bmatrix}\\]        방향 네트워크의 경우 상삼각은 외향 연결 정도를, 하삼각은 내향 연결 정도를 나타냄\\[\\begin{bmatrix}  -&amp;3&amp;4&amp;2&amp;3\\\\  0&amp;-&amp;0&amp;0&amp;5\\\\   0&amp;5&amp;-&amp;3&amp;0\\\\  0&amp;0&amp;0&amp;-&amp;4\\\\  0&amp;0&amp;0&amp;4&amp;-  \\end{bmatrix}\\]  "
  },
  
  {
    "title": "RNN",
    "url": "/posts/RNN/",
    "categories": "Machine Learning Techs, Deep Learning",
    "tags": "Deep Learning, RNN, NLP",
    "date": "2024-01-26 00:00:00 +0900",
    





    
    "snippet": "RNNRecurrent Neural Network      완전 연결 계층의 문제점 : 시계열 데이터 처리 불가능              동시성의 문제      과거 상태를 보관할 메모리 장치의 부재            순환 신경망 : 이전 단계의 출력을 현재 단계에서 반복적으로 고려하며 입력 정보를 순차적으로 처리하는 신경망 알고리즘         ...",
    "content": "RNNRecurrent Neural Network      완전 연결 계층의 문제점 : 시계열 데이터 처리 불가능              동시성의 문제      과거 상태를 보관할 메모리 장치의 부재            순환 신경망 : 이전 단계의 출력을 현재 단계에서 반복적으로 고려하며 입력 정보를 순차적으로 처리하는 신경망 알고리즘            용례              one to one      one to many : Image Captioning      many to one : 감성 분석(Sentiment Classification)      many to many : 기계 번역(Machine Translation)      작동 방식      은닉 상태($\\overrightarrow{s}_{t}$)의 갱신\\[\\begin{aligned}  \\overrightarrow{s}_{t}  &amp;= \\text{tanh}(\\mathbf{U}\\cdot\\overrightarrow{x}_{t}+\\mathbf{W}\\cdot\\overrightarrow{s}_{t-1}+\\overrightarrow{\\beta}_{s})  \\end{aligned}\\]          $\\text{tanh}$ : 활성화 함수      $\\overrightarrow{x}_{t}$ : $t$ 시점에서의 입력 벡터      $\\mathbf{U}$ : 입력값에 대한 가중치 행렬      $\\overrightarrow{s}_{t-1}$ : $t-1$ 시점에서의 은닉 상태 벡터      $\\mathbf{W}$ : 이전 은닉 상태에 대한 가중치 행렬      $\\overrightarrow{\\beta}_{s}$ : 편향 벡터            출력값($\\overrightarrow{o}_{t}$)의 도출\\[\\begin{aligned}  \\overrightarrow{o}_{t}  &amp;= \\text{softmax}(\\mathbf{V}\\cdot\\overrightarrow{s}_{t}+\\overrightarrow{\\beta}_{o})  \\end{aligned}\\]          $\\text{softmax}$ : 활성화 함수      $\\overrightarrow{s}_{t}$ : $t$ 시점에서의 은닉 상태 벡터      $\\mathbf{V}$ : 은닉값에 대한 가중치 행렬      $\\overrightarrow{\\beta}_{o}$ : 편향 벡터      LSTMLong Short-Term Memory      RNN의 한계점 : 장기 의존성 문제              역전파 과정에서 기울기가 소실되어 시퀀스가 길수록 초기 순번 정보에 대하여 학습되지 않음            장-단기 메모리 기법 : 여러 개의 게이트(Gate)를 설치하고 셀 상태와 은닉 상태를 구분함으로써 RNN의 한계점을 보완하는 기법      작동 방식      얼마나 잊을 것인가              망각 게이트($f_{t}(x_{t},h_{t-1})$) : 얼마나 잊을지 결정하는 관문            얼마나 기억할 것인가              입력 게이트($i_{t}(x_{t},h_{t-1})$) : 얼마나 기억할지 결정하는 관문      셀 상태 업데이트(\\(\\widetilde{C}_{t}(x_{t},h_{t-1})\\)) : 입력 게이트에서 판단할 정보를 도출하는 관문            현재 상태를 어떻게 정의할 것인가              셀 상태($C_{t}$) : 이전 셀 상태($C_{t-1}$)를 적당히 망각하고($f_{t}$), 현재 상태에서 갱신된 정보(\\(\\widetilde{C}_{t}\\))를 적당히 기억하는(\\(i_{t}\\)) 상태            얼마나 출력할 것인가              출력 게이트($o_{t}(x_{t},h_{t-1})$) : 얼마나 출력할지 결정하는 관문      은닉 상태($h_{t}$) : 셀 상태($C_{t}$)에서 적당히 출력된($o_{t}$) 상태      이미지 출처  https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr"
  },
  
  {
    "title": "Latent Factor Model",
    "url": "/posts/LFM/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Paper Review, Data Mining, RecSys, Collaborative Filtering, Latent Factor Model",
    "date": "2024-01-25 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "CNN",
    "url": "/posts/CNN/",
    "categories": "Machine Learning Techs, Deep Learning",
    "tags": "Deep Learning, CNN, CV",
    "date": "2024-01-25 00:00:00 +0900",
    





    
    "snippet": "What? Cov-Net      완전 연결 계층의 문제점 : 입력값을 1차원으로 평탄화(Flatten)하는 과정에서 공간적 구조(Spatial Structure)를 무너뜨림    \\[\\mathbf{Y}_{N \\times P \\cdot Q \\cdot R}  = \\text{flatten}(\\mathbf{X}_{N \\times P \\times Q \\tim...",
    "content": "What? Cov-Net      완전 연결 계층의 문제점 : 입력값을 1차원으로 평탄화(Flatten)하는 과정에서 공간적 구조(Spatial Structure)를 무너뜨림    \\[\\mathbf{Y}_{N \\times P \\cdot Q \\cdot R}  = \\text{flatten}(\\mathbf{X}_{N \\times P \\times Q \\times R})\\]        합성곱 신경망(Convolution Neural Network; CNN) : 형상의 특징을 추출하고 기록하는 전처리 과정이 존재하는 신경망 알고리즘              입력 계층(Input Layer) : 관측치의 속성값을 입력 받는 계층      컨볼루션 계층(Convolution Layer) : 자료의 공간 구조 상 특징을 포착하는 계층      풀링 계층(Pooling Layer) : 컨볼루션 계층에서 포착한 특징의 대표값을 선별함으로써 자료 규모를 축소하는 계층      완전 연결 계층(Fully-Connected Layer)      Convolution Layerfrom tensorflow.keras.layers import Conv2Dconv_layer = Conv2D(    filters = k,    kernel_size = (M,N),    strides = s,    padding = \"valid\",    activation = \"relu\"    )Convolution Operation      합성곱 연산(Convolution Operation) : 입력값의 부분공간을 커널과 아다마르 곱셈($\\odot$)하는 과정을 반복하여 새로운 행렬을 구성함    \\[\\begin{aligned}  \\mathbf{Y}  &amp;= \\text{ReLU}(\\mathbf{C}+\\mathbf{\\beta})\\\\  \\mathbf{C}  &amp; \\in \\mathbb{R}^{\\lfloor \\displaystyle\\frac{P-M}{s}+1 \\rfloor \\times \\lfloor \\displaystyle\\frac{Q-N}{s}+1 \\rfloor \\times k}\\\\  &amp;= \\mathbf{W}_{M \\times N} \\odot \\mathbf{X}_{P \\times Q}\\\\  c_{i,j}  &amp;= \\sum_{n=1}^{N}\\sum_{m=1}^{M}{w_{m,n} \\cdot x_{i+m-1,j+n-1}}\\\\  \\end{aligned}\\]                  특성 맵(Feature Map; $\\mathbf{Y}$) : 합성곱 연산 결과 입력값 형상의 특징으로서 반환된 새로운 배열                            커널(Kernel; $\\mathbf{W}_{M \\times N}$) : 입력값의 부분공간에 아다마르 곱셈하는 여과기(Filter)                  filters : 커널 갯수          kernel_size : 커널 크기          strides : 커널 이동 보폭                            $\\mathbf{X}_{P \\times Q}$ : 관측치            Strides &amp; Padding      스트라이드(Stride; $s$) : 커널 이동 보폭            패딩(Padding) : 입력값의 주변을 특정 값으로 채우는 기법              valid : 패딩을 적용하지 않음      same : 입력 크기와 동일하도록 출력 크기를 조절하여 모서리 정보를 보존함      Downsampling using Poolingfrom tensorflow.keras.layers import MaxPooling2Dpooling_layer = MaxPooling2D(    pool_size = (M,N),    strides = s,    padding = \"valid\"    )      합동 연산(Pooling Operation) : 주어진 행렬에 대하여 그 부분공간마다 대표값을 추출하여 새로운 행렬을 구성함            종류                  Max Pooling : 대표값을 부분공간의 가장 큰 값으로 설정함\\[\\begin{aligned}  \\mathbf{Y}  &amp;= \\left\\{y_{i,j}\\bigg|y_{i,j}=\\max_{n=1}^{N}{\\max_{m=1}^{M}{\\mathbf{X}[i:i \\cdot s + m-1, j:j \\cdot s + n-1]}}\\right\\}  \\end{aligned}\\]                    Average Pooling : 대표값을 부분공간의 평균으로 설정함\\[\\begin{aligned}  \\mathbf{Y}  &amp;= \\left\\{y_{i,j}\\bigg|y_{i,j}=\\frac{1}{M \\cdot N}\\sum_{n=1}^{N}{\\sum_{m=1}^{M}{\\mathbf{X}[i:i \\cdot s + m-1, j:j \\cdot s + n-1]}}\\right\\}  \\end{aligned}\\]            "
  },
  
  {
    "title": "Optimizer",
    "url": "/posts/Optimizer/",
    "categories": "Machine Learning Techs, Deep Learning",
    "tags": "Deep Learning, Optimization",
    "date": "2024-01-24 00:00:00 +0900",
    





    
    "snippet": "What? Gadient Descent      정의 : 손실 함수의 도함수(경사)를 최소화하는 가중치를 추정하는 방법\\[\\hat{\\beta}=\\{\\beta\\,|\\, \\min_{\\beta} \\displaystyle\\frac{\\partial}{\\partial \\beta} \\text{Loss}(\\beta, \\cdots) \\}\\]        최적 가중치 ...",
    "content": "What? Gadient Descent      정의 : 손실 함수의 도함수(경사)를 최소화하는 가중치를 추정하는 방법\\[\\hat{\\beta}=\\{\\beta\\,|\\, \\min_{\\beta} \\displaystyle\\frac{\\partial}{\\partial \\beta} \\text{Loss}(\\beta, \\cdots) \\}\\]        최적 가중치 추정 방법\\[\\beta_t  = \\beta_{t-1} - \\alpha \\times \\displaystyle\\frac{\\partial}{\\partial \\beta_{n-1}}\\text{Loss}(\\beta_{t-1},\\cdots)\\]          $\\text{Loss}(\\beta,\\cdots)$ : 손실 함수      $t$ : 극소점 탐색 횟수      $\\alpha$ : 학습률      $\\beta$ : 가중치      Example: three-layer model순전파 연산 과정      손실 $e$ 를 다음과 같이 정의하자\\[\\begin{aligned}  e  &amp;= \\text{Loss}(\\hat{y})\\\\  &amp;= \\hat{y} - y  \\end{aligned}\\]          $\\hat{y}$ : 예측값      $y$ : 실제값            $n$ 개의 계층으로 구성된 모델의 예측값 $\\hat{y}$ 은 다음과 같음\\[\\hat{y}  = f_{n} \\circ g_{n} \\circ f_{n-1} \\circ g_{n-1} \\circ \\cdots \\circ f_{1} \\circ g_{1}(x)\\]                  $x$ : 입력값                    $f_{i}(x)$ : $i$ 번째 계층의 활성화 함수                    $g_{i}(x)=w_{i} \\cdot x + b_{i}$ : $i$ 번째 계층의 순입력 함수                  $w_{i}$ : $i$ 번째 계층의 가중치          $b_{i}$ : $i$ 번째 계층의 편향으로서 편의상 $0$ 이라고 가정함                          $3$ 개의 계층으로 구성된 모델의 손실 $e$ 를 다음과 같이 서술할 수 있음\\[\\begin{aligned}  e  &amp;= h_{3} - y\\\\  &amp;= f_{3}(z_{3}) - y\\\\  &amp;= f_{3}(g_{3}(h_{2})) - y\\\\  &amp;= f_{3}(w_{3} \\cdot h_{2}) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(z_{2})) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(g_{2}(h_{1}))) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(w_{2} \\cdot h_{1})) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(w_{2} \\cdot f_{1}(z_{1}))) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(w_{2} \\cdot f_{1}(g_{1}(h_{0})))) - y\\\\  &amp;= f_{3}(w_{3} \\cdot f_{2}(w_{2} \\cdot f_{1}(w_{1} \\cdot h_{0}))) - y  \\end{aligned}\\]          $z_{i}=g_{i}(h_{i-1})$ : $i$ 번째 계층의 순입력 함수 값      $h_{i}=f_{i}(z_{i})$ : $i$ 번째 계층의 활성화 함수 값      $h_{0} = x$ : 입력값      역전파 학습 과정      손실 $e$ 를 $1$ 번째 계층 가중치 $w_{1}$ 에 대하여 미분하면 다음과 같음\\[\\begin{aligned}  \\frac{\\partial e}{\\partial w_{1}}  &amp;= \\frac{\\partial e}{\\partial\\not{h_{3}}}  \\cdot \\frac{\\partial\\not{h_{3}}}{\\partial\\not{z_{3}}}  \\cdot \\frac{\\partial\\not{z_{3}}}{\\partial\\not{h_{2}}}  \\cdot \\frac{\\partial\\not{h_{2}}}{\\partial\\not{z_{2}}}  \\cdot \\frac{\\partial\\not{z_{2}}}{\\partial\\not{h_{1}}}  \\cdot \\frac{\\partial\\not{h_{1}}}{\\partial\\not{z_{1}}}  \\cdot \\frac{\\partial\\not{z_{1}}}{\\partial w_{1}}  \\end{aligned}\\]        위 수식의 각 항목을 다음과 같이 일반화할 수 있음\\[\\begin{aligned}  \\frac{\\partial e}{\\partial h_{n}}  &amp;= \\frac{\\partial(h_{n}-y)}{\\partial h_{n}}\\\\  &amp;= 1\\\\\\\\  \\frac{\\partial h_{i}}{\\partial z_{i}}  &amp;= \\frac{\\partial f_{i}(z_{i})}{\\partial z_{i}}\\\\  &amp;= f^{\\prime}_{i}(z_{i})\\\\\\\\  \\frac{\\partial z_{i}}{\\partial h_{i-1}}  &amp;= \\frac{\\partial g_{i}(h_{i-1})}{\\partial h_{i-1}}\\\\  &amp;= \\frac{\\partial (w_{i} \\cdot h_{i-1})}{\\partial h_{i-1}}\\\\  &amp;= w_{i}\\\\\\\\  \\frac{\\partial z_{i}}{\\partial w_{i}}  &amp;= \\frac{\\partial g_{i}(h_{i-1})}{\\partial w_{i}}\\\\  &amp;= \\frac{\\partial (w_{i} \\cdot h_{i-1})}{\\partial w_{i}}\\\\  &amp;= h_{i-1}  \\end{aligned}\\]        손실 $e$ 를 $k$ 번째 계층 가중치 $w_{k}$ 에 대하여 미분한 값을 다음과 같이 일반화할 수 있음\\[\\begin{aligned}  \\frac{\\partial e}{\\partial w_{k}}  &amp;= h_{k-1} \\times (w_{n} \\cdot w_{n-1} \\cdots w_{k+1}) \\times \\{f^{\\prime}_{n}(z_{n}) \\cdot f^{\\prime}_{n-1}(z_{n-1}) \\cdots f^{\\prime}_{k}(z_{k})\\}\\\\  &amp;= h_{k-1} \\times \\displaystyle\\prod^{n}_{i=k+1}{w_i} \\times \\displaystyle\\prod^{n}_{i=k}{f^{\\prime}_{i}(z_{i})}  \\end{aligned}\\]          $h_{k-1}$ : $k-1$ 번째 계층 출력값이자 $k$ 번째 계층 입력값      $\\displaystyle\\prod^{n}_{i=k+1}{w_i}$ : 출력층에서부터 $k+1$ 번째 계층까지 가중치 곱      \\(\\displaystyle\\prod^{n}_{i=k}{f^{\\prime}_{i}(z_{i})}\\) : 출력층에서부터 $k$ 번째 계층까지 활성화 함수 값 곱            경사하강법에 의해 갱신된 $k$ 번째 계층의 가중치 $(w_{k})_{new}$ 는 다음과 같음\\[\\begin{aligned}  (w_{k})_{new}  &amp;= w_{k} - \\eta \\times \\frac{\\partial e}{\\partial w_{k}}\\\\  &amp;= w_{k} - \\eta \\times h_{k-1} \\displaystyle\\prod^{n}_{i=k+1}{w_i} \\cdot \\displaystyle\\prod^{n}_{i=k}{f^{\\prime}_{i}(z_{i})}  \\end{aligned}\\]  종류경사하강법 각 항목의 의미\\[w_{t}=w_{t-1} - \\eta \\times \\frac{\\partial e_{t-1}}{\\partial w_{t-1}}\\]      $\\eta$ : 학습률(Learning Rate)로서 갱신 크기            $\\displaystyle\\frac{\\partial e_{t-1}}{\\partial w_{t-1}}$ : 가중치에 대한 손실의 변화율 벡터로서 갱신 방향  갱신 크기 중심      Adagrad : 갱신 크기를 결정함에 있어 이전까지 갱신 규모를 반영함\\[\\begin{aligned}  w_{t}  &amp;= w_{t-1} - \\frac{\\eta}{\\sqrt{h_{t}}} \\times \\frac{\\partial e_{t-1}}{\\partial w_{t-1}}\\\\  h_{t}  &amp;= h_{t-1} + \\frac{\\partial e_{t}}{\\partial w_{t}} \\odot \\frac{\\partial e_{t}}{\\partial w_{t}}  \\end{aligned}\\]                  $h_{t-1}$ : 이전까지 갱신 규모                    $\\displaystyle\\frac{\\partial e_{t}}{\\partial w_{t}} \\odot \\displaystyle\\frac{\\partial e_{t}}{\\partial w_{t}}$ : 현 시점 갱신 규모 추정치                  RMSProp : 갱신 크기를 결정함에 있어 이전까지 갱신 규모를 지수가중이동평균하여 반영함\\[\\begin{aligned}  w_{t}  &amp;= w_{t-1} - \\frac{\\eta}{\\sqrt{h_{t}}} \\times \\frac{\\partial e_{t-1}}{\\partial w_{t-1}}\\\\  h_{t}  &amp;= \\rho \\cdot h_{t-1} + (1 - \\rho) \\cdot \\frac{\\partial e_{t}}{\\partial w_{t}} \\odot \\frac{\\partial e_{t}}{\\partial w_{t}}  \\end{aligned}\\]          $\\rho$ : 붕괴 계수      갱신 방향 중심      Momentum : 갱신 방향을 결정함에 있어 $m_{t-1}$ 을 $\\gamma$ 만큼 반영함\\[\\begin{aligned}  w_{t}  &amp;= w_{t-1} - m_{t}\\\\  m_{t}  &amp;= \\eta \\cdot \\frac{\\partial e_{t-1}}{\\partial w_{t-1}} + \\gamma \\cdot m_{t-1}  \\end{aligned}\\]          $m_{t-1}$ : 직전 시점 갱신 방향      $\\gamma$ : 관성 계수      "
  },
  
  {
    "title": "Activation Functions",
    "url": "/posts/Activation_Functions/",
    "categories": "Machine Learning Techs, Deep Learning",
    "tags": "Deep Learning",
    "date": "2024-01-23 00:00:00 +0900",
    





    
    "snippet": "활성화 함수의 이해      정의 : 순입력 함수 결과값에 대하여, 역치를 기준으로 정보 전달 여부를 판단하는 함수            문제점                  Hard Decision Problem                                      현상 : 유의미하지 않은 차이로 인해 활성화 여부가 결정되는 현상     ...",
    "content": "활성화 함수의 이해      정의 : 순입력 함수 결과값에 대하여, 역치를 기준으로 정보 전달 여부를 판단하는 함수            문제점                  Hard Decision Problem                                      현상 : 유의미하지 않은 차이로 인해 활성화 여부가 결정되는 현상                                원인 : 순전파 연산 과정에서 마진이 충분히 확보되지 않음                          마진(Margin) : 결정 경계와 가장 가까운 두 관측치 간 거리              결정 경계(Decision Boundary) : 활성화 여부 판단 기준이 되는 선으로서 역치 혹은 임계값                                                  Gradient Problem                          현상 : 역전파 학습 과정에서 출력층으로부터 멀어질수록 가중치가 제대로 갱신되지 않는 현상          원인 : 활성화 함수의 도함수가 $0$ 과 $1$ 사이 값을 취함                    종류Step Function      공식\\[\\text{step}(x)=\\begin{cases} 1, \\ \\text{if} \\ x&gt;0 \\\\ 0, \\ \\text{otherwise} \\end{cases}\\]        공역\\[y \\in \\{0, 1\\}\\]  Sigmoid Function      공식\\[\\text{sigmoid}(x)=\\frac{1}{1+e^{-x}}\\]        공역\\[y \\in [0, 1]\\]  Hyperbolic TANgent(TANH) Function      공식\\[\\begin{aligned}  \\text{tanh}(x)&amp;=\\frac{\\text{sinh}(x)}{\\text{cosh}(x)} \\\\  &amp;=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}  \\end{aligned}\\]        공역\\[y \\in [-1, 1]\\]  ReLU Function      공식\\[\\text{ReLU}(x)=\\max(0,x)\\]        공역\\[y \\in [0, \\infty]\\]  Softmax Function      공식\\[\\begin{aligned}  \\text{softmax}(x)_{i} &amp;= \\frac{e^{x_i}}{\\textstyle \\sum_{j \\ne i}^{}{e^{x_j}}}\\\\  \\displaystyle\\sum_{i=1}^{n}{\\text{softmax}(x)_{i}} &amp;= 1\\\\  \\text{softmax}(x) &amp;= \\Big\\{\\frac{e^{x_1}}{\\textstyle \\sum_{j \\ne 1}^{}{e^{x_j}}}, \\frac{e^{x_2}}{\\textstyle \\sum_{j \\ne 2}^{}{e^{x_j}}}, \\cdots , \\frac{e^{x_i}}{\\textstyle \\sum_{j \\ne i}^{}{e^{x_j}}}, \\cdots , \\frac{e^{x_n}}{\\textstyle \\sum_{j \\ne n}^{}{e^{x_j}}}\\Big\\}  \\end{aligned}\\]        공역\\[y \\in [0, 1]\\]  "
  },
  
  {
    "title": "Deep Learning WorkFlow",
    "url": "/posts/DNN/",
    "categories": "Machine Learning Techs, Deep Learning",
    "tags": "Deep Learning, FFNN",
    "date": "2024-01-22 00:00:00 +0900",
    





    
    "snippet": "What? Deep Learning  정의 : 심층 인공 신경망 알고리즘을 활용한 기계학습 방법          심층 신경망(Deep Artificial Neural Network; DNN) : 층을 겹겹이 쌓아올려 구성한 알고리즘      알고리즘(Algorithm) : 관측치들로부터 표현을 학습하는 수학 모델            인공 신경망과 심층...",
    "content": "What? Deep Learning  정의 : 심층 인공 신경망 알고리즘을 활용한 기계학습 방법          심층 신경망(Deep Artificial Neural Network; DNN) : 층을 겹겹이 쌓아올려 구성한 알고리즘      알고리즘(Algorithm) : 관측치들로부터 표현을 학습하는 수학 모델            인공 신경망과 심층 신경망의 구분              인공 신경망(Artificial Neural Network; ANN) : 은닉층이 하나인 신경망      심층 신경망(Deep Artificial Neural Network; DNN) : 은닉층이 둘 이상인 신경망            심층 신경망의 구성 : 완전 연결 계층(Fully Connected Layer)              입력층(Input Layer) : 관측치를 입력 받는 계층      평탄화층(Flatten Layer) : 관측치 속성의 구조를 1차원으로 평탄화하는 계층      은닉층(Hidden Layer) : 입력층과 출력층 사이에 존재하는 계층      출력층(Output Layer) : 예측값(Target value)을 출력하는 계층            학습 목표 : 모델 파라미터에 대하여, 손실을 최소화하는 아규먼트 탐색    파라미터 종류          모델 파라미터(Model Parameter)                  Weight          Bias                    하이퍼 파라미터(Hyper Parameter)                  Unit Layer          Unit Node          Activation Function          Loss Function          Optimizer          Batch Size          Epoch                    층(Layer)의 이해      정의 : 하나 이상의 텐서를 입력값으로 받고, 하나 이상의 텐서를 출력값으로 반환하는 데이터 처리 모듈            구성 : 퍼셉트론(Perceptron)            상태 : 모델 파라미터로서 가중치 행렬(Weight; $W$) 과 편향 벡터(bias; $\\overrightarrow{b}$)        연산 : 순입력 함수와 활성화 함수로 구성된 정방향 패스(Forward Path)                  순입력 함수(Net Input Function)        \\[W \\cdot \\overrightarrow{x} + \\overrightarrow{b}\\]                    활성화 함수(Activation Function)                  Relu          Tanh          Sigmoid          Step          Softmax                    학습 과정의 이해      학습 횟수의 이해              epochs : 훈련용 데이터 세트를 구성하는 모든 관측치가 신경망을 통과하는 횟수      iteration : epoch 를 1회 마치는 동안 모델 파라미터 갱신 횟수      batch_size : epoch 를 1회 마치는 동안 모델 파라미터를 1회 갱신하기 위하여 동원할 관측치 갯수            iteration 과정              Forward Path : 관측치에 대하여 순전파 연산하여 예측값을 도출함      Loss Output : 손실 함수를 통해 손실을 도출함      Backward Path : 손실을 줄이도록 각 계층의 모델 파라미터를 갱신함        학습 목적 함수 : 손실 함수(Loss Function)                  정의 : 손실을 반응변수, 모델 파라미터를 설명변수로 가지는 함수            판별 분석 : 대개 crossentropy 를 손실로 간주함                  binary_crossentropy : 이항 분류 분석 시 사용하는 크로스 엔트로피 불순도          categorical_crossentropy : 다항 분류 분석, 반응변수가 희소 행렬인 경우          sparse_categorical_crossentropy : 다항 분류 분석, 반응변수가 희소 행렬이 아닌 경우                    회귀 분석 : 대개 squared_error 를 손실로 간주함                  mean_squared_error          mean_squared_log_error          mean_absolute_error          mean_absolute_percentage_error          cosine_similarity                      학습 방식 : 경사하강법(Gadient Descent)          GD : 모든 관측치를 검토하여 가중치 갱신 방향 및 크기 결정      SGD : 일부 관측치만 확률적으로 검토함      Momentum      RMSProp      Adam      텐서플로와 케라스  텐서플로(TensorFlow) : 저수준 컴퓨팅 플랫폼          텐서(Tensor)      미분(Gradient Tape API)        케라스(Keras) : 고수준 딥러닝 API          층(Layer)      모델(Sequential API, Functional API, Model Class)      옵티마이저(Optimizer)      손실 함수(Loss Function)      성능 검증 지표(Metric)      "
  },
  
  {
    "title": "What? RecSys",
    "url": "/posts/What_RecSys/",
    "categories": "AI & Data Mining, Recommender System",
    "tags": "Data Mining, Recommender System",
    "date": "2024-01-18 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Hierarchical Clustering",
    "url": "/posts/Hierarchical_Clustering/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2024-01-15 00:00:00 +0900",
    





    
    "snippet": "What? Hierarchical ClusteringHierarchical Clustering      정의 : 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram) : 결합 혹은 분할하는 순서를 나타내는 계층적...",
    "content": "What? Hierarchical ClusteringHierarchical Clustering      정의 : 계층적 트리모형을 활용하여 개별 개체들을 유사한 개체/군집과 계층적으로 통합하거나, 표본을 유의미하게 구분되는 지점에서 계층적으로 분할해가는 알고리즘        덴드로그램(Dendrogram) : 결합 혹은 분할하는 순서를 나타내는 계층적 트리모형            종류              상향식 군집화(Agglomerative Clustering) : 개별 개체들을 유사한 개체/군집과 계층적으로 통합해가는 방식      하향식 군집화(Divisive Clustering) : 표본을 유의미하게 구분되는 지점마다 계층적으로 분할해가는 방식      How to Agglomerative Clustering      모든 개체를 개별 군집으로서 정의함\\[C_{i} = \\{\\overrightarrow{x}_{i}\\} \\quad \\text{for} \\quad i=1,2,\\cdots, n\\]        군집 간 거리 행렬을 계산함\\[\\mathbf{D}_{i,j}=d(C_{i},C_{j})\\]        가장 가까운 두 개의 군집을 하나의 군집으로 통합함\\[\\begin{aligned} C_{k}&amp;=\\hat{C}_{i} \\cup \\hat{C}_{j}\\\\ \\hat{C}_{i},\\hat{C}_{j}&amp;=\\text{arg} \\min_{C_{i},C_{j}}{d(C_{i},C_{j})} \\end{aligned}\\]        군집 간 거리 행렬을 갱신함\\[\\mathbf{D}_{N} = \\mathbf{D}_{N-1} \\quad \\text{Recalculate} \\quad d(C_{i^{\\forall} \\ne k},C_{k})\\]        모든 개체가 하나의 군집으로 통합될 때까지 ③, ④의 과정을 반복함  How to Calculate Distance      Single Linkage(Minimum Distance) : 각 군집에 속한 개체들 사이 거리 최소값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\min_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Complete Linkage(Maximum Distance) : 각 군집에 속한 개체들 사이 거리 최대값\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\max_{\\overrightarrow{a} \\in \\mathbf{A},\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Average Linkage(Mean Distance) : 각 군집에 속한 개체들 사이 거리 평균\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{a} \\in \\mathbf{A}}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{a},\\overrightarrow{b})}  \\end{aligned}\\]        Centroid Linkage(Distance Between Centroids) : 각 군집 중심 간 거리\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= d(\\overrightarrow{\\mu}_{A},\\overrightarrow{\\mu}_{B})\\\\  \\overrightarrow{\\mu}_{A}  &amp;= \\frac{1}{|\\mathbf{A}|}\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{\\overrightarrow{a}}\\\\  \\overrightarrow{\\mu}_{B}  &amp;= \\frac{1}{|\\mathbf{B}|}\\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{\\overrightarrow{b}}  \\end{aligned}\\]        Ward’s Method : 병합 후 SSE와 병합 전 개별 군집의 SSE의 합의 차\\[\\begin{aligned}  d(\\mathbf{A},\\mathbf{B})  &amp;= \\sum_{\\overrightarrow{c} \\in \\mathbf{C}}{d(\\overrightarrow{c},\\overrightarrow{\\mu}_{C})} - \\Big[\\sum_{\\overrightarrow{a} \\in \\mathbf{A}}{d(\\overrightarrow{a},\\overrightarrow{\\mu}_{A})} + \\sum_{\\overrightarrow{b} \\in \\mathbf{B}}{d(\\overrightarrow{b},\\overrightarrow{\\mu}_{B})}\\Big]\\\\  \\mathbf{C}  &amp;= \\mathbf{A} \\cup \\mathbf{B}  \\end{aligned}\\]  sklearn.cluster.AgglomerativeClusteringfrom sklearn.cluster import AgglomerativeClustering      n_clusters(default : 2) : 생성할 클러스터의 수        distance_threshold(default : None) : 병합하기 위한 클러스터 간 거리 임계값    linkage(default : 'ward'): 클러스터 간 거리 계산 방식          'ward'      'complete'      'average'      'single'        affinity(default : 'euclidean'): 관측치 간 거리 계산 방식          'manhattan' or 'l1'      'euclidean' or 'l2'      'cosine'      'precomputed'        memory(default : None) : 계산된 거리 행렬을 저장할 위치이미지 출처  https://towardsdatascience.com/hierarchical-clustering-explained-e59b13846da8  https://harshsharma1091996.medium.com/hierarchical-clustering-996745fe656b"
  },
  
  {
    "title": "DBSCAN",
    "url": "/posts/DBSCAN/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2024-01-14 00:00:00 +0900",
    





    
    "snippet": "Density-Based Spatial Clustering of Applications with Noise      정의 : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empt...",
    "content": "Density-Based Spatial Clustering of Applications with Noise      정의 : 밀도 기반 배타적 분리형 군집화 알고리즘            군집 : 사전에 주어진 $\\varepsilon, \\text{MinPts}$ 에 기초했을 때 Maximality, Connectivity 조건을 만족하는 Non-Empty Subset                      Maximality                  표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 에 대하여, $\\overrightarrow{p} \\in C \\subseteq D$ 이고, $\\overrightarrow{q}$ 가 $\\overrightarrow{p}$ 로부터 밀도 기준 도달 가능한(Directly Density-Reachable) 벡터이면, $\\overrightarrow{q} \\in C$ 임                            Connectivity                  군집 $C$ 에 속하는 관측치 벡터 $\\overrightarrow{p}, \\overrightarrow{q}$ 간에는 밀도 기준 연결되어 있음(Density-Connected)                    용어의 이해      $\\varepsilon$-neighborhood of a point              표본 $D$ 에 속하는 관측치 벡터 $\\overrightarrow{p}$ 에 대하여, $\\overrightarrow{p}$ 의 이웃 집합 $N_{\\varepsilon}(\\overrightarrow{p})$ 은 $\\overrightarrow{p}$ 와의 거리가 $\\varepsilon$ 이하인 관측치 벡터 $\\overrightarrow{q}$ 의 집합임    \\[N_{\\varepsilon}(\\overrightarrow{p})  =\\{\\overrightarrow{q} \\in D \\big| d(\\overrightarrow{p},\\overrightarrow{q}) \\le \\varepsilon\\}\\]        Directly Density-Reachable              Core Point Condition 을 만족하는 관측치 벡터 $\\overrightarrow{p} \\in D$ 에 대하여, 그 이웃 관측치 벡터($\\varepsilon$-neighborhood of a point) $\\overrightarrow{q}$ 는 $\\overrightarrow{p}$ 로부터 밀도 기준 직접 도달 가능한(Directly Density-Reachable) 관측치 벡터임                      Core Point Condition\\[|N_{\\varepsilon}(\\overrightarrow{p})| \\ge \\text{MinPts}\\]                    Reachability\\[\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{p})\\]                  Density-Reachable              Core Point Condition 을 만족하는 관측치 벡터 \\(\\overrightarrow{p} \\in D\\) 에 대하여, \\(\\overrightarrow{p}\\) 와 \\(\\overrightarrow{q}\\) 사이에 \\(\\overrightarrow{p}\\) 로부터 밀도 기준 직접 도달 가능한 관측치 벡터 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2},\\cdots,\\overrightarrow{x}_{n}\\) 이 연쇄적으로 존재한다면, \\(\\overrightarrow{q}\\) 는 \\(\\overrightarrow{p}\\) 로부터 밀도 기준 도달 가능한(Density-Reachable) 관측치 벡터임              \\(\\vert N_{\\varepsilon}(\\overrightarrow{p})\\vert \\ge \\text{MinPts}\\) : Core Point Condition      \\(\\overrightarrow{x}_{1} \\in N_{\\varepsilon}(\\overrightarrow{p})\\) : Reachability      \\(\\vert N_{\\varepsilon}(\\overrightarrow{x}_{\\forall})\\vert \\ge \\text{MinPts}\\) : \\(\\overrightarrow{x}_{\\forall}\\) 의 이웃 벡터 갯수가 하한선 $\\text{MinPts}$ 이상임      \\(\\overrightarrow{x}_{i+1} \\in N_{\\varepsilon}(\\overrightarrow{x}_{i})\\) : \\(\\overrightarrow{x}_{i+1}\\) 는 \\(\\overrightarrow{x}_{i}\\) 의 이웃 벡터임      \\(\\overrightarrow{q} \\in N_{\\varepsilon}(\\overrightarrow{x}_{n})\\) : $\\overrightarrow{q}$ 는 $\\overrightarrow{x}_{n}$ 의 이웃 벡터임            Density-Connected              Core Point Condition 을 만족하는 관측치 벡터 \\(\\overrightarrow{p},\\overrightarrow{q} \\in D\\) 에 대하여, \\(\\overrightarrow{p}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 동시에 \\(\\overrightarrow{q}\\) 로부터 밀도 기준 도달 가능한(Density-Connected) 관측치 벡터 \\(\\overrightarrow{x} \\in D\\) 가 적어도 하나 존재한다면, \\(\\overrightarrow{p},\\overrightarrow{q}\\) 는 밀도 기준 연결되어 있음(Density-Connected)              $\\vert N_{\\varepsilon}(\\overrightarrow{p})\\vert \\ge \\text{MinPts}$      $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{p})$      $\\vert N_{\\varepsilon}(\\overrightarrow{q})\\vert \\ge \\text{MinPts}$      $\\overrightarrow{x} \\in N_{\\varepsilon}(\\overrightarrow{q})$      sklearn.cluster.DBSCANfrom sklearn.cluster import DBSCANGeneral HyperParameter  random_state(default : None)  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter      eps(default : 0.5) : 직경    metric(default : 'euclidean') : 직경 측정 방법          'l1', 'manhattan' or 'cityblock' : 맨해튼 거리 측정법      'l2' or 'euclidean' : 유클리드 거리 측정법      'cosine' : 코사인 거리 측정법      'haversine' : 하버사인 거리 측정법      callable        p(default : None) : metric 의 아규먼트가 'minkowski' 인 경우 추가 설정          1 : 맨해튼 거리 측정법      2 : 유클리드 거리 측정법        min_samples(default : 5) : 최소 요소 갯수Atrribute  labels_ : 각 관측치가 속한 군집 번호          -1 : 이상치 군집        core_sample_indices_ : 군집별 핵심 요소의 행 번호이미지 출처  https://ai.plainenglish.io/dbscan-density-based-clustering-aaebd76e2c8c  https://journals.sagepub.com/doi/10.1177/1748301817735665"
  },
  
  {
    "title": "k-Means",
    "url": "/posts/kMeans/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering",
    "date": "2024-01-13 00:00:00 +0900",
    





    
    "snippet": "What? k-Meansk-Means      정의 : 중심점 기반 배타적 분리형 군집화 알고리즘            목표 : 각 군집에 대하여, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화함\\[\\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j}...",
    "content": "What? k-Meansk-Means      정의 : 중심점 기반 배타적 분리형 군집화 알고리즘            목표 : 각 군집에 대하여, 관측치와 중심점(Centroid) 간 평균 거리(Means)를 최소화함\\[\\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j} \\in C_{i}}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}}\\]  한계점      초기 군집 중심에 민감함            이상치에 민감함            구형이 아닌 형태의 군집을 탐지하기 어려움            서로 다른 규모의 군집을 탐지하기 어려움            서로 다른 밀도의 군집을 탐지하기 어려움      중심점 탐색 과정      군집 갯수를 설정함\\[X=C_{1} \\cup C_{2} \\cup \\cdots \\cup C_{k}\\\\ \\\\ C_{i} \\cap C_{j \\ne i} = \\emptyset\\]        $k$ 개의 초기 군집 중심 벡터 $\\overrightarrow{c}$ 를 임의로 선정함\\[M=\\{\\overrightarrow{\\mu}_{1},\\overrightarrow{\\mu}_{2},\\cdots,\\overrightarrow{\\mu}_{k}\\}\\]        모든 관측치 벡터 $\\overrightarrow{x}$ 를 가장 가까운 거리에 위치한 중심 벡터 $\\overrightarrow{\\mu}$ 의 군집에 배타적으로 할당함\\[\\overrightarrow{x}_{j} \\rightarrow C_{i}\\\\ \\begin{aligned} \\\\\\text{s.t.} \\quad  &amp; i=\\text{arg} \\min_{i}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}\\\\ &amp;\\overrightarrow{\\mu}_{i} \\in C_{i} \\end{aligned}\\]        각 군집별 할당된 관측치 벡터들의 평균 벡터로 군집 중심 벡터를 갱신함\\[\\begin{aligned} \\overrightarrow{\\mu}_{i} &amp;=\\displaystyle\\frac{1}{|C_{i}|}\\sum_{\\overrightarrow{x}_{j}\\in C_{i}}{\\overrightarrow{x}_{j}} \\end{aligned}\\]        ③, ④의 과정을 반복하여 최적의 군집 중심 벡터 집합 $\\hat{M}$ 을 탐색함\\[\\begin{aligned} \\hat{M} &amp;= \\{\\overrightarrow{\\mu}_{i} \\big| \\text{arg} \\min_{\\overrightarrow{\\mu}_{i}}{\\sum_{i=1}^{k}\\sum_{\\overrightarrow{x}_{j} \\in C_{i}}{||\\overrightarrow{x}_{j}-\\overrightarrow{\\mu}_{i}||^2}}\\} \\end{aligned}\\]  sklearn.cluster.KMeansfrom sklearn.cluster import KMeansGeneral HyperParameter  random_state(default : None)Model HyperParameter      n_cluster(default : 8) : 군집 갯수    init(default : 'k-means++') : 중심점 초기화 방법          'k-means++'      'random'      callable        n_init(default : 10) : 중심점 초기화 횟수          'auto'      int            max_iter(default : 300) : 학습(Means 최소화) 최대 횟수    tol(default : 1e-4) : 허용 손실Attribute  labels_ : 각 관측치가 속한 군집 번호  cluster_centers_ : 군집별 중심점 위치  n_iter_ : 중심점 이동 횟수  inertia_ : 군집별 Means 평균으로서 수치가 낮을수록 응집도가 높다고 판단함이미지 출처  https://ai-times.tistory.com/158  https://github.com/pilsung-kang/multivariate-data-analysis/blob/master/09%20Clustering/09-2_K-Means%20Clustering.pdf  https://github.com/lovit/python_ml_intro/blob/master/lecture_notes/10_clustering.pdf  https://paulvanderlaken.com/2018/12/12/visualizing-the-inner-workings-of-the-k-means-clustering-algorithm/"
  },
  
  {
    "title": "What? Clustering",
    "url": "/posts/Clustering/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Clustering, Metric",
    "date": "2024-01-12 00:00:00 +0900",
    





    
    "snippet": "What? Cluster AnalysisCluster Analysis      정의 : 표본을 관측치 간 유사성과 상이성을 계산하여 k개의 군집으로 분할하는 작업          Cluster analysis or clustering is the task of grouping a set of objects in such a way that object...",
    "content": "What? Cluster AnalysisCluster Analysis      정의 : 표본을 관측치 간 유사성과 상이성을 계산하여 k개의 군집으로 분할하는 작업          Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. (by.Wikipedia)            목표 : 군집 내 응집도 최대화 및 군집 간 분리도 최대화            판별 분석과 비교              판별 분석(Classification Analysis)                  학습 방식 : 지도학습(훈련 관측치의 정답 정보를 사전에 알고 있음)          학습 목표 : $X$ 와 $Y$ 의 관계를 나타내는 함수를 탐색함                    군집 분석(Cluster Analysis)                  학습 방식 : 비지도학습(훈련 관측치의 정답 정보를 사전에 알 수 없거나 존재하지 않음)          학습 목표 : 주어진 표본을 분할하는 여러 개의 군집을 탐색함                    구분      관측치 중복 여부에 따른 구분              Hard(or Crisp) Clustering : 관측치가 하나의 군집에만 할당됨      Soft(or Fuzzy) Clustering : 관측치가 여러 개의 군집에 할당될 수 있음            군집 간 위계 여부에 따른 구분              Partitional Clustering : 군집 간 위계가 존재하지 않음      Hierarchical Clustering : 군집 간 위계가 존재함      Metrics군집화 유효성 평가 기준  External : 정답 정보와의 비교          Rand Statistic      Jaccard Coefficient      Folks and Mallows Index      Hurbert $\\Gamma$ Statistic      V-Measure        Internal : 군집 내 응집도          Cophenetic Correlation Coefficient      Sum of Squared Error(SSE)      Cohesion and Separation        Relative : 군집 간 분리도          Dunn Family of Indices      Davies-Bouldin Index      Semi-partial R-squared      SD Validity Index      Silhouette      External Metrics      V-Measure : 정확성과 완전성의 조화평균\\[\\begin{aligned}  \\text{V}  &amp;= 2\\times\\frac{H(C|K) \\cdot C(K|C)}{H(C|K) + C(K|C)}  \\end{aligned}\\]          $H(C \\vert K)$ : 정확성(Homogeneity)      $C(K \\vert C)$ : 완전성(Completeness)            정확성(Homogeneity) : 각 군집의 클래스에 대한 엔트로피 합계\\[\\begin{aligned}  H(C|K)  &amp;= -\\sum_{k=1}^{K}{\\sum_{c=1}^{C}{P(c|k) \\cdot \\log{P(c|k)}}}  \\end{aligned}\\]          $k$ : 군집 번호      $c$ : 클래스 번호      $P(c \\vert k)$ : 군집 $K=k$ 가 주어졌을 때, 클래스 $C=c$ 가 발생할 가능성            완전성(Completeness) : 각 클래스의 군집에 대한 엔트로피 합계\\[\\begin{aligned}  C(K|C)  &amp;= -\\sum_{c=1}^{C}{\\sum_{k=1}^{K}{P(k|c) \\cdot \\log{P(k|c)}}}  \\end{aligned}\\]          $P(k \\vert c)$ : 클래스 $C=c$ 가 주어졌을 때, 군집 $K=k$ 가 발생할 가능성      Internal Metrics      Sum of Squared Error(SSE) : 각 군집의 중심점 벡터와 해당 군집 내 관측치 벡터 간 거리 자승으로 측정한 군집 응집도\\[\\begin{aligned}  \\text{SSE}  &amp;= \\sum_{k=1}^{K}{\\sum_{\\overrightarrow{x}_{i} \\in C_{k}}{||\\overrightarrow{x}_{i}-\\overrightarrow{\\mu}_{k}||^2}}  \\end{aligned}\\]          $k$ : 군집 번호      $C_{k}$ : $k$ 번째 군집      \\(\\overrightarrow{x}_{i} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 $i$ 번째 관측치 벡터      \\(\\overrightarrow{\\mu}_{k} \\in C_{k}\\) : 군집 \\(C_{k}\\) 의 중심 벡터      Relative Metrics      Dunn Index : 군집 내 응집도(Cohesion) 최대값 대비 군집 간 분리도(Separation) 최소값 비율\\[\\begin{aligned}  \\text{DI}  &amp;= \\frac{\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}}{\\max_{1 \\le k \\le K}{\\Delta(C_{k})}}  \\end{aligned}\\]          $\\min_{1 \\le i \\ne j \\le K}{d_{C}(C_{i},C_{j})}$ : 군집 간 분리도 최소값으로서 분리도에 대한 최악의 경우      $\\max_{1 \\le k \\le K}{\\Delta(C_{k})}$ : 군집 내 응집도 최대값으로서 응집도에 대한 최악의 경우            실루엣 계수(Silhouette) : 군집 내 응집성(cohesion)과 군집 간 분리도(separation)를 종합적으로 고려하여 측정한 개별 관측치 벡터에 대한 군집화 적합성의 평균값\\[\\begin{aligned}  \\text{S}  &amp;= \\frac{1}{n}\\sum_{i=1}^{n}{\\frac{b(\\overrightarrow{x}_{i})-a(\\overrightarrow{x}_{i})}{\\max{[a(\\overrightarrow{x}_{i}),b(\\overrightarrow{x}_{i})]}}}  \\end{aligned}\\]          \\(a(\\overrightarrow{x}_{i})\\) : 관측치 벡터 \\(\\overrightarrow{x}_{i}\\) 기준 군집 내 응집도로서, 해당 관측치와 같은 군집에 속한 관측치와의 평균 거리      \\(b(\\overrightarrow{x}_{i})\\) : 관측치 벡터 \\(\\overrightarrow{x}_{i}\\) 기준 군집 간 분리도로서, 해당 관측치와 다른 군집에 속한 관측치와의 평균 거리 중 최소값      이미지 출처  https://www.scaler.com/topics/supervised-and-unsupervised-learning/  https://towardsdatascience.com/a-brief-introduction-to-unsupervised-learning-20db46445283  https://tyami.github.io/machine%20learning/clustering/"
  },
  
  {
    "title": "tSNE",
    "url": "/posts/tSNE/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2024-01-11 00:00:00 +0900",
    





    
    "snippet": "What? t-SNEStochastic Neighbor Embedding      정의 : 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소      t-distributed Stochastic Neighbor Embedding      SNE의 문제점 : Crowding Problem              ...",
    "content": "What? t-SNEStochastic Neighbor Embedding      정의 : 관측치 간 고차원 공간 상 확률적 유사도를 보존하면서 저차원으로 매핑하는 비선형 차원 축소      t-distributed Stochastic Neighbor Embedding      SNE의 문제점 : Crowding Problem              가우시안 분포는 양쪽 꼬리 부분이 충분히 두텁지 않은 형태를 보임      즉, 확률변수 \\(\\Vert \\overrightarrow{x}_{i}-\\overrightarrow{x}_{j} \\Vert\\) 가 일정한 값 이상부터는 유사도에 큰 차이가 없음            t-SNE의 해결책 : Student t-Dristribution    \\[\\begin{aligned}  T  &amp;= \\frac{Z}{\\sqrt{\\displaystyle\\frac{V}{\\nu}}}\\\\  V  &amp;= \\sum_{i=1}^{k}{Z_{i}^{2}}  \\end{aligned}\\]          $Z$ : 표준 가우시안 분포      $V$ : 자유도가 $\\nu$ 인 카이제곱 분포      수학적 이해두 관측치의 고차원 공간 상 유사도 도출      확률변수 $X$ 가 가우시안 분포 $N(\\mu, \\sigma^{2})$ 을 따른다고 했을 때, $X$ 의 확률밀도함수는 다음과 같음\\[\\begin{aligned}  f(x)  &amp;= \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\left[-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right]}  \\end{aligned}\\]        관측치 \\(\\overrightarrow{x}_{i}\\) 로부터의 거리에 대한 \\(\\overrightarrow{x}_{i}\\) 와의 유사도의 가우시안 분포에 기초했을 때, \\(\\overrightarrow{x}_{j}\\) 가 \\(\\overrightarrow{x}_{i}\\) 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  p_{j|i}   = \\frac{\\exp{\\left[-\\frac{||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}||^{2}}{2\\sigma^{2}}\\right]}}{\\sum_{k \\ne i}{\\exp{\\left[-\\frac{||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{k}||^{2}}{2\\sigma^{2}}\\right]}}}\\\\\\\\  ||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|| \\sim N_{i}(0,\\sigma^{2})  \\end{aligned}\\]        또한 관측치 \\(\\overrightarrow{x}_{j}\\) 로부터의 거리에 대한 \\(\\overrightarrow{x}_{j}\\) 와의 유사도의 가우시안 분포에 기초했을 때, \\(\\overrightarrow{x}_{i}\\) 가 \\(\\overrightarrow{x}_{j}\\) 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  p_{i|j}  = \\frac{\\exp{\\left[-\\frac{|\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|^{2}}{2\\sigma^{2}}\\right]}}{\\sum_{k \\ne j}{\\exp{\\left[-\\frac{|\\overrightarrow{x}_{j}-\\overrightarrow{x}_{k}|^{2}}{2\\sigma^{2}}\\right]}}}\\\\\\\\  ||\\overrightarrow{x}_{i}-\\overrightarrow{x}_{j}|| \\sim N_{j}(0,\\sigma^{2})  \\end{aligned}\\]        두 가능성은 서로 다른 확률 분포에 기초하고 있으므로 그 값이 반드시 일치한다고 볼 수 없음\\[p_{j|i} \\ne p_{i|j}\\]        따라서 \\(\\overrightarrow{x}_{i}\\) 와 \\(\\overrightarrow{x}_{j}\\) 의 유사도를 다음과 같이 정의함\\[\\begin{aligned}  p_{i,j}  &amp;= \\frac{p_{j|i} + p_{i|j}}{2n}  \\end{aligned}\\]  두 관측치의 2차원 공간 상 유사도 도출      관측치 \\(\\overrightarrow{y}_{i}\\) 로부터의 거리에 대한 \\(\\overrightarrow{y}_{i}\\) 와의 유사도의 가우시안 분포에 기초했을 때, \\(\\overrightarrow{y}_{j}\\) 가 \\(\\overrightarrow{y}_{i}\\) 와 유사할 가능성을 다음과 같이 정의하자\\[\\begin{aligned}  q_{j|i}   = \\frac{\\exp{\\left[-||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{j}||^{2}\\right]}}{\\sum_{k \\ne i}{\\exp{\\left[-||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{k}||^{2}\\right]}}}\\\\\\\\  ||\\overrightarrow{y}_{i}-\\overrightarrow{y}_{j}|| \\sim N_{i}(0,\\sigma^{2})  \\end{aligned}\\]          \\(\\overrightarrow{y}\\) : 고차원 공간 상의 관측치 벡터 \\(\\overrightarrow{x}\\) 를 2차원 공간 상에 매핑한 벡터            \\(\\overrightarrow{y}_{i}\\) 와 \\(\\overrightarrow{y}_{j}\\) 의 유사도를 다음과 같이 정의함\\[\\begin{aligned}  q_{i,j}  &amp;= \\frac{q_{j|i} + q_{i|j}}{2n}  \\end{aligned}\\]  비용함수를 최소화하는 아규먼트 도출      KL(Kullback-Leibler Divergence) : 확률변수 $X$ 의 동일한 아규먼트 $x_{i}$ 에 대하여 두 확률 분포 $P,Q$ 의 차이를 측정하는 지표\\[\\text{KL}(P|Q)  = \\sum_{i=1}^{n}{P(X=x_{i})\\cdot\\log{\\frac{P(X=x_{i})}{Q(X=x_{i})}}}\\]        KL에 기초한 비용함수 정의\\[\\begin{aligned}  Cost  &amp;= \\sum_{i}{\\text{KL}(P_{i}|Q_{i})}\\\\  &amp;= \\sum_{i}{\\sum_{j}{p_{i,j}\\cdot\\log{\\frac{p_{i,j}}{q_{i,j}}}}}  \\end{aligned}\\]        $\\hat{\\mathbf{Y}}$ 도출\\[\\begin{aligned}  \\hat{\\mathbf{Y}}  &amp;= \\{\\hat{\\overrightarrow{y}}_{i}|\\text{arg} \\min_{\\overrightarrow{y}_{i}}{Cost}\\}  \\end{aligned}\\]  sklearn.manifold.TSNEfrom sklearn.manifold import TSNEGeneral HyperParameter  random_state = None  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter  n_components(default : 2) : 축소할 차원의 갯수  metric(default : 'euclidean') : 관측치 간 기하 거리 측정 방법  perplexity(default : 30.0) : 참조할 Nearest Neighbors 갯수로서 5~50 사이의 값을 권장함  early_exaggeration(default :12.0) : perplexity 에 기초하여 형성된 군집 간 거리Learning Task HyperParameter  learning_rate(default : 'auto') : 학습률  n_iter(default : 1000) : 다양체 탐색 횟수로서 250 이상의 값을 권장함  n_iter_without_progress(default : 300) : 손실 함수가 몇 번 이상 개선되지 않을 경우 학습을 중단할 것인가"
  },
  
  {
    "title": "PCA & LDA",
    "url": "/posts/PCA_LDA/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2024-01-10 00:00:00 +0900",
    





    
    "snippet": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &...",
    "content": "PrerequisiteProjection      벡터 $\\overrightarrow{a}$ 를 벡터 $\\overrightarrow{b}$ 에 정사영했을 때, 정사영 벡터 $\\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})$ 는 다음과 같음\\[\\begin{aligned}  \\cos{90^{\\circ}}  &amp;= \\frac{(\\overrightarrow{a}-p\\overrightarrow{b})^{T}\\overrightarrow{b}}{||\\overrightarrow{a}||\\cdot||\\overrightarrow{b}||}\\\\  &amp;= 0\\\\  \\therefore \\text{proj}_{\\overrightarrow{b}}(\\overrightarrow{a})  &amp;= p\\overrightarrow{b}\\\\  &amp;= \\left(\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{||\\overrightarrow{b}||^{2}}\\right)\\overrightarrow{b}  \\end{aligned}\\]          $p=\\displaystyle\\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{\\Vert\\overrightarrow{b}\\Vert^{2}}$ : 정사영 벡터의 크기      $\\overrightarrow{b}$ : 정사영 벡터의 방향      Covariance Matrix      공분산(Covariance) : 두 확률변수의 선형관계를 나타내는 지표로서, 두 확률변수의 편차(관측치와 평균 사이 거리)를 곱한 값의 평균\\[\\sigma_{XY} = \\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_X)(Y_{i}-\\mu_Y)\\]        공분산행렬(Covariance Matrix) : $n$ 개 변수들 간 공분산을 나열한 $n \\times n$ 정방행렬\\[\\Sigma=  \\begin{matrix}  &amp; \\overrightarrow{A} &amp; \\overrightarrow{B} &amp; \\overrightarrow{C} \\\\  \\overrightarrow{A} &amp; \\sigma_{A}^2 &amp; \\sigma_{AB} &amp; \\sigma_{AC} \\\\  \\overrightarrow{B} &amp; \\sigma_{BA} &amp; \\sigma_{B}^2 &amp; \\sigma_{BC} \\\\  \\overrightarrow{C} &amp; \\sigma_{CA} &amp; \\sigma_{CB} &amp; \\sigma_{C}^2  \\end{matrix}\\]  Linear Transformation      행렬 $\\mathbf{X}$ 을 통한 선형변환은 어떤 좌표를 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계에서 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계로 변환하는 것을 의미함\\[\\begin{aligned}  \\mathbf{X}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix} \\overrightarrow{x}_{1}&amp;\\overrightarrow{x}_{2} \\end{pmatrix}  \\end{aligned}\\]        벡터 $\\overrightarrow{v}$ 는 \\(\\begin{pmatrix}1\\\\0\\end{pmatrix},\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 를 나타냄\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= -1\\begin{pmatrix}1\\\\0\\end{pmatrix} + 2\\begin{pmatrix}0\\\\1\\end{pmatrix}\\\\  \\end{aligned}\\]        $\\mathbf{X}$ 를 통한 선형 변환 결과 \\(\\overrightarrow{v}\\) 는 \\(\\overrightarrow{x}_{1},\\overrightarrow{x}_{2}\\) 를 기저로 사용하는 2차원 좌표계의 좌표 $(-1,2)$ 로 변환되었음\\[\\begin{aligned}  \\mathbf{X}\\cdot\\overrightarrow{v}  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\cdot \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\\\  &amp;= \\begin{pmatrix}-5\\\\2\\end{pmatrix}\\\\  &amp;= -1\\overrightarrow{x}_{1} + 2\\overrightarrow{x}_{2}  \\end{aligned}\\]  Eigen-Vector      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A_n$ 으로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 $\\overrightarrow{0}$ 이 아닌 벡터\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]        고유값(Eigen-Value; $\\lambda$) : 고유벡터의 선형변환 전 크기 대비 선형변환 후 크기의 비율  PCAPrincipal Component Analysis      정의 : 고차원 데이터에 대하여, X의 방향적 분포를 가장 잘 설명하는 새로운 저차원 직교 좌표를 학습하는 기법              주성분(Principal Component; PC) : 새로운 저차원 직교 좌표            방법 : 관측치 간 상대적 특성을 잘 보존하는 성분들을 추출함              $\\text{component}$ : 주성분 벡터 $\\overrightarrow{w}$      $\\text{datapoint}$ : 관측치 벡터 $\\overrightarrow{x}\\in \\mathbf{X}$      $\\text{projected data}$ : 주성분 벡터에 대한 관측치 벡터의 정사영 벡터 $\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{x})$      $D_{1}$ : 관측치 벡터에 대하여 보존하는 정보로서 분산      $D_{2}$ : 관측치 벡터에 대하여 유실하는 정보      $D_{3}$ : 관측치 벡터의 본래 정보      주성분 도출 과정의 이해      관측치 행렬 $X_{N \\times P}$ 를 단위벡터 $\\overrightarrow{w}$ 에 정사영한다고 하자\\[\\begin{aligned}  proj_{\\overrightarrow{w}}(\\mathbf{X})  &amp;= \\frac{&lt;\\mathbf{X},\\overrightarrow{w}&gt;}{||w||^2}\\cdot\\overrightarrow{w}\\\\  &amp;= (\\overrightarrow{w}^{T}\\mathbf{X})\\cdot\\overrightarrow{w}(\\because ||w||=1)  \\end{aligned}\\]          $\\overrightarrow{w}$ : 정사영 벡터의 방향      $\\overrightarrow{w}^{T}\\mathbf{X}$ : 정사영 벡터의 크기            $\\overrightarrow{w}$ 에 정사영된 관측치들의 분산 $\\mathbf{V}$ 은 다음과 같음\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w})\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}  \\end{aligned}\\]          $\\Sigma=\\displaystyle\\frac{1}{n}\\mathbf{X}\\mathbf{X}^{T}$ : 관측치 행렬 $X$ 의 공분산 행렬            $\\mathbf{V}$ 을 최대화하는 $\\overrightarrow{w}$ 를 채택한다고 하자\\[\\hat{\\overrightarrow{w}}  = \\text{arg} \\max_{\\overrightarrow{w}}{\\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}}  \\quad \\text{s.t.} \\quad  \\overrightarrow{w}^{T}\\overrightarrow{w}=1\\]        라그랑주 승수법에 기초하여 $\\hat{\\overrightarrow{w}}$ 도출\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\overrightarrow{w}}  &amp;= \\Sigma\\overrightarrow{w}-\\lambda\\overrightarrow{w}\\\\  &amp;= 0\\\\\\\\  \\therefore (\\Sigma-\\lambda\\mathbf{I})\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]        $\\mathbf{V}$ 를 최대화하는 주성분 $\\overrightarrow{w}$ 은 $\\mathbf{X}$ 의 공분산 행렬 $\\Sigma$ 의 고유벡터임\\[\\begin{aligned}  \\Sigma  &amp;= \\mathbb{V}\\mathbb{\\Lambda}\\mathbb{V}^{-1},\\\\  \\mathbb{V}  &amp;= \\begin{pmatrix}\\overrightarrow{w}_{1}&amp;\\overrightarrow{w}_{2}&amp;\\cdots&amp;\\overrightarrow{w}_{p}\\end{pmatrix}\\\\  \\mathbb{\\Lambda}  &amp;= \\text{diag}(\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{p})  \\end{aligned}\\]  주성분 벡터의 설명력 이해      주성분 벡터의 고유값 : 관측치 행렬 $\\mathbf{X}$ 에 대하여 주성분 벡터에 대한 정사영 벡터 간 분산\\[\\begin{aligned}  \\mathbf{V}  &amp;= \\frac{1}{n}(\\overrightarrow{w}^{T}\\mathbf{X})(\\overrightarrow{w}^{T}\\mathbf{X})^{T}\\\\  &amp;= \\frac{1}{n}\\overrightarrow{w}^{T}\\mathbf{X}\\mathbf{X}^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\Sigma\\overrightarrow{w}\\\\  &amp;= \\hat{\\overrightarrow{w}}^{T}\\lambda\\hat{\\overrightarrow{w}}(\\because \\Sigma\\hat{\\overrightarrow{w}}-\\lambda\\hat{\\overrightarrow{w}}=0)\\\\  &amp;= \\lambda(\\because \\overrightarrow{w}^{T}\\overrightarrow{w}=1)  \\end{aligned}\\]        주성분 벡터의 설명력 : 관측치 행렬 $\\mathbf{X}_{N \\times P}$ 에 대하여 생성 가능한 $P$ 개의 주성분 벡터 고유값 합계 대비 해당 주성분 벡터 고유값 비율\\[\\frac{\\lambda_{k}}{\\sum_{i=1}^{p}{\\lambda_{i}}}\\]  LDALinear Discriminant Analysis      정의 : 고차원 데이터에 대하여, 주어진 클래스를 가장 잘 구분할 수 있는 새로운 저차원 직교 좌표를 찾는 기법            방법 : 클래스 간 분산은 최대화하는 동시에 클래스 내 관측치 간 분산은 최소화하는 성분들을 추출함\\[\\hat{\\overrightarrow{w}}  =\\text{arg} \\max_{\\overrightarrow{w}}{\\frac{\\Sigma^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}}  \\quad \\text{s.t.} \\quad  \\overrightarrow{w}^{T}\\overrightarrow{w}=1\\]          $\\Sigma^{2}$ : 정사영 후 클래스 간 분산      $\\sigma_{i}^{2}$ : 정사영 후 $i$ 번째 클래스 내 관측치 간 분산      선형 판별 함수 도출 과정의 이해      정사영 후 범주 간 분산 $\\Sigma^{2}$\\[\\begin{aligned}  \\Sigma^{2}  &amp;= (\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})(\\overrightarrow{\\mu}_{1}-\\overrightarrow{\\mu}_{2})^{T}\\\\  &amp;= (\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})(\\overrightarrow{w}^{T}\\overrightarrow{m}_{1}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{2})^{T}\\quad(\\because \\overrightarrow{\\mu}_{i}=\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})\\\\  &amp;= \\overrightarrow{w}^{T}(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})(\\overrightarrow{m}_{1}-\\overrightarrow{m}_{2})^{T}\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}  \\end{aligned}\\]          \\(\\overrightarrow{m}_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 중심점 벡터      \\(\\overrightarrow{\\mu}_{i}=\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{m}_{i})\\) : \\(\\overrightarrow{m}_{i}\\) 의 정사영 벡터      \\(\\mathbf{S}_{B}\\) : 범주 \\(C_{i},C_{j}\\) 간 편차      \\(\\Sigma\\) : 정사영 후 범주 \\(C_{i},C_{j}\\) 간 편차            정사영 후 범주 내 분산 $\\sigma_{i}^{2}$\\[\\begin{aligned}  \\sigma_{i}^{2}  &amp;= \\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})(\\overrightarrow{y}_{j}-\\overrightarrow{\\mu}_{i})^{T}}\\quad(\\overrightarrow{x}_{j} \\in C_{i})\\\\  &amp;= \\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})(\\overrightarrow{w}^{T}\\overrightarrow{x}_{j}-\\overrightarrow{w}^{T}\\overrightarrow{m}_{i})^{T}}\\quad(\\because \\overrightarrow{y}_{j}=\\overrightarrow{w}^{T}\\overrightarrow{x}_{j})\\\\  &amp;= \\overrightarrow{w}^{T}\\left[\\sum_{j=1}^{|C_{i}|}{(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})(\\overrightarrow{x}_{j}-\\overrightarrow{m}_{i})^{T}}\\right]\\overrightarrow{w}\\\\  &amp;= \\overrightarrow{w}^{T}\\mathbf{S}_{i}\\overrightarrow{w}  \\end{aligned}\\]          \\(\\overrightarrow{x}_{j} \\in C_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 \\(j\\) 번째 관측치 벡터      \\(\\overrightarrow{y}_{j}=\\text{proj}_{\\overrightarrow{w}}(\\overrightarrow{x}_{j})\\) : \\(\\overrightarrow{x}_{j}\\) 의 정사영 벡터      \\(S_{i}\\) : \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차      \\(\\sigma_{i}\\) : 정사영 후 \\(i\\) 번째 범주 \\(C_{i}\\) 의 범주 내 관측치 간 편차            목적 함수 재정의\\[\\hat{\\overrightarrow{w}}  =\\text{arg} \\max_{\\overrightarrow{w}}{\\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}}\\\\  \\begin{aligned}  \\\\\\text{s.t.} \\quad  &amp; \\overrightarrow{w}^{T}\\overrightarrow{w}=1  \\end{aligned}\\]        라그랑주 승수법을 통한 최적화 문제 풀이\\[\\begin{aligned}  L(\\overrightarrow{w},\\lambda)  &amp;= \\frac{\\overrightarrow{w}^{T}\\mathbf{S}_{B}\\overrightarrow{w}}{\\overrightarrow{w}^{T}(\\mathbf{S}_{1}+\\mathbf{S}_{2})\\overrightarrow{w}}-\\lambda(\\overrightarrow{w}^{T}\\overrightarrow{w}-1)\\\\\\\\  \\frac{\\partial L(\\overrightarrow{w},\\lambda)}{\\partial \\overrightarrow{w}}  &amp;= 0\\\\\\\\  \\therefore \\left[\\mathbf{S}_{B}^{-1}(\\mathbf{S}_{1}+\\mathbf{S}_{2})-\\lambda\\mathbf{I}\\right]\\hat{\\overrightarrow{w}}  &amp;=0  \\end{aligned}\\]  sklearn.decomposition.PCAfrom sklearn.decomposition import PCAGeneral HyperParameter  random_state = NoneModel HyperParameter  n_components(default : 5) : 축소할 차원의 개수  whiten(default : False) : Standard Scaling 여부Attribute  n_features_ : 축소 전 차원의 개수  feature_names_in_ : 축소 전 차원명  mean_ : 축소 전 차원별 평균  n_components_ : 축소 후 차원의 개수  components_ : 고유벡터  explained_variance_ : 각 고유벡터의 고유값  explained_variance_ratio_ : 전체 고유벡터의 고유값 대비 각 고유벡터의 고유값이미지 출처  http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/  https://github.com/lovit/python_ml_intro"
  },
  
  {
    "title": "Curse of Dimensionality",
    "url": "/posts/Curse_of_Dimensionality/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Unsupervised Learning, Feature Engineering",
    "date": "2024-01-09 00:00:00 +0900",
    





    
    "snippet": "Curse of Dimensionality차원의 저주      정의 : 고차원일수록 알고리즘이 제대로 학습하지 못하는 현상              관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해짐            차원 축소의 당위성              Manifold hypothesis      Many hig...",
    "content": "Curse of Dimensionality차원의 저주      정의 : 고차원일수록 알고리즘이 제대로 학습하지 못하는 현상              관측치 간 거리가 기하급수적으로 멀어짐에 따라 차원별 학습 가능한 관측치가 희소해짐            차원 축소의 당위성              Manifold hypothesis      Many high-dimensional data sets that occur in the real world actually lie along low-dimensional latent manifolds inside that high-dimensional space.      차원 축소 기법의 종류  차원 선택(Feature Selection) : 유효한 차원을 선별하는 방법                  Filter Approach                    Wrapper Approach                  Forward Selection          Backward Elimination          Stepwise Selection                      차원 추출(Feature Extraction) : 원본의 특징을 보존하는 새로운 차원을 추출하는 방법          $\\text{arg} \\max_{\\overrightarrow{w}}{\\sigma^{2}}$                  주성분 분석(Principle Component Analysis; PCA)          선형 판별 분석(Linear Discriminant Analysis; LDA)                    $\\text{arg} \\max_{\\overrightarrow{w}}{dist}$                  다차원 척도법(Multi-Dimensional Scaling; MDS)                    Reveal Non-Linear Structure                  t-SNE(t-distributed Stochastic Neighbor Embedding)          LLE(Locally Linear Embedding)          ISOMAP(ISOmetric feature MAPping)                    Feature Selection  Occam’s Razor  Entities should not be multiplied beyond necessity.Wrapper Approach      Forward Selection : 어떤 변수도 선택되지 않은 상태에서 가장 설명력이 좋은 변수를 하나씩 추가하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(x_{i})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(x_{j \\ne i};\\hat{x}_{i})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(x_{k \\ne i,j};\\hat{x}_{i},\\hat{x}_{j})]\\\\  &amp;\\vdots  \\end{aligned}\\]        Backward Elimination : 모든 변수가 포함된 상태에서 시작하여 불필요한 변수를 하나씩 제거하는 방법\\[\\begin{aligned}  \\hat{x}_{i}&amp;=\\text{arg} \\max_{x_{i}}R^2[y,f(\\not{x_{i}})]\\\\  \\hat{x}_{j}&amp;=\\text{arg} \\max_{x_{j}}R^2[y,f(\\not{x_{j \\ne i}};\\not{\\hat{x}_{i}})]\\\\  \\hat{x}_{k}&amp;=\\text{arg} \\max_{x_{k}}R^2[y,f(\\not{x_{k \\ne i,j}};\\not{\\hat{x}_{i}},\\not{\\hat{x}_{j}})]\\\\  &amp;\\vdots  \\end{aligned}\\]        Stepwise Selection : 어떤 변수도 선택되지 않은 상태에서 Forward Selection 과 Backward Elimination 을 번갈아 수행하는 방법  Metrics      Akaike Information Criteria(AIC)\\[\\begin{aligned}  \\text{AIC}  &amp;= -2\\ln{\\hat{L}}+2k  \\end{aligned}\\]                  $\\hat{L}$ : 모델 적합도로서 \\(\\overrightarrow{x}_{i}\\) 가 주어졌을 때 $y_{i}$ 가 발생할 가능성\\[\\begin{aligned}  \\hat{L}  &amp;= \\prod_{i=1}^{n}{P(Y=y_{i}|X=\\overrightarrow{x}_{i};\\hat{\\overrightarrow{\\theta}})}\\\\  \\hat{\\overrightarrow{\\theta}}  &amp;= \\begin{pmatrix}\\hat{\\beta_{0}}&amp;\\hat{\\beta_{1}}&amp;\\cdots&amp;\\hat{\\beta_{d}}\\end{pmatrix}  \\end{aligned}\\]                    $k$ : 모델 복잡도                  Bayesian Information Criteria(BIC)\\[\\begin{aligned}  \\text{BIC}  &amp;= -2\\ln{\\hat{L}}+k\\ln{n}  \\end{aligned}\\]  이미지 출처  https://www.incodom.kr/%EC%B0%A8%EC%9B%90%EC%B6%95%EC%86%8C#h_85f3fb207a586b3f9b5702a3be7799e1  http://matrix.skku.ac.kr/math4ai-intro/W12/"
  },
  
  {
    "title": "Regression",
    "url": "/posts/Regression/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Regression, Regulation, Optimization",
    "date": "2024-01-08 00:00:00 +0900",
    





    
    "snippet": "What? Regression      정의 : 반응변수와 그 설명변수 간 상관관계 추세를 요약하는 수렴 작업    설명변수의 개수에 따른 구분                  단순 회귀 모형(Simple Regression Model) : 반응변수에 대한 설명변수가 하나인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1X+\\vareps...",
    "content": "What? Regression      정의 : 반응변수와 그 설명변수 간 상관관계 추세를 요약하는 수렴 작업    설명변수의 개수에 따른 구분                  단순 회귀 모형(Simple Regression Model) : 반응변수에 대한 설명변수가 하나인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1X+\\varepsilon\\]                    다중 회귀 모형(Multiple Regression Model) : 반응변수에 대한 설명변수가 두 가지 이상인 경우(이하는 선형모형을 가정)\\[Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\cdots+\\beta_k X_k+\\varepsilon\\]              선형 가정 여부에 따른 구분          선형 회귀 모형(Linear Regression Model) : 설명변수와 반응변수 간 선형관계를 가정하는 경우                  sklearn.linear_model.LinearRegression          sklearn.linear_model.SGDRegressor                    비선형 회귀 모형(Non-Linear Regression Model) : 설명변수와 반응변수 간 선형관계를 가정하지 않는 경우                  sklearn.svm.SVR          sklearn.tree.DecisionTreeRegressor                    Linear Regression단순 선형 회귀 모형      단순 선형 회귀 모형의 이해\\[\\begin{aligned}  &amp;Y=\\beta_0+\\beta_1X+\\varepsilon\\\\  &amp;\\Rightarrow y_i=\\beta_0+\\beta_1x_i+\\varepsilon_i  \\end{aligned}\\]          $\\varepsilon$ : 잔차항(Residual)                  $E[\\varepsilon]=0$                            $\\beta_0$ : 편향(Bias)            $\\beta_1$ : 가중치(Weight)            최소자승법에 기초한 회귀계수 최적값 도출                  최소자승법(Least Square Method; OLS) : 회귀계수 최적값을 잔차항 $\\varepsilon_{i}$ 자승의 합계를 최소화하는 값으로 탐색하는 방법\\[\\begin{aligned}  \\hat{\\beta_{0}},\\hat{\\beta_{1}}  &amp;= \\text{arg} \\min_{\\beta_{0},\\beta_{1}}{L_{OLS}}  \\end{aligned}\\]                    최소자승법에 기초한 손실 함수 $L_{OLS}$\\[\\begin{aligned}  L_{OLS}  &amp;= \\sum_{i=1}^{n}{\\varepsilon_{i}^2}\\\\  \\varepsilon_{i}  &amp;= y_{i}-\\hat{y}_{i}\\\\  &amp;= y_{i}-(\\beta_{0}+\\beta_{1}\\hat{x}_{i})  \\end{aligned}\\]                    최소자승법에 기초한 회귀계수 $\\beta_{0}$ 의 최적값 $\\hat{\\beta_{0}}$\\[\\begin{aligned}  \\hat{\\beta_{0}}  &amp;= \\overline{y}-\\beta_{1}\\overline{x}  \\end{aligned}\\]                    최소자승법에 기초한 회귀계수 $\\beta_{1}$ 의 최적값 $\\hat{\\beta_{1}}$\\[\\begin{aligned}  \\hat{\\beta_{1}}  &amp;= \\frac{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})(y_{i}-\\overline{y})}}{\\sum_{i=1}^{n}{(x_{i}-\\overline{x})^{2}}}\\\\  &amp;=\\frac{\\sigma_{xy}}{\\sigma_{x}^{2}}  \\end{aligned}\\]            다중 선형 회귀 모형      관측치 $i$ 에 대한 다중 선형 회귀 모형이 다음과 같다고 하자\\[y_{i}=\\beta_{0}+\\beta_{1}x_{i,1}+\\beta_{2}x_{i,2}+\\cdots+\\beta_{d}x_{i,d}\\]          $i\\in{1,2,\\cdots,n}$ : 관측치 번호      $k\\in{1,2,\\cdots,d}$ : 설명변수 번호            $n$ 개의 관측치가 존재한다고 했을 때 위 모형을 선형대수로 표현할 수 있음\\[\\hat{\\overrightarrow{y}} = \\hat{\\mathbf{X}}\\overrightarrow{\\beta}\\]        최소자승법에 기초하여 도출한 가중치 벡터를 정규방정식(Normal Equation)이라고 정의함\\[\\begin{aligned}  \\hat{\\overrightarrow{\\beta}}  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{L_{OLS}}\\\\  &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\overrightarrow{y}  \\end{aligned}\\]  Logistic Regression      정의 : 회귀 기법을 판별분석에 활용하는 비선형 함수 알고리즘    \\[P(c=1)  = \\frac{1}{1+\\exp[-(\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d})]}\\]  Logistic Function      설명변수와 반응변수 가정                  어떠한 관측치 벡터 $\\overrightarrow{x}$ 가 다음과 같이 주어졌다고 하자\\[\\begin{aligned}  f(\\overrightarrow{x})  &amp;=\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d} \\in (-\\infty,\\infty)  \\end{aligned}\\]                    $\\overrightarrow{x}$ 의 반응변수 $y$ 는 다음과 같음\\[\\begin{aligned}  y  &amp;=c \\in \\{0,1\\}  \\end{aligned}\\]                    $y$ 와 $\\overrightarrow{x}$ 간에는 공역이 일치하지 않으므로 등식이 성립하지 않음\\[y \\ne \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}\\]                  반응변수 재정의 : 범주 $1$ 에 속할 확률\\[\\begin{aligned}  y  &amp;= P(c=1) \\in [0,1]  \\end{aligned}\\]        공역 조정을 통한 연결함수 $f(x)$ 도출                  승산(Odds) : 범주 $1$ 에 속하지 않을 확률 대비 속할 확률\\[\\begin{aligned}  f(x)  &amp;= \\text{odds}\\\\  &amp;= \\frac{P(c=1)}{1-P(c=1)} \\in [0, \\infty)  \\end{aligned}\\]                    로짓(Logit) : 승산에 자연로그를 취한 값\\[\\begin{aligned}  f(x)  &amp;= \\text{logit}\\\\  &amp;= \\ln{\\frac{P(c=1)}{1-P(c=1)}} \\in (-\\infty, \\infty)  \\end{aligned}\\]                    로짓 함수와 $\\overrightarrow{x}$ 연결\\[\\begin{aligned}  \\text{logit}  &amp;= f(x)\\\\  &amp;= \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}  \\end{aligned}\\]                  연결함수를 활용하여 재정의된 반응변수와 설명변수 연결\\[\\begin{aligned}  \\ln{\\frac{P(c=1)}{1-P(c=1)}}  &amp;= f(x)\\\\  &amp;= \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}\\\\\\\\  \\frac{P(c=1)}{1-P(c=1)}  &amp;= e^{f(x)}\\\\  &amp;= \\exp[\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d}]\\\\\\\\  \\therefore  y  &amp;= P(c=1)\\\\  &amp;= \\frac{1}{1+\\exp[-(\\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{d}x_{d})]}  \\end{aligned}\\]  가중치 규제(Weight Regulation)      p-norm : $n$ 차원 벡터 $\\overrightarrow{x}=\\begin{pmatrix}x_{1}&amp;x_{2}&amp;\\cdots&amp;x_{n}\\end{pmatrix}$ 의 크기를 정의하는 방법    \\[||x||_{p}=(|x_{1}|^{p}+|x_{2}|^{p}+\\cdots+|x_{n}|^{p})^{\\frac{1}{p}}\\]        가중치 규제(Weight Regulation) : 회귀계수 최적값을 탐색함에 있어 회귀계수 벡터 $\\overrightarrow{\\beta}$ 의 크기에 제약을 두는 것    \\[\\begin{aligned}  \\overrightarrow{\\hat{\\beta}}  &amp;= \\text{arg} \\min_{\\overrightarrow{\\beta}}{\\left[L_{OLS}+\\lambda||\\beta||_{p}^{2}\\right]}  \\end{aligned}\\]                  $L_{OLS}(\\overrightarrow{\\beta})$ : 최소자승법에 기초한 손실 함수                    $\\overrightarrow{\\beta}$ : 회귀계수 벡터                    $\\lambda$ : 회귀계수 벡터 $\\overrightarrow{\\beta}$ 크기 제약 강도                    p : 벡터 크기 정의 방법                  p=1 : LASSO          p=2 : Ridge                    경사하강법(Gradient Descent)      그라디언트(Gradient) : 다변수 함수에 대하여 모든 방향으로의 순간변화율 벡터    \\[\\begin{aligned}  \\nabla{f(x_{1},x_{2},\\cdots,x_{n})}  &amp;= \\begin{pmatrix}  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{1}}\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{2}}\\\\  \\vdots\\\\  \\displaystyle\\frac{\\partial f(x^{\\forall})}{\\partial x_{n}}\\\\  \\end{pmatrix}  \\end{aligned}\\]        경사하강법(Gradient Descent) : 회귀계수 최적값을 탐색함에 있어 손실 함수의 그라디언트를 활용하는 방법            절차          회귀계수 벡터 $\\overrightarrow{w}$ 의 초기 아규먼트 설정      현재 아규먼트 \\(\\overrightarrow{w}_{prev}\\) 에서 손실 함수의 그라디언트 \\(\\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}\\) 계산      현재의 아규먼트에서 음의 방향으로 \\(\\alpha \\times \\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}\\) 만큼 이동하여 새로운 아규먼트 \\(\\overrightarrow{w}_{new}\\) 적용      ②, ③을 반복하여 손실 함수를 최소화하는 지점 탐색            회귀계수 갱신 규칙\\[\\begin{aligned}  \\overrightarrow{w}_{new}  &amp;= \\overrightarrow{w}_{prev} - \\alpha \\times \\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}  \\end{aligned}\\]          $\\overrightarrow{w}_{prev}$ : 현재 회귀계수 아규먼트      $\\overrightarrow{w}_{new}$ : 새로운 회귀계수 아규먼트      $\\alpha$ : 학습률      $\\nabla{L_{OLS}(\\overrightarrow{w}_{prev})}$ : 최소자승법에 기초하여 도출한 손실 함수의 그라디언트            학습률(Learning Rate) : 손실 함수에 대하여 그 극소점을 탐색하기 위한 회귀계수 갱신 보폭                  학습률이 낮을수록 과대적합될 가능성이 높음                            학습률이 높을수록 과소적합될 가능성이 높음                    이미지 출처  https://medium.com/analytics-vidhya/multiple-linear-regression-an-intuitive-approach-f874f7a6a7f9  https://towardsdatascience.com/an-intuitive-explanation-of-gradient-descent-83adf68c9c33  https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html  https://observablehq.com/@petulla/l1-l2l_1-l_2l1-l2-norm-geometric-interpretation"
  },
  
  {
    "title": "Support Vector Machine",
    "url": "/posts/SVM/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-07 00:00:00 +0900",
    





    
    "snippet": "Support Vector Machine      정의 : 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘            용어의 이해              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장...",
    "content": "Support Vector Machine      정의 : 마진(Margin)을 최대로 가져가는 초평면(Hyper Plane)을 규칙으로 하여 관측치를 분류하는 알고리즘            용어의 이해              초평면(Hyper Plane) : 범주를 구분하는 경계      서포트 벡터(Support Vector) : 인접한 범주에 가장 가까이 위치한 벡터      마진(Margin) : 인접한 두 범주의 서포트 벡터를 지나는 평행한 두 직선 사이의 유클리드 거리      결정 함수 도출정의      초평면 정의\\[\\overrightarrow{w}^{T}\\overrightarrow{x}+b=0\\]          $\\overrightarrow{x}$ : 초평면 위에 위치한 벡터      $\\overrightarrow{w}$ : 초평면의 법선 벡터      $b$ : 편향으로서 세로축 절편            범주 정의\\[y_{i} = \\begin{cases}  +1,\\;if\\;\\overrightarrow{x}_{i} \\in X^{+}\\\\  -1,\\;if\\;\\overrightarrow{x}_{i} \\in X^{-}  \\end{cases}\\]        서포트 벡터 정의                  편의상 관측치 벡터 $\\overrightarrow{x}_{\\forall}$ 와 초평면 사이 거리 절대값은 최소 $1$ 이라고 하자                    좌측 서포트 벡터 $\\overrightarrow{x}^{+}$ : 범주 $X^{+}$ 에서 초평면에 가장 가까이 위치한 벡터\\[\\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=+1\\]                    우측 서포트 벡터 $\\overrightarrow{x}^{-}$ : 범주 $X^{-}$ 에서 초평면에 가장 가까이 위치한 벡터\\[\\overrightarrow{w}^{T}\\overrightarrow{x}^{-}+b=-1\\]            마진 도출      우측 서포트 벡터 $\\overrightarrow{x}^{-}$ 에 대하여 방향 $\\overrightarrow{w}$ 으로 크기 $margin$ 만큼 이동하면 좌측 서포트 벡터 $\\overrightarrow{x}^{+}$ 에 안착한다고 하자\\[\\overrightarrow{x}^{+} = \\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w}\\]        $\\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=1$ 을 다음과 같이 재정의할 수 있음\\[\\begin{aligned}  \\overrightarrow{w}^{T}\\overrightarrow{x}^{+}+b=1\\\\  \\overrightarrow{w}^{T}(\\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w})+b=1\\\\  \\overrightarrow{w}^{T}\\overrightarrow{x}^{-} + margin \\cdot \\overrightarrow{w}^{T}\\overrightarrow{w} + b = 1\\\\  (\\overrightarrow{w}^{T}\\overrightarrow{x}^{-} + b) + margin \\cdot \\overrightarrow{w}^{T}\\overrightarrow{w} = 1\\\\  -1 + margin \\cdot ||w||^2 = 1  \\end{aligned}\\]        따라서 마진을 다음과 같이 도출할 수 있음\\[margin = \\frac{2}{||w||^2}\\]  마진 최대화  최적화 문제 정의                  목적 함수\\[\\max{\\frac{2}{||w||^2}}  \\Rightarrow \\min{\\frac{1}{2}||w||^2}\\]                    제약 조건\\[y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1\\]                  라그랑주 함수 도출\\[\\begin{aligned}  L(w,b,\\lambda)&amp;=\\frac{1}{2}||w||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}  \\end{aligned}\\]          $\\lambda_{i}\\ge0$ : 라그랑주 승수        KKT 조건 하 라그랑주 듀얼 함수로 변환                  목적 함수\\[\\begin{aligned}  g(\\lambda) &amp;= \\inf_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}{\\min_{w,b}{L(w,b,\\lambda)}}  \\end{aligned}\\]                    제약 조건 ($\\because$ Complementary Slackness, KKT)\\[\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}=0\\]                  서포트 벡터 : \\(y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b = 1\\))          그 외 벡터 : \\(\\lambda_{i \\notin SV}=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\notin SV}+b &gt; 1\\))                          라그랑주 듀얼 함수 풀이                  $\\overrightarrow{w}$, $b$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial L(w,b,\\lambda)}{\\partial w}  &amp;= \\overrightarrow{w} - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  &amp;= 0\\\\  \\therefore \\overrightarrow{w}^{*}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\\\\\  \\frac{\\partial L(w,b,\\lambda)}{\\partial b}  &amp;= 0 - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}\\\\  &amp;= 0\\\\  \\therefore \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}   &amp;= 0  \\end{aligned}\\]                    편미분한 결과를 라그랑주 듀얼 함수에 대입\\[\\begin{aligned}  \\frac{1}{2}||w^{*}||^2  &amp;= \\frac{1}{2}\\overrightarrow{w}^{*}\\cdot\\overrightarrow{w}^{*}\\\\  &amp;= \\frac{1}{2}\\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}} \\cdot \\sum_{j=1}^{n}{\\lambda_{j}y_{j}\\overrightarrow{x}_{j}}\\\\  &amp;= \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}^{T}\\overrightarrow{x}_{j}}\\\\\\\\  \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}} + b\\sum_{i=1}^{n}{\\lambda_{i}y_{i}} - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}(\\sum_{j=1}^{n}\\lambda_{j}y_{j}\\overrightarrow{x}_{j})\\overrightarrow{x}_{i}} + b \\cdot 0 - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\  &amp;= \\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}\\overrightarrow{x}_{j}} - \\sum_{i=1}^{n}{\\lambda_{i}}\\\\\\\\  \\therefore g(\\lambda)  &amp;= \\inf_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}\\min_{w,b}{L(w,b,\\lambda)}\\\\  &amp;= \\max_{\\lambda}{L(\\lambda)}\\\\  &amp;= \\max_{\\lambda}{\\left[\\frac{1}{2}||w^{*}||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\cdot\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b)-1\\}}\\right]}\\\\  &amp;= \\max_{\\lambda}{\\left[\\sum_{i=1}^{n}{\\lambda_{i}} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\lambda_{i}\\lambda_{j}y_{i}y_{j}\\overrightarrow{x}_{i}^{T}\\overrightarrow{x}_{j}}\\right]}  \\end{aligned}\\]            서포트 벡터 도출      마진을 최대화하는 법선 벡터 $\\overrightarrow{w}^{*}$\\[\\overrightarrow{w}^{*}  = \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\]    마진을 최대화하는 편향 $b^{*}$          라그랑주 듀얼 함수의 제약 조건 ($\\because$ Complementary Slackness, KKT)                  서포트 벡터 : \\(y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\) (\\(\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b = 1\\))          그 외 벡터 : $\\lambda_{i \\notin SV}=0$ ($\\because \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\notin SV}+b &gt; 1$)                            마진을 구함에 있어 그 외 벡터는 필요하지 않음\\[y_{i \\in SV}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}+b)-1=0\\]                    따라서 마진을 최대화하는 서포트 벡터의 편향 $b^{*}_{SV}$ 을 다음과 같이 도출할 수 있음\\[\\begin{aligned}  b^{*}  &amp;= y_{i \\in SV} - \\overrightarrow{w}^{T}\\overrightarrow{x}_{i \\in SV}\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}{\\left[y_{i} - \\overrightarrow{w}^{T}\\overrightarrow{x}_{i}\\right]}\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}{\\left[y_{i} - \\left(\\sum_{j \\in SV}{\\lambda_{j}y_{j}\\overrightarrow{x}_{j}}\\right)\\overrightarrow{x}_{i}\\right]}\\;(\\because \\overrightarrow{w}^{*}=\\sum_{i}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}})\\\\  &amp;= \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}  \\end{aligned}\\]                  마진을 최대화하는 서포트 벡터 $\\overrightarrow{x}_{SV} \\in SV$\\[\\begin{aligned}  SV   &amp;= \\{\\overrightarrow{x}_{SV}|\\overrightarrow{w}^{*} \\cdot \\overrightarrow{x}_{SV} + b^{*}=|1|\\}\\\\  &amp;= \\left\\{ \\overrightarrow{x}_{SV}|\\left(\\sum_{i=1}^{n}{\\lambda_{i}^{*}y_{i}\\overrightarrow{x}_{i}}\\right) \\cdot \\overrightarrow{x}_{SV} + \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}=|1| \\right\\}  \\end{aligned}\\]  요약\\[\\begin{aligned}y_{q}&amp;= \\begin{cases}+1,\\;if\\;f(\\overrightarrow{q}) &gt; 0 \\\\-1,\\;if\\;f(\\overrightarrow{q}) &lt; 0 \\\\\\end{cases}\\\\\\\\f(\\overrightarrow{q})&amp;= \\overrightarrow{w}^{*} \\cdot \\overrightarrow{q} + b^{*}\\\\&amp;= \\left(\\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\right) \\cdot \\overrightarrow{q} + \\frac{1}{|SV|}\\sum_{i \\in SV}\\sum_{j \\in SV}{\\left[y_{i} - \\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}\\end{aligned}\\]  $\\overrightarrow{q}$ : 신규 관측치 벡터  $y_{q}$ : $\\overrightarrow{q}$ 의 범주  $f(\\overrightarrow{q})$ : 결정 함수로서 초평면 $\\overrightarrow{w}^{T}\\overrightarrow{x}+b=0$ 과 벡터의 사영 거리소프트 마진      하드 마진(Hard Margin)의 문제점 : 이상 관측치가 존재하는 경우 마진을 최대화하는 초평면을 탐색하기 어려움            소프트 마진(Soft Margin)의 해결책 : 마진 위반 $\\xi$ 를 허용하여 일부 이상 관측치를 배제했을 때 마진을 최대화하는 초평면을 탐색함              마진 위반(Margin Violation; $\\xi$) : 초평면 근방에서 발생 가능한 소수의 이상 관측치에 대한 오류로서, 해당 관측치로부터 서포트 벡터를 지나고 초평면과 평행한 직선까지의 유클리드 거리      마진 위반 $\\xi$ 를 고려하는 최적화 문제 정의      하드 마진의 최적화 문제\\[\\begin{aligned}  &amp;\\min{\\frac{1}{2}||w||^2}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1  \\end{aligned}\\]        소프트 마진의 최적화 문제\\[\\begin{aligned}  &amp;\\min{\\left[\\frac{1}{2}{||w||^2}+C\\sum_{i=1}^{n}{\\xi_i}\\right]}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1-\\xi_i,\\\\  &amp;\\xi_i \\ge 0  \\end{aligned}\\]                  $\\xi_{i}$ : 관측치 벡터 $\\overrightarrow{x}_{i}$ 에 대한 마진 위반                    $C$ : 마진 위반에 대한 규제 강도                    라그랑주 승수법에 기초한 풀이      라그랑주 함수 도출\\[\\begin{aligned}  L(w,b,\\lambda,\\xi,\\mu)  = &amp;\\left[\\frac{1}{2}||w||^2 - \\sum_{i=1}^{n}{\\lambda_{i}\\{y_{i}(\\overrightarrow{w}^{T}+b)-(1-\\xi_{i})\\}}\\right]\\\\  &amp;+ \\left[C\\sum_{i=1}^{n}{\\xi_{i}}-\\sum_{i=1}^{b}{\\mu_{i}\\xi_{i}}\\right]  \\end{aligned}\\]          $\\lambda \\ge 0$ : 제약 조건 $y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}+b) \\ge 1-\\xi_{i}$ 에 대한 라그랑주 승수      $\\mu \\ge 0$ : 제약 조건 $\\xi_{i} \\ge 0$ 에 대한 라그랑주 승수            KKT 조건 하 라그랑주 듀얼 함수 도출\\[\\begin{aligned}  g(\\lambda,\\mu)  &amp;= \\inf_{w,b,\\xi}{L(w,b,\\lambda,\\xi,\\mu)}\\\\  &amp;= \\max_{\\lambda,\\mu}{\\min_{w,b,\\xi}{L(w,b,\\lambda,\\xi,\\mu)}}\\\\\\\\  \\quad \\text{s.t.} \\quad &amp;\\lambda_{i}\\{y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}+b)-(1-\\xi_{i})\\}=0,\\\\  &amp;\\mu_{i}\\xi_{i}=0  \\end{aligned}\\]        $\\overrightarrow{w}$,$b$,$\\xi$ 에 대하여 편미분\\[\\begin{aligned}  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial w}  &amp;= \\overrightarrow{w} - \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  &amp;= 0\\\\\\\\  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial b}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}\\\\  &amp;= 0\\\\\\\\  \\frac{\\partial L(w,b,\\lambda,\\xi,\\mu)}{\\partial \\xi}  &amp;= C-\\lambda_{i}-\\mu_{i}\\\\  &amp;= 0\\\\\\\\  \\therefore \\overrightarrow{w}^{*}  &amp;= \\sum_{i=1}^{n}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}},\\\\  \\sum_{i=1}^{n}{\\lambda_{i}y_{i}}  &amp;= 0,\\\\  \\mu_{i}  &amp;= C - \\lambda_{i}  \\end{aligned}\\]        위 결과를 라그랑주 듀얼 함수에 대입하여 \\(\\overrightarrow{w}^{*}\\), \\(b^{*}\\) 도출\\[\\begin{aligned}  \\overrightarrow{w}^{*}  &amp;= \\sum_{i \\in SV}{\\lambda_{i}y_{i}\\overrightarrow{x}_{i}}\\\\  b^{*}  &amp;= \\sum_{i \\in SV}{\\sum_{j \\in SV}{\\left[y_{i}-\\lambda_{j}y_{j}\\overrightarrow{x}_{j}\\overrightarrow{x}_{i}\\right]}}  \\end{aligned}\\]  Kernel Trick      정의 : 선형으로는 구분하기 어려운 저차원 공간상의 데이터 세트를, 적절한 결정 경계를 찾을 수 있는 고차원 공간으로 매핑하는 기법      머서의 정리(Mercer’s Theorem)  저차원 공간 $L$ 에서 고차원 공간 $H$ 로 관측치들을 매핑하는 커널함수 $K$ 는 $L$ 에서 표현된 관측치들 간 유클리드 거리와 $H$ 에서 표현된 관측치들 간 유클리드 거리를 보존함      임의의 관측치 $X_a, X_b$ 에 대하여, $2$ 차원 공간에서 해당 관측치를 나타내는 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1\\\\a_2\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1\\\\b_2\\end{pmatrix}  \\end{aligned}\\]        $\\overrightarrow{a}, \\overrightarrow{b}$ 을 $3$ 차원상의 벡터 $\\Phi(\\overrightarrow{a}),\\Phi(\\overrightarrow{b})$ 로 매핑하는 커널함수 $K(\\overrightarrow{a}, \\overrightarrow{b})$ 는 다음의 조건을 만족함\\[\\begin{aligned}  K(\\overrightarrow{a}, \\overrightarrow{b})  &amp;= (\\overrightarrow{a}^T \\overrightarrow{b})^2 \\\\  &amp;= a_1^2b_1^2 + 2(a_1b_1a_2b_2) + a_2^2b_2^2 \\\\  &amp;= (a_1^2, \\sqrt{2}a_1a_2, a_2^2) \\cdot (b_1^2, \\sqrt{2}b_1b_2, b_2^2) \\\\  &amp;= \\Phi(\\overrightarrow{a}) \\cdot \\Phi(\\overrightarrow{b})  \\end{aligned}\\]  커널함수의 종류      Linear\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\overrightarrow{a}^T \\overrightarrow{b}\\]        Polynomial\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = (\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)^d\\]        Radial Basis Function(RBF)\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\exp(-\\gamma ||\\overrightarrow{a}- \\overrightarrow{b}||^2)\\]        Hyperbolic Tangent\\[K(\\overrightarrow{a}, \\overrightarrow{b}) = \\tanh(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)\\]  SVR      초평면\\[\\begin{aligned}  f(\\overrightarrow{x}_{i})  &amp;= \\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b  \\end{aligned}\\]        차이점 : 제약 조건                      판별 분석 : 마진 범위 이내에 관측치 벡터가 존재하지 않음\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp;y_{i}(\\overrightarrow{w}^{T}\\overrightarrow{x}_{i}+b) \\ge 1 + \\xi_{i},\\\\  &amp;\\xi_{i} \\ge 0  \\end{aligned}\\]                    회귀 분석 : 마진 범위 이내에 모든 관측치 벡터가 존재함\\[\\begin{aligned}  \\text{s.t.} \\quad  &amp;-(\\varepsilon + \\xi_{i}) \\le f(\\overrightarrow{x}_{i}) - y_{i} \\le \\varepsilon + \\eta_{i},\\\\  &amp;\\xi_{i},\\eta_{i} \\ge 0  \\end{aligned}\\]                  SVR 최적화 문제\\[\\overrightarrow{\\hat{w}},\\hat{b},\\hat{\\xi}_{i},\\hat{\\eta}_{i}  =\\text{arg} \\min_{\\overrightarrow{w},b,\\xi,\\eta}{\\left[\\frac{1}{2}||w||^{2}+C\\sum_{i=1}^{n}{(\\xi_{i}+\\eta_{i})}\\right]}\\]\\[\\begin{aligned}  \\\\ \\text{s.t.} \\quad  &amp; \\varepsilon + \\xi_{i} + f(\\overrightarrow{x}) - y_{i} \\ge 0,\\\\  &amp; \\varepsilon + \\eta_{i} - f(\\overrightarrow{x}) + y_{i} \\ge 0,\\\\  &amp; \\xi_{i}, \\eta_{i} \\ge 0  \\end{aligned}\\]  sklearn.svm.SVCfrom sklearn.svm import SVCGeneral HyperParameter  random_state(default : None)Model HyperParameter  decision_function_shape(default : 'ovr') : 다항 분류 시 결정 경계 탐색 방법          'ovo' : One VS One(일대일 구분 결정 경계 탐색)      'ovr' : One VS Rest(일대다 구분 결정 경계 탐색)      Soft Margin      C(default : 1.0) : 마진 위반에 대한 규제 강도    gamma(default : 'scale') : 결정 경계를 얼마나 유연하게 그을 것인가          'auto' : $\\displaystyle\\frac{1}{n(features)}$      'scale' : $\\displaystyle\\frac{1}{n(features) \\times X.var()}$      float type        tol(default : 0.001) : 허용 오차Kernel Trick  kernel(default : 'rbf') : 커널함수 설정          'linear' : $\\overrightarrow{a}^T \\overrightarrow{b}$      'poly' : $(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)^d$      'rbf' : $\\tanh(\\gamma \\overrightarrow{a}^T \\overrightarrow{b} + r)$            degree(default : 3) : 다항식 커널함수의 차수 $d$ 설정    coef0(default : 0.0) : 다항식 커널함수의 상수항 $r$ 설정To Prevent Overfitting  max_iter(default : -1) : 결정 경계 탐색 최대 횟수To Prevent Underfitting  class_weight(default : None) : 가중할 범주와 그 값          'balanced'      dictionary type      이미지 출처  https://velog.io/@shlee0125  https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927"
  },
  
  {
    "title": "kNN",
    "url": "/posts/kNN/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-06 00:00:00 +0900",
    





    
    "snippet": "k-Nearest Neighbors      정의 : 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]        한계점          검색 비용 문제                  관측치 갯수만큼 거리를 계산해야 함         ...",
    "content": "k-Nearest Neighbors      정의 : 기하 거리를 규칙으로 하여 관측치를 분류하는 알고리즘    \\[\\hat{y}=\\text{arg} \\max_{C}{\\sum_{i=1}^{k}{I(y_{i}=C)}}\\]        한계점          검색 비용 문제                  관측치 갯수만큼 거리를 계산해야 함                    거리 측정 함수 설정 문제                  분석가가 문제에 적합한 함수를 판단해야 함          고차원으로 갈수록 거리 개념이 무의미해짐          범주형 변수의 경우 각 범주 간 거리를 정의해야 함                    기하 거리 측정 방법맨해튼 거리 측정법      맨해튼 거리(Manhattan Distance; L1) : 두 점 사이의 엣지(Edge) 갯수          $\\overrightarrow{i_{1}}, \\overrightarrow{i_{2}}, \\cdots, \\overrightarrow{i_{n}}$ 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리를 합산한 값            계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 맨해튼 거리 $d_{L1}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= || \\overrightarrow{a} - \\overrightarrow{b} ||_{L1} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n} |a_i - b_i|  \\end{aligned}\\]            유클리드 거리 측정법  유클리드 거리(Euclidean Distance; L2) : 두 점 사이의 직선 거리          $\\overrightarrow{i_{1}}, \\overrightarrow{i_{2}}, \\cdots, \\overrightarrow{i_{n}}$ 를 기저벡터로 사용하는 $n$ 차원 좌표계에 위치한 두 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 에 대하여 각 축 방향으로의 기저벡터 단위 거리의 제곱을 합산한 후 제곱근한 값        계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 유클리드 거리 $d_{L2}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= || \\overrightarrow{a} - \\overrightarrow{b} ||_{L2} \\\\  &amp;= \\sqrt{\\displaystyle\\sum_{i=1}^{n} (a_i - b_i)^2}  \\end{aligned}\\]            코사인 거리 측정법      코사인 거리(Cosine Distance; $\\cos$) : 임의의 두 점에 대하여, 원점과 각 점을 잇는 직선의 사이각 $\\theta$ 의 코사인 값        계산 방법                  벡터 $\\overrightarrow{a},\\overrightarrow{b}$ 를 다음과 같이 정의하자\\[\\begin{aligned}  \\overrightarrow{a}  &amp;= \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}\\\\  \\overrightarrow{b}  &amp;= \\begin{pmatrix}b_1&amp;b_2&amp;\\cdots&amp;b_n\\end{pmatrix}  \\end{aligned}\\]                    $\\overrightarrow{a}$ 와 $\\overrightarrow{b}$ 의 코사인 거리 $d_{cos}(\\overrightarrow{a},\\overrightarrow{b})$ 는 다음과 같음\\[\\begin{aligned}  d(\\overrightarrow{a},\\overrightarrow{b})  &amp;= \\cos{\\theta}\\\\  &amp;= \\frac{\\overrightarrow{a}^{T}\\overrightarrow{b}}{||a||\\cdot||b||}\\\\  &amp;= \\frac{\\sum_{i=1}^{n}{a_{i}b_{i}}}{\\sqrt{\\sum_{i=1}^{n}{a_{i}^{2}}} \\cdot \\sqrt{\\sum_{i=1}^{n}{b_{i}^{2}}}}\\;(a_{i^{\\forall}}\\in\\overrightarrow{a},b_{i^{\\forall}}\\in\\overrightarrow{b})  \\end{aligned}\\]            하버사인 거리 측정법      하버사인 거리(Haversine Distance; $\\text{hav}$) : 구 표면상에 존재하는 두 지점에 대하여, 위도($\\varphi$), 경도($\\lambda$) 및 호 중심각($\\Theta$)을 활용하여 측정한 호의 길이        계산 방법                  반지름이 $r$, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta  \\end{aligned}\\]                    점 $A$,$B$ 의 위도가 $\\varphi_{A}$,$\\varphi_{B}$, 경도가 $\\lambda_{A}$,$\\lambda_{B}$ 이고, 호 $\\overline{AB}$ 의 중심각이 $\\Theta$ 일 때, 호의 길이 $\\text{hav}{\\Theta}$ 는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\text{hav}(\\varphi_{B}-\\varphi_{A})  + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})  \\end{aligned}\\]                    $\\sin$, $\\cos$, $\\text{hav}$ 의 관계는 다음과 같음\\[\\begin{aligned}  \\text{hav}{\\Theta}  &amp;= \\sin^{2}{\\frac{\\Theta}{2}}\\\\  &amp;= \\frac{1-\\cos{\\Theta}}{2}  \\end{aligned}\\]                    따라서 반지름, 경도, 위도가 주어졌을 때 호 $\\overline{AB}$ 의 길이 $d(A,B)$ 는 다음과 같음\\[\\begin{aligned}  d(A,B)  &amp;= r \\cdot \\Theta\\\\  &amp;= r \\cdot \\text{archav}(\\text{hav}{\\Theta})\\\\  &amp;= 2r \\cdot \\arcsin(\\sqrt{\\text{hav}{\\Theta}})\\\\  &amp;= 2r \\cdot \\arcsin\\left(\\sqrt{\\text{hav}(\\varphi_{B}-\\varphi_{A}) + \\cos{\\varphi_{A}} \\cdot \\cos{\\varphi_{B}} \\cdot \\text{hav}(\\lambda_{B}-\\lambda_{A})}\\right)  \\end{aligned}\\]            sklearn.neighbors.KNeighborsClassifierfrom sklearn.neighbors import KNeighborsClassifierGeneral HyperParameter  n_jobs(default : None) : 병렬로 작업할 코어 갯수Model HyperParameter      n_neighbors(default : 5) : 참조할 근접 벡터의 갯수    metric(default : 'minkowski') : 거리 측정 방법          'l1', 'manhattan' or 'cityblock' : 맨해튼 거리 측정법      'l2' or 'euclidean' : 유클리드 거리 측정법      'cosine' : 코사인 거리 측정법      'haversine' : 하버사인 거리 측정법      callable            p(default : 2) : metric 의 아규먼트가 'minkowski' 인 경우 추가 설정\\[minkowski=\\left(\\displaystyle\\sum_{i=1}^{n}{|x_i-y_i|^p}\\right)^{\\frac{1}{p}}\\]          1 : 맨해튼 거리 측정법      2 : 유클리드 거리 측정법        weights(default : 'uniform') : 근접 벡터에 대하여 가중치 부여 방법 설정          None      'uniform' : 근접 벡터에 대하여 동등한 가중치를 부여함      'distance' : 근접 벡터에 대하여 거리에 따른 가중치를 부여함      callable      이미지 출처  https://076923.github.io/posts/Python-opencv-43/"
  },
  
  {
    "title": "Naive Bayes",
    "url": "/posts/Naive_Bayes/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Classification, Bayesian",
    "date": "2024-01-05 00:00:00 +0900",
    





    
    "snippet": "Naive Bayes      정의 : 조건부 확률에 기초하여 관측치의 범주를 판별하는 알고리즘        조건부 확률의 이해\\[\\begin{aligned}P(B|A)&amp;= \\frac{P(A,B)}{P(A)}\\end{aligned}\\]          \\(P(B \\vert A)\\) : 사건 \\(A\\) 가 발생한 상태에서 사건 \\(B\\) 가 발생...",
    "content": "Naive Bayes      정의 : 조건부 확률에 기초하여 관측치의 범주를 판별하는 알고리즘        조건부 확률의 이해\\[\\begin{aligned}P(B|A)&amp;= \\frac{P(A,B)}{P(A)}\\end{aligned}\\]          \\(P(B \\vert A)\\) : 사건 \\(A\\) 가 발생한 상태에서 사건 \\(B\\) 가 발생할 확률      \\(P(A,B)\\) : 사건 \\(A\\), \\(B\\) 가 공동으로 발생할 확률      \\(P(A)\\) : 사건 \\(A\\) 가 발생할 확률      \\(P(B)\\) : 사건 \\(B\\) 가 발생할 확률            한계점 : Class Conditional Independent Assumption                  Class Conditional Independent Assumption : 범주 내에서 특정 특성의 존재 또는 부재가 다른 특성의 존재 또는 부재와 독립적이라는 가정\\[\\begin{aligned}  P(X_{1},X_{2},\\cdots,X_{n}|Y)  &amp;= P(X_{1}|Y) \\times P(X_{2}|Y) \\times \\cdots \\times P(X_{n}|Y)  \\end{aligned}\\]            결정 함수 도출      문제 정의\\[\\begin{aligned}  \\hat{Y}  &amp;= f(\\overrightarrow{x})\\\\  &amp;= \\text{arg} \\max_{Y}{P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          관측치 벡터 \\(\\overrightarrow{x}\\) 의 범주 \\(\\hat{Y}\\) 는 \\(\\overrightarrow{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 로 주어졌을 때, 범주 \\(Y\\) 가 \\(i=1,2,\\cdots\\) 일 확률이 최대인 \\(i\\) 임            베이즈 정리에 의해 다음이 성립함\\[\\begin{aligned}  &amp;P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}  \\end{aligned}\\]          \\(P(Y=i \\vert X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 벡터 \\(\\overrightarrow{x}=(x_{1},x_{2},\\cdots,x_{n})\\) 가 주어졌을 때, 해당 관측치의 범주 \\(Y\\) 가 $i$ 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n} \\vert Y=i)\\) : 범주 \\(Y=i\\) 가 주어졌을 때, 관측치 벡터 \\(\\overrightarrow{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률      \\(P(Y=i)\\) : 범주 \\(Y\\) 가 \\(i\\) 일 확률      \\(P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\) : 관측치 벡터 \\(\\overrightarrow{x}\\) 가 \\((x_{1},x_{2},\\cdots,x_{n})\\) 일 확률            클래스 조건부 독립 가정 하 다변량 조건부 확률을 단변량 조건부 확률로 변환할 수 있음\\[\\begin{aligned}  &amp;P(X_{1},X_{2},\\cdots,X_{n}|Y)\\\\  &amp;= P(X_{1}|Y) \\times P(X_{2}|Y) \\times \\cdots \\times P(X_{n}|Y)  \\end{aligned}\\]        따라서 관측치 벡터 \\(\\overrightarrow{x}\\) 의 범주 \\(Y\\) 가 \\(i\\) 일 확률은 다음과 같음\\[\\begin{aligned}  &amp;P(Y=i|X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n})}\\\\  &amp;= \\frac{P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=i) \\cdot P(Y=i)}{\\sum_{j}P(X_{1}=x_{1},X_{2}=x_{2},\\cdots,X_{n}=x_{n}|Y=j)}\\\\  &amp;= \\frac{\\prod_{k=1}^{n}{P(X_{k}=x_{k}|Y=i)} \\cdot P(Y=i)}{\\sum_{j}{\\prod_{k=1}^{n}{P(X_{k}=x_{k}|Y=j)}}}  \\end{aligned}\\]  라플라스 평활화      라플라스 평활화(Laplace Smoothing) : 훈련 데이터 세트에 존재하지 않는 사례 \\(\\overrightarrow{x}_{k}\\) 에 대한 확률을 \\(0\\) 으로 부여하는 것을 방지하기 위한 기법        계산 방법\\[P(\\overrightarrow{x}_{k}|Y)  = \\frac{\\text{count}(\\overrightarrow{x}_{k},Y)+\\alpha}{\\text{count}(Y)+2\\alpha}\\]          \\(P(\\overrightarrow{x}_{k} \\vert Y)\\) : 관측치 벡터 \\(\\overrightarrow{x}_{k}\\) 가 범주 \\(Y\\) 에 속할 조건부 확률      \\(\\text{count}(\\overrightarrow{x}_{k},Y)\\) : 관측치 벡터 \\(\\overrightarrow{x}_{k}\\) 와 범주 \\(Y\\) 의 동시 출현 빈도      \\(\\text{count}(Y)\\) : 범주 \\(Y\\) 의 출현 빈도      \\(\\alpha\\) : 라플라스 평활화 강도      sklearn.naive_bayes.MultinomialNBfrom sklearn.naive_bayes import MultinomialNBLaplace Smoothing  alpha(default : 1.0) : 라플라스 평활화 강도  force_alpha(default : False) : alpha 하한선을 \\(1e-10\\) 으로 강제할지 여부Learn Class Prior Probabilities  fit_prior(default : True) : 클래스 사전 확률 학습 여부          True : 훈련 데이터 세트의 클래스 사전 확률을 학습함      False : 클래스 사전 확률을 균등하게 부여함        class_prior(default : None) : 클래스 사전 확률 강제 지정"
  },
  
  {
    "title": "Decision Tree",
    "url": "/posts/Decision_Tree/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Classification",
    "date": "2024-01-04 00:00:00 +0900",
    





    
    "snippet": "Decision Tree      정의 : 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘            구조              루트 노드(Root Node) : 깊이가 0인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건 ...",
    "content": "Decision Tree      정의 : 순도(Uniformity)를 최대로 가져가는 이진 판별 규칙들로 구성된 수형도(Tree)를 세우고 관측치를 분류하는 알고리즘            구조              루트 노드(Root Node) : 깊이가 0인 꼭대기 노드로서 최상위 노드      결정 노드(Decision Node) : 규칙 조건      리프 노드(Leaf Node) : 하위 노드가 존재하지 않는 노드로서 최종 범주      서브트리(Subtree) : 어떠한 규칙 노드를 루트 노드로 가지는 하위 트리로서 판별 규칙 집합의 부분집합      재귀적 분기(Recursive Partitioning)      정의 : 판별 규칙을 기준으로 상위 노드를 분할하여 순도가 높은 하위 노드를 생성하는 반복적인 과정                  판별 규칙 : 어떤 분기에서 하나의 설명변수를 사용하여 생성한 분할 조건                            순도(Purity) : 어떤 노드에 속한 관측치들이 동일한 범주에 속하는 정도                          순도를 정확히 측정하기 어려우므로 그 대리변수로서 불순도(Impurity)를 사용함                    판별 규칙      어떤 노드에 대하여, 설명변수 $X_{i} \\ge x_{i}$ 를 기준으로 해당 노드를 분할한다고 하자\\[y=\\begin{cases}  \\begin{aligned}  N_{left},\\;&amp;if\\;X_{i} \\ge x_{i}\\\\  N_{right},\\;&amp;if\\;X_{i} &lt; x_{i}\\\\  \\end{aligned}  \\end{cases}\\]        판별 규칙 $X_{i} \\ge x_{i}$ 의 비용 $J(X_{i} \\ge x_{i})$ 는 다음과 같음\\[\\begin{aligned}  J(X_{i} \\ge x_{i})  &amp;= \\frac{m_{left}}{m}I_{left} + \\frac{m_{right}}{m}I_{right}  \\end{aligned}\\]          $m$ : 결정 노드에 속한 관측치 갯수      $m_{left}$ : 좌측 하위 노드로 분기한 관측치 갯수      $I_{left}$ : 좌측 하위 노드의 불순도      $m_{right}$ : 우측 하위 노드로 분기한 관측치 갯수      $I_{right}$ : 우측 하위 노드의 불순도            설명변수 $X_{i}$ 기준 분할 시 최적의 분기점 $\\hat{x}_{i}$ 는 다음과 같음\\[\\hat{x}_{i}  =\\text{arg} \\min_{x_{i}}{J(X_{i} \\ge x_{i})}\\]        특정 노드를 분할하는 최적의 설명변수 $\\hat{X}_{i}$ 는 다음과 같음\\[\\hat{X}_{i}  = \\text{arg} \\min_{X_{i}}{\\left\\{\\min{J(X_{1})},\\min{J(X_{2})},\\cdots,\\min{J(X_{n})}\\right\\}}\\]  불순도      지니 지수(Gini Index) : 불순도를 경제적 불평등 개념에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율            엔트로피 지수(Entropy Index) : 불순도를 정보 획득의 불확실성 개념에 기초하여 계산한 지표\\[\\begin{aligned}  I(N_{k})  &amp;= -\\sum_{i=1}^{c}{\\left[p_{i} \\cdot \\log_{2}{p_{i}}\\right]}  \\end{aligned}\\]          $c$ : 범주 갯수      $p_{i}$ : 노드 $N_{k}$ 에서 $i$ 번째 범주에 속하는 관측치 비율      가지치기(Pruning)      정의 : 자세하게 구분된 영역을 통합함으로써 과적합을 방지하는 기법    절차          Full Tree 생성      모든 노드에 대하여 비용 복잡도 지수 계산      비용 복잡도 지수가 가장 낮은 노드에 대하여 가지치기 수행      2~3 단계를 반복하며 최적의 $\\alpha$ 탐색      최적의 $\\alpha$ 하 Tree 도출            비용 복잡도 지수(Cost-Complexity)\\[\\begin{aligned}  R_{\\alpha}(T)  &amp;= L(T) + \\alpha \\cdot |\\text{leaf}(T)|\\\\  L(T)  &amp;= \\sum_{m=1}^{|\\text{leaf}(T)|}{\\sum_{\\overrightarrow{x}_{i} \\in R_{m}}{(y_{i}-\\hat{y}_{i})^2}}  \\end{aligned}\\]          $T$ : 타깃 노드를 루트 노드로 하는 서브트리      $\\text{leaf}(T)$ : $T$ 의 리프 노드 집합      $R_{m} \\in \\text{leaf}(T)$ : $T$ 의 $m$ 번째 리프 노드      \\(\\overrightarrow{x}_{i} \\in R_{m}\\) : \\(R_{m}\\) 에 속한 \\(i\\) 번째 관측치 벡터      $y_{i}$ : $\\overrightarrow{x}_{i}$ 의 실제값      \\(\\hat{y}_{i}\\) : \\(\\overrightarrow{x}_{i}\\) 의 예측값      $\\alpha$ : 가지치기 강도      $L(T)$ : $T$ 의 훈련 관측치에 대한 예측 손실      $R_{\\alpha}(T)$ : 타깃 노드의 비용 복잡도 지수      DTR      재귀적 분기\\[\\begin{aligned}  \\hat{X}_{i}  &amp;= \\text{arg} \\min_{X_{i}}{\\{J(X_{1},\\hat{x}_{1}),J(X_{2},\\hat{x}_{2}),\\cdots,J(X_{n},\\hat{x}_{n})\\}}\\\\  \\hat{x}_{i}  &amp;= \\text{arg} \\min_{x_{i}}{J(X_{i},x_{i})}\\\\  J(X_{i},x_{i})  &amp;= \\frac{m_{left}}{m}L_{left}+\\frac{m_{right}}{m}L_{right}  \\end{aligned}\\]        차이점 : 손실 함수                      판별 분석 : 불순도(Impurity)를 최소화하도록 분기\\[\\begin{aligned}  L_{gini}(N_{k})  &amp;= 1-\\sum_{i=1}^{c}{p_{i}^2}  \\end{aligned}\\]                    회귀 분석 : 오차(Error)를 최소화하도록 분기\\[\\begin{aligned}  L_{MSE}(N_{k})  &amp;= \\sum_{i=1}^{m}{(y_{i}-\\hat{y}_{i})^2}  \\end{aligned}\\]            sklearn.tree.DecisionTreeClassifierfrom sklearn.tree import DecisionTreeClassifierGeneral HyperParameter  random_state(default : None)Model HyperParameter  max_features(default : None) : 규칙 설계 시 고려할 설명변수 갯수          'sqrt' : $\\sqrt{n}$      'log2' : $\\log_2{n}$      None : $n$      Recursive Partitioning  criterion(default : 'gini') : 균일도 측정 방법          'gini' : 지니지수      'entropy' : 엔트로피지수      Pruning  ccp_alpha(default : 0)To Prevent Overfitting  max_depth(default : None) : 트리 최대 깊이  max_leaf_nodes(default : None) : 리프 노드의 최대 갯수  min_samples_split(default : 2) : 하위 노드로 가지를 뻗기 위해 필요한 최소한의 관측치 갯수  min_impurity_decrease(default : 0) : 하위 노드로 가지를 뻗기 위해 필요한 최소한의 불순도 개선 정도  min_samples_leaf(default : 1) : 리프 노드의 관측치 최소 갯수To Prevent Underfitting  class_weight(default : None) : 가중할 범주와 그 값          'balanced'      dictionary type      "
  },
  
  {
    "title": "Supervised Model Selection",
    "url": "/posts/Supervised_Model_Selection/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Supervised Learning, Metric, Cross Validation",
    "date": "2024-01-03 00:00:00 +0900",
    





    
    "snippet": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitiv...",
    "content": "Classification MetricsConfusion Matrix  TP(True Positive) : 긍정으로 예측한 것(Possitive) 중 옳게 예측한(True) 항목  TN(True Negative) : 부정인 것(Negative) 중 옳게 예측한(True) 항목  FP(False Possitive) : 긍정으로 예측한 것(Possitive) 중 잘못 예측한(False) 항목  FN(False Negative) : 부정으로 예측한 것(Negative) 중 잘못 예측한(False) 항목Sensitive to Threshold      정확도(Accuracy) : 전체 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP + TN}{TP + TN + FP + FN}\\]        민감도(Sensitivity) 혹은 재현율(Recall) : 실제 긍정인 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP}{TP + FN}\\]        특이도(Specificity) : 실제 부정인 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TN}{TN + FP}\\]        정밀도(Precision) : 긍정으로 예측한 관측치 대비 옳게 예측한 관측치 비율\\[\\frac{TP}{TP + FP}\\]        F1-Score : 재현율과 정밀도의 조화 평균\\[2 \\times \\frac{precision \\times recall}{precision + recall}\\]          재현율 : 제1종 오류(참을 거짓으로 예측하는 오류; FN)를 강조하는 지표      정밀도 : 제2종 오류(거짓을 참으로 예측하는 오류; FP)를 강조하는 지표      AUROC : Robust to Threshold      AUROC                      ROC Curve(Receiver Operating Characteristic Curve) : FPR 값에 따른 TPR의 변화 추이를 나타낸 곡선                    AUROC(Area Under ROC) : ROC Curve 아래 면적                  이상적 분류기(Ideal Classifier) : 1          무작위 분류기(Random Classifier) : 0.5                          개념 설명                  FNR(False Negative Rate) : 실제 긍정인 관측치(TP+FN) 대비 잘못 예측한 관측치(FN) 비율\\[\\begin{aligned}  FNR  &amp;=\\frac{FN}{TP+FN}  \\end{aligned}\\]                    TPR(True Positive Rate) : 실제 긍정인 관측치(TP+FN) 대비 옳게 예측한 관측치(TP) 비율\\[\\begin{aligned}  TPR  &amp;=\\frac{TP}{TP+FN}\\\\  &amp;= 1-FNR  \\end{aligned}\\]                    FPR(False Possitive Rate) : 실제 부정인 관측치(TN+FP) 대비 잘못 예측한 관측치(FP) 비율\\[\\begin{aligned}  FPR  &amp;=\\frac{FP}{TN+FP}  \\end{aligned}\\]                    TNR(True Negative Rate) : 실제 부정인 관측치(TN+FP) 대비 옳게 예측한 관측치(TN) 비율\\[\\begin{aligned}  TNR  &amp;=\\frac{TN}{TN+FP}\\\\  &amp;= 1-FPR  \\end{aligned}\\]            Regression Metrics      Average Error(AE)\\[AE=\\frac{1}{n}\\sum_{i=1}^{n}{y_{i}-\\hat{y}_{i}}\\]          정의 : 오차의 합계      한계점 : 오차의 방향에 따른 크기 상쇄 가능성            Mean Squared Error(MSE) : 오차 자승의 평균\\[MSE = \\frac{1}{n}\\sum_{i=1}^{n}{(y_{i}-\\hat{y}_{i})^2}\\]        Root Mean Squared Error(RMSE) : 오차 자승의 평균의 자승근\\[RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{(y_{i}-\\hat{y}_{i})^2}}\\]        Mean Absolute Error(MAE) : 오차 절대값의 평균\\[MAE = \\frac{1}{n}\\sum_{i=1}^{n}{|y_{i}-\\hat{y}_{i}|}\\]        Mean Absolute Percentage Error(MAPE) : 실제값 대비 오차 비율 절대값의 평균\\[MAPE = \\frac{1}{n}\\sum_{i=1}^{n}|\\frac{y_{i}-\\hat{y}_{i}}{y_{i}}|\\]  Split일반화의 문제  모델링 목적 : 일반화          일반화(Generalization) : 모델이 훈련 관측치에서 학습한 패턴을 사용하여 이전에 보지 못한 관측치에 대하여 예측하는 것            문제점 : 과대적합 현상              과대적합(Overfitting) : 모델이 일반적이지 않은, 즉 훈련 관측치에서만 포착되는 노이즈나 이상치까지 학습하여 신규 관측치에 대해서는 제대로 기능하지 못하는 상태      과소적합(Underfitting) : 모델이 훈련 관측치에서 나타나는 일반적인 패턴을 충분히 학습하지 못하여 관측치의 다양성과 복잡성을 잡아내지 못하는 상태            해결 방법 : $E_{gen}$ 최소화                      Training Error : Training Data Set 에 대한 오차\\[E_{trn} = \\sum^{N_{trn}}_{i=1}{L(y_{i},\\hat{y}_{i})}\\]                    Generalization Error : Unseen Data Set 에 대한 오차\\[E_{gen}=\\int{L(y_{i},\\hat{y}_{i})}\\]            모수의 추정  $E_{gen}$ 측정 상의 문제점          Unseen Data Set 자체에 대해서 알 수 없으므로 이상적인 개념임      해당 모수를 추정하기 위하여 추정량 $E_{val}$, $E_{tst}$ 를 제시함            Split Seen Data Set              Training : 모델 훈련 시 사용하는 표본으로서, 해당 표본으로부터 $E_{val}$ 을 추정함      Validation : 모델 간 성능 비교 시 사용하는 표본으로서, 해당 표본으로부터 $E_{tst}$ 를 추정함      Test : 최종 선택된 모델 성능 측정 시 사용하는 표본으로서, 해당 표본로부터 $E_{gen}$ 를 추정함      Cross Validation      교차 검증(Cross Validation)              정의 : 표본을 여러 세트로 나누어 모델을 여러 번 학습하고 평가함으로써 모델의 일반화 성능을 측정하는 절차      필요성 : Training 에서 Test 를 분리한 상태에서 Validation 을 재차 분리하기에는 학습에 사용할 표본 크기가 충분하지 않음            LOOCV(Leave-One-Out Cross Validation)              $n$ 개의 표본을 $n-1$ 개의 training 과 $1$ 개의 validation 으로 나누어 $n$ 번 학습하는 방식            k-Fold Cross Validation              $n$ 개의 표본을 $k$ 개의 데이터 세트로 나누고, $k-1$ 개는 training 으로, $1$ 개는 validation 으로 구분하여 $k$ 번 학습하는 방식      "
  },
  
  {
    "title": "Data Preprocessing",
    "url": "/posts/Data_Preprocessing/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning, Feature Engineering",
    "date": "2024-01-02 00:00:00 +0900",
    





    
    "snippet": "Data Preprocessing      정의 : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정    필요성 : 분석에 완벽하게 적합한 데이터를 얻는 것은 불가능함          호환성 문제                  데이터 불일치          데이터 중복                    데이터 수집 문제       ...",
    "content": "Data Preprocessing      정의 : 데이터를 분석에 사용할 수 있는 형식의 데이터로 만드는 일련의 과정    필요성 : 분석에 완벽하게 적합한 데이터를 얻는 것은 불가능함          호환성 문제                  데이터 불일치          데이터 중복                    데이터 수집 문제                  센서와 데이터베이스 간 통신 문제          센서 자체 문제          샘플링 기반 데이터 수집 정책                      데이터 품질에 영향을 끼치는 인자          Nosie : 데이터 측정 시 무작위로 발생하여 오류를 발생시키는 문제      Outlier : 대부분의 데이터와 다른 특성을 보이거나 특정 속성의 값이 유별난 데이터      Artifact : 어떤 요인으로 인해 반복적으로 발생하는 왜곡이나 오류      Precision : 동일한 결과물을 반복적으로 측정하였을 때 각 측정값 사이의 일관성 문제      Bias : 측정 장비에 포함된 시스템 상 문제      Accuacy : 측정 장비의 한계로 정확하지 않은 수를 측정함에 따라 발생하는 문제      Inconsistent Value : 데이터 불일치 문제      Duplicate : 데이터 중복 문제        절차                  Data Integration : 동일한 단위, 양식으로 데이터를 결합하는 절차            Data Cleansing : 낮은 품질의 데이터를 활용할 수 있도록 하는 절차                  중복값 제거          결측치 처리          이상치 처리                    Data Transformation : 데이터 형식 및 구조를 학습에 적합하도록 변환하는 절차                  표준화(Standardization)          정규화(Normalization)                    Data Reduction : 고차원 데이터를 저차원 데이터로 변환하는 절차      Data Cleansing결측치 처리  결측치 종류          완전 무작위 결측(Missing Completely At Random; MCAR) : 데이터가 어떤 패턴이나 규칙 없이 누락되는 경우      무작위 결측(Missing At Random; MAR) : 데이터의 누락이 다른 변수에 종속된 경우      비무작위 결측(Missing Not At Random; MNAR) : 결측치가 어떤 규칙 또는 패턴을 따라 발생하는 경우        결측치 처리 권장 사항          10% 미만 : 제거 또는 대체      10~20% : 최빈값, 평균, 중앙값 등으로 대체      20% 이상 : model-based method      이상치 처리      이상치의 정의 : 관측된 데이터의 범위에서 지나치게 벗어나 값이 매우 크거나 작은 값        이상치의 탐지 : Turkey Fence 기법    \\[\\begin{aligned}  Outliers  &amp;=\\{X|X &lt; X_{lower} \\; or \\; X &gt; X_{upper}\\}  \\end{aligned}\\]          하한값($X_{lower}$) : $Q_1-IQR \\times 1.5$      상한값($X_{upper}$) : $Q_3+IQR \\times 1.5$      사분위 범위(InterQuartile Range; IQR) : $Q_3 - Q_1$      Data Transformationz-Score 정규화from sklearn.preprocessing import StandardScaler      정의 : 값의 분포를 평균이 0, 분산이 1인 형태로 변환함\\[X_{scaled}=\\frac{X_{origin}-E(X)}{\\sigma}\\]        기능 : 정규 분포화  (이상치) 강건 정규화from sklearn.preprocessing import RobustScaler      정의 : 평균과 분산 대신 중앙값과 사분위 범위를 활용함\\[X_{scaled}=\\frac{X_{origin}-median}{IQR}\\]        기능 : 이상치 영향력 최소화  최대-최소 정규화from sklearn.preprocessing import MinMaxScaler      정의 : 값의 분포를 특정 범위로 확대 혹은 축소함\\[X_{scaled}=\\frac{X_{origin}-X_{min}}{X_{max}-X_{min}}\\]        기능 : 척도 통일  "
  },
  
  {
    "title": "What? Data Science",
    "url": "/posts/Data_Science/",
    "categories": "Machine Learning Techs, Machine Learning",
    "tags": "Machine Learning",
    "date": "2024-01-01 00:00:00 +0900",
    





    
    "snippet": "Data-Driven Decision Making데이터 기반 의사결정  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend     ...",
    "content": "Data-Driven Decision Making데이터 기반 의사결정  Descriptive : Explains What Happend          Comprehensive, Accurate, Live Data      Effective Visualisation        Diagnostic : Explains Why It Happend          Ability to Drill Down to the Root-cause      Ability to Isolate All Confounding Information        Predictive : Forcasts What Might Happned          Business Have Remained Fairly Consistent Over Time      Historical Patterns Being Used to Predict Specific Outcomes Using Algorithms      Decisions are Automated Using Algorithms and Tech.        Prescriptive : What Do I Need to Do?          Recommends Action Based On The Forecast      Applying Advanced Analytical Techs to Make Specific Recommendatons      데이터 기반 문제 해결 과정      문제 정의          어떤 문제를 해결할 것인가?이를 위해 필요한 데이터는 무엇인가?            데이터 획득          어떻게 데이터를 수집할 것인가?            데이터 탐색          데이터 전처리탐색적 자료 분석            모델링          문제에 맞는 기계학습 알고리즘 선택모델 구축            배포          제품 배포 및 시스템 유지 보수      Data Science데이터 과학의 이해      정의          정형, 비정형의 다양한 데이터로부터 지식 및 시사점을 도출하는 데 과학적 방법론을 동원하는 융합 분야(출처 : 위키백과)            주요 개념                  빅데이터(Bigdata)                  통상적으로 사용되는 데이터 수집, 관리, 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터(출처 : 위키백과)                          Volume(Data Quantity)          Variety(Data Types)          Velocity(Data Speed)          Value(Data Impact)                            데이터 마이닝(Data Mining)                  대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 짜임을 분석하여 가치 있는 정보를 빼내는 과정(출처 : 위키백과)                            기계학습(Machine Learning)                  기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야(출처 : 위키백과)                            인공지능(Artificial Intelligence; AI)                  인간의 학습, 추론, 지각 능력을 인공적으로 구현하려는 컴퓨터 과학의 세부 분야(출처 : 위키백과)                    기계학습의 분류  지도학습(Supervised Learning)                  정의 : 정답 세트가 존재하는 데이터를 활용하는 학습 방법                    분류                  판별 분석(Classificaiton) : 범주형 값을 가지는 종속변수를 예측하는 방법론          회귀 분석(Regression) : 수치형 값을 가지는 종속변수를 예측하는 방법론                      비지도학습(Unsupervised Learning)                  정의 : 정답 세트가 존재하지 않는 데이터를 활용하는 학습 방법                    분류                  군집화(Clustering) : 유사한 개체들의 집단을 만든 후 새 개체가 어떤 집단과 유사한지 예측하는 방법론          차원축소(Dimension Reduction) : 고차원 데이터를 저차원 데이터로 변환하는 방법론                    Scikit-Learn Library      API 사용 방법          적절한 알고리즘 클래스 불러오기      인터페이스의 하이퍼 파라미터를 적절한 값으로 설정하여 인스턴스 생성      데이터 세트를 문제지(Feature)와 정답지(Traget)로 배치      fit() 을 통해 인스턴스를 학습용 데이터 세트로 훈련      predict() 을 통해 훈련된 인스턴스에 평가용 데이터 세트를 적용하여 성능 평가      모듈      알고리즘                            모듈          설명          예시                                      sklearn.tree          결정 트리 알고리즘 제공          Decision Tree 등                          sklearn.neighbors          최근접 이웃 알고리즘 제공          K-NN 등                          sklearn.svm          서포트 벡터 머신 알고리즘 제공                                     sklearn.naive_bayes          나이브 베이즈 알고리즘 제공          가우시안 NB, 다항 분포 NB 등                          sklearn.cluster          클러스터링 알고리즘 제공          K-Means, 계층형 클러스터링, DBSCAN 등                          sklearn.linear_model          회귀분석 알고리즘 제공          선형 회귀, 확률적 경사하강 회귀(SGD), 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등                          sklearn.decomposition          차원 축소 알고리즘 제공          PCA, NMF, Truncated SVD 등                          sklearn.ensemble          앙상블 알고리즘 제공          Random Forest, AdaBoost, GradientBoost 등                          전처리                            모듈          설명          예시                                      sklearn.preprocessing          데이터 전처리 기능 제공          인코더, 스케일러 등                          sklearn.feature_selection          특성(feature)을 선택할 수 있는 기능 제공                                     sklearn.feature_extraction          특성(feature)을 추출할 수 있는 기능 제공                                     sklearn.pipeline          특성 처리, 학습, 예측을 묶어서 실행할 수 있는 기능 제공                                     검증 및 성능 평가 지표                            모듈          설명          예시                                      sklearn.model_selection          교차 검증, 최적 하이퍼파라미터 추출 API 제공          GridSearch 등                          sklearn.metrics          성능 평가 지표 제공          Accuracy, Precision, Recall, ROC-AUC, RMSE 등                    내장 데이터 세트sklearn.datasets      내장 데이터 형식                            이름          설명                                      DESCR          자료에 대한 설명                          data          설명 변수                          target          반응 변수                          feature_names          설명 변수 이름 리스트                          target_names          반응 변수 이름 리스트                          내장 데이터 세트 목록                            데이터 로드 함수          데이터          참고                                      load_boston          보스턴 집값          내장 데이터                          load_diabetes          당뇨병                                     load_linnerud          linnerud                                     load_iris          붓꽃                                     load_digits          필기 숫자(digit) 이미지                                     load_wine          포도주(wine) 등급                                     load_breast_cancer          유방암 진단                                     fetch_california_housing          캘리포니아 집값          인터넷 다운로드                          fetch_covtype          토지조사                                     fetch_20newsgroups          뉴스 그룹 텍스트                                     fetch_olivetti_faces          얼굴 이미지                                     fetch_lfw_people          유명인 얼굴                                     fetch_lfw_pairs          유명인 얼굴                                     fetch_rcv1          로이터 뉴스 말뭉치                                     fetch_kddcup99          Kddcup 99 Tcp dump                                     make_regression          회귀분석용          가상 데이터                          make_classification          분류용                                     make_blobs          클러스터링용                               "
  },
  
  {
    "title": "SubTree",
    "url": "/posts/SubTree/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-12 00:00:00 +0900",
    





    
    "snippet": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 ...",
    "content": "SubTree      정의 : 하위 폴더 형식으로 다른 저장소의 하위 항목 혹은 전체를 현재 저장소에 병합하는 기법        NICKNAME          origin : 하위 원격 저장소      upstream : 하위 원격 저장소 내역을 포함할 원격 저장소                  subtree : upstream 에서 하위 저장소 내역을 저장하는 폴더                    Initial Configgit clone &lt;UPSTREAM-URL&gt;cd &lt;UPSTREAM-PATH&gt;git remote add upstream &lt;UPSTREAM-URL&gt;git remote add origin &lt;ORIGIN-URL&gt;Creategit subtree add --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree add : 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 내역을 저장할 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 를 생성함Pull : Update Changes in Origin to Upstreamgit subtree pull --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree pull : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 의 변경 사항을 병합(pull)함Push : Update Changes in Upstream to Origingit subtree push --prefix=&lt;SUBTREE-PATH&gt; &lt;ORIGIN&gt; &lt;ORIGIN-BRANCH&gt;  subtree push : 상위 저장소의 폴더 &lt;SUBTREE-PATH&gt; 에서 직접 갱신한 내역을 하위 저장소 &lt;ORIGIN&gt; 의 브랜치 &lt;ORIGIN-BRANCH&gt; 에 추가함Splitgit subtree split --prefix=&lt;SUBTREE-PATH&gt; -b &lt;NEW-BRANCH&gt;  subtree split : 하위 저장소와 연동되어 있는 폴더 &lt;SUBTREE-PATH&gt; 에 관한 커밋을 추출하여 새로운 브랜치를 생성함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Interlock",
    "url": "/posts/Interlock/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-11 00:00:00 +0900",
    





    
    "snippet": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격...",
    "content": "Interlock Local &amp; RemoteSearchgit remote &lt;OPTION&gt;      remote : 원격 저장소와 관련된 작업에 사용하는 명령어        &lt;OPTION&gt;          None : 로컬 저장소에 연결되어 있는 원격 저장소의 별명을 조회함      -v : 로컬 저장소에 연결되어 있는 원격 저장소의 별명 및 경로를 조회함      Interlockgit remote add &lt;NICKNAME&gt; &lt;REMOTE-REPO-PATH&gt;      remote add : 로컬 저장소에 원격 저장소를 연결함    &lt;NICKNAME&gt; : 호출 시 사용할 원격 저장소 별칭          upstream : 최상위 원격 저장소      origin : 여러 개의 원격 저장소를 위계를 세워 연동하지 않는 한 통상 해당 이름을 사용함      alt        &lt;REMOTE-REPO-PATH&gt; : 연결할 원격 저장소의 경로Renamegit remote rename &lt;EXISITING-NAME&gt; &lt;NEW-NAME&gt;  remote rename : 원격 저장소 별명을 &lt;EXISITING-NAME&gt; 에서 &lt;NEW-NAME&gt; 으로 변경함Changegit remote set-url &lt;NICKNAME&gt; &lt;NEW-PATH&gt;  remote set-url : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소 경로를 변경함Resetgit remote remove &lt;NICKNAME&gt;  remote remove : &lt;NICKNAME&gt; 에 할당되어 있는 원격 저장소와의 연결을 해제함DownLoad Remote Repository복제하기git clone &lt;OPTION&gt; &lt;REMOTE-REPO-PATH&gt;      clone : 원격 저장소의 커밋 내역을 가져와서 로컬에 새로운 저장소를 생성함        &lt;OPTION&gt;          None      -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제함      --single-branch -b &lt;BRANCH-NAME&gt; : 특정 브랜치만 복제 후 해당 브랜치만 추적함      --depth &lt;N&gt; : 최신 커밋 HEAD 로부터 특정 깊이까지만 복제함      가져와서 병합하기git pull &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;      pull : 원격 저장소의 커밋 내역을 가져와서 로컬 저장소의 내역과 병합함        &lt;OPTION&gt;          None : fetch + merge      -r : fetch + rebase      가져와서 임시 분기하기git fetch &lt;OPTION&gt; &lt;NICKNAME&gt; &lt;BRANCH-NAME&gt;:&lt;NEW-NAME&gt;  fetch : 원격 저장소의 커밋 내역을 가져와서 브랜치명 &lt;NEW-NAME&gt; 으로 임시 분기한 상태로 열람함          &lt;NEW-NAME&gt; 을 별도로 지정하지 않으면 FETCH_HEAD 로 자동 설정함        &lt;OPTION&gt;          None      --dry-run : 원격 저장소의 커밋 내역을 로컬로 가져오지 않고, 가져올 것이 있는지 여부만 확인      --all : 원격 저장소의 모든 브랜치에 대한 내역을 가져옴      Upload Local Changes to RemotePushgit push &lt;OPTION&gt; &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;      push : 로컬 브랜치의 커밋(변경 확정 내역)을 원격 브랜치에 반영함        &lt;OPTION&gt;          None      --all : 모든 로컬 브랜치에 대하여 기능함      --tags : 모든 로컬 태그에 대하여 기능함      --force : 충돌 시 경고를 무시하고 강제로 기능함      --dry-run : 실제로 푸시하지 않고 어떤 변경 사항이 발생할지 미리 확인함      Trackinggit push --set-upstream &lt;REMOTE-NICKNAME&gt; &lt;REMOTE-BRANCH-NAME&gt;  push --set-upstream : 현재 체크인한 로컬 브랜치를 원격 저장소 &lt;REMOTE-NICKNAME&gt; 의 브랜치 &lt;REMOTE-BRANCH-NAME&gt; 에 연동함Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Branch",
    "url": "/posts/Branch/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-10 00:00:00 +0900",
    





    
    "snippet": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들...",
    "content": "가지치기      정의 : 특정 커밋에서 분기하여 새로운 흐름을 생성하는 작업    규칙          통상 Main Branch 커밋에서 Sub Branch 로 가지치기함                  Main : 최종본 커밋을 기록하는 브랜치로서 기본값으로 설정되어 있는 브랜치          Sub : 특정 최종본으로부터 분기되어 변경된 사항들을 기록하는 브랜치                    최종본 커밋을 기록하는 브랜치에는 최종본 내역 이외의 내역을 남기지 않음                  Main Branch 에는 최종본 커밋만을 기록함          Sub Branch 에는 작업 커밋을 기록함                          방법 : Five Branch Style              Main : 최종본 커밋을 기록하는 브랜치      Develop : Feature 들을 병합하는 브랜치      Feature : Develop 로부터 작업 주제에 따라 추가 분기하는 브랜치      Release : Develop 에서 확정되어 최종본이 된 커밋을 Main 으로 배포하는 브랜치      Hot-Fix : Develop 을 거치지 않고 수정하고 싶을 때 Main 에서 임시 분기하는 브랜치      PruningSearchgit branch &lt;OPTION&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 로컬 저장소에 존재하는 브랜치 목록을 조회함      -vv : 로컬 저장소에 존재하는 브랜치 및 각 브랜치가 추적하는 원격 브랜치 목록을 조회함      Create, Rename, Deletegit branch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      branch : 브랜치 관리(조회, 생성, 이름 변경, 삭제 등)에 대하여 기능함        &lt;OPTION&gt;          None : 현재 체크인하고 있는 커밋으로부터 분기하는 새로운 브랜치 &lt;BRANCH-NAME&gt; 를 생성함      -m : 현재 체크인하고 있는 브랜치 이름을 &lt;BRANCH-NAME&gt; 으로 변경함      -d : 브랜치 &lt;BRANCH-NAME&gt; 를 삭제함      Check-Ingit switch &lt;OPTION&gt; &lt;BRANCH-NAME&gt;      switch : 브랜치 및 커밋의 전환에 대하여 기능함        &lt;OPTION&gt;          -c : 현재 체크인하고 있는 커밋에서 분기하는 새로운 브랜치를 만들고 해당 브랜치로 체크인함      IntegrationMergegit switch &lt;OPTION&gt; &lt;BASE-BRANCH&gt;git merge &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;      merge : 현재 체크인한 브랜치에서 다른 브랜치를 병합하여 새로운 커밋을 생성함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Rebasegit switch &lt;OPTION&gt; &lt;TARGET-BRANCH&gt;git rebase &lt;OPTION&gt; &lt;BASE-BRANCH&gt;      rebase : 현재 체크인한 브랜치 내역을 다른 브랜치와 공통분모가 되는 커밋에 삽입함        &lt;OPTION&gt;          --abort : 충돌 시 병합을 중단함      --continue : 충돌 시 병합을 재개함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit Control",
    "url": "/posts/Commit_Control/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-09 00:00:00 +0900",
    





    
    "snippet": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석...",
    "content": "SearchCommit Historygit log &lt;OPTION&gt;      log : 현재 위치한 브랜치의 커밋 내역을 조회함        &lt;OPTION&gt;          None : 현재 위치한 브랜치의 커밋 히스토리 조회      --stat : 파일별 변경 사항 히스토리 조회      --oneline : 커밋 해시 및 주석 목록 조회      Commitgit show &lt;COMMIT-HASH&gt;      show : 특정 커밋의 정보를 상세 조회함        &lt;COMMIT-HASH&gt;          None : HEAD 커밋      Differencegit diff &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt;      diff : 커밋 간 변경 사항의 차이점을 조회함        &lt;COMMIT-1&gt;..&lt;COMMIT-2&gt; : &lt;COMMIT-1&gt; 에만 존재하는 변경 사항  Move      커밋 전환의 이해              커밋을 이동하는 것은 변수 HEAD 가 가리키는 커밋을 변경하는 작업임            변수 HEAD 의 이해              변수 HEAD 는 현재 체크인하고 있는 브랜치를 가리키고, 각 브랜치는 마지막 커밋을 가리킴      즉, 변수 HEAD 는 현재 체크인하고 있는 브랜치를 참조하여 마지막 커밋을 간접으로 가리키게 됨            DETACHED HEAD                      정의 : HEAD 가 브랜치를 참조하지 않고 커밋을 직접 가리키는 상태                    문제점                  이동한 커밋에서 새로운 커밋을 생성하면 해당 커밋은 브랜치를 벗어나 단독으로 존재하는 상태가 됨          본래 커밋은 직접 지목되지 않고 브랜치를 참조하여 지목되므로 해당 커밋을 가리킬 방법이 없음          이러한 경우 새로운 커밋에서 시작하는 새로운 브랜치를 생성하여 해결함                    refer. Commit Hashgit switch &lt;COMMIT-HASH&gt;refer. Taggit switch tags/&lt;TAG-NAME&gt;Copy &amp; PastePaste# 커밋을 붙여넣을 브랜치로 이동git switch &lt;BRANCH-NAME&gt;# 커밋 붙여넣기git cherry-pick &lt;COMMIT-HASH&gt;  cherry-pick : 현재 위치한 브랜치에 특정 커밋을 기록함If Conflict# 충돌 사항 수정 후 해당 파일들을 스테이지에 올리기git add &lt;conflict files&gt;# 일시중지 작업에 대하여 재개 혹은 중단git cherry-pick &lt;OPTION&gt;  &lt;OPTION&gt; : 일시중지 작업에 대하여 기능함          --continue : 작업 재개      --abort : 작업 중단 및 일시중단 이전 상태로 복원      Cancel커밋 되돌리기git revert &lt;COMMIT-HASH&gt;  revert : 특정 커밋 상태로 되돌리는 새로운 커밋을 생성함커밋 삭제하기git reset &lt;OPTION&gt; &lt;COMMIT-HASH&gt;      reset : 특정 커밋 이후에 추가 기록된 커밋들을 모두 삭제하고 해당 커밋으로 되돌림        &lt;OPTION&gt;              --hard : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 해제하고, 해당 커밋 이후에 기록된 커밋을 삭제함      --mixed : HEAD 를 해당 커밋으로 되돌리고, 파일의 modified 및 staged 상태를 유지하되, 해당 커밋 이후에 기록된 커밋을 삭제함      --soft : HEAD 를 해당 커밋으로 되돌리되, 파일의 modified 및 staged 상태를 유지하고, 해당 커밋 이후에 기록된 커밋을 유지함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "File Control",
    "url": "/posts/File_Control/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-08 00:00:00 +0900",
    





    
    "snippet": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&g...",
    "content": "staged 파일 임시 저장하기임시 저장 목록 조회하기git stash list   stash list : 임시 저장 목록을 조회함변경 사항 임시 저장하기git stash save  stash save : staged 파일의 변경 사항을 확정하지 않고 임시 저장함임시 저장 항목 불러와서 적용하기git stash apply &lt;STASH-NAME&gt; &lt;OPTION&gt;      stash apply : 임시 저장 항목을 HEAD 커밋에 불러와서 적용함        option          None : 임시 저장 항목을 불러와서 HEAD 커밋과 병합한 후 변경 사항을 스테이지 영역에 추가함      --index : HEAD 커밋과 병합 시 충돌 사항을 조회함      임시 저장 항목 삭제하기git stash drop &lt;STASH-NAME&gt;  stash drop : 특정 임시 저장 항목을 삭제함git stash clear  stash clear : 임시 저장 목록을 초기화함파일 상태 다루기.gitignoreWORKING-DIRECTORY-PATH/.gitignore  .gitignore : 워킹 디렉토리 하위 항목 중 Git 의 추적에서 제외할 항목을 설정하는 파일rmgit rm &lt;OPTION&gt; &lt;FILE-NAME&gt;      rm : 파일을 삭제하거나 추적에서 제외함        &lt;OPTION&gt;          None : 파일을 삭제함      --cached : 파일을 untracked 상태로 전환하고 워킹 디렉토리에서는 삭제하지 않음      -r : 워킹 디렉토리의 하위 항목을 모두 삭제함      --dry-run : 명령어 실행 시 어떤 파일들이 삭제될 것인지 조회함      파일 상태 복원하기git restore &lt;OPTION&gt; &lt;FILE-NAME&gt;  restore : 파일 상태를 특정 시점으로 복원할 때 사용하는 명령어          커밋을 이동하는(변수 HEAD 의 아규먼트를 변경하는) 작업이 아니므로 detached HEAD 를 초래하지 않음      단, restore 상태에서 커밋 생성 시 detached HEAD 발생함        &lt;OPTION&gt;          None : 파일 상태를 HEAD 시점으로 복원함      --worktree : modified 파일의 상태를 HEAD 시점으로 복원함      --staged : staged 파일의 상태를 HEAD 시점으로 복원함      --source=&lt;COMMIT-HASH&gt; : 파일 상태를 특정 커밋 시점으로 복원함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Commit",
    "url": "/posts/Commit/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-07 00:00:00 +0900",
    





    
    "snippet": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대...",
    "content": "Status      untracked : 한번도 커밋되지 않아 git 이 수정 여부를 추적할 수 없는 상태        tracked          Non-modified : 마지막 커밋 후 변경 사항이 없는 상태      Modified : 마지막 커밋 후 변경 사항이 존재하는 상태      Staged : 변경 사항을 확정하여 기록하기 위해 대기하는 상태      Committed : 변경 사항이 확정되어 브랜치에 기록된 상태      Statusgit status  status : 현재 체크인하고 있는 로컬 저장소 브랜치의 상태를 조회함          현재 위치하고 있는 로컬 브랜치      modified 파일 목록      staged 파일 목록      untracked 파일 목록      Differencegit diff &lt;OPTION&gt; &lt;FILE-NAME&gt;      diff : modified 파일의 변경 사항을 조회함        &lt;OPTION&gt;          None : unstaged area 와 stage area 간 변경 사항 조회      HEAD : unstaged area 와 최신 커밋 HEAD 간 변경 사항 조회      --staged : stage area 와 최신 커밋 HEAD 간 변경 사항 조회      Commit ProcessAddgit add &lt;FILE-NAME&gt;  add : modified 파일을 스테이지 영역에 추가함Commitgit commit &lt;OPTION&gt;      commit : staged 파일의 변경 사항을 확정하여 로컬 브랜치에 기록함        &lt;OPTION&gt;          None      -m \"COMMIT MESSAGE\" : 텍스트 에디터를 열지 않고 커멘트 창에서 커밋 메시지를 작성함      --date=\"YYYY-MM-DD HH:MM:SS\" : 커밋한 시각을 명시함      --signoff : 커밋 메시지 끝에 커밋한 사용자의 user.name 과 user.email 을 표기함      --allow-empty : 변경 사항이 없는 빈 커밋을 생성함      --amend : 현재 staged 파일들의 변경 사항을 최신 커밋에 추가 기록하여 새로운 커밋을 생성하고, 기존 커밋을 삭제함      Commit Message Rule  제목(header), 본문(body), 바닥글(footer)은 빈 행(\\n)으로 구분함  본문과 바닥글은 생략해도 무방함  제목은 50글자 이내로 제한함  제목의 첫 글자는 대문자로 작성함  제목 끝에는 마침표를 넣지 않음  제목은 명령문으로 사용하며 과거형을 사용하지 않음  본문에는 HOW 보다는 WHAT, WHY 에 대해서 서술함  본문의 각 행은 72글자 내로 제한함  바닥글에는 참조 정보를 기입함Type            type      설명                  docs      문서 갱신, 주석 추가 또는 데이터의 출처와 처리 방법 등을 문서화              feat      새로운 데이터 분석 기능이나 알고리즘 추가              fix      버그 수정 또는 데이터 정제 과정에서의 오류 수정              perf      성능 향상을 위한 코드 수정              style      코드 스타일 변경 또는 주석의 스타일 수정              refactor      데이터 처리 또는 분석 코드의 구조 변경              data      데이터셋의 추가, 업데이트, 또는 데이터 전처리과정에 관련된 작업              test      새로운 테스트 추가 또는 기존 테스트 수정              chore      빌드 시스템 설정 변경, 라이브러리 업데이트 또는 그 외 기타 작업      TagSearchgit tag -list &lt;OPTION&gt;      tag -list : 로컬 브랜치의 태그 목록을 조회함        &lt;OPTION&gt;          None : 전체 태그 목록      &lt;CONDITION.*&gt; : 키워드 CONDITION 을 포함하는 태그 목록      git show &lt;TAG-NAME&gt;      show : 특정 태그 정보를 상세조회함          태그 주석(Tag Annotation)      태그 작성자(Tagger)      태그 날짜(Date)      해당 태그가 가리키는 커밋      Creategit tag &lt;OPTION&gt; &lt;TAG-NAME&gt; &lt;COMMIT-HASH&gt;      tag : 특정 커밋에 태그를 부착함        &lt;OPTION&gt;          None : 기본 태그(LightWeight Tag)              -a : 주석 태그(Annotated Tag)          git tag -a &lt;TAG-NAME&gt; -m \"Annotation\" &lt;COMMIT-HASH&gt;                    Deletegit tag -d &lt;TAG-NAME&gt;      tag -d : 로컬 저장소의 특정 태그를 삭제함        &lt;TAG-NAME&gt;          $(git tag -l) : 로컬 저장소의 모든 태그를 삭제함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "What? GIT",
    "url": "/posts/Git/",
    "categories": "AI Dev. Env., GIT",
    "tags": "Dev. Env., DVCS, GIT",
    "date": "2023-03-06 00:00:00 +0900",
    





    
    "snippet": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중...",
    "content": "What? GitHub  정의 : Git 을 지원하는 원격 저장소 제공 서비스          Git : 분산형 버전 관리 시스템(Distributed Virsion Control System; DVCS)의 일종        분산형 버전 관리 시스템의 이해                  데이터 저장 방식                          중앙 집중 방식 : 데이터를 통합 관리하는 중앙 서버에 최종본 한 벌을 두고 로컬에서 서버에 접근하는 방식          분산 저장 방식 : 개별 노드가 네트워크를 통해 개별 노드가 확정본 변경 사항을 동기화하면서 공동으로 관리하는 방식                            버전 관리 시스템                  정의 : 확정본 및 이로부터 분기되어 변경된 사항을 추적/관리하는 시스템                      복사본을 이용한 버전 관리                                            버전 관리 시스템을 이용한 버전 관리                                            기능 및 관련 도구          병렬 작업 : Branch(데이터 형상 변경 내역 흐름)      변경점 관리 : Commit(데이터 형상 변경 내역)      확정본 관리 : Tag(데이터 변경 내역에 다는 꼬리표)      Traking Working DirectoryGit DownLoad  Git DownLoadTrackinggit initEnroll GitHub Accountgit config --global user.name &lt;NAME&gt;git config --global user.email &lt;EMAIL&gt;Configworking-directory-path/.git/config  설정 파일 config 는 워킹 디렉토리의 숨김 폴더 .git 내부에 위치함Searchgit config &lt;SCOPE&gt; &lt;FIELD&gt;      config : config 파일에 대하여 기능함    &lt;SCOPE&gt; : 범위          --system : 시스템 전체 설정      --global : 홈 디렉토리 설정      --local : 워킹 디렉토리 설정        &lt;FIELD&gt; : 아규먼트에 대하여 기능할 속성 파라미터          --list : 모든 속성 파라미터의 아규먼트를 반환함      user.name : 워킹 디렉토리에 연동할 깃허브 계정 닉네임      user.email : 워킹 디렉토리에 연동할 깃허브 계정 이메일      core.editor      color.ui      alias.[alias-name]      Setgit config &lt;SCOPE&gt; &lt;FIELD&gt; &lt;VALUE&gt;  config : config 파일에 대하여 기능함  &lt;VALUE&gt; : 필드에 할당할 아규먼트Resetgit config &lt;SCOPE&gt; &lt;OPTION&gt; &lt;FIELD&gt;  &lt;OPTION&gt;          --unset : 특정 필드의 아규먼트를 초기화함      --unset-all : 모든 필드의 아규먼트를 초기화함      Reference  Git - 간편 안내서  누구나 쉽게 이해할 수 있는 Git 입문"
  },
  
  {
    "title": "Integration",
    "url": "/posts/Integration/",
    "categories": "Mathematical Techs, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-15 00:00:00 +0900",
    





    
    "snippet": "적분의 이해적분(Integration)      정의 : 매우 작은 양을 쌓아가는 방법            미분과의 관계                  미분\\[f(x)  = F(x) \\times \\displaystyle\\frac{1}{\\Delta x}\\]                  $F(x)$ 의 $x$ 에 대한 순간변화율 $f(x)$ 를 구하는 ...",
    "content": "적분의 이해적분(Integration)      정의 : 매우 작은 양을 쌓아가는 방법            미분과의 관계                  미분\\[f(x)  = F(x) \\times \\displaystyle\\frac{1}{\\Delta x}\\]                  $F(x)$ 의 $x$ 에 대한 순간변화율 $f(x)$ 를 구하는 방법          $F(x)$ 를 $\\Delta x$ 로 잘게 쪼개는 방법                            적분\\[F(x) + C  = \\displaystyle\\sum{[f(x) \\times \\Delta x]}\\]                  $x$ 축과 피적분함수 $f(x)$ 로 둘러싸인 면적의 너비 $F(x)+C$ 를 구하는 방법          미분소($f(x) \\times \\Delta x$)를 쌓아가는 방법                    부정적분(Indefinite Integral)      정의 : 어떤 함수 $f(x)$ 를 도함수로 하는 모든 함수 $F(x)+C$ 를 구하는 연산\\[F(x) + C = \\int{f(x)dx}\\]          $f(x)$ : $F(x)+C$ 의 피적분함수, 도함수 혹은 미분계수      $F(x)+C$ : $f(X)$ 의 부정적분함수      $C$ : 적분상수            성질          $\\displaystyle\\int{\\alpha \\cdot f(x)dx} = \\alpha \\cdot \\displaystyle\\int{f(x)dx}$      $\\displaystyle\\int{[f(x) \\pm g(x)] dx} = \\displaystyle\\int{f(x)dx} \\pm \\displaystyle\\int{g(x)dx}$      $\\displaystyle\\int{x^n dx} = \\displaystyle\\frac{x^{n+1}}{n+1} + C$      $\\displaystyle\\int{\\frac{1}{x}dx} = \\ln{\\vert x \\vert}+C$      $\\displaystyle\\int{e^{x}dx} = e^{x}+C$      $\\displaystyle\\int{\\frac{f^{\\prime}(x)}{f(x)}dx} = \\ln{\\vert f(x) \\vert}+C$      $\\displaystyle\\int{\\sin{x}dx} = -\\cos{x}+C$      $\\displaystyle\\int{\\cos{x}dx} = \\sin{x}+C$      정적분(Definite Integral)      정의 : $x \\in [a,b]$ 과 피적분함수 $f(x)$ 로 둘러싸인 면적의 너비를 구하는 연산\\[\\begin{aligned}  S  &amp;= \\int_{a}^{b}{f(x)dx} \\\\  &amp;= F(b) - F(a)  \\end{aligned}\\]          $a$ : 적분의 아래 한계      $b$ : 적분의 위의 한계            성질          $\\displaystyle\\frac{d}{dx}\\displaystyle\\int_{a}^{x}{f(t)dt} = f(x)$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} = \\alpha \\displaystyle\\int_{a}^{b}{f(x)dx}$      $\\displaystyle\\int_{a}^{b}{f(x) \\pm g(x)dx} = \\displaystyle\\int_{a}^{b}{f(x)dx} \\pm \\displaystyle\\int_{a}^{b}{g(x)dx}$      $\\displaystyle\\int_{a}^{a}{\\alpha f(x)dx} = 0$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} = -\\displaystyle\\int_{b}^{a}{\\alpha f(x)dx}$      $\\displaystyle\\int_{a}^{b}{\\alpha f(x)dx} + \\displaystyle\\int_{b}^{c}{\\alpha f(x)dx} = \\displaystyle\\int_{a}^{c}{\\alpha f(x)dx}\\,(a&lt;b&lt;c)$      중적분(Multiple Integral)      정의 : 영역 $B$ 에서 적분 가능한 다변수함수 $y=f(x_1,x_2,\\cdots,x_n)$ 에 대하여 변수 $x_1,x_2,\\cdots,x_n$ 에 대한 정적분\\[\\begin{aligned}  \\int_{x_n} \\cdots \\int_{x_2} \\int_{x_1} f(x_1,x_2,\\cdots,x_n) dx_1 dx_2 \\cdots dx_n  \\end{aligned}\\]        이중적분(Double Integral)의 예시                  영역 $B$ 를 다음과 같이 정의하자\\[\\begin{aligned}  B  &amp;= [a,b]\\times[c,d]\\\\  &amp;= \\{(x,y)|a \\leq x \\leq b, c \\leq y \\leq d\\}  \\end{aligned}\\]                    2변수함수 $z=f(x,y)$ 는 영역 $B$ 에서 적분 가능한 함수임\\[\\begin{aligned}  \\lim_{x \\rightarrow k-}f(x,y)=\\lim_{x \\rightarrow k+}f(x,y)=f(k,y)\\;(a \\leq k \\leq b)\\\\  \\lim_{y \\rightarrow k-}f(x,y)=\\lim_{y \\rightarrow k+}f(x,y)=f(x,k)\\;(c \\leq k \\leq d)\\\\  \\end{aligned}\\]                    피적분함수 $z=f(x,y)$ 를 영역 $B$ 에서 $y$ 에 대하여 적분하면 다음과 같음\\[\\begin{aligned}  g(x)  &amp;= \\int_{c}^{d}{z}dy\\\\  &amp;= \\int_{c}^{d}{f(x,y)}dy\\\\  &amp;= F(x,d)-F(x,c)  \\end{aligned}\\]                    $x$ 에 관한 함수 $g(x)$ 를 영역 $B$ 에서 $x$ 에 대하여 적분하면 다음과 같음\\[\\begin{aligned}  \\int_{a}^{b}{g(x)}dx  &amp;= G(b) - G(a)  \\end{aligned}\\]                    이상을 요약하면 다음과 같음\\[\\begin{aligned}  \\int_{a}^{b}(\\int_{c}^{d}{z}dy)dx  &amp;= \\int_{a}^{b}\\int_{c}^{d}{f(x,y)}dy\\,dx  \\end{aligned}\\]            특수한 경우의 적분법부분적분 : 곱셈의 적분법      $x$ 에 대하여 미분 가능한 함수 $u(x),v(x)$ 의 곱을 $x$ 에 대하여 미분하면 다음과 같음\\[\\begin{aligned}  \\frac{d}{dx}uv  &amp;= u\\frac{dv}{dx} + v\\frac{du}{dx}  \\end{aligned}\\]        양변에 $dx$ 를 곱하면 다음과 같음\\[\\begin{aligned}  d(uv)  &amp;= u \\cdot dv + v \\cdot du  \\end{aligned}\\]        양변의 일부 항목을 이항하면 다음과 같음\\[\\begin{aligned}  u \\cdot dv  &amp;= d(uv) - v \\cdot du  \\end{aligned}\\]        양변을 적분하면 다음과 같음\\[\\begin{aligned}  \\int{u \\cdot dv}  &amp;= uv - \\int{v \\cdot du}  \\end{aligned}\\]  유리함수의 적분법      진분수함수 $\\displaystyle\\frac{f(x)}{g(x)}$ 를 다음과 같이 가정하자\\[\\begin{aligned}  \\frac{f(x)}{g(x)}  &amp;= \\frac{x^3 - x^2 - 2}{x(x-1)}  \\end{aligned}\\]        $f(x)$ 를 $g(x)$ 로 나누면 다음과 같음\\[\\begin{aligned}  f(x) \\div g(x)  &amp;= \\frac{x^3 - x^2 - 2}{x(x-1)} \\\\  &amp;= \\frac{x^2(x - 1) - 2}{x(x-1)} \\\\  &amp;= x - \\frac{2}{x(x-1)}  \\end{aligned}\\]        나머지를 부분분수분해하면 다음과 같음\\[\\begin{aligned}  \\frac{2}{x(x-1)}  &amp;= 2 \\times \\frac{1}{(x-1)-x}(\\frac{1}{x}-\\frac{1}{x-1})\\\\  &amp;= -\\frac{2}{x} + \\frac{2}{x-1}  \\end{aligned}\\]        $\\displaystyle\\frac{f(x)}{g(x)}$ 를 재정의하면 다음과 같음\\[\\begin{aligned}  \\frac{f(x)}{g(x)}  &amp;= x + \\frac{2}{x} - \\frac{2}{x-1}  \\end{aligned}\\]        양변을 적분하면 다음과 같음\\[\\begin{aligned}  \\int\\frac{f(x)}{g(x)}dx  &amp;= \\int{[x + \\frac{2}{x} - \\frac{2}{x-1}]dx}\\\\  &amp;= \\int{x}dx + \\int{\\frac{2}{x}}dx - \\int{\\frac{2}{x-1}}dx  \\end{aligned}\\]  이상적분 : 극한치의 적어도 한 개가 무한일 경우의 적분법      피적분함수 $f(x)=\\displaystyle\\frac{1}{x^2}$ 에 대한 정적분을 다음과 같이 가정하자\\[\\int_{1}^{\\infty}{\\frac{1}{x^2}}dx\\]        적분의 위의 한계 $\\infty$ 를 상수 $k$ 로 치환하면 다음과 같음\\[\\lim_{k\\rightarrow\\infty}{\\int_{1}^{k}{\\frac{1}{x^2}}dx}\\]        $f(x)$ 를 $[1,k]$ 에서 정적분하면 다음과 같음\\[\\begin{aligned}  \\int_{1}^{k}{\\frac{1}{x^2}}dx  &amp;= [-x^{-1}]^{k}_{1}\\\\  &amp;= -\\frac{1}{k}+1  \\end{aligned}\\]        $k\\rightarrow\\infty$ 일 때 위 식의 값은 다음과 같음\\[\\begin{aligned}  \\lim_{k\\rightarrow\\infty}{-\\frac{1}{k}+1}  &amp;= 1  \\end{aligned}\\]  "
  },
  
  {
    "title": "Partial Derivative",
    "url": "/posts/Partial_Derivative/",
    "categories": "Mathematical Techs, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-14 00:00:00 +0900",
    





    
    "snippet": "편미분(Partial Derivative)      정의 : 다변수함수 $y=f(x,\\cdots)$ 에 대하여, 변수 $x$ 를 제외한 모든 변수를 일정한 상수로 고정하였을 때 $x$ 축에 평행한 방향에 대한 $y$ 의 순간변화율                  $z$ 에 대한 $x,y$ 의 2변수함수 $f$ 를 상정하자\\[z=f(x,y)\\]      ...",
    "content": "편미분(Partial Derivative)      정의 : 다변수함수 $y=f(x,\\cdots)$ 에 대하여, 변수 $x$ 를 제외한 모든 변수를 일정한 상수로 고정하였을 때 $x$ 축에 평행한 방향에 대한 $y$ 의 순간변화율                  $z$ 에 대한 $x,y$ 의 2변수함수 $f$ 를 상정하자\\[z=f(x,y)\\]                    $y=b$ 로서 고정되어 있을 경우, $z$ 는 $x$ 만의 함수라고 볼 수 있음\\[z=f(x,y=b)\\]                    $z$ 에 대한 $x$ 만의 함수 $f(x,y=b)$ 가 $x=a$ 에서 미분 가능하다고 하자\\[\\begin{aligned}  \\frac{\\partial}{\\partial x}f(a,b)  &amp;= \\lim_{h\\rightarrow 0}\\frac{f(a+h,b)-f(a,b)}{h}  \\end{aligned}\\]                    $(a,b)$ 에서 $x$ 에 관한 편미분계수(Partial Derivatial) 를 다음과 같이 표현함\\[\\begin{aligned}  D_{x}f(x=a,y=b)  &amp;=f_{x}(x=a,y=b)\\\\  &amp;=\\frac{\\partial}{\\partial x} f(x=a,y=b)\\\\  &amp;=\\frac{\\partial z}{\\partial x}  \\end{aligned}\\]              예시                  $\\text{temperature} = T(x, time)$                            $\\text{temperature} = T(x,time=3)$                            $\\text{temperature} = T(x) \\ (\\text{s.t.} \\, time=3)$                            $\\displaystyle\\frac{d}{dx}T(x,time=3)$                      고계편도함수 : 다변수함수에 대하여 그 편도함수의 편도함수                  $z$ 에 대한 $x,y$ 의 2변수함수 $f$ 를 상정하자\\[z=f(x,y)\\]                    $f$ 의 $x,y$ 에 대한 1계편도함수는 다음과 같음\\[f_{x}(x,y) = \\frac{\\partial}{\\partial x}f(x,y)\\\\  f_{y}(x,y) = \\frac{\\partial}{\\partial y}f(x,y)\\]                    1계편도함수의 $x,y$ 에 대한 편도함수는 다음과 같음\\[\\begin{aligned}  f_{xx}(x,y)  &amp;= (f_{x})_{x}\\\\  &amp;= \\frac{\\partial^2}{\\partial x^2}f(x,y)\\\\\\\\  f_{xy}(x,y)  &amp;= (f_{x})_{y}\\\\  &amp;= \\frac{\\partial^2}{\\partial y \\partial x}f(x,y)\\\\\\\\  f_{yx}(x,y)  &amp;= (f_{y})_{x}\\\\  &amp;= \\frac{\\partial^2}{\\partial x \\partial y}f(x,y)\\\\\\\\  f_{yy}(x,y)  &amp;= (f_{y})_{y}\\\\  &amp;= \\frac{\\partial^2}{\\partial y^2}f(x,y)  \\end{aligned}\\]            2변수함수의 극값      2변수함수의 그래프              2변수함수 $z=f(x,y)$ 의 그래프 ${(x,y,f(x,y)) \\vert (x,y)\\in D(f)}$ 는 $xyz$-공간에서의 곡면임        2변수함수의 임계점                  임계점(Critical Point) : 함수의 1계편도함수 값이 $0$ 이거나 존재하지 않는 지점\\[f_x = f_y = 0\\]                    극점(Local Extremum Point) : 임계점 중에서 극값을 갖는 지점                          $f$ 의 임계점 $(a,b)$ 의 모든 열린 근방 $(x,y)$ 에 대하여 다음 중 하나만을 만족하는 경우                          극대점 : $f(a,b) \\leq f(x,y)$              극소점 : $f(a,b) \\ge f(x,y)$                                            이는 $x,y$ 에 대한 이계편도함수가 다음을 만족함을 의미함\\[f_{xx} \\cdot f_{yy} - f^{2}_{xy} &gt; 0\\]                                      안장점(Saddle Point) : 임계점 중에서 극값을 갖지 않는 점으로서, 어떤 측면에서는 극소값이 되고, 동시에 다른 측면에서는 극대값이 되는 지점                          $f$ 의 임계점 $(a,b)$ 의 모든 열린 근방 $(x,y)$ 에 대하여 다음을 동시에 만족하는 경우                          $f(a,b) \\leq f(x,y)$              $f(a,b) \\ge f(x,y)$                                            이는 $x,y$ 에 대한 이계편도함수가 다음을 만족함을 의미함\\[f_{xx} \\cdot f_{yy} - f^{2}_{xy} &lt; 0\\]                                헤시안 행렬의 행렬식을 활용한 2변수함수의 극값 판별                  헤시안 행렬(Hessian Matrix) : 어떤 이변수함수의 이계편도함수를 표현한 행렬\\[\\begin{pmatrix}  f_{xx}&amp;f_{xy}\\\\  f_{xy}&amp;f_{yy}\\\\   \\end{pmatrix}\\]                    헤시안 행렬의 행렬식($D$)\\[\\begin{aligned}  D  &amp;=f_{xx} \\cdot f_{yy} - f^{2}_{xy}\\\\  &amp;=\\begin{vmatrix}  f_{xx}&amp;f_{xy}\\\\  f_{xy}&amp;f_{yy}\\\\   \\end{vmatrix}  \\end{aligned}\\]                    헤시안 행렬의 행렬식을 활용한 2변수함수의 극값 판별                  $f_x=f_y=0$ 인 점 $(a,b)$ 의 근방에서 함수 $f$ 와 그 일계편도함수가 모두 연속이라고 하자                          $D=0$ : 극값의 존재 여부를 결정할 수 없음              $D&lt;0$ : $f$ 는 $(a,b)$ 에서 안장점을 가짐              $D&gt;0$ : $f$ 는 $(a,b)$ 에서 극값을 가짐                                  $f_{xx} &lt; 0$ : 극대값                  $f_{xx} &gt; 0$ : 극소값                                                                        그라디언트(Gradient)      정의 : $n$ 변수함수 $y=f(x_{1},x_{2},\\cdots,x_{n})$ 에 대하여 각 변수에 대한 일계편도함수로 구성된 벡터\\[\\nabla f  =(\\frac{\\partial f}{\\partial x_{1}}, \\frac{\\partial f}{\\partial x_{2}}, \\cdots, \\frac{\\partial f}{\\partial x_{n}})^{T}\\]        해석 : \\(\\nabla f \\vert _{(x_{1},x_{2},\\cdots,x_{n})}\\) 는 점 \\((x_{1},x_{2},\\cdots,x_{n})\\) 에서 \\(f\\) 의 값이 가장 가파르게 증가하는 방향임      "
  },
  
  {
    "title": "Taylor Series",
    "url": "/posts/Taylor_Series/",
    "categories": "Mathematical Techs, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-13 00:00:00 +0900",
    





    
    "snippet": "극점과 극값  극대점과 극대값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\ge f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극대값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극대점이라고 하고,      ...",
    "content": "극점과 극값  극대점과 극대값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\ge f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극대값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극대점이라고 하고,                          극대점(Local Maximum Point) : 주위 모든 점의 함수값 이상의 함수값을 갖는 점                                이때의 함수값 $f(c)$ 를 $y=f(x)$ 의 극대값이라고 함                          극대값(Local Maximum Value) : 극대점이 갖는 함수값                                          성질                  함수 $y=f(x)$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c(a&lt;c&lt;b)$ 에서 극대값을 가지면 다음을 만족함                          $\\displaystyle\\frac{d}{dx}f(c)=f^\\prime(c)=0$              $\\displaystyle\\frac{d^2}{dx^2}f(c)=f^{\\prime\\prime}(c)&lt;0$                                            극소점과 극소값          정의 : 함수 $y=f(x)$ 에 대하여 $x=c$ 에 근접한 모든 $x$ 가 $f(c) \\le f(x)$ 인 경우                  $y=f(x)$ 는 $x=c$ 에서 극소값을 가진다고 하고,          점 $(x=c,y=f(c))$ 를 $y=f(x)$ 의 극소점이라고 하고,                          극대점(Local Minimum Point) : 주위 모든 점의 함수값 이상의 함수값을 갖는 점                                이때의 함수값 $f(c)$ 를 $y=f(x)$ 의 극소값이라고 함                          극대값(Local Minimum Value) : 극대점이 갖는 함수값                                          성질                  함수 $y=f(x)$ 가 구간 $[a,b]$ 에서 미분 가능하고, $x=c(a&lt;c&lt;b)$ 에서 극소값을 가지면 다음을 만족함                          $\\displaystyle\\frac{d}{dx}f(c)=f^\\prime(c)=0$              $\\displaystyle\\frac{d^2}{dx^2}f(c)=f^{\\prime\\prime}(c)&gt;0$                                          테일러 급수      테일러 다항식(Taylor Polynomial) : $x=a$ 에서 미분 가능한 함수 $y=f(x)$ 에 대하여, $y=f(x)$ 와 $x=a$ 에서 근사하는 $n$ 차 함수\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{n}{\\frac{f^{k}(a)}{k!}(x-a)^{k}}\\\\  &amp;= f(a)  + f^{\\prime}(a)(x-a)  + \\frac{f^{\\prime \\prime}(a)}{2!}(x-a)^{2}  + \\cdots  + \\frac{f^{n}(a)}{n!}(x-a)^{n}  \\end{aligned}\\]        선형 근사(Linear Approximation) : $y=f(x)$ 와 $x=a$ 에서 근사하는 $1$ 차 함수 혹은 그러한 함수를 찾는 방법\\[f(x) \\approx f(a) + f^{\\prime}(a)(x-a)\\]        테일러 급수(Taylor Series) : $n$ 이 무한대로 발산하는 경우 테일러 다항식\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{\\infty}{\\frac{f^{k}(a)}{k!}(x-a)^{k}}\\\\  &amp;= f(a)  + f^{\\prime}(a)(x-a)  + \\frac{f^{\\prime \\prime}(a)}{2!}(x-a)^{2}  + \\cdots  + \\frac{f^{n}(a)}{n!}(x-a)^{n}  + \\cdots  \\end{aligned}\\]        매클로린 급수(Maclaurin’s Series) : $a=0$ 인 경우 테일러 급수\\[\\begin{aligned}  f(x)  &amp;\\approx \\sum^{k=0}_{\\infty}{\\frac{f^{k}(0)}{k!}x^{k}}\\\\  &amp;= f(0)  + f^{\\prime}(0)x  + \\frac{f^{\\prime \\prime}(0)}{2!}x^{2}  + \\cdots  + \\frac{f^{n}(0)}{n!}x^{n}  + \\cdots  \\end{aligned}\\]  "
  },
  
  {
    "title": "Differentiation",
    "url": "/posts/Differentiation/",
    "categories": "Mathematical Techs, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-12 00:00:00 +0900",
    





    
    "snippet": "What? Differentiation  미분(Differentiation)          설명변수 $x$ 에 대한 반응변수 $y$ 의 순간변화율      설명변수 $x$ 가 $\\Delta x$ 만큼 변화할 때 $y$ 는 얼마만큼 변화하는가            평균변화율의 이해              설명변수 $x \\in X$ 에 대한 반응변수 $y...",
    "content": "What? Differentiation  미분(Differentiation)          설명변수 $x$ 에 대한 반응변수 $y$ 의 순간변화율      설명변수 $x$ 가 $\\Delta x$ 만큼 변화할 때 $y$ 는 얼마만큼 변화하는가            평균변화율의 이해              설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여              다음을 구간 $[x,a]$ 에서 $x$ 에 대한 $y$ 의 평균변화율이라고 정의함\\[\\begin{aligned}  \\displaystyle\\frac{\\Delta y}{\\Delta x}  &amp;=\\displaystyle\\frac{f(x)-f(a)}{x-a}\\\\  &amp;=\\displaystyle\\frac{f(x +\\Delta x)-f(x)}{\\Delta x}  \\end{aligned}\\]                  순간변화율의 이해\\[\\begin{aligned}  \\displaystyle\\frac{d y}{d x}  &amp;=\\lim_{x \\rightarrow a}\\displaystyle\\frac{f(x)-f(a)}{x-a}\\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{f(x + \\Delta x)-f(x)}{\\Delta x}  \\end{aligned}\\]          $x \\rightarrow a$ 일 때 구간 $[x,a]$ 에서 $x$ 에 대한 $y$ 의 평균변화율      $\\Delta x \\rightarrow 0$ 일 때 $x$ 에 대한 $y$ 의 평균변화율      즉, $x$ 의 변화폭이 0에 한없이 가까워질 때 $y$ 의 변화폭        미분 가능하다는 말의 의미          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $x=a$ 에서 순간변화율 값이 존재하면 $f$ 는 $x=a$ 에서 미분 가능하다고 말함      모든 정의역에 대하여 미분 가능하다면 $f$ 는 $x$ 에 대하여 미분 가능하다고 말함        성질                  $x$ 에 대하여 미분 가능한 함수 $f(x), g(x)$ 와 상수 $\\alpha$ 에 대하여 다음이 성립함                  $\\displaystyle\\frac{d}{dx}\\alpha=0$          $\\displaystyle\\frac{d}{dx}(\\alpha \\times f(x)) = \\alpha \\times (\\displaystyle\\frac{d}{dx}f(x))$          $\\displaystyle\\frac{d}{dx}x^n=n \\times x^{n-1}$          $\\displaystyle\\frac{d}{dx}(f(x)\\pm g(x))=\\displaystyle\\frac{d}{dx}f(x) \\pm \\frac{d}{dx}g(x)$          $\\displaystyle\\frac{d}{dx}(f(x)\\times g(x))=(\\displaystyle\\frac{d}{dx}f(x))\\times g(x) + f(x) \\times (\\displaystyle\\frac{d}{dx}g(x))$          $\\displaystyle\\frac{d}{dx}\\displaystyle\\frac{f(x)}{g(x)}=\\big( (\\displaystyle\\frac{d}{dx}f(x))\\times g(x) - f(x) \\times (\\displaystyle\\frac{d}{dx}g(x)) \\big) \\times \\displaystyle\\frac{1}{(g(x))^2}$                    합성함수의 미분법  연쇄법칙(Chain Rule)                  $y=f(u)$ 가 $u$ 에 대하여 미분 가능하고, $u=g(x)$ 가 $x$ 에 대하여 미분 가능한 경우 다음이 성립함\\[\\begin{aligned}  \\displaystyle\\frac{dy}{dx}  &amp;=\\displaystyle\\frac{dy}{du}\\times \\displaystyle\\frac{du}{dx} \\\\  &amp;=\\displaystyle\\frac{d}{du}f(u) \\times \\displaystyle\\frac{d}{dx}g(x)  \\end{aligned}\\]              예시                  $y=(3x+2)^5$\\[\\begin{aligned}  y&amp;=u^5,\\\\  u&amp;=3x+2 \\\\\\\\  \\therefore \\displaystyle\\frac{dy}{dx}  &amp;=\\frac{d}{du}u^5 \\times \\displaystyle\\frac{d}{dx}(3x+2) \\\\  &amp;=5u^4 \\times 3 \\\\  &amp;=15(3x+2)^4  \\end{aligned}\\]            자연로그의 밑의 미분법자연로그의 밑의 이해      자연로그함수의 정의 : 기호 $e$ 로 표기되는 특정 상수를 밑으로 하는 로그함수\\[\\begin{aligned}  f(x)  &amp;=\\log_e x \\\\  &amp;=\\ln x\\\\  &amp;=\\displaystyle\\int_{1}^{x}\\displaystyle\\frac{1}{t}dt  \\end{aligned}\\]        자연로그의 밑의 정의 : 자연로그함수 $f(x)$ 에 대하여 $f(x)=1$ 을 만족하는 양의 실수 $x$\\[\\begin{aligned}  f(x)  &amp;=\\displaystyle\\int_{1}^{x}\\displaystyle\\frac{1}{t}dt \\\\  &amp;=\\log_{e} x \\\\  &amp;=1 \\\\\\\\  \\Leftrightarrow x  &amp;=e \\\\  &amp;=\\lim_{n \\rightarrow \\infty} (1+\\displaystyle\\frac{1}{n})^n \\\\  &amp;=2.71828\\cdots,\\;n\\in R  \\end{aligned}\\]  자연로그의 밑의 미분법      자연로그함수의 미분법\\[\\begin{aligned}  \\displaystyle\\frac{d}{dx}\\ln x  &amp;=\\displaystyle\\frac{d}{dx}\\displaystyle\\int_{t=1}^{x}\\displaystyle\\frac{1}{t}dt \\\\  &amp;=\\displaystyle\\frac{1}{x}  \\end{aligned}\\]        자연로그의 밑에 대한 지수함수의 미분법\\[\\begin{aligned}  f(x)  &amp;=e^x\\\\\\\\  \\displaystyle\\frac{d}{dx}f(x)  &amp;=\\displaystyle\\frac{d}{dx}e^x \\\\  &amp;=e^x  \\end{aligned}\\]          증명                              함수 정의\\[f(x)=a^x\\]                                미분 정의\\[\\begin{aligned}  \\displaystyle\\frac{d}{dx}f(x)  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{f(x+\\Delta x) - f(x)}{\\Delta x}\\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{x+\\Delta x} - a^{x}}{\\Delta x} \\\\  &amp;=\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{x}(a^{\\Delta x} - 1)}{\\Delta x} \\\\  &amp;=a^{x}  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $a^x$ 소거\\[\\begin{aligned}  \\lim_{\\Delta x \\rightarrow 0}a^x \\times \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;=a^x \\\\  \\displaystyle\\frac{1}{a^x}\\times a^x \\times \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;= a^x \\times \\displaystyle\\frac{1}{a^x}\\\\  \\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{a^{\\Delta x} - 1}{\\Delta x}  &amp;= 1  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\displaystyle\\frac{1}{\\Delta x}$ 소거\\[\\begin{aligned}  \\displaystyle\\frac{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)}{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x}  &amp;= 1 \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\times \\frac{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)}{\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x}  &amp;= 1 \\times \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x}-1)  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x  \\end{aligned}\\]                                극한의 성질에 근거하여 좌변에서 $1$ 소거\\[\\begin{aligned}  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}-\\displaystyle\\lim_{\\Delta x \\rightarrow 0}1  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}-\\displaystyle\\lim_{\\Delta x \\rightarrow 0}1 + \\displaystyle\\lim_{\\Delta x \\rightarrow 0}1  &amp;= \\displaystyle\\lim_{\\Delta x \\rightarrow 0}1 + \\displaystyle\\lim_{\\Delta x \\rightarrow 0}\\Delta x \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)  \\end{aligned}\\]                                극한의 성질에 근거하여 양변에 $\\displaystyle\\frac{1}{\\Delta x}$ 제곱\\[\\begin{aligned}  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}a^{\\Delta x}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x) \\\\  \\displaystyle\\lim_{\\Delta x \\rightarrow 0}(a^{\\Delta x})^{\\frac{1}{\\Delta x}}  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)^{\\frac{1}{\\Delta x}} \\\\  a  &amp;=\\displaystyle\\lim_{\\Delta x \\rightarrow 0}(1+\\Delta x)^{\\displaystyle\\frac{1}{\\Delta x}}  \\end{aligned}\\]                                $\\Delta x$ 를 $\\displaystyle\\frac{1}{n}$ 로 치환\\[\\begin{aligned}  a  &amp;=\\displaystyle\\lim_{n \\rightarrow \\infty}(1+\\displaystyle\\frac{1}{n})^n \\\\  &amp;=e  \\end{aligned}\\]                              삼각함수의 미분법삼각함수의 이해      각도에 대한 대변, 빗변, 이웃변 정의              대변(Homologous Side) : 각 $A$ 와 마주보는 변 $a$      이웃변(Adjoint Side) : 각 $A$ 와 이웃하는 변 $b$      빗변(Hypotenuse) : 직각 $C$ 와 마주보는 변 $c$            삼각함수(Trigonometric Function) : 각도에 대한 삼각비의 함수          삼각비(Trigonometric Ratio) : 직각삼각형 두 변의 비율              사인 함수(Sine Function; $\\sin$) : 각 $\\theta$ 에 대하여 그 빗변 대비 대변의 비율\\[\\sin \\theta = \\frac{a}{c}\\]                    코사인 함수(Cosine Function; $\\cos$) : 각 $\\theta$ 에 대하여 그 빗변 대비 이웃변의 비율\\[\\cos \\theta = \\frac{b}{c}\\]                    탄젠트 함수(Tangent Function; $\\tan$) : 각 $\\theta$ 에 대하여 그 이웃변 대비 대변의 비율\\[\\begin{aligned}  \\tan \\theta &amp;= \\frac{a}{b} \\\\  &amp;= \\frac{\\sin \\theta}{\\cos \\theta}  \\end{aligned}\\]            삼각함수의 미분법      사인 함수의 미분\\[\\frac{d}{dx}\\sin x=\\cos x\\]        코사인 함수의 미분\\[\\frac{d}{dx}\\cos x=-\\sin x\\]        탄젠트 함수의 미분\\[\\frac{d}{dx}\\tan x=\\frac{1}{\\cos^2 x}\\]  "
  },
  
  {
    "title": "Limit and Continuity",
    "url": "/posts/Limit_Continuity/",
    "categories": "Mathematical Techs, Calculus",
    "tags": "Mathematics",
    "date": "2022-07-11 00:00:00 +0900",
    





    
    "snippet": "극한      극한(Limiting)\\[\\begin{aligned}  y&amp;=f(x) \\\\  \\displaystyle\\lim_{x  \\rightarrow a}y&amp;=L  \\end{aligned}\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여     ...",
    "content": "극한      극한(Limiting)\\[\\begin{aligned}  y&amp;=f(x) \\\\  \\displaystyle\\lim_{x  \\rightarrow a}y&amp;=L  \\end{aligned}\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $x \\ne a$ 이면서 $x$ 가 $a$ 에 한없이 가까워질 때 $y$ 가 일정한 값 $L$ 에 가까워지는 경우      $y$ 는 $x  \\rightarrow a$ 일 때 $L$ 에 수렴한다(Converge) 라고 정의함      또한 $L$ 를 $x  \\rightarrow a$ 인 경우 $y$ 의 극한(Limiting) 이라고 정의함            좌극한과 우극한\\[\\displaystyle\\lim_{x  \\rightarrow a}f(x)=L \\Rightarrow \\displaystyle\\lim_{x  \\rightarrow a-0}f(x)=\\displaystyle\\lim_{x  \\rightarrow a+0}f(x)=L\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $f$ 가 값 $a$ 에서 극한이 존재하면      그 좌극한 $x  \\rightarrow a-0$ 과 우극한 $x  \\rightarrow a+0$ 이 존재하고, 그 값이 서로 같음            성질                  $\\displaystyle\\lim_{x  \\rightarrow a}f(x), \\displaystyle\\lim_{x  \\rightarrow a}g(x)$ 가 존재하는 경우 다음이 성립함                  $\\displaystyle\\lim_{x  \\rightarrow a}\\alpha f(x)=\\alpha\\displaystyle\\lim_{x  \\rightarrow a}f(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}(f(x)+g(x))=\\displaystyle\\lim_{x  \\rightarrow a}f(x)+\\displaystyle\\lim_{x  \\rightarrow a}g(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}(f(x) \\times g(x))=\\displaystyle\\lim_{x  \\rightarrow a}g(x) \\times \\displaystyle\\lim_{x  \\rightarrow a}f(x)$          $\\displaystyle\\lim_{x  \\rightarrow a}\\frac{f(x)}{g(x)}=\\frac{\\displaystyle\\lim_{x  \\rightarrow a}f(x)}{\\displaystyle\\lim_{x  \\rightarrow a}g(x)}\\;(s.t.\\displaystyle\\lim_{x  \\rightarrow a}g(x) \\ne 0)$                    연속      연속성(Continuity)\\[f(a)=\\displaystyle\\lim_{x  \\rightarrow a}f(x)\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      $f$ 가 $x=a$ 에서 함수값과 극한값이 모두 존재하고 그 값이 같을 때      $y=f(x)$ 는 $x=a$ 에서 연속이라고 정의함            연속함수(Continuous Function)\\[f(a)=\\displaystyle\\lim_{x  \\rightarrow a}f(x), \\; a \\in X=R\\]          설명변수 $x \\in X$ 에 대한 반응변수 $y \\in Y$ 의 함수 $f:\\,X\\rightarrow Y$ 에 대하여      정의역 $X$ 를 모든 실수 $R$ 라고 정의하자      $f$ 가 정의역에 대하여 연속이면 $f$ 를 연속함수라고 정의함      자연로그의 밑      자연로그의 밑 $e$ 의 정의\\[\\begin{aligned}  e&amp;=\\displaystyle\\lim_{n \\rightarrow \\infty}(1+\\frac{1}{n})^n\\\\  &amp;=2.71818\\cdots,\\;n \\in R  \\end{aligned}\\]        자연로그의 정의\\[\\ln x=\\log_e x=a \\Leftrightarrow x=e^a\\]    예시                  $f(x)=\\displaystyle\\lim_{x\\rightarrow 0}(1+3x)^{\\frac{1}{x}}$\\[\\begin{aligned}  n=\\frac{1}{x} \\Rightarrow   f(x)  &amp;=\\displaystyle\\lim_{n\\rightarrow \\infty}(1+\\frac{3}{n})^n\\\\  &amp;=\\displaystyle\\lim_{n\\rightarrow \\infty}(1+\\frac{3}{\\frac{1}{3}n})^{3 \\times \\frac{1}{3}n}\\\\  &amp;=e^3  \\end{aligned}\\]              연속복리와 $e$          복리의 이해                              원금 $a$ 를 연이율 $r$ 로 $n$ 년간 복리예금 시 원리금 $S$ 를 다음과 같이 정의함\\[S=a(1+r)^n\\]                              연속복리 : 가장 짧은 시간 간격으로 취하는 복리                  원금 $a$ 를 연이율 $r$ 로 $n$ 년간 복리예금한다고 하자                      $n$ 년간 $m$ 번 이자를 계산하는 경우 원리금 $S$ 를 다음과 같이 정의함\\[S=a[(1+\\frac{r}{m})^m]^n\\]                                $m$ 이 무한대로 발산한다고 했을 때 원리금 $S$ 를 다음과 같이 정의함\\[\\begin{aligned}  \\lim_{m \\rightarrow \\infty} S  &amp;=\\lim_{m \\rightarrow \\infty} a[(1+\\frac{r}{m})^m]^n \\\\  &amp;=\\lim_{m \\rightarrow \\infty} a[(1+\\frac{1}{\\frac{1}{r}m})^{r \\times \\frac{1}{r}m}]^{n} \\\\  &amp;=a\\times e^{r \\times n}  \\end{aligned}\\]                              "
  },
  
  {
    "title": "Matrix Decomposition",
    "url": "/posts/Matrix_Decomposition/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-09 00:00:00 +0900",
    





    
    "snippet": "Matrix Decomposition      정의 : 하나의 행렬을 특정한 구조를 가진 다른 행렬의 합과 곱으로 나타내는 작업        종류          스펙트럼 분해(Spectral Decomposition) : 대칭행렬에 대한 분해      특이값 분해(Singular Value Decomposition; SVD) : 비대칭행렬에 대한 분...",
    "content": "Matrix Decomposition      정의 : 하나의 행렬을 특정한 구조를 가진 다른 행렬의 합과 곱으로 나타내는 작업        종류          스펙트럼 분해(Spectral Decomposition) : 대칭행렬에 대한 분해      특이값 분해(Singular Value Decomposition; SVD) : 비대칭행렬에 대한 분해      Spectral Decomposition      대칭행렬 $A_{n \\times n}$ 와 그 고유값 $ \\vert \\lambda_{1} \\vert \\ge \\vert \\lambda_{2} \\vert \\ge \\cdots \\ge \\vert \\lambda_{n} \\vert$, 고유벡터 $\\overrightarrow{v_{1}},\\overrightarrow{v_{2}},\\cdots,\\overrightarrow{v_{n}}$ 에 대하여, 직교행렬 $P$ 와 대각행렬 $\\Lambda$ 를 다음과 같이 정의하자\\[\\begin{aligned}  P  &amp;= \\begin{bmatrix} \\overrightarrow{v_{1}} &amp; \\overrightarrow{v_{2}} &amp; \\cdots &amp; \\overrightarrow{v_{n}} \\end{bmatrix} \\\\  \\Lambda  &amp;= diag(\\lambda_1, \\lambda_2, \\cdots, \\lambda_n)  \\end{aligned}\\]        $A_{n \\times n}$ 를 다음과 같이 분해하는 작업을 스펙트럼 분해라고 정의함\\[\\begin{aligned}  A  &amp;= P \\Lambda P^{T} \\\\  &amp;= \\lambda_1 \\overrightarrow{v_{1}} \\overrightarrow{v_{1}^T} + \\lambda_2 \\overrightarrow{v_{2}} \\overrightarrow{v_{2}^T} + \\cdots + \\lambda_n \\overrightarrow{v_{n}} \\overrightarrow{v_{n}^T} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{n}\\lambda_i \\overrightarrow{v_{i}} \\overrightarrow{v_{i}^T}  \\end{aligned}\\]  Singular Value DecompositionSVD      비대칭행렬 $A_{m \\times n}$ 에 대하여 다음과 같이 분해하는 작업을 특이값 분해라고 정의함\\[\\begin{aligned}  A_{m \\times n}  =  \\begin{cases}  U_{n \\times m} D_{m \\times m} (V_{n \\times m})^T\\;&amp;if\\;m \\le n \\\\  U_{m \\times n} D_{n \\times n} (V_{n \\times n})^T\\;&amp;if\\;n \\le m \\\\  \\end{cases}  \\end{aligned}\\]        행렬 $U$ 는 행렬 $AA^{T}(=(A^{T}A)^T)$ 의 고유벡터 $\\overrightarrow{u}$ 의 집합임\\[\\begin{aligned}  U &amp;= \\begin{bmatrix} \\overrightarrow{u_1}&amp;\\overrightarrow{u_2}&amp;\\cdots&amp;\\overrightarrow{u_k} \\end{bmatrix}\\\\  k &amp;= \\min (m, n)\\\\  &amp;= rank(A)\\\\  \\overrightarrow{u_i}   &amp;\\in \\{\\overrightarrow{u}\\,|\\,AA^{T}\\overrightarrow{u} = \\lambda \\overrightarrow{u}\\}  \\end{aligned}\\]        행렬 $V$ 는 행렬 $A^{T}A(=(AA^{T})^T)$ 의 고유벡터 $\\overrightarrow{v}$ 의 집합임\\[\\begin{aligned}  U  &amp;= \\begin{bmatrix} \\overrightarrow{v_1}&amp;\\overrightarrow{v_2}&amp;\\cdots&amp;\\overrightarrow{v_k} \\end{bmatrix}\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)\\\\  \\overrightarrow{v_i}  &amp;\\in \\{\\overrightarrow{v}\\,|\\,A^{T}A\\overrightarrow{v} = \\lambda \\overrightarrow{v}\\}  \\end{aligned}\\]        행렬 $D$ 는 행렬 $AA^{T}$ 혹은 그 전치행렬 $A^{T}A$ 의 고유값의 제곱근 $\\sqrt{\\lambda_1} \\ge \\sqrt{\\lambda_2} \\ge \\cdots \\ge \\sqrt{\\lambda_k} &gt; 0$ 을 대각원소로 가지는 대각행렬임\\[\\begin{aligned}  D  &amp;= diag(\\sqrt{\\lambda_1}, \\sqrt{\\lambda_2}, \\cdots, \\sqrt{\\lambda_k}) \\\\  &amp;= \\begin{pmatrix}  \\sqrt{\\lambda_1} &amp; 0 &amp; \\cdots &amp; 0 \\\\  0 &amp; \\sqrt{\\lambda_2} &amp; \\cdots &amp; 0 \\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\  0 &amp; 0 &amp; \\cdots &amp; \\sqrt{\\lambda_k}  \\end{pmatrix} \\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]  Singular Value &amp; Vector      특이값(Singular Value) : 대각행렬 $D$ 의 대각원소로서, 행렬 $AA^{T}$ 혹은 그 전치행렬 $A^{T}A$ 의 고유값의 제곱근\\[\\sqrt{\\lambda_1} \\ge \\sqrt{\\lambda_2} \\ge \\cdots \\ge \\sqrt{\\lambda_k} &gt; 0\\]        왼쪽 특이벡터(Left Singular Vector) : 행렬 $U$ 의 열벡터로서 행렬 $AA^{T}$ 의 고유벡터\\[\\begin{aligned}  \\overrightarrow{u_i}   &amp;\\in \\{\\overrightarrow{u}\\,|\\,AA^{T}\\overrightarrow{u} = \\lambda \\overrightarrow{u}\\},\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]        오른쪽 특이벡터(Right Singular Vector) : 행렬 $V$ 의 열벡터로서 행렬 $AA^{T}$ 의 전치행렬 $A^{T}A$ 의 고유벡터\\[\\begin{aligned}  \\overrightarrow{v_i}  &amp;\\in \\{\\overrightarrow{v}\\,|\\,A^{T}A\\overrightarrow{v} = \\lambda \\overrightarrow{v}\\},\\\\  k  &amp;= \\min (m, n)\\\\  &amp;= rank(A)  \\end{aligned}\\]        특이값 분해의 전개\\[\\begin{aligned}  A_{m \\times n}  &amp;=  \\begin{cases}  U_{n \\times m} D_{m \\times m} (V_{n \\times m})^T\\;if\\;m \\le n \\\\  U_{m \\times n} D_{n \\times n} (V_{n \\times n})^T\\;if\\;n \\le m \\\\  \\end{cases} \\\\  &amp;= \\displaystyle\\sum_{i=1}^{\\min (m,n)} \\sqrt{\\lambda_i} u_i v_i^T  \\end{aligned}\\]  "
  },
  
  {
    "title": "Eigen",
    "url": "/posts/Eigen/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-08 00:00:00 +0900",
    





    
    "snippet": "고유값과 고유벡터      정의\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n...",
    "content": "고유값과 고유벡터      정의\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{1n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  =  \\lambda  \\begin{pmatrix}  v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}  \\end{pmatrix}  \\Leftrightarrow  A_{n \\times n} \\overrightarrow{v}   = \\lambda \\overrightarrow{v}  \\end{aligned}\\]          고유값(Eigen-Value; $\\lambda$) : 정방행렬 $A$ 에 대하여 위 식을 만족하는 상수 $\\lambda$      고유벡터(Eigen-Vector; $\\overrightarrow{v}$) : 정방행렬 $A$ 에 대하여 위 식을 만족하는 $\\overrightarrow{0}$ 이 아닌 벡터 $\\overrightarrow{v}$            기하학적 의미                  어떤 벡터 $\\overrightarrow{v}$ 에 대하여 행렬 $A$ 로 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 경우                  $\\overrightarrow{v}$ : $A$ 의 고유벡터(Eigen-Vactor)          $\\lambda$ : $A$ 의 고유값(Eigen-Value) 으로서 선형변환 전 크기 대비 선형변환 후 크기의 비율                            Rotation Matrix 와 고유값\\[A  = \\begin{pmatrix} \\cos \\theta &amp; -\\sin \\theta \\\\ \\sin \\theta &amp; \\cos \\theta \\end{pmatrix}\\]                  행렬 $A$ 의 고유벡터는 $A$ 를 통해 선형변환했을 때, 그 방향은 변하지 않고 단지 크기만 변하는 벡터라고 정의함          행렬 $A$ 가 Rotation Matrix 인 경우, 그 회전변환 각도 $\\theta$ 가 $0^{\\circ}, 180^{\\circ}, 360^{\\circ}$ 인 경우에만 고유벡터가 존재함                      성질                  행렬 $A$ 의 고유값 $\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{n}$ 과 고유벡터 $\\overrightarrow{v_{1}},\\overrightarrow{v_{2}},\\cdots,\\overrightarrow{v_{n}}$ 에 대하여 다음이 성립함                  $tr(A)=\\displaystyle\\sum_{i=1}^{n}\\lambda_{i}$          $det(A)=\\displaystyle\\prod_{i=1}^{n}\\lambda_{i}$          행렬 $A$ 의 고유값 $\\lambda_{i}=0$ 이면 $A$ 는 특이행렬임          행렬 $A$ 의 고유값 $\\lambda_{i} \\ne \\lambda_{j}\\;(i \\ne j)$ 이면 고유벡터들은 선형 독립임          행렬 $A$ 의 고유값과 그 전치행렬 $A^{T}$ 의 고유값은 동일함                      계산 방법                  고유방정식(Eigenvalue Equation) 혹은 특성방정식(Characteristic Equation)\\[\\begin{aligned}  A \\overrightarrow{v}   &amp;= \\lambda \\overrightarrow{v} \\\\  A \\overrightarrow{v} - \\lambda \\overrightarrow{v}   &amp;= \\overrightarrow{0} \\\\  \\therefore (A-\\lambda I)\\overrightarrow{v}   &amp;= \\overrightarrow{0}  \\end{aligned}\\]                  행렬 $A$ 에 대하여 그 고유방정식 $(A-\\lambda I)\\overrightarrow{v} = \\overrightarrow{0}$ 의 해 $\\lambda$ 를 $A$ 의 고유값, $\\overrightarrow{v}$ 를 $A$ 의 고유벡터라고 함                            해가 존재할 조건                              행렬 $A - \\lambda I$ 에 대하여 그 역행렬이 존재하면 고유방정식의 해는 불능임\\[\\begin{aligned}  \\overrightarrow{v}  &amp;= (A - \\lambda I)^{-1} \\overrightarrow{0} \\\\  &amp;= \\overrightarrow{0}  \\end{aligned}\\]                                행렬 $A$ 의 고유방정식 $(A - \\lambda I)\\overrightarrow{v} = \\overrightarrow{0}$ 의 해가 존재하기 위해서는 행렬 $A - \\lambda I$ 의 역행렬이 존재하지 않아야 함\\[\\left\\lvert A - \\lambda I \\right\\rvert = 0\\]                              행렬의 대각화      행렬의 대각화(Diagonalization)\\[\\begin{aligned}  P^{-1}AP   &amp;= \\Lambda \\\\  &amp;= diag(a_{11},a_{22},\\cdots,a_{nn})  \\end{aligned}\\]          정방행렬 $A$ 에 대하여 $P^{-1}AP$ 가 대각행렬 $\\Lambda$ 가 되도록 만드는 정방행렬 $P\\;(\\vert P \\vert \\ne 0)$ 가 존재하는 경우      행렬 $A$ 를 대각화(Diagonalization) 할 수 있는 행렬이라고 함      행렬 $P$ 가 행렬 $A$ 를 대각화시킨다고 표현함            대칭행렬의 대각화                  대칭행렬 $A\\;(a_{ij}=a_{ji})$ 에 대하여 그 고유값이 $\\lambda_1,\\lambda_2,\\cdots,\\lambda_n$ 이고, 고유벡터가 $\\overrightarrow{v_1},\\overrightarrow{v_2},\\cdots,\\overrightarrow{v_n}$ 이라고 하자                    고유벡터 $\\overrightarrow{v_{i^{\\forall}}}, \\overrightarrow{v_{j^{\\forall}}}\\;(i \\ne j)$ 는 직교함\\[\\overrightarrow{v_i} \\perp \\overrightarrow{v_j}\\]                    고유벡터들로 구성된 직교행렬 $P=\\begin{bmatrix}\\overrightarrow{v_1}&amp;\\overrightarrow{v_2}&amp;\\cdots&amp;\\overrightarrow{v_n}\\end{bmatrix}$ 은 $A$ 를 그 고유값들로 구성된 대각행렬 $\\Lambda$ 로 대각화시킴\\[\\begin{aligned}  P^{-1}AP  &amp;= \\Lambda \\\\  &amp;= diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)  \\end{aligned}\\]            "
  },
  
  {
    "title": "Linear Transformation",
    "url": "/posts/Linear_Transformation/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-07 00:00:00 +0900",
    





    
    "snippet": "Linear Transformation선형변환      정의 : 하나의 벡터를 입력하여 다른 벡터를 출력하는 함수            기하학적 의미 : 평면을 휘어트리지 않는 선에서 벡터 공간을 늘리고 뒤틀어서 입력 벡터가 나타내는 직선을 출력 벡터가 나타내는 직선으로 변화하는 과정        성질          $L(\\overrightarrow{...",
    "content": "Linear Transformation선형변환      정의 : 하나의 벡터를 입력하여 다른 벡터를 출력하는 함수            기하학적 의미 : 평면을 휘어트리지 않는 선에서 벡터 공간을 늘리고 뒤틀어서 입력 벡터가 나타내는 직선을 출력 벡터가 나타내는 직선으로 변화하는 과정        성질          $L(\\overrightarrow{v} + \\overrightarrow{w}) = L(\\overrightarrow{v}) + L(\\overrightarrow{w})$      $L(\\alpha \\times \\overrightarrow{v}) = \\alpha L(\\overrightarrow{v})$            선형변환을 통한 행렬과 벡터 곱의 이해          행렬 \\(A = \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix}\\) 과 벡터 \\(\\overrightarrow{v} = \\begin{pmatrix} 1\\\\-2 \\end{pmatrix}\\) 의 곱은 \\(\\overrightarrow{v}\\) 에 대하여 단위벡터를 기저로 사용하는 직교좌표계에서 \\(A\\) 의 열벡터 \\(\\overrightarrow{a_1}=\\begin{pmatrix} 1\\\\-2 \\end{pmatrix}, \\overrightarrow{a_2}=\\begin{pmatrix} 3\\\\0 \\end{pmatrix}\\) 를 기저로 사용하는 좌표계로의 선형변환으로 이해할 수 있음    \\[\\begin{aligned}  L(\\overrightarrow{v})  &amp;= L(\\begin{pmatrix} 1\\\\-2 \\end{pmatrix}) \\\\  &amp;= L(-1 \\overrightarrow{i} + 2 \\overrightarrow{j}) \\\\  &amp;= -1L(\\overrightarrow{i}) + 2L(\\overrightarrow{j}) \\\\  &amp;= -1 \\begin{pmatrix} 1\\\\-2 \\end{pmatrix} + 2\\begin{pmatrix} 3\\\\0 \\end{pmatrix} \\\\  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\begin{pmatrix} -1\\\\2 \\end{pmatrix} \\\\  &amp;= \\begin{pmatrix} 1&amp;3\\\\-2&amp;0 \\end{pmatrix} \\overrightarrow{v}  \\end{aligned}\\]  기저의 변환과 좌표      벡터 \\(\\overrightarrow{v}=\\begin{pmatrix}-1\\\\2\\end{pmatrix}\\) 는 단위벡터 \\(\\overrightarrow{i}=\\begin{pmatrix}1\\\\0\\end{pmatrix}, \\overrightarrow{j}=\\begin{pmatrix}0\\\\1\\end{pmatrix}\\) 를 기저로 사용하는 직교좌표계의 좌표 \\((x, y) = (-1, 2)\\) 을 의미함\\[\\begin{aligned}  \\begin{pmatrix}  -1\\\\  2  \\end{pmatrix}  &amp;= -1   \\begin{pmatrix}  1\\\\  0  \\end{pmatrix}  + 2  \\begin{pmatrix}  0\\\\  1  \\end{pmatrix}  \\end{aligned}\\]        선형변환 \\(L(\\overrightarrow{v})\\) 를 통해 입력벡터 \\(\\overrightarrow{v}\\) 는 출력벡터 \\(\\begin{pmatrix}5\\\\2\\end{pmatrix}\\) 로 변환되었음\\[\\begin{aligned}  L(\\overrightarrow{v})  &amp;= \\begin{pmatrix}5\\\\2\\end{pmatrix}  \\end{aligned}\\]        출력벡터 \\(\\begin{pmatrix}5\\\\2\\end{pmatrix}\\) 는 벡터 \\(L(\\overrightarrow{i})=\\begin{pmatrix}1\\\\-2\\end{pmatrix}, L(\\overrightarrow{j})=\\begin{pmatrix}3\\\\0\\end{pmatrix}\\) 를 기저로 사용하는 변환된 좌표계의 좌표 \\((x, y) = (-1, 2)\\) 을 의미함\\[\\begin{aligned}  \\begin{pmatrix}5\\\\2\\end{pmatrix}  &amp;= -1 \\begin{pmatrix}1\\\\-2\\end{pmatrix} + 2 \\begin{pmatrix}3\\\\0\\end{pmatrix}  \\end{aligned}\\]  특별한 선형변환      Rotation Matrix : 반시계 방향으로 $\\theta^{\\circ}$ 회전하는 선형변환    \\[\\begin{pmatrix}  \\cos \\theta &amp; -\\sin \\theta \\\\  \\sin \\theta &amp; \\cos \\theta  \\end{pmatrix}\\]        Scaling Matrix : $X$ 축을 $\\alpha$ 배, $Y$ 축을 $\\beta$ 배 늘리는 선형변환    \\[\\begin{pmatrix}  \\alpha &amp; 0 \\\\  0 &amp; \\beta  \\end{pmatrix}\\]        Shearing Matrix : 각 축의 기저벡터를 변형시키는 선형변환                      Horizontal Shearing Matrix(Shear in \\(X\\)) : \\(X\\) 축의 기저벡터는 그대로, \\(Y\\) 축의 단위벡터는 \\(\\begin{pmatrix} s\\\\1 \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;s\\\\0&amp;1 \\end{pmatrix}\\]                    Vertical Shearing Matrix(Shear in \\(Y\\)) : \\(Y\\) 축의 기저벡터는 그대로, \\(X\\) 축의 단위벡터는 \\(\\begin{pmatrix} 1\\\\s \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;0\\\\s&amp;1 \\end{pmatrix}\\]                    Arbitrary Shearing Matrix : \\(X\\) 축의 기저벡터는 \\(\\begin{pmatrix} 1\\\\ t \\end{pmatrix}\\) 으로, \\(Y\\) 축의 단위벡터는 \\(\\begin{pmatrix} s\\\\ 1 \\end{pmatrix}\\) 으로 변형시키는 선형변환\\[\\begin{pmatrix} 1&amp;s\\\\ t&amp;1 \\end{pmatrix}\\]            Determinant      행렬식(Determinant; $det$) : 행렬로 표현되는 선형변환의 어떤 특성을 표현하는 값\\[\\vert A \\vert  = \\displaystyle\\sum_{\\sigma \\in S_n} (sgn(\\sigma) \\prod_{i=1}^{n}a_{i,\\sigma_{i}})\\]          $S_n$ : ${1,2,\\cdots,n}$ 의 모든 순열      $\\sigma_i$ : $S_n$ 의 원소 중 하나인 $\\sigma$ 의 $i$ 번째 원소      $sgn(\\sigma)$ : 주어진 순열을 연속적으로 짝수만큼 움직였을 때 재정렬되면 $1$, 아니면 $-1$의 값을 가지는 규칙            행렬식의 기하학적 의미 : 행렬 $A$ 에 의한 선형변환이 변화시키는 면적의 비율 $c$            $det(A)=0$ 인 경우의 기하학적 의미\\[\\begin{aligned}  A  &amp;= \\begin{pmatrix} 4&amp;2 \\\\ 2&amp;1 \\end{pmatrix} \\\\  &amp;= \\begin{bmatrix} \\overrightarrow{a_1} &amp; \\overrightarrow{a_2} \\end{bmatrix}  \\end{aligned}\\]                  $det(A)=0$ 이면 행렬 $A$ 의 열벡터는 선형 종속임\\[\\begin{aligned}  \\overrightarrow{a_1}  &amp;= 2 \\times \\overrightarrow{a_2}  \\end{aligned}\\]                    $A$ 에 의한 선형변환은 모든 점을 $1$ 차원 직선에 $mapping$ 하여 그 면적을 $0$ 으로 만듦\\[\\begin{aligned}  \\begin{pmatrix} 4&amp;2 \\\\ 2&amp;1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}  = \\begin{pmatrix} 10 \\\\ 5 \\end{pmatrix}  \\end{aligned}\\]              해석          $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 계수는 $n$ 임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음        성질          $det(\\alpha)=\\alpha$      $det(I)=1$      $det(A)=det(A^T)$      $det(A^{-1})=det(A)^{-1}$      $det(AB)=det(A) \\times det(B)$      $det(\\alpha \\times A_n)=\\alpha^n \\times det(A_n)$      $\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_i} \\cdots \\overrightarrow{a_j} \\end{vmatrix}=-\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_j} \\cdots \\overrightarrow{a_i} \\end{vmatrix}$      $\\begin{vmatrix}\\alpha \\times a &amp; \\alpha \\times b \\ c &amp; d\\end{vmatrix} = \\alpha \\times \\begin{vmatrix}a&amp;b\\ c&amp;d\\end{vmatrix}$        계산 방법          $det(A_2)=a_{11}a_{22}-a_{12}a_{21}$      삼각행렬에 대하여 그 행렬식은 대각항 원소들의 곱으로 구할 수 있음      $3\\times 3$ 이상의 정방행렬에 대하여 그 행렬식은 가우스-조르단 소거법(Gaussian Elimination)으로 구함      "
  },
  
  {
    "title": "Linear Equation",
    "url": "/posts/Linear_Equation/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-06 00:00:00 +0900",
    





    
    "snippet": "Linear Equation선형방정식      정의 : 최고차 항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  &amp; a_1x_1 + a_2x_2 + \\cdots + a_nx_n  = b  \\end{aligned}\\]        선형방정식을 벡터로 표현하면 다음과 같음\\[\\begin{aligne...",
    "content": "Linear Equation선형방정식      정의 : 최고차 항의 차수가 $1$ 을 넘지 않는 다항방정식으로서 $1$ 차 방정식\\[\\begin{aligned}  &amp; a_1x_1 + a_2x_2 + \\cdots + a_nx_n  = b  \\end{aligned}\\]        선형방정식을 벡터로 표현하면 다음과 같음\\[\\begin{aligned}  \\begin{pmatrix}a_1&amp;a_2&amp;\\cdots&amp;a_n\\end{pmatrix}  \\begin{pmatrix}x_1\\\\x_2\\\\ \\vdots\\\\ x_n \\end{pmatrix}  = b  \\end{aligned}\\]        이때 벡터 $\\overrightarrow{a}$ 는 방정식의 계수들을 나열하고 있음\\[\\begin{aligned}  \\overrightarrow{a}^T \\overrightarrow{x}  = b  \\end{aligned}\\]  선형연립반정식      정의 : 둘 이상의 선형방정식의 집합\\[\\begin{aligned}  \\begin{matrix}  a_{11}x_1 &amp; + &amp; a_{12}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1 \\\\  a_{21}x_1 &amp; + &amp; a_{22}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2 \\\\  \\vdots &amp; + &amp; \\vdots &amp; + &amp; \\ddots &amp; + &amp; \\vdots &amp; = &amp; \\vdots \\\\  a_{m1}x_1 &amp; + &amp; a_{m2}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m  \\end{matrix}  \\end{aligned}\\]        선형연립방정식을 행렬로 표현하면 다음과 같음\\[\\begin{aligned}  \\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2n}\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  a_{m1}&amp;a_{m2}&amp;\\cdots&amp;a_{mn}  \\end{pmatrix}  \\begin{pmatrix}x_1\\\\x_2\\\\\\vdots\\\\ x_n \\end{pmatrix}      &amp;= \\begin{pmatrix}b_1\\\\ b_2\\\\ \\vdots\\\\ b_m \\end{pmatrix}  \\end{aligned}\\]  첨가 행렬      정의 : 선형연립방정식 계수들의 집합으로서 벡터 $\\overrightarrow{x}$ 를 선형변환하는 행렬\\[\\begin{aligned}  A \\overrightarrow{x}  &amp;= \\overrightarrow{b}  \\end{aligned}\\]        첨가 행렬 $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 을 구분하여 표현할 수 있음\\[\\begin{aligned}  \\overrightarrow{a_1} x_1 + \\overrightarrow{a_2} x_2 + \\cdots + \\overrightarrow{a_n} x_n  &amp;= \\overrightarrow{b}  \\end{aligned}\\]  선형방정식의 갯수와 미지수의 갯수가 같은 경우첨가 행렬의 역행렬과 방정식의 해\\[\\begin{aligned}\\begin{pmatrix} a_{11}&amp;a_{12}\\\\ a_{21}&amp;a_{22} \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} b_1\\\\ b_2 \\end{pmatrix}\\Leftrightarrow A \\overrightarrow{x} = \\overrightarrow{b}\\end{aligned}\\]      크기가 $n \\times n$ 인 첨가 행렬 $A$ 에 대하여 그 역행렬 $A^{-1}$ 이 존재할 조건          $Rank(A_n)=n$      $det(A) \\ne 0$      $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 를 $span$ 하여 $n$ 차원 공간을 구성할 수 없음      $A$ 의 열벡터 $\\overrightarrow{a_1}, \\overrightarrow{a_2}, \\cdots, \\overrightarrow{a_n}$ 는 모두 선형 독립임            첨가 행렬 $A$ 에 대하여 그 역행렬이 존재하면 단 하나의 해가 존재함            첨가 행렬 $A$ 에 대하여 그 역행렬이 존재하지 않으면 불능이거나 부정임                  불능(Underdetermined) : 해를 구할 수 없음                            부정(Inconsistent, Impossible) : 해가 무수히 많아 하나로 정할 수 없음                    해가 하나 존재하는 경우의 기하학적 이해\\[\\begin{pmatrix} 7&amp;2\\\\ -7&amp;5 \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} -5\\\\ 12 \\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix} 7\\\\ -7 \\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix} 2\\\\ 5 \\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix} -5\\\\ 12 \\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 있음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 독립임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $2$ 차원 평면에 $\\overrightarrow{b}$ 가 포함됨    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 있음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 종속임      해를 구할 수 없는 경우의 이해\\[\\begin{pmatrix} 5&amp;5\\\\ 5&amp;5 \\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}=\\begin{pmatrix} 10\\\\ 20 \\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix} 5\\\\ 5 \\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix} 5\\\\ 5 \\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix} 10\\\\ 20 \\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 없음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 종속임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $1$ 차원 직선에 $\\overrightarrow{b}$ 가 포함되지 않음    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 없음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 독립임      해가 무수히 많은 경우의 이해\\[\\begin{pmatrix}1&amp;1\\\\2&amp;2\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}=\\begin{pmatrix}10\\\\20\\end{pmatrix}\\Leftrightarrow\\overrightarrow{a_1}x_1 + \\overrightarrow{a_2}x_2= \\overrightarrow{b}\\]\\[\\overrightarrow{a_1}= \\begin{pmatrix}1\\\\2\\end{pmatrix},\\overrightarrow{a_2}= \\begin{pmatrix}1\\\\2\\end{pmatrix},\\overrightarrow{b}= \\begin{pmatrix}10\\\\20\\end{pmatrix}\\]  $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 $span$ 하여 $2$ 차원 평면을 구성할 수 없음          $\\overrightarrow{a_1}$ 와 $\\overrightarrow{a_2}$ 는 선형 종속임            $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 가 $span$ 하여 구성할 수 있는 $1$ 차원 직선에 $\\overrightarrow{b}$ 가 포함됨    $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 를 선형결합하여 $\\overrightarrow{b}$ 를 만들 수 있음          $\\overrightarrow{b}$ 는 $\\overrightarrow{a_1}, \\overrightarrow{a_2}$ 에 대하여 선형 종속임      선형방정식의 갯수와 미지수의 갯수가 다른 경우선형방정식의 갯수보다 미지수의 갯수가 더 많은 경우\\[\\begin{pmatrix}1&amp;2&amp;3\\\\1&amp;5&amp;1\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\end{pmatrix}=\\begin{pmatrix}2\\\\1\\end{pmatrix}\\LeftrightarrowA\\overrightarrow{x}= \\overrightarrow{b}\\]  하나의 방정식을 만족하는 벡터 $\\overrightarrow{x}$ 는 $3$ 차원 공간의 $2$ 차원 평면을 구성함  두 방정식을 동시에 만족하는 벡터 $\\overrightarrow{x}$ 는 두 평면이 교차하는 $1$ 차원 직선의 모든 점임미지수의 갯수보다 선형방정식의 갯수가 더 많은 경우\\[\\begin{pmatrix}0&amp;1\\\\-2&amp;1\\\\2&amp;1\\\\ \\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}=\\begin{pmatrix}-1\\\\-4\\\\8\\end{pmatrix}\\LeftrightarrowA\\overrightarrow{x}= \\overrightarrow{b}\\]  하나의 방정식을 만족하는 벡터 $\\overrightarrow{x}$ 는 $2$ 차원 평면의 $1$ 차원 직선을 구성함  세 방정식을 동시에 만족하는 벡터 $\\overrightarrow{x}$ 는 존재하지 않음"
  },
  
  {
    "title": "Matrix",
    "url": "/posts/Matrix/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-05 00:00:00 +0900",
    





    
    "snippet": "What? Matrix\\[\\begin{aligned}A_{n\\times p}&amp;=\\begin{pmatrix}a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1p}\\\\a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2p}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\a_{n1}&amp;...",
    "content": "What? Matrix\\[\\begin{aligned}A_{n\\times p}&amp;=\\begin{pmatrix}a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1p}\\\\a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2p}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{np}\\end{pmatrix}\\\\&amp;=(a_{ij})\\in R^{n\\times p}, \\\\i&amp;=1, 2, \\cdots, n,\\\\j&amp;=1, 2, \\cdots, p\\end{aligned}\\]  행렬(Matrix)          행(row)과 열(column)로 구분된 직사각 모양의 배열      행벡터 혹은 열벡터의 집합        표기법          행렬(Matrix) : $A$      벡터(Vector) : $\\overrightarrow{a}$      스칼라(Scala) : $\\alpha, \\beta, \\gamma, \\cdots$      원소(Element) : $a_{ij}$        크기(Size)          길이(Length; $n$) : 행벡터의 갯수, 관측치의 갯수      차원(Dimention; $p$) : 열벡터의 갯수, 특징의 갯수      크기(Size; $n \\times p$) : 행렬의 크기      특수한 행렬      정방행렬(Square Matrix) : 행벡터의 갯수와 열벡터의 갯수가 동일한 행렬\\[\\begin{aligned}  A_{n}&amp;=\\begin{pmatrix}  a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\  a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2n}\\\\  \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\  a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}  \\end{pmatrix}\\\\  &amp;=(a_{ij})\\in R^{n\\times n}, \\\\  i&amp;=1, 2, \\cdots, n,\\\\  j&amp;=1, 2, \\cdots, n  \\end{aligned}\\]        영행렬(Zero-Matrix) : 그 원소가 모두 0인 행렬\\[0=\\begin{pmatrix}  0&amp;0&amp;0\\\\  0&amp;0&amp;0\\\\  0&amp;0&amp;0  \\end{pmatrix}\\]                  덧셈에 대한 항등원\\[A + 0 = A\\]                  항등행렬(Identify Matrix; $I_n$) : 대각항 원소는 모두 1이고, 비대각항 원소는 모두 0인 정방행렬\\[I_3=\\begin{pmatrix}  1&amp;0&amp;0\\\\  0&amp;1&amp;0\\\\  0&amp;0&amp;1  \\end{pmatrix}\\]                  내적에 대한 항등원\\[A\\cdot I = I \\cdot A = A\\]                    각 차원에 대하여 그 단위벡터들의 모임\\[\\begin{aligned}  I_n&amp;=  \\begin{bmatrix}\\overrightarrow{e_1}&amp;\\overrightarrow{e_2}&amp;\\overrightarrow{e_3}&amp;\\cdots&amp;\\overrightarrow{e_n}\\end{bmatrix}\\\\  &amp;=  \\begin{bmatrix}  \\overrightarrow{e_1}\\\\  \\overrightarrow{e_2}\\\\  \\overrightarrow{e_3}\\\\  \\vdots\\\\  \\overrightarrow{e_n}  \\end{bmatrix}  \\end{aligned}\\]                  대각행렬(Diagonal Matrix; $\\text{diag}$) : 대각항을 제외한 모든 원소가 0인 정방행렬\\[\\text{diag}(1, 2, 3)=\\begin{pmatrix}  1&amp;0&amp;0\\\\  0&amp;2&amp;0\\\\  0&amp;0&amp;3  \\end{pmatrix}\\]        삼각행렬(Triangular Matrix) : 대각항을 기준으로 그 아래 혹은 위에 위치한 원소가 모두 0인 정방행렬\\[\\begin{pmatrix}  1&amp;4&amp;5\\\\  0&amp;2&amp;6\\\\  0&amp;0&amp;3  \\end{pmatrix},  \\begin{pmatrix}  1&amp;0&amp;0\\\\  4&amp;2&amp;0\\\\  5&amp;6&amp;3  \\end{pmatrix}\\]        대칭행렬(Symmetric Matrix) : 그 전치행렬이 자기 자신이 되는 정방행렬\\[\\begin{aligned}  A^T&amp;=A\\\\  a_{ij}&amp;=a_{ji}  \\end{aligned}\\]\\[\\begin{pmatrix}  1&amp;3&amp;0\\\\  3&amp;2&amp;1\\\\  0&amp;1&amp;-1  \\end{pmatrix}^T=  \\begin{pmatrix}  1&amp;3&amp;0\\\\  3&amp;2&amp;1\\\\  0&amp;1&amp;-1  \\end{pmatrix}\\]                  대칭행렬이 가역성을 가지면 그 역행렬 또한 대칭행렬임\\[\\begin{aligned}  if\\;A^T&amp;=A,\\\\  A^{-1}A&amp;=I\\\\  (A^{-1}A)^T&amp;=I \\, (\\because I^T=I)\\\\  A^T(A^{-1})^T&amp;=I\\\\  A(A^{-1})^T&amp;=I\\\\  A^{-1}A(A^{-1})^T&amp;=A^{-1}I\\\\  \\therefore (A^{-1})^T&amp;=A^{-1}  \\end{aligned}\\]                  직교행렬(Orthogonal Matrix) : 모든 행벡터 혹은 열벡터가 직교정규벡터로 구성된 행렬\\[\\overrightarrow{a_{1}}\\perp\\overrightarrow{a_{2}}\\perp\\cdots\\perp\\overrightarrow{a_{n}},\\]\\[A=  \\begin{bmatrix}  \\overrightarrow{a_1}&amp;\\overrightarrow{a_2}&amp;\\cdots&amp;\\overrightarrow{a_n}  \\end{bmatrix}\\]                  직교행렬의 역행렬은 그 전치행렬임\\[A^TA=AA^T=I\\]            Matrix Operation  덧셈과 뺄셈                  크기가 $n\\times p$ 로 동일한 행렬 $A, B$ 의 덧셈 혹은 뺄셈을 대응 원소의 합 혹은 차로 정의함\\[\\begin{aligned}  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix},\\\\  B_{n \\times p}&amp;=\\begin{bmatrix}b_{ij}\\end{bmatrix}\\\\  A+B&amp;=\\begin{bmatrix}a_{ij}+b_{ij}\\end{bmatrix},\\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]              스칼라-행렬 곱셈                  스칼라와 행렬의 곱셈을 행렬의 모든 원소에 대한 스칼라 곱으로 정의함\\[\\begin{aligned}  \\alpha &amp;\\in R, \\\\  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix} \\\\  \\alpha A_{n \\times p}&amp;=\\begin{bmatrix}\\alpha \\times a_{ij}\\end{bmatrix},\\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]              전치(Transpose)                  행렬의 전치는 그 행과 열의 위치를 바꾸는 연산으로 정의함\\[\\begin{aligned}  A_{n \\times p}&amp;=\\begin{bmatrix}a_{ij}\\end{bmatrix} \\\\  (A_{n \\times p})^T&amp;=\\begin{bmatrix}a_{ji}\\end{bmatrix} \\\\  &amp;=A_{p \\times n}, \\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p  \\end{aligned}\\]                    성질                  $\\alpha^T=\\alpha$          $(A+B)^T=A^T+B^T$          $(\\alpha A)^T=\\alpha(A^T)$          $(AB)^T=B^TA^T$                      대각합(Trace; $\\text{tr}$)                  정방행렬 $A_n$ 의 대각합은 그 대각항의 총합으로 정의함\\[\\text{tr}(A_n)=\\sum_{i=1}^{n}a_{ii}\\]            Matrix Multiplication  적합성 조건(Conformability Condition)          전항의 차원(열벡터 갯수)과 후항의 길이(행벡터 갯수)가 동일함        행렬 곱셈                  적합성 조건을 만족하는 행렬 $A_{n \\times p},B_{p \\times m}\\(을 곱한 값\\)C_{n \\times m}$$ 를 다음과 같이 정의함\\[\\begin{aligned}  C_{n \\times m}&amp;=\\begin{bmatrix}c_{il}\\end{bmatrix}\\\\  c_{il}&amp;=\\sum_{j=1}^{p}(a_{ij}\\times b_{jl}), \\\\  i&amp;=1, 2, 3, \\cdots, n, \\\\  j&amp;=1, 2, 3, \\cdots, p, \\\\  l&amp;=1, 2, 3, \\cdots, m  \\end{aligned}\\]                  즉, 전항의 $i$ 번째 행벡터와 후항의 $i$ 번째 열벡터 간 내적의 집합임                            교환법칙이 성립하지 않음\\[A_{n \\times p}B_{p \\times m} \\ne B_{p \\times m}A_{n \\times p}\\]            Inverse Matrix  역행렬(Inverse Matrix)                  정방행렬 $A_n, B_n$ 에 대하여 다음을 만족하는 경우 양자는 서로 역행렬 관계에 있음\\[AB=BA=I \\Rightarrow A^{-1}=B\\,and\\,B^{-1}=A\\]              성질          $I^{-1}=I$      $A_n=diag\\begin{bmatrix}a_{ii}\\end{bmatrix},\\;i=1,2,3,\\cdots,n \\ \\Rightarrow A^{-1}=diag\\begin{bmatrix}\\frac{1}{a_{ii}}\\end{bmatrix}$      $A=\\begin{bmatrix}\\overrightarrow{a_1}&amp;\\overrightarrow{a_2}&amp;\\cdots&amp;\\overrightarrow{a_n}\\end{bmatrix},\\;\\overrightarrow{a_{1}}\\perp\\overrightarrow{a_{2}}\\perp\\cdots\\perp\\overrightarrow{a_{n}} \\ \\Rightarrow A^{-1}=A^T$      $(\\alpha A)^{-1}=\\alpha^{-1}A^{-1}$      $(A^{T})^{-1}=(A^{-1})^T$      $(AB)^{-1}=B^{-1}A^{-1}$        가역성          가역성(Inverible) : 그 역을 계산할 수 있는 성질                  정칙행렬(Non-Singular Matrix) : 가역성을 가지는 행렬          특이행렬(Singular Matrix) : 가역성을 가지지 않는 행렬                    가역성을 가질 조건                  $\\text{det}(A_n) \\ne 0$          $\\text{rank}(A_n)=n$          행렬 $A_n$ 를 구성하는 모든 벡터는 선형 독립임          행렬 $A_n$ 를 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음                      계산 방법                  $2\\times 2$ 정방행렬에 한하여 그 역행렬을 다음과 같이 구할 수 있음\\[\\begin{aligned}  &amp;A_2=  \\begin{pmatrix}  a&amp;b\\\\  c&amp;d  \\end{pmatrix},\\;ad-bc \\ne 0 \\\\  &amp;\\Rightarrow A_{2}^{-1}=\\frac{1}{ad-bc}\\begin{pmatrix}  d&amp;-b\\\\  -c&amp;a  \\end{pmatrix}  \\end{aligned}\\]                    $3\\times 3$ 이상의 정방행렬에 대하여 그 역행렬은 가우스-조르단 소거법(Gaussian Elimination)으로 구함            Determinant      행렬식(Determinant; $\\text{det}$)\\[\\text{det}(A_n)\\; or\\; |A|\\]          정방행렬 $A_n$ 를 실수에 대응시키는 함수      기하학적으로 봤을 때, 정방행렬 $A_n$ 를 구성하는 열벡터에 의해 결정되는 평행사변형의 부피를 의미함        해석          $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 그 계수는 $n$ 임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 행렬식이 $0$ 이 아닌 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음        성질          $\\text{det}(\\alpha)=\\alpha$      $\\text{det}(I)=1$      $\\text{det}(A)=det(A^T)$      $\\text{det}(A^{-1})=\\text{det}(A)^{-1}$      $\\text{det}(AB)=\\text{det}(A) \\times \\text{det}(B)$      $\\text{det}(\\alpha \\times A_n)=\\alpha^n \\times \\text{det}(A_n)$      $\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_i} \\cdots \\overrightarrow{a_j} \\end{vmatrix}=-\\begin{vmatrix} \\cdots &amp; \\overrightarrow{a_j} \\cdots \\overrightarrow{a_i} \\end{vmatrix}$      $\\begin{vmatrix}\\alpha \\times a &amp; \\alpha \\times b \\ c &amp; d\\end{vmatrix} = \\alpha \\times \\begin{vmatrix}a&amp;b\\ c&amp;d\\end{vmatrix}$        계산 방법          $\\text{det}(A_2)=a_{11}a_{22}-a_{12}a_{21}$      삼각행렬에 대하여 그 행렬식은 대각항 원소들의 곱으로 구할 수 있음      $3\\times 3$ 이상의 정방행렬에 대하여 그 행렬식은 가우스-조르단 소거법(Gaussian Elimination)으로 구함      Rank      계수(Rank) : 임의의 행렬을 구성하는 벡터 중 선형 독립인 벡터의 갯수\\[\\text{rank}(A)\\]        Full-Rank : 크기가 $n \\times p$ 인 모든 행렬에 대하여 그 계수가 될 수 있는 가장 큰 값\\[\\text{rank}(A_{n \\times p})=\\min{(n,p)}\\]        해석          $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 그 역행렬이 존재함      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 그 행렬식은 $0$ 이 아님      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 이를 구성하는 구성하는 모든 벡터는 선형 독립임      $n \\times n$ 정방행렬에 대하여 그 계수가 $Full-Rank$ 인 경우 이를 구성하는 구성하는 모든 벡터를 $span$ 하여 $n$ 차원 공간을 구성할 수 있음      "
  },
  
  {
    "title": "Vector",
    "url": "/posts/Vector/",
    "categories": "Mathematical Techs, Linear Algebra",
    "tags": "Mathematics",
    "date": "2022-07-04 00:00:00 +0900",
    





    
    "snippet": "What? Vector  벡터(Vector) : 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량          원소(Element) : 벡터를 구성하는 요소      차원(Dimension) : 원소의 갯수              부분벡터(Sub-Vector) : 임의의 벡터 $\\overrightarrow{a}$ 에 대하여 그 부분 공...",
    "content": "What? Vector  벡터(Vector) : 벡터 공간의 원소로서 크기와 원점으로부터 뱡향을 가지는 물리량          원소(Element) : 벡터를 구성하는 요소      차원(Dimension) : 원소의 갯수              부분벡터(Sub-Vector) : 임의의 벡터 $\\overrightarrow{a}$ 에 대하여 그 부분 공간으로 구성된 벡터\\[\\overrightarrow{a_{r:s}}=\\begin{pmatrix}a_r\\\\a_{r+1}\\\\a_{r+2}\\\\\\vdots\\\\a_{s} \\end{pmatrix}\\]              특수한 벡터                  영벡터(Zero Vector) : 벡터 공간에서의 덧셈에 대한 항등원이 되는 벡터\\[\\overrightarrow{0}=\\begin{pmatrix}0\\\\0\\\\\\vdots\\\\0 \\end{pmatrix}\\]                    단위벡터(Unit Vector) : 길이가 1인 벡터\\[(\\overrightarrow{e_{i}})_{j}=\\begin{cases}1,\\;if\\;j=i\\\\0,\\;if\\;j \\ne i\\end{cases}\\]\\[\\overrightarrow{e_{1}}=\\begin{pmatrix}1\\\\0\\\\0\\\\\\vdots\\\\0 \\end{pmatrix},   \\overrightarrow{e_{2}}=\\begin{pmatrix}0\\\\1\\\\0\\\\\\vdots\\\\0 \\end{pmatrix},   \\overrightarrow{e_{3}}=\\begin{pmatrix}0\\\\0\\\\1\\\\\\vdots\\\\0 \\end{pmatrix}\\]              벡터의 기하학적 해석          직각좌표계에 표현된 벡터 공간의 원소                  직각좌표계(Catesian Coordinate System) : 좌표축과 평행한 단위벡터끼리 항상 서로 수직한 모든 좌표계                    좌표평면상 하나의 점      좌표평면상 원점의 위치 이동              좌표평면상 단위벡터의 선형 결합\\[\\begin{pmatrix}3\\\\2 \\end{pmatrix} = 3 \\times \\overrightarrow{e_{1}} + 2 \\times \\overrightarrow{e_{2}}\\]            Vector Operation  스칼라-벡터 곱셈                  스칼라와 벡터의 곱셈은 벡터의 모든 원소에 대한 스칼라 곱으로 정의함\\[\\alpha \\times \\overrightarrow{a} = \\begin{pmatrix}\\alpha \\times a_{1}\\\\\\alpha \\times a_{2}\\\\\\vdots\\\\\\alpha \\times a_{n}\\end{pmatrix}\\]                    기하학적으로 봤을 때 이는 벡터를 스칼라 비율로 확대 혹은 축소하는 작업으로 해석할 수 있음                            벡터에 음수를 곱하면 벡터의 방향이 원점에 대하여 반대가 됨                      덧셈과 뺄셈                  차원이 $n$ 으로 동일한 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 의 덧셈 혹은 뺄셈을 대응 원소의 합 혹은 차로 정의함\\[\\begin{pmatrix}a_{1}\\\\a_{2}\\\\\\vdots\\\\a_{n}\\end{pmatrix} + \\begin{pmatrix}b_{1}\\\\b_{2}\\\\\\vdots\\\\b_{n}\\end{pmatrix} = \\begin{pmatrix}a_{1}+b_{1}\\\\a_{2}+b_{2}\\\\\\vdots\\\\a_{n}+b_{n} \\end{pmatrix}\\]                    기하학적으로 봤을 때 이는 벡터 $\\overrightarrow{a}$ 를 방향 $\\overrightarrow{b}$ 으로 폭 $\\Vert \\overrightarrow{b} \\Vert$ 만큼 평행이동하는 작업으로 해석할 수 있음                              덧셈                                            뺄셈                                          Linear Combination      선형 결합(Linear Combination)\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}}\\]          차원이 $n$ 으로 동일한 임의의 벡터와 스칼라에 대하여, 각 항에 스칼라를 곱하거나 상호 더함으로써 일련의 항으로 구성하는 작업        선형 종속(Linearly Dependent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현 가능한 경우                  좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치는 경우                            $n$ 차원 벡터 $\\overrightarrow{a_{1}}, \\overrightarrow{a_{2}}, \\cdots, \\overrightarrow{a_{p}}$ 와 스칼라 $\\alpha_{1}, \\alpha_{2}, \\cdots, \\alpha_{p}$ 에 대하여 다음을 만족하는 경우\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}} = 0, \\alpha^{\\forall} \\ne 0\\]              선형 독립(Linearly Independent) : 어떤 벡터가 다른 벡터들의 선형 결합으로 표현될 수 없는 경우                  좌표평면상에서 어떤 벡터가 다른 벡터들을 선형 결합한 결과와 겹치지 않는 경우                            $n$ 차원 벡터 $\\overrightarrow{a_{1}}, \\overrightarrow{a_{2}}, \\cdots, \\overrightarrow{a_{p}}$ 와 스칼라 $\\alpha_{1}, \\alpha_{2}, \\cdots , \\alpha_{p}$ 에 대하여 다음을 만족하는 경우\\[\\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{p}\\overrightarrow{a_{p}} = 0 \\Rightarrow \\alpha^{\\forall} = 0\\]              기저(Basis)          $n$ 차원에 대하여 선형 독립인 벡터들의 집합      $n$ 차원 기저벡터의 최대 갯수는 $n$ 개임            $span$\\[\\overrightarrow{x} = \\alpha_{1}\\overrightarrow{a_{1}} + \\alpha_{2}\\overrightarrow{a_{2}} + \\cdots + \\alpha_{n}\\overrightarrow{a_{n}}\\]          주어진 벡터들의 선형 결합으로 나타낼 수 있는 벡터의 집합, 혹은 그러한 작업      $n$ 차원의 모든 기저벡터들을 $span$ 하면 해당 공간을 모두 나타낼 수 있음      Inner Product and Norm      내적(Inner Product)\\[\\begin{aligned}  \\overrightarrow{a}\\cdot\\overrightarrow{b}&amp;=&lt;\\overrightarrow{a},\\overrightarrow{b}&gt;\\\\  &amp;=\\overrightarrow{a^{T}}\\overrightarrow{b}\\\\  &amp;=\\sum_{i}^{n}a_{i}b_{i}  \\end{aligned}\\]          차원이 $n$ 으로 동일한 두 벡터에 대하여 이를 대표하는 하나의 스칼라로 수렴하는 작업            유클리디안 노름(L-2 Norm)\\[\\Vert \\overrightarrow{a} \\Vert=\\sqrt{\\overrightarrow{a}^T\\cdot\\overrightarrow{a}}\\]                  정의 : 벡터의 규모(Magnitude) 혹은 길이(Length)                    성질                  $\\Vert \\overrightarrow{a} \\Vert \\ge0$          $\\Vert \\overrightarrow{a} \\Vert =0\\Rightarrow\\overrightarrow{a}=\\overrightarrow{0}$          $\\Vert \\alpha\\overrightarrow{a} \\Vert =\\vert \\alpha \\vert \\times \\Vert \\overrightarrow{a}\\Vert$          $\\Vert \\overrightarrow{a}+\\overrightarrow{b}\\Vert\\le\\Vert\\overrightarrow{a}\\Vert+\\Vert\\overrightarrow{b}\\Vert$                          코사인 유사도(Cosine Similarity) : 두 벡터의 사이각 $\\theta$ 의 코사인 값을 이용하여 측정한 벡터 간 유사도\\[cos\\theta=\\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{\\Vert\\overrightarrow{a}\\Vert\\times\\Vert\\overrightarrow{b}\\Vert}\\]          $\\theta$ : 임의의 벡터 $\\overrightarrow{a}, \\overrightarrow{b}$ 를 좌표평면상에 나타냈을 때, 두 벡터가 이루는 각도              $\\Vert\\overrightarrow{a}\\Vert \\cos{\\theta}$ : $\\overrightarrow{a}$ 를 $\\overrightarrow{b}$ 에 정사영(Projection)하여 얻은 벡터의 길이                    해석                  $-1\\le \\cos{\\theta} \\ge1$          $\\cos{\\theta} = -1$ : 음의 유사도를 가진다고 볼 수 있으며 기하학적으로 상반된 방향성을 가짐          $\\cos{\\theta} = 1$ : 양의 유사도를 가진다고 볼 수 있으며 기하학적으로 동일한 방향성을 가짐          $\\cos{\\theta} = 0$ : 유사하다고 볼 수 없으며 기하학적으로 직교함                          직교정규벡터(Orthonomal Vector) : 임의의 벡터에 대하여 해당 벡터와 직교하면서 그 노름이 1인 벡터          정규벡터(Normal Vector) : 노름이 1인 벡터      상호직교(Mutually Orthonal)                              수학적으로 봤을 때 내적값이 0인 관계\\[\\overrightarrow{a}\\perp\\overrightarrow{b}\\Leftrightarrow\\overrightarrow{a}\\cdot\\overrightarrow{b}=0\\]                                기하학적으로 봤을 때 사잇각이 90도인 관계\\[\\overrightarrow{a}\\perp\\overrightarrow{b}\\Leftrightarrow\\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{||\\overrightarrow{a}||\\times||\\overrightarrow{b}||}=cos90^\\circ\\]                              "
  },
  
  {
    "title": "Economic Growth Theory (4) Government Expenditure",
    "url": "/posts/Economic_Growth_Theory_4/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Economic Growth Theory, Government Expenditure",
    "date": "2019-08-08 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Economic Growth Theory (3) Invest",
    "url": "/posts/Economic_Growth_Theory_3/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Economic Growth Theory, Invest",
    "date": "2019-08-07 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Economic Growth Theory (2) Consumption",
    "url": "/posts/Economic_Growth_Theory_2/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Economic Growth Theory, Consumption",
    "date": "2019-08-06 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Economic Growth Theory (1) Economic Growth Model",
    "url": "/posts/Economic_Growth_Theory_1/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Economic Growth Theory, Solow Model, AK Model, Two-Sector Model",
    "date": "2019-08-05 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Keynesian Economics (2) AD-AS Model",
    "url": "/posts/Keynesian_Economics_2/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Keynesian Economics",
    "date": "2019-08-02 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Keynesian Economics (1) IS-LM Model",
    "url": "/posts/Keynesian_Economics_1/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Keynesian Economics",
    "date": "2019-08-01 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Classical Economics (2) Money Market",
    "url": "/posts/Classical_Economics_2/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Classical Economics",
    "date": "2019-07-31 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Classical Economics (1) Goods Market",
    "url": "/posts/Classical_Economics_1/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics, Classical Economics",
    "date": "2019-07-30 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "What? Macroeconomics",
    "url": "/posts/What_Macro/",
    "categories": "Economics, Macroeconomics",
    "tags": "Economics, Macroeconomics",
    "date": "2019-07-29 00:00:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "Welfare Economics (2) Social Choice",
    "url": "/posts/Welfare_Economics_2/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Welfare Economics, Pareto Efficiency, Pareto, Efficiency, Social Welfare, Welfare, Equity, Social Choice",
    "date": "2019-07-23 00:00:00 +0900",
    





    
    "snippet": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : ...",
    "content": "Pareto Efficiency      자원 배분에 관한 사회적 의사결정 기준          주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합 하에서 형평성 있는 지점을 선택함              자원 배분의 효율성(Efficiency) : 파레토 효율성(Pareto Efficiency)      자원 배분의 형평성(Equity) : 사회후생함수(Social Welfare Function)      What? Pareto Efficiency      파레토 효율성(Pareto Efficiency) : 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 어떤 경제주체의 효용수준도 개선할 수 없을 정도로 자원이 배분되었음        예시                            자원 배분 방법          부존자원량          총배분자원량          $A$          $B$          잉여자원량                                      배분1          100          100          30          70          0                          배분2          100          100          70          30          0                          배분3          100          100          50          50          0                          배분4          100          80          20          60          20                          배분5          100          80          60          20          20                          배분6          100          80          40          40          20                            $\\text{배분1},\\text{배분2},\\text{배분3}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서는 다른 경제주체의 자원 보유량을 개선할 수 없는 상태로서 파레토 최적인 상태임(Pareto Optimal)      $\\text{배분4},\\text{배분5},\\text{배분6}$ : 임의의 경제주체가 취득한 자원을 회수하지 않고서도 잉여자원 $20$ 으로써 다른 경제주체의 자원 보유량을 개선할 수 있는 상태로서 파레토 개선 가능한 상태임(Pareto Improvement)      따라서 $\\text{배분1},\\text{배분2},\\text{배분3}$ 은 $\\text{배분4},\\text{배분5},\\text{배분6}$ 보다 파레토 우월함(Pareto Superiority)      Condition      생산의 효율성(Productive Efficiency) : 사용 가능한 생산요소 제약 하 경제 전반의 재화 생산량을 극대화하여, 임의의 재화의 생산량을 몇 단위 포기하지 않고서는 다른 재화의 생산량을 개선하지 못하는 상태를 이룸\\[MRTS^{(X)}_{L,K}=\\frac{w}{v}=MRTS^{(Y)}_{L,K}\\]                생산요소 $L,K$ 제약 하 재화 $X,Y$ 에 대한 생산의 계약곡선                  상품 공간 상에 표현된 재화 $X,Y$ 에 대한 생산의 계약곡선으로서생산가능경계(Production Possibility Frontier; PPF)          교환의 효율성(Allocative Efficiency) : 배분 가능한 부존자원 제약 하 경제 전반의 효용을 극대화하여, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 다른 경제주체의 효용수준을 개선하지 못하는 상태를 이룸\\[MRS^{(A)}_{X,Y}=\\frac{P_X}{P_Y}=MRS^{(B)}_{X,Y}\\]                부존자원 $X,Y$ 제약 하 경제주체 $A,B$ 에 대한 교환의 계약곡선          총체적 효율성(Overall Efficiency) : 사용 가능한 생산요소 제약 하 극대화된 재화 생산량을 경제주체들에게 모두 배분하여 경제 전반의 효용수준을 극대화한 상태를 이룸\\[MRPT_{X,Y}=MRS_{X,Y}\\]                총체적 효율성 하에서는 재화 간 한계생산변환율과 경제주체별 재화 간 한계대체율이 일치함                  주어진 자원들과 기술 수준에서 달성 가능한 최대 효용 조합으로서효용가능경계(Utility Possibility Frontier; UPF)    Social Welfare Function      사회후생함수(Social Welfare Function) : 사회 구성원들의 효용수준($X$)과 사회후생수준($Y$) 간 상관관계를 나타내는 함수\\[SW=F\\left(U_{A},U_{B}\\right)\\]          효율성의 정의가 파레토 효율성으로써 합의된 데 반해, 형평성은 윤리적 관점에 따라 그 해석이 다양함. 이에 따라 파레토 최적 상태 하 형평성 달성도를 나타내는 사회후생함수 역시 어느 하나로 합의되지 않고 다양한 형태를 띰.            (초기) 공리주의 사회후생함수(Utilitarian Social Welfare Function) : 최대 다수의 최대 행복          비록 효용이 주관적 개념이긴 하나, 개인 간에 질적으로는 차이가 없고, 오로지 양적으로만 차이가 있음. 따라서 사회 전체의 효용수준은 그저 그 사회 구성원들이 누리는 효용의 총합에 불과함.    \\[SW=U_{A}+U_{B}\\]            롤스 사회후생함수(Rawlsian Social Welfare Function) : 최소 수혜자의 최대 이익          사회 구성원들에게 무지의 베일을 씌운 원초적 상황 하에서 민주적으로 자원 배분 정책을 수립한다고 하자. 타인의 이익에 무관심하고 오로지 자신의 이익에만 관심이 있음에도 불구하고, 사회 구성원들은 자신이 최악의 상황에 처할 가능성을 고려하여 최소극대화 원칙에 근거한 배분 정책을 수립할 것임.    \\[SW=\\min{\\left[U_{A},U_{B}\\right]}\\]            (실질적) 평등주의 사회후생함수(Egalitarian Social Welfare Function) : 한계효용의 평등          빈자에게 있어서 1원과 부자의 그것이 가지는 실질적 가치가 같다고 볼 수 없음. 따라서 사회 전체의 효용수준을 논함에 있어서 개인의 사정을 고려해야 함.    \\[SW=\\left(U_A\\right)^{\\alpha} \\cdot \\left(U_B\\right)^{1-\\alpha}\\]      Impossibility Theorem  합리성의 공리와 민주성의 공리는 상호위배된다. 따라서 사회후생수준을 평가할 수 있는, 합리적인 동시에 민주적인 사회선호체계란 존재할 수 없다. (케네스 애로우)  합리적 사회선호체계의 공리                  완비성(Completeness); 사회선호체계가 모든 사회적 상태를 비교하고 평가할 수 있어야 한다.\\[X \\neq Y \\implies X \\succeq Y \\;\\text{or}\\; Y \\succeq X \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]                    이행성(Transitivity); 사회적 상태 $X, Y, Z$ 에 대하여 사회선호체계가 $X$ 를 $Y$ 보다 선호하고 $Y$ 를 $Z$ 보다 선호하면 $X$ 를 $Z$ 보다 선호해야 한다.\\[X \\succeq Y \\;\\text{and}\\; Y \\succeq Z \\implies X \\succeq Z \\quad\\text{for}\\quad X, Y, Z \\in \\mathcal{S}\\]                    파레토 원칙(Pareto Principle); 임의의 사회적 상태에 대하여 모든 사회 구성원들이 해당 사회적 상태를 다른 사회적 상태보다 선호한다면, 사회선호체계 역시 해당 사회적 상태를 다른 사회적 상태보다 선호해야 한다.\\[\\begin{aligned} X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ i^{\\forall} &amp;\\in N \\end{aligned}\\]                    독립성(Independence); 사회선호체계가 두 가지 사회적 상태의 선호관계를 평가함에 있어서 이들과 무관한 것으로부터 영향을 받지 말아야 한다.\\[\\begin{aligned} X \\succ Y \\implies X \\succ^{\\prime} Y \\quad\\text{for}\\quad X, Y &amp;\\in \\mathcal{S},\\\\ Z &amp;\\in \\mathcal{S} \\setminus \\{X, Y\\} \\end{aligned}\\]              민주적 사회선호체계의 공리                  비독재성(Non-dictatorship); 사회선호체계가 사회 구성원 소수의 선호체계에 좌우되지 말아야 한다.\\[\\nexists i \\in N \\; \\text{such that} \\; X \\succ_i Y \\implies X \\succ Y \\quad\\text{for}\\quad X, Y \\in \\mathcal{S}\\]              이행성과 민주성의 동시 성립 불가능성                  사회 구성원 $A,B,C$ 가 사회적 상태 $X,Y,Z$ 에 대하여 각각 다음과 같이 평가한다고 하자\\[\\begin{aligned}  A:\\quad &amp;X \\succ_A Y \\; \\text{and} \\; Y \\succ_A Z\\\\  B:\\quad &amp;Y \\succ_B Z \\; \\text{and} \\; Z \\succ_B X\\\\  C:\\quad &amp;Z \\succ_C X \\; \\text{and} \\; X \\succ_C Y  \\end{aligned}\\]                    사회선호체계는 파레토 원칙 및 비독재성에 의해 사회적 상태를 다음과 같이 평가함\\[\\begin{aligned}  \\mathcal{S}: X \\succ Y \\; \\text{and} \\; Y \\succ Z \\; \\text{and} \\; Z \\succ X  \\end{aligned}\\]                    따라서 민주성의 공리에 기초하여 도출한 사회선호체계는 이행성을 보장하지 못함            "
  },
  
  {
    "title": "Welfare Economics (1) Theorems of Welfare Economics",
    "url": "/posts/Welfare_Economics_1/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Welfare Economics",
    "date": "2019-07-22 00:00:00 +0900",
    





    
    "snippet": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자...",
    "content": "Why? Exchange      후생경제학(Welfare Economics) : 임의의 경제가 사회적 후생을 어느 정도 달성했는지 평가하는 학문          해당 경제 내 부존자원 제약 하 효용이 극대화되었는가?            에지워스 상자(Edgeworth Box) : 자원 분배에 따른 효용 달성 정도를 분석하는 도구로서, 두 가지 부존자원 $X,Y$ 을 보유하고 있고, 두 명의 경제주체 $A,B$ 가 활동하는 가상의 경제를 상정함      Walras Equilibrium  시장에서 모든 경제주체가 동시에 자신의 최적화 문제를 해결하고, 모든 시장이 동시에 균형을 이루는 상태로서, 모든 부존자원에 대하여 모든 경제주체의 주관적 교환 비율과 객관적 교환 비율이 일치하는 상태.Initial Endowment Point      초기부존자원점(Initial Endowment Point)              자원 $X$ 의 부존량 $X=\\overline{X}_A+\\overline{X}_B$      자원 $Y$ 의 부존량 $Y=\\overline{Y}_A+\\overline{Y}_B$            초기부존자원 하 효용 수준              초기부존자원 하 경제주체의 효용 수준을 초기부존자원점에서 서로 교차하는 경제주체 각각의 무차별곡선으로 나타낼 수 있음. 위 그래프는 각각의 무차별곡선이 교차하되 접하지는 않는 상태임. 이때 어느 한 무차별곡선을 원점 가까이 조정하지 않고서도 다른 무차별곡선을 원점에서 더 멀리 이동시킬 수 있음. 즉, 어느 경제주체의 효용 수준을 낮추지 않고서도 다른 경제주체의 효용 수준을 개선할 여지가 있음. 따라서 위 초기부존자원은 이상적인 자원 배분이 아님.      Walras Dis-Equilibrium      교환하기 위한 가격체계 설정              교환(Exchange) : 시장경제체제에서 경제주체들이 각자 효용을 극대화하는 자원조합을 구성하기 위해 상호간에 초기부존자원을 거래하는 행위      가격체계(Price System) : 두 재화 간 객관적 교환 비율로서, (위 그래프의 경우) 부존자원 $X,Y$ 에 대하여 $X$ 의 $Y$ 에 대한 상대가격            가격체계 하 효용 극대화 지점 도출\\[MRS_{X,Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}\\]                $A$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량                  $B$ 의 효용 극대화 지점 하 각 부존자원에 대한 수요량과 공급량          왈라스 불균형\\[MRS^{(A)}_{X,Y} \\ne MRS^{(B)}_{X,Y}\\]                현재 가격체계 하에서는 두 경제주체 간 이해관계가 맞아떨어지지 않음                  $A$ 의 효용 극대점에서 거래를 강제하는 경우$B$ 의 효용수준이 낮아짐                  $B$ 의 효용 극대점에서 거래를 강제하는 경우$A$ 의 효용수준이 낮아짐          왈라스 불균형 하 수요량과 공급량의 불일치        Walras Equilibrium      모색 과정 : 왈라스 균형에 도달하기 위해 가격체계를 조정하는 과정            왈라스 균형\\[MRS^{(A)}_{X,Y} = \\frac{P_X}{P_Y} = MRS^{(B)}_{X,Y}\\]            왈라스 균형 하 수요량과 공급량의 일치            계약곡선(Contract Curve) : 두 경제주체가 교환을 통해 효용을 극대화하는(왈라스 균형을 실현하는) 배분점의 집합      Theorems of Welfare EconomicsThe First Fundamental Theorem  모든 경제주체의 선호체계가 강단조성을 갖고, 하나의 경제에 외부성이 존재하지 않으면, 왈라스 균형 하에서의 배분은 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없을 정도로 자원이 효율적으로 배분된 상태를 실현한다(파레토 최적이다).해석: 경제주체들은 이기적으로 행동함에도 불구하고, 시장에서 보이지 않는 손에 의해 경제주체 간 상충하는 욕망이 조정되어, 사익과 공익이 조화를 이루게 된다.The Second Fundamental Theorem  초기부존지원이 적절하게 분배된 상태에서 모든 경제주체의 선호체계가 연속성, 강단조성, 볼록성을 가진다면, 임의의 경제주체의 효용수준을 이전보다 불리하게 만들지 않고서는 최소한 하나의 경제주체의 효용수준조차 개선할 수 없는 상태를 실현하는(파레토 효율적인) 배분은 왈라스 균형이 된다.해석: 초기부존자원을 적절한 가격체계 위에 설정한다면, 이상적인(파레토 효율적인) 배분을 왈라스 균형 하 배분으로 만드는 가격체계가 실현될 수 있다."
  },
  
  {
    "title": "Competition Theory",
    "url": "/posts/Competition_Theory/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Equilibrium, Competition Theory, Perfect Competition Theory",
    "date": "2019-07-21 00:00:00 +0900",
    





    
    "snippet": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별...",
    "content": "AssumptionWhat? Competition Theory      경쟁시장이론(Competition Theory) : 개별생산자들의 경쟁 양상에 따라 시장 유형을 세분화하여 분석하는 이론    완전 경쟁(Perfect competition) : 사회적 후생이 극대화된 상태로서, 이상적인 상태로 간주되는 경쟁 상태          개별소비자와 개별생산자는 가격 수용자이다.      하나의 시장에서 거래되는 상품은 모두 동질적이다.      개별생산자는 시장에 자유롭게 진입하거나 퇴출할 수 있다.      시장에 관한 모든 정보는 모든 시장 참여자들에게 있어서 주지사실이다.        시장실패(Market Failure) : 완전 경쟁의 네 가지 조건이 동시에 충족되지 못하여 사회적 후생이 극대화되지 못함          산업조직론(Industrial Organization) : 불완전 경쟁으로 인한 시장실패 현상을 분석함      공공경제학(Public Economics) : 공공재 및 외부효과로 인한 시장실패 현상을 분석함      정보경제학(Information Economics) : 정보의 비대칭성으로 인한 시장실패 현상을 분석함      법경제학(Law and Economics) : 정부의 과도한 경제 간섭과 규제로 인한 시장실패 현상을 분석함      Demand &amp; Supply under Perfect Competition      완전탄력적 수요곡선(Perfectly Elastic Demand Curve) : 개별생산자가 단독으로 직면하는 시장수요곡선              소비자는 가격 수용자로서, 가격의 특정 수준에 대하여 수요량을 조절함으로써 영향력을 행사할 수 없음. 따라서 개별생산자가 단독으로 직면하는 시장수요곡선은 균형가격에서 수평선(완전탄력적인 곡선)이 됨.            평균비용곡선의 극소점을 상회하는 수준의 한계비용곡선(Marginal Cost Curve above the Minimum Point of the Average Cost Curve) : 개별공급곡선              생산자는 가격 수용자로서, 주어진 가격 하 양의 이윤을 보장받을 수 있는 상태에서 이윤을 극대화하는 생산량을 공급함. 따라서 생산자들의 개별공급곡선은 한계비용곡선 중 평균비용곡선의 극소점을 상회하는 수준이 됨.                      주어진 가격 하 양의 이윤을 보장받을 수 있는 생산량 $Q^{*}$\\[\\pi(Q^{*}) \\ge 0 \\Leftrightarrow Q^{*} \\bigg\\vert AR(Q) \\ge AC(Q)\\]                    주어진 가격 하 이윤을 극대화하는 생산량 $Q^{*}$\\[\\max{\\pi(Q^{*})} \\Leftrightarrow Q^{*} \\bigg\\vert MR(Q)=MC(Q)\\]                    주어진 가격 하 평균수익($AR$)과 한계수익($MR$)\\[\\begin{aligned}  TR(Q)&amp;= P \\cdot Q\\\\\\\\  AR(Q)&amp;= \\frac{TR(Q)}{Q}\\\\&amp;= P\\\\\\\\  MR(Q)&amp;= \\frac{\\Delta TR(Q)}{\\Delta Q}\\\\&amp;= P  \\end{aligned}\\]                    종합\\[Q^{*} \\bigg\\vert P=MC(Q) \\quad \\&amp; \\quad P &gt; AC(Q)\\]            Short-Term$P &gt; AC \\Rightarrow \\pi &gt; 0$  균형가격이 평균비용곡선의 극소점을 상회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_A$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_A$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_A)$ 과 균형공급량 $Q_A$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_A)$ 에서 총비용 $TC(Q_A)$ 을 뺀 값임.총수익이 총비용보다 크므로($TR(Q_A)&gt;TC(Q_A)$) 양의 이윤이 발생함($\\pi(Q_A)&gt;0$).        $TR(Q_A)=P \\times Q_A$        $TC(Q_A)=AC(Q_A) \\times Q_A$        $\\pi(Q_A)=TR(Q_A)-TC(Q_A)&gt;0$$P &lt; AC \\Rightarrow \\pi &lt; 0$  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되었다고 가정하자.균형공급량 $Q_B$ 은 한계수익곡선 $MR(Q)$ 과 한계비용곡선 $MC(Q)$ 이 일치하는 공급량임.총수익 $TR(Q)$ 은 평균수익 $AR=P$ 과 균형공급량 $Q_B$ 을 곱한 값임.총비용 $TC(Q)$ 은 균형공급량에서의 평균비용 $AC(Q_B)$ 과 균형공급량 $Q_B$ 을 곱한 값임.총이윤 $\\pi(Q)$ 은 총수익 $TR(Q_B)$ 에서 총비용 $TC(Q_B)$ 을 뺀 값임.총수익이 총비용보다 작으므로($TR(Q_B)&lt;TC(Q_B)$) 음의 이윤이 발생함($\\pi(Q_B)&lt;0$).        $TR(Q_B)=P \\times Q_B$        $TC(Q_B)=AC(Q_B) \\times Q_B$        $\\pi(Q_B)=TR(Q_B)-TC(Q_B)&lt;0$Negative Profit Analysis  균형가격이 평균비용곡선의 극소점을 하회하는 수준에서 형성되어 음의 이윤이 발생하는 경우, 생산을 중단하여 비용을 없애는 것이 합리적인 의사결정임. 그러나 단기에는 공급을 중단하더라도 고정비용이 발생함. 따라서 생산중단을 결정하기 전에 생산을 지속함으로써 고정비용을 회수할 수 있는지 여부를 검토할 필요가 있음.$P&lt;AFC(Q)$  균형가격이 평균고정비용곡선의 극소점을 하회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 작으므로($TR(Q_C)&lt;TFC(Q_C)$) 생산을 지속해도 총고정비용을 회수할 수 없음.따라서 균형가격이 평균고정비용곡선의 극소점을 하회하는 수준에서 형성되는 경우($P&lt;AFC(Q)$) 생산을 중단하는 것이 유리함.        $TR(Q_C)=P \\times Q_C$        $TC(Q_C)=TVC(Q_C)+TFC(Q_C)$        $TR(Q_C)&lt;TFC(Q_C)$$AFC(Q)&lt;P&lt;AVC(Q)$  균형가격이 평균고정비용곡선의 극소점을 상회하는 가격수준에서 형성되었다고 가정하자.총비용 $TC(Q)$ 을 총가변비용 $TVC(Q)$ 과 총고정비용 $TFC(Q)$ 으로 세분화할 수 있음.총고정비용 $TFC(Q)$ 은 균형공급량에서의 평균고정비용 $AFC(Q_C)$ 과 균형공급량 $Q_C$ 를 곱한 값임.총수익이 총고정비용보다 크므로($TR(Q_C)&gt;TFC(Q_C)$) 생산을 지속하면 총고정비용을 회수할 수 있음.따라서 균형가격이 평균고정비용곡선의 극소점을 상회하는 수준에서 형성되는 경우($P&gt;AFC(Q)$) 생산을 중단하는 것이 불리함.        $TR(Q_D)=P \\times Q_D$        $TC(Q_D)=TVC(Q_D)+TFC(Q_D)$        $TR(Q_D)&gt;TFC(Q_D)$Long-Term시장수요곡선의 장기화      $P&gt;\\min{AC} \\Rightarrow \\pi&gt;0$ : 잠재적 생산자가 시장에 진입하여 시장공급곡선이 우측으로 이동함에 따라 균형가격이 하락함            $P&lt;\\min{AC} \\Rightarrow \\pi&lt;0$ : 시장에 진입해 있는 생산자가 퇴출되어 시장공급곡선이 좌측으로 이동함에 따라 균형가격이 상승함            $P=\\min{AC} \\Rightarrow \\pi=0$ : 균형가격은 생산자 진입 및 퇴출에 따라 등락을 반복하다가 점차 이윤이 발생하지 않는 수준으로 수렴함      개별공급곡선의 장기화      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합    \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합    \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]        장기개별공급곡선(Long-Term Individual Supply Curve) : 장기평균비용곡선의 극소점을 상회하는 수준의 장기한계비용곡선      장기 균형      $P(=AR)=LAC \\Rightarrow \\pi=0$          개별생산자의 평균수익 $AR$ 과 장기평균비용 $LAC$ 이 일치함에 따라 이윤 $\\pi$ 이 발생하지 않음. 따라서 잠재적 생산자의 시장 진입 혹은 진입해 있는 생산자의 시장 퇴출 가능성이 제거됨. 즉, 외부교란요인이 발생할 여지가 없음.            $P(=MR)=LMC \\Rightarrow \\max{\\pi}$          개별생산자의 한계수익 $MR$ 과 장기한계비용 $LMC$ 이 일치함에 따라 이윤 $\\pi$ 가 극대화됨.      "
  },
  
  {
    "title": "Producer Theory (3) Joint Production",
    "url": "/posts/Producer_Theory_3/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-20 00:00:00 +0900",
    





    
    "snippet": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합  ...",
    "content": "Joint Production      결합 생산(Joint Production) : 개별생산자가 두 가지 품종 이상을 함께 생산하는 경우\\[Z = F(X,Y)\\]        생산변환곡선(Product Transformation Curve) : 재화 $X,Y$ 에 대하여, 생산하는데 동일한 비용($Z$)이 요구되는 상품묶음 $(X,Y)$ 의 집합            한계생산변환율(Marginal Rate of Product Transformation; MRPT) : 재화 $X,Y$ 에 대하여, 동일한 비용 수준에서 특정 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta x \\cdot MC_X + \\Delta y \\cdot MC_Y = 0\\]\\[\\therefore MRPT_{X,Y}:= -\\frac{\\Delta y}{\\Delta x} = \\frac{MC_X}{MC_Y}\\]          $MC_X = \\displaystyle\\frac{\\partial z}{\\partial x}$ : 재화 $X$ 에 대한 한계비용      $MC_Y = \\displaystyle\\frac{\\partial z}{\\partial y}$ : 재화 $Y$ 에 대한 한계비용            한계생산변환율 체증의 법칙 : 특정 재화의 생산량이 증가할수록 동일한 비용 수준에서 해당 재화를 한 단위 추가 생산하기 위해 포기해야 하는 다른 재화의 공급분이 증가하는 현상\\[\\frac{\\partial MRPT_{X,Y}}{\\partial X} \\succ 0\\]  Revenue Constraint      한계수익불변 하 등수익곡선(Iso-Revenue Curve subject to Constant Marginal Revenue) : 공급 시 동일한 수익을 얻을 수 있는 상품묶음의 조합\\[X \\cdot P_X + Y \\cdot P_Y \\le R\\]                  한계수익불변(Constant Marginal Revenue) : 한계수익이 특정 재화의 공급량 변화에 반응하지 아니하고 일정함\\[\\frac{\\partial R}{\\partial X}=\\overline{\\alpha},\\frac{\\partial R}{\\partial Y}=\\overline{\\beta}\\]                  상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 수익 수준에서 특정 재화를 한 단위 추가 공급하기 위해 포기해야 하는 다른 재화의 공급분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Cost Minimization under Revenue Constraint\\[\\min{Z} \\quad \\text{s.t.} \\; X \\cdot P_{X} + Y \\cdot P_{Y} \\le R\\]      생산변환곡선의 접선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 한계생산변환율 $MRPT_{X,Y}$\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{MC_X}{MC_Y}\\]        등수익곡선의 기울기 : 재화 $X,Y$ 에 대하여, $X$ 의 $Y$ 에 대한 상대가격\\[-\\frac{\\Delta Y}{\\Delta X} = \\frac{P_X}{P_Y}\\]        생산변환곡선과 등수익곡선의 접점 : 수익 제약 하 비용을 최소화하는 상품묶음\\[\\begin{aligned}  \\frac{MC_X}{MC_Y}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_X}{P_Y}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MC_{X}}{P_X}$ 와 $\\displaystyle\\frac{MC_{Y}}{P_Y}$ 가 일치함\\[\\frac{MC_{X}}{MC_{Y}}=\\frac{P_X}{P_Y} \\Leftrightarrow \\frac{MC_{X}}{P_X}=\\frac{MC_{Y}}{P_Y}\\]          $\\displaystyle\\frac{MC_{X}}{P_X}$ : 화폐 단위당 취득 가능한 $X$ 단위의 한계비용      $\\displaystyle\\frac{MC_{Y}}{P_Y}$ : 화폐 단위당 취득 가능한 $Y$ 단위의 한계비용      "
  },
  
  {
    "title": "Producer Theory (2) Profit Maximization",
    "url": "/posts/Producer_Theory_2/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-19 00:00:00 +0900",
    





    
    "snippet": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{align...",
    "content": "Revenue      총수익(Total Revenue; TR) : 개별생산자가 재화를 공급하고서 취득할 수 있는 수익의 총합\\[\\begin{aligned}  TR(Q \\vert \\alpha, \\beta)  &amp;=P \\cdot Q\\\\  &amp;=\\left(\\alpha - \\beta \\cdot Q \\right) \\cdot Q  \\end{aligned}\\]          $P=\\alpha - \\beta \\cdot Q$ : 단위당 시장가격      $Q$ : 총 공급량            평균수익(Average Revenue; AR) : 개별생산자가 재화 단위당 취득할 수 있는 수익\\[\\begin{aligned}  AR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{TR(Q \\vert \\alpha, \\beta)}{Q}\\\\  &amp;= P  \\end{aligned}\\]        한계수익(Marginal Revenue; MR) : 개별생산자가 재화를 한 단위 추가 공급했을 때 추가 취득할 수 있는 수익\\[\\begin{aligned}  MR(Q \\vert \\alpha, \\beta)  &amp;= \\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}\\\\  &amp;= \\alpha - 2 \\beta \\cdot Q  \\end{aligned}\\]  $\\max{TR}$\\[\\begin{aligned}\\frac{\\partial TR(Q \\vert \\alpha, \\beta)}{\\partial Q}&amp;= MR(Q)\\\\&amp;= P \\cdot \\left(1 + \\frac{Q / \\Delta Q}{P / \\Delta P}\\right)\\\\&amp;= P \\cdot \\left(1 - \\frac{1}{\\varepsilon_{P}} \\right)\\\\&amp;= 0\\end{aligned}\\]\\[\\therefore \\hat{Q} = \\text{arg}\\max{TR(Q \\vert \\alpha, \\beta)} \\quad \\text{for} \\; \\varepsilon_{P}=1\\]CostShort-Term Cost      단기총비용(Short-Term Total Cost; STC) : 개별생산자가 재화를 총 $Q$ 단위 공급하기 위해 지불해야 하는 비용\\[\\begin{aligned}  STC(Q \\vert K) &amp;= STVC(Q) + STFC\\\\  STVC(Q) &amp;= L \\cdot w\\\\  STFC &amp;= \\overline{K} \\cdot v  \\end{aligned}\\]        단기평균비용(Short-Term Average Cost; SAC) : 개별생산자가 재화 단위당 지불해야 하는 비용\\[\\begin{aligned}  SAC(Q \\vert K)  &amp;= \\frac{STC(Q \\vert K)}{Q}\\\\  &amp;= \\frac{STVC(Q)}{Q} + \\frac{STFC}{Q}  \\end{aligned}\\]        단기한계비용(Short-Term Marginal Cost; SMC) : 개별생산자가 재화 단위를 추가할 때 추가 지불해야 하는 비용\\[\\begin{aligned}  SMC(Q \\vert K)  &amp;= \\frac{\\partial STC(Q \\vert K)}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} + \\frac{\\partial STFC}{\\partial Q}\\\\  &amp;= \\frac{\\partial STVC(Q)}{\\partial Q} \\quad \\left(\\because \\frac{\\partial STFC}{\\partial Q} = 0 \\right)  \\end{aligned}\\]  Long-Term Cost      장기평균비용(Long-Term Average Cost; LAC) : 각 생산량 수준($Q$)에서 단기평균비용이 최저인 점들의 집합      \\[LAC(Q)=\\min_{K}{SAC(Q \\vert K)}\\]        장기한계비용(Long-Term Marginal Cost; LMC) : 각 생산량 수준($Q$)에서 채택된 단기평균비용곡선에 대응하는 단기한계비용곡선 점들의 집합      \\[\\begin{aligned}  LMC(Q)&amp;= SMC\\left(Q \\vert \\hat{K} \\right)\\\\  \\hat{K}&amp;= \\text{arg} \\min_{K}{SAC\\left(Q \\vert K \\right)}  \\end{aligned}\\]  Profit Maximization      양의 이윤을 극대화하는 생산량 도출\\[Q_{S}^{*}= \\text{arg} \\max{\\pi(Q)}\\]        이윤 함수(Profit Function)\\[\\pi(Q) = TR(Q) - TC(Q)\\]        일계 조건\\[\\begin{aligned}  \\frac{\\partial \\pi(Q)}{\\partial Q}  &amp;= \\frac{\\partial TR(Q)}{\\partial Q} - \\frac{\\partial TC(Q)}{\\partial Q}\\\\  &amp;= MR(Q) - MC(Q)\\\\  &amp;=0\\\\\\\\  \\therefore MR(Q)&amp;=MC(Q)  \\end{aligned}\\]        이계 조건\\[\\begin{aligned}  \\frac{\\partial^2 \\pi(Q)}{\\partial Q^2}  &amp;= \\frac{\\partial}{\\partial Q} \\frac{\\partial \\pi(Q)}{\\partial Q}\\\\  &amp;= \\frac{\\partial MR(Q)}{\\partial Q} - \\frac{\\partial MC(Q)}{\\partial Q}\\\\  &amp;&lt; 0\\\\\\\\  \\therefore \\frac{\\partial MR(Q)}{\\partial Q} &amp;&lt; \\frac{\\partial MC(Q)}{\\partial Q}  \\end{aligned}\\]  "
  },
  
  {
    "title": "Producer Theory (1) Output Maximization under Cost Constraint",
    "url": "/posts/Producer_Theory_1/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Producer Theory",
    "date": "2019-07-18 00:00:00 +0900",
    





    
    "snippet": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat...",
    "content": "Production  개별생산자의 최적 의사결정 과정                  이윤을 극대화하는 생산량 수준 $Q^{*}_{S}$ 도출\\[Q^{*}_{S} = \\text{arg} \\max{\\pi}\\]                    이윤 극대화 생산량 $Q^{*}_{S}$ 을 최소 비용으로 달성하는 요소조합 $\\left(\\hat{L}, \\hat{K}\\right)$ 도출\\[\\hat{L}, \\hat{K}=\\text{arg} \\min{L \\cdot w + K \\cdot v} \\quad \\text{s.t.} \\; Q^{*}_{S}=F(L,K)\\]            Production      생산 함수(Production Function) : 단기 콥-더글라스 생산 함수임을 가정          가정 : 생산 기간은 단기로 간주하고, 투입되는 생산요소를 노동($L$)과 자본($K$)으로 제한하자. 단기에는 고정투입요소의 투입량을 유동적으로 조정할 수 없으며($\\overline{K}$), 생산기술이 일정한 수준으로 유지된다($\\overline{H}$).    \\[\\begin{aligned}  Q_S  &amp;= F\\left(L,\\overline{K}\\right)\\\\  &amp;= \\overline{H} \\cdot L^{\\alpha} \\cdot \\overline{K}^{\\beta}  \\end{aligned}\\]          $Q_S$ : 개별생산량      $L$ : 노동으로서 가변투입요소      $\\overline{K}$ : 자본으로서 고정투입요소      $\\overline{H}$ : 생산기술            등량 곡선(Isoquant Curve) : 노동 투입량을 X축으로, 자본 투입량을 Y축으로 하는 좌표평면 위에 생산량이 무차별한 요소조합을 이은 곡선    \\[Q_K = F(L, K)\\]          동일한 생산함수의 상이한 생산량수준을 나타내는 두 개의 등량곡선은 교차하지 않는다.      원점에서 비교적 먼 등량곡선은 비교적 높은 생산량수준을 나타낸다.      등량곡선은 우하향한다.      제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 등량곡선이 하나 존재한다.      등량곡선은 원점에 대하여 볼록한 모양을 가진다.      Productivity of Factors of Production      생산요소의 생산력                      노동의 총생산(Total Production of Labor; $TP_L$) : 노동을 $L$ 단위 투입했을 때 가능한 생산량\\[TP_L = f(L,\\overline{K})\\]                    노동의 평균생산(Average Production of Labor; $AP_L$) : 노동 단위당 가능한 생산량\\[AP_L = \\frac{TP_L}{L}\\]                    노동의 한계생산(Marginal Production of Labor; $MP_L$) : 노동 단위 추가 투입 시 가능한 추가 생산량\\[MP_L = \\frac{\\partial TP_L}{\\partial L}\\]                  한계기술대체율(Marginal Rate of Technical Substitution; MRTS) : 동일한 생산량 수준에서 특정 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소 단위\\[\\Delta L \\cdot MP_L + \\Delta K \\cdot MP_K = 0\\]\\[\\therefore MRTS_{L,K}:= -\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        한계기술대체율 체감의 법칙 : 특정 생산요소의 투입량이 증가할수록 동일한 생산량 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분이 감소하는 현상\\[\\frac{\\partial MRTS_{L,K}}{\\partial L} \\prec 0\\]  Cost Constraint      등비용곡선(Iso-Cost Curve) : 주어진 비용($C$)과 요소가격 상황($P_L=w,P_K=v$)에 맞게 취득할 수 있는 요소조합의 집합\\[(L,K) \\quad \\text{s.t.} \\; L \\cdot w + K \\cdot v \\le C\\]        상대가격(Relative Price) : 특정 생산요소에 대하여, 동일한 비용 수준에서 해당 생산요소를 한 단위 추가 투입하기 위해 포기해야 하는 다른 생산요소의 투입분\\[\\Delta L \\cdot w + \\Delta K \\cdot v = 0\\]\\[\\therefore - \\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]  Output Maximization under Cost Constraint\\[\\max{Q_S} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      등량곡선의 접선의 기울기 : 노동의 자본에 대한 한계기술대체율 $MRTS_{L,K}$\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{MP_L}{MP_K}\\]        등비용곡선의 기울기 : 노동의 자본에 대한 상대가격\\[-\\frac{\\Delta K}{\\Delta L} = \\frac{w}{v}\\]        등비용곡선과 등량곡선의 접점 : 비용 제약 하 생산량을 극대화하는 요소조합\\[\\begin{aligned}  \\frac{MP_L}{MP_K}=-\\frac{\\Delta K}{\\Delta L}=\\frac{w}{v}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MP_{L}}{w}$ 과 $\\displaystyle\\frac{MP_{K}}{v}$ 이 일치함\\[\\frac{MP_{L}}{MP_{K}}=\\frac{w}{v} \\Leftrightarrow \\frac{MP_{L}}{w}=\\frac{MP_{K}}{v}\\]          $\\displaystyle\\frac{MP_{L}}{w}$ : 화폐 단위당 취득 가능한 노동 단위의 한계생산      $\\displaystyle\\frac{MP_{K}}{v}$ : 화폐 단위당 취득 가능한 자본 단위의 한계생산      "
  },
  
  {
    "title": "Consumer Theory (2) Demand Response to Changes in Market Demend Determinants",
    "url": "/posts/Consumer_Theory_2/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Consumer Theory",
    "date": "2019-07-17 00:00:00 +0900",
    





    
    "snippet": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른...",
    "content": "Demand Response to Changes in Market Demend Determinants      상품 공간(Commodity Space) : 두 재화 $X,Y$ 로 구성되는 상품묶음을 표현하는 좌표평면        가격-수량 평면(Price-Quantity Plane) : 임의의 재화 $X$ 에 대하여 그 시장가격 $P_{X}$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면        소득-수량 평면(Income-Quantity Plane) : 임의의 재화 $X$ 에 대하여 소득수준(혹은 예산제약) $M$ 에 따른 수요량 $Q_{X}$ 을 표현하는 좌표평면  Price Changes  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 재 시장가격 $P_{Y}$ 와 소득수준 $M$ 이 일정한 상황에서 $X$ 재 시장가격 $P_{X}$ 는 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $\\displaystyle\\frac{P_{X}}{P_{Y}}$ 이 감소함      예산선의 기울기가 점차 완만해짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Q_{X}^{*}$ 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격소비곡선(Price Consumption Curve; PCC) : 상품 공간에서 시장가격의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            개별수요곡선(Individual Demand Curve) : 가격-수량 평면에서 시장가격의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      개별수요곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta P_X}{\\Delta Q_X}\\right)$ 와 개별수요의 가격 탄력성 $\\varepsilon_{P}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{P}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta P_X/P_X}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta P_X} \\cdot \\frac{P_X}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta P_{X}}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{P_X}{Q_X}  \\end{aligned}\\]            Income Changes  가정 : 정상재 $X,Y$ 에 대하여, 그 시장가격 $P_{X},P_{Y}$ 이 일정한 상황에서 소득수준 $M$ 이 지속적으로 상승하는 추세에 있다.            현상      상품 공간 상의 표현                  예산규모 $M$ 이 증가함      예산선이 원점에서 점차 멀어짐              $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{X}}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $Y$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_{Y}}$ 이 증가함      예산선의 $Y$ 절편이 점차 원점에서 멀어짐              \\(Q_{X}^{*}, Q_{Y}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 우상향함            소득소비곡선(Income Consumption Curve; ICC) : 상품 공간에서 소득수준의 변화에 따른 최적 선택의 변화 양상을 나타낸 곡선            엥겔곡선(Engel Curve; EC) : 소득-수량 평면에서 소득수준의 변화에 따른 최적 선택 하 수요량의 변화 양상을 나타낸 곡선                      엥겔곡선의 기울기 $\\left(\\displaystyle\\frac{\\Delta M}{\\Delta Q_X}\\right)$ 와 개별수요의 소득 탄력성 $\\varepsilon_{M}$ 의 관계\\[\\begin{aligned}  \\varepsilon_{M}  &amp;= -\\frac{\\Delta Q_X/Q_X}{\\Delta M/M}\\\\  &amp;= -\\frac{\\Delta Q_X}{\\Delta M} \\cdot \\frac{M}{Q_X}\\\\  &amp;= -\\left(\\frac{\\Delta M}{\\Delta Q_{X}}\\right)^{-1} \\cdot \\frac{M}{Q_X}  \\end{aligned}\\]            Price Effect  가정 : 대체 관계에 있는 정상재 $X,Y$ 에 대하여, $Y$ 의 시장가격 $P_Y$ 가 일정한 상태에서 $X$ 의 시장가격 $P_{X}$ 이 지속적으로 감소하는 추세에 있다.            현상      상품 공간 상의 표현                  $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함      예산선의 $X$ 절편이 점차 원점에서 멀어짐              $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함      예산선의 기울기가 점차 완만해짐              \\(Q_{X}^{*}\\) 가 증가함      무차별곡선과 예산선의 접점이 점차 오른쪽으로 이동함            가격 효과(Price Effect) : 특정 재화의 가격 변동이 해당 재화의 수요량에 미치는 총 효과            $\\text{Price Effect} = \\text{Substitution Effect} + \\text{Income Effect}$                      $E_1 \\rightarrow E_3$ : 대체 효과                  대체 관계에 있는 재화 $X,Y$ 에 대하여, 동일한 효용수준을 유지하는 경우, $Y$ 에 대한 $X$ 의 상대가격 $-\\displaystyle\\frac{\\Delta Y}{\\Delta X}=\\displaystyle\\frac{P_X}{P_Y}$ 이 감소함에 따라 $Y$ 단위당 기회비용이 증가하므로 $Y$ 의 개별수요량 $Q_Y$ 일부가 $X$ 의 개별수요량 $Q_X$ 으로 대체될 수 있음                            $E_3 \\rightarrow E_2$ : 소득 효과                  정상재 $X$ 에 대하여, $X$ 단위 실질소득수준 $\\displaystyle\\frac{M}{P_X}$ 이 증가함에 따라 $X$ 의 개별수요량 $Q_X$ 이 증가할 수 있음                    Price Effect Analysis      대체 효과(Substitution Effect; $E_1 \\rightarrow E_3$) : 특정 재화의 가격이 감소했을 때, 동일한 효용 수준을 유지하면서 상대적으로 더 저렴해진 재화를 더 많이 소비하고, 더 비싸진 재화를 덜 소비하는 효과              동일한 효용 수준을 유지하므로 무차별곡선에 변화가 없음      상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하므로 예산선의 기울기가 완만해짐      최적 선택 하 $Q_Y$ 일부가 $Q_X$ 으로 대체되므로 예산선과 무차별곡선의 접점이 우하향함            소득 효과(Income Effect; $E_3 \\rightarrow E_2$) : 특정 재화의 가격이 감소했을 때, 소비자가 동일한 예산 제약 하에서 취득 가능한 수량(구매력)이 증가하여 효용 수준이 변화하는 효과              상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 대체 효과 이후와 동일하므로 예산선은 대체 효과로 인해 완만해진 예산선과 평행함      실질 소득 수준이 증가하므로 예산선은 원점에서 멀어짐                  $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하므로 $X$ 절편이 우측으로 이동함          $Y$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_Y}$ 에는 변화가 없으므로 $Y$ 절편은 대체 효과 이전으로 회귀함                    VariationCompensating Variation      보상 변화(Compensating Variation; CV) : 특정 재화의 가격이 변화했을 때, 이전과 동일한 효용 수준을 누리기 위해 보상 받아야 하는 추가 소득              $P_X$ 가 감소함에 따라 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가하였음. 가격체계를 임의로 조정할 수 없는 상태에서 이전과 동일한 효용 수준으로 회귀하기 위해서는, 가격 변화 이전에 누렸던 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기가 완만해진 상태에서 기울기를 임의로 조정할 수 없는 경우, 가격 변화 이전의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 보상 변화가 됨.            보상수요곡선(Compensated Demand Curve) : 가격 효과를 반영한 개별수요곡선에서 소득 효과를 제외한 대체 효과, 혹은 보상 변화만을 반영한 개별수요곡선      Equivalent Variation      대등 변화(Equivalent Variation; EV) : 특정 재화의 가격이 변화했다고 가정했을 때 누릴 수 있는 효용 수준과 대등한 효용 수준을 누리기 위해 필요한 추가 소득              $P_X$ 가 감소한다고 가정한다면, 상대가격 $\\displaystyle\\frac{P_X}{P_Y}$ 이 감소하고, $X$ 에 대한 구매력 $\\displaystyle\\frac{M}{P_X}$ 이 증가할 것임. 이에 따라 누릴 수 있는 효용 수준이 상승할 것임. 실제로는 가격체계에 변함이 없는 상태에서 가정과 대등한 효용 수준을 누리기 위해서는, 가격 변화 이후 누릴 수 있는 효용 수준 하에서 최적 선택이 이루어지도록 예산 규모를 조정해야 함. 즉, 예산선의 기울기에 변함이 없는 경우, 가격 변화 이후의 무차별곡선과 접하는 수준까지 예산선을 평행이동해야 함. 예산선 평행이동 폭이 대등 변화가 됨.      "
  },
  
  {
    "title": "Consumer Theory (1) Utility Maximization under Budget Constraint",
    "url": "/posts/Consumer_Theory_1/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Consumer Theory",
    "date": "2019-07-16 00:00:00 +0900",
    





    
    "snippet": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Pr...",
    "content": "UtilityPreference System  선호체계(Preference System) : 상품묶음 간 선호관계를 평가하는 주관적 척도                  상품묶음(Commodity Bundle) : 개별소비자가 선택 가능한 여러 상품에 대하여 각 품목의 수량 조합\\[(X,Y)=(x,y)\\]                    선호관계(Preference Relation) : 임의의 상품묶음과 다른 상품묶음 간 선호의 우열관계\\[(x,y) \\succ (x', y')\\]              선호체계의 공리                  완비성(Completeness); 동일한 품목의 수량을 나타내는 상품묶음 사이의 선호관계를 비교할 수 있다.\\[A \\succ B \\; \\text{or} \\; B \\succ A \\; \\text{or} \\; A \\sim B \\quad \\text{for}\\;(A, B)^{\\forall} \\in X\\]                    이행성(Transitivity); 동일한 품목의 수량을 나타내는 상품묶음 A, B, C에 대하여 A보다 B를 선호하고, B보다 C를 선호하면 A보다 C를 선호한다.\\[A \\succ B \\; \\text{and} \\; B \\succ C \\implies A \\succ C \\quad \\text{for}\\; (A, B, C)^{\\forall} \\in X\\]                    강단조성(Strong Monotonicity); 상품묶음이 나타내는 두 가지 재화 중에서 임의의 재화에 대하여 다른 재화의 수량이 일정하다면 해당 상품의 수량이 더 높은 상품묶음을 선호한다.\\[x_i \\ge y_i \\; \\text{for all} \\; i \\; \\text{and} \\; x_i &gt; y_i \\; \\text{for some} \\; i \\implies A \\succ B \\quad \\text{for} \\; (A, B)^{\\forall} \\in X\\]                    연속성(Continuity); 두 상품묶음에 대한 선호도의 차이는 두 상품묶음이 나타내는 수량의 차이에 비례한다.\\[A \\succ B \\; \\text{and} \\; C \\approx A \\implies C \\succ B \\quad \\text{for}\\;(A, B, C)^{\\forall} \\in X\\]                    볼록성(Convexity); 극단적인 수량의 조합을 나타내는 상품묶음보다는 두 가지 재화의 수량이 고루 섞여 있는 상품묶음을 선호한다.\\[\\begin{aligned} \\lambda A + (1 - \\lambda)B \\succ A \\quad \\text{for} \\quad &amp;\\lambda^{\\forall} \\in (0, 1)\\\\ &amp;(A, B)^{\\forall} \\in X \\end{aligned}\\]            Utility      효용함수(Utility Function) : 상품묶음과 선호도 값 사이의 상관관계를 나타내는 함수\\[\\begin{aligned}  U^{(1)}:&amp; \\quad U(A)=10, U(B)=20, U(C)=30\\\\  U^{(2)}:&amp; \\quad U(A)=40, U(B)=60, U(C)=80  \\end{aligned}\\]          $U^{(1)}$ 과 $U^{(2)}$ 는 재화에 대하여 선호도 값을 다르게 매겼으나, 선호관계를 동일하게 평가하였음. 따라서 두 효용함수는 실질적으로는 무차별함. 이처럼 효용함수는 선호도 값의 기수성이 아니라 서수성이 중요함.            무차별곡선(Indifference curve) : 재화 $X,Y$ 에 대하여, 동일한(무차별한) 효용 수준을 누릴 수 있는 상품묶음 $(X, Y)$ 의 집합    \\[U(x,y)=u_{i}\\]          완비성(Completeness); 동일한 효용함수의 상이한 효용수준을 나타내는 두 개의 무차별곡선은 교차하지 않는다.      이행성(Transitivity); 무차별곡선은 원점에서 멀수록 더 높은 효용수준을 나타낸다.      강단조성(Strong Monotonicity); 무차별곡선은 우하향한다.      연속성(Continuity); 제1사분면 위에 존재하는 임의의 점에 대하여 그 점을 지나는 무차별곡선이 하나 존재한다.      볼록성(Convexity); 무차별곡선은 원점에 대하여 볼록한 모양을 가진다.      Subjective Rate of Substitution      한계효용(Marginal Utility; MU) : 임의의 재화를 한 단위 추가 소비함으로써 추가로 누릴 수 있는 효용 수준\\[MU_{X}:= \\frac{\\partial U}{\\partial X}\\]        한계대체율(Marginal Rate of Substitution; MRS) : 재화 $X,Y$ 에 대하여, 동일한 효용 수준에서 해당 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot MU_{X} + \\Delta Y \\cdot MU_{Y} = 0\\]\\[\\therefore MRS_{X,Y}:= -\\frac{\\Delta Y}{\\Delta X} = \\frac{MU_{X}}{MU_{Y}}\\]        한계대체율 체감의 법칙 : 임의의 상품에 대하여, 해당 상품의 보유량이 증가할수록 동일한 효용수준에서 해당 상품을 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분이 감소하는 현상\\[\\frac{\\partial MRS_{X,Y}}{\\partial X} \\prec 0\\]  Budget Constraint      예산선(Budget Line) : 주어진 예산($M$)과 가격 상황($P_{X}, P_{Y}$)에 맞게 취득할 수 있는 상품묶음들의 집합\\[\\begin{aligned}  (x,y) \\quad \\text{s.t.}\\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M  \\end{aligned}\\]        상대가격(Relative Price) : 재화 $X,Y$ 에 대하여, 동일한 예산 수준에서 특정 재화를 한 단위 추가 소비하기 위해 포기해야 하는 관련재 소비분\\[\\Delta X \\cdot P_{X} + \\Delta Y \\cdot P_{Y} = 0\\]\\[\\therefore - \\frac{\\Delta Y}{\\Delta X} = \\frac{P_{X}}{P_{Y}}\\]  Utility Maximization under Budget Constraint\\[\\max{U(x,y)} \\quad \\text{s.t.} \\; x \\cdot P_{X} + y \\cdot P_{Y} \\le M\\]      무차별곡선의 접선의 기울기 : X재의 Y재에 대한 주관적 교환비율로서 한계대체율\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{MU_{X}}{MU_{Y}}\\]        예산선의 기울기 : X재의 Y재에 대한 객관적 교환비율로서 상대가격\\[-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}\\]        예산선과 무차별곡선의 접점 : 예산 제약 하 효용을 극대화하는 상품묶음\\[\\begin{aligned}  \\frac{MU_{X}}{MU_{Y}}=-\\frac{\\Delta Y}{\\Delta X}=\\frac{P_{X}}{P_{Y}}  \\end{aligned}\\]        최적 선택 하에서는 $\\displaystyle\\frac{MU_{X}}{P_{X}}$ 과 $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ 이 일치함\\[\\frac{MU_{X}}{MU_{Y}}=\\frac{P_{X}}{P_{Y}} \\Leftrightarrow \\frac{MU_{X}}{P_{X}}=\\frac{MU_{Y}}{P_{Y}}\\]          $\\displaystyle\\frac{MU_{X}}{P_{X}}$ : 화폐 단위당 취득 가능한 X재 단위의 한계효용      $\\displaystyle\\frac{MU_{Y}}{P_{Y}}$ : 화폐 단위당 취득 가능한 Y재 단위의 한계효용      이미지 출처  https://enotesworld.com/price-budget-line-or-budget-constraint/"
  },
  
  {
    "title": "What? Microeconomics",
    "url": "/posts/What_Micro/",
    "categories": "Economics, Microeconomics",
    "tags": "Economics, Microeconomics, Optimization, Equilibrium",
    "date": "2019-07-15 00:00:00 +0900",
    





    
    "snippet": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원...",
    "content": "What? Microeconomics  미시경제학(Microeconomics) : 한 사회 구성원들의 경제 활동 과정을 연구하는 학문          경제 활동 : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득하기 위한 활동        경제제도(Economy) : 경제주체가 주어진 제약 하에서 욕망을 최대한 충족시키는 자원 조합을 취득할 수 있도록 마련한 절차          시장경제체제(Market Economy) : 한 사회의 자원 배분이 그 구성원들의 경제 활동으로써(혹은 시장 수요와 공급에 의해) 결정되는 제도      계획경제체제(Command Economy) : 한 사회의 자원 배분 및 그 구성원들의 경제 활동이 정부에 의해 결정되는 제도        시장경제체제의 운용 원리          모든 선택에는 대가가 있다.      선택의 대가는 그것을 얻기 위해 포기한 것이다.      합리적 판단은 한계적으로 이루어진다.      경제주체는 경제적 유인에 반응한다.      자유거래는 모든 경제주체를 이롭게 한다.      일반적으로 시장이 경제활동을 조직하는 좋은 수단이다.      경우에 따라 정부가 시장의 성과를 개선할 수 있다.      한 나라의 생활수준은 그 나라의 생산 능력에 달려 있다.      통화량이 지나치게 증가하면 물가는 상승한다.      단기적으로는 인플레이션과 실업 사이에 상충관계가 있다.      Equilibrium      보이지 않는 손(Invisible Hand)          시장 참여자들이 자신의 이익을 추구하는 과정에서 가격 메커니즘을 통해 사회 전체의 자원 배분이 효율적으로 이루어지는 현상, 혹은 이러한 현상을 가능케 하는 메커니즘              교환(Exchange) : 이상적인 자원 조합을 구성하기 위해 상대가격이 낮은 자원을 지불하여 상대가격이 높은 자원을 구입하는 행위      상대가격(Relative Price) : 다른 자원의 단위로 측정한 어떤 자원의 가치로서, 시장 참여자 상호간에 합의된 자원 간 상대적 교환 비율      가격(Price) : 화폐로써 수량화된 자원의 가치로서, 화폐 단위당 자원의 절대적 교환 비율            최적화(Optimization) : 시장 참여자들이 제약 하에서 목표를 최대화하거나 최소화하는 과정으로서, 경제 활동 혹은 경제 활동의 결과 실현된 상태    수요자의 최적 의사결정          쾌락의 최대화 : 동일한 가치를 지불함으로써 취득 가능한 자원 단위를 최대화함      고통의 최소화 : 동일한 자원 단위를 취득하기 위해 지불해야 하는 가치를 최소화함      최대지불의사(Willingness to Pay; WTP) : 어떤 시장 참여자가 특정 자원을 취득하기 위해 포기할 수 있는 최대 가치        공급자의 최적 의사결정          쾌락의 극대화 : 동일한 자원 단위를 지불함으로써 취득 가능한 가치를 최대화함      고통의 최소화 : 동일한 가치를 취득하기 위해 교환해야 하는 자원 단위를 최소화함      유보가격(Reservation Price) : 어떤 시장 참여자가 특정 자원을 포기하는 대신 취득하고자 하는 최소 가치            균형(Equilibrium) : 자원의 교환 가치를 낮추려는 힘과 높이려는 힘이 맞아떨어져서 외부 교란 요인이 없는 한 유지되는 상태              존재성 : 균형이 존재하는 성질      유용성 : 균형이 적을수록 유용한 성질      안정성 : 다수의 균형이 존재하는 경우 안정적인 균형이 선호되는 성질      Market DemandDeterminants      시장수요결정변수(Market Demand Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장수요($Y$)를 결정하는 요인($X$)\\[f_{D}:P;M,P_{R},N \\rightarrow Q_{D}\\]        가격(Price; $P$) : 수요자가 자원을 취득하기 위해 지불해야 할 가치                  수요의 법칙(Law of Demand; LOD) : 가격과 수요량 간 음의 상관관계\\[\\frac{\\Delta Q_{D}}{\\Delta P} &lt; 0\\]                  소득수준(Income; $M$) : 수요자가 자원을 취득하기 위해 지불 가능한 예산 규모        관련재의 가격(Prices of Substitutes and Complements; $P_{R}$)        수요자 수(Population; $N$)  Elasticity  수요의 탄력성(Elasticity of Demand) : 시장수요결정변수의 변화에 따른 시장수요의 변동성          $\\varepsilon &gt; 1$ : 시장수요결정변수에 대하여 탄력적      $\\varepsilon = 1$ : 시장수요결정변수에 대하여 단위탄력적      $\\varepsilon &lt; 1$ : 시장수요결정변수에 대하여 비탄력적            수요량의 가격 탄력성(Price Elasticity of Demand; PED) : 가격의 단위 변화에 따른 시장수요량의 변동성\\[\\varepsilon_{P}:= -\\frac{\\Delta Q_{D}/Q_D}{\\Delta P/P} \\quad (\\because \\text{LOD})\\]        수요의 소득 탄력성(Income Elasticity of Demand; IED) : 소득수준의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{M}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta M/M}\\]                  정상재(Normal Goods) : 소득수준의 변동성과 시장수요의 변동성이 비례하는 자원\\[\\varepsilon_{M} &gt; 0\\]                              사치재(Luxury Goods) : 소득수준의 단위 변화에 따른 수요의 변동성이 탄력적인 자원\\[\\varepsilon_{M} &gt; 1\\]                                필수재(Necessities) : 소득수준의 단위 변화에 따른 수요의 변동성이 비탄력적인 자원\\[0 &lt; \\varepsilon_{M} &lt; 1\\]                                      열등재(Inferior Goods) : 소득수준의 변동성과 시장수요의 변동성이 반비례하는 자원\\[\\varepsilon_{M} &lt; 0\\]                  수요의 교차 탄력성(Cross-Price Elasticity of Demand; XED) : 관련재 가격의 단위 변화에 따른 시장수요의 변동성\\[\\varepsilon_{C}:= \\frac{\\Delta Q_{D}/Q_D}{\\Delta P_{R}/P_R}\\]                  대체재(Substitutes) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 증가하는 경우\\[\\varepsilon_{C} &gt; 0\\]                    보완재(Complements) : 어떤 자원의 가격이 상승할 때 다른 자원의 시장수요가 감소하는 경우\\[\\varepsilon_{C} &lt; 0\\]                    독립재(Unrelated Goods) : 어떤 자원의 가격 변동성이 다른 자원의 시장수요 변동성에 영향을 미치지 않는 경우\\[\\varepsilon_{C} = 0\\]            Market SupplyDeterminants      시장공급결정변수(Market Supply Determinants) : 임의의 자원을 교환하는 시장에서 해당 자원의 시장공급($Y$)을 결정하는 요인($X$)\\[f_{S}:P;w,v,H,C \\rightarrow Q_{D}\\]        가격(Price; $P$) : 공급자가 자원 단위를 공급함으로써 취득하는 가치                  공급의 법칙(Law of Supply; LOS) : 가격과 공급량 간 양의 상관관계\\[\\frac{\\Delta Q_{S}}{\\Delta P} &gt; 0\\]              자원 생산 시 투입되는 생산요소의 단위당 가격          임금(Wage; $w$) : 노동의 단위당 가격      임대료(Rent; $v$) : 자본의 단위당 가격            기술수준(Hechnics; $H$)    공급자 수(Population; $C$)Elasticity  공급의 탄력성(Elasticity of Supply) : 시장공급결정변수의 변화에 따른 시장공급의 변동성          $\\epsilon &gt; 1$ : 시장공급결정변수에 대하여 탄력적      $\\epsilon = 1$ : 시장공급결정변수에 대하여 단위탄력적      $\\epsilon &lt; 1$ : 시장공급결정변수에 대하여 비탄력적            공급량의 가격 탄력성(Price Elasticity of Supply) : 가격의 단위 변화에 따른 시장공급량의 변동성\\[\\epsilon_{P}:= \\frac{\\Delta Q_{S}/Q_S}{\\Delta P/P} \\quad (\\because \\text{LOS})\\]  이미지 출처  https://policonomics.com/supply-and-demand/  https://thismatter.com/economics/supply.htm"
  }
  
]


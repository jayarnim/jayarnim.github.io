

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://jayarnim.github.io/</id>
  <title>Data Scientist</title>
  <subtitle>A minimal, responsive and feature-rich Jekyll theme for technical writing.</subtitle>
  <updated>2025-12-08T04:02:03+09:00</updated>
  <author>
    <name>jayarnim</name>
    <uri>https://jayarnim.github.io/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="https://jayarnim.github.io/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="https://jayarnim.github.io/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2025 jayarnim </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Hidden Markov Model</title>
    <link href="https://jayarnim.github.io/posts/hmm/" rel="alternate" type="text/html" title="Hidden Markov Model" />
    <published>2025-08-07T00:00:00+09:00</published>
  
    <updated>2025-08-07T00:00:00+09:00</updated>
  
    <id>https://jayarnim.github.io/posts/hmm/</id>
    <content src="https://jayarnim.github.io/posts/hmm/" />
    <author>
      <name>jayarnim</name>
    </author>

  
    
    <category term="5.BAYES" />
    
    <category term="4.stochastic process" />
    
  

  <summary>Markov Chain



  
    The Markov Property is a property in which past information is concentrated in the current state, so that the future state is independent of the past state conditionally on the current state.

\[\begin{gathered}
  X(t+1)\perp X(0),X(1),\cdots,X(t-1)\mid X(t)
  \end{gathered}\]
  
  
    For a random variable sequence \(\{X(t):t\in T\}\) defined on a discrete time space \(...</summary>

  </entry>

  
  <entry>
    <title>GP (3) Random Fourier Features Gaussian Process</title>
    <link href="https://jayarnim.github.io/posts/gp_rffgp/" rel="alternate" type="text/html" title="GP (3) Random Fourier Features Gaussian Process" />
    <published>2025-08-06T00:00:00+09:00</published>
  
    <updated>2025-08-06T00:00:00+09:00</updated>
  
    <id>https://jayarnim.github.io/posts/gp_rffgp/</id>
    <content src="https://jayarnim.github.io/posts/gp_rffgp/" />
    <author>
      <name>jayarnim</name>
    </author>

  
    
    <category term="5.BAYES" />
    
    <category term="4.stochastic process" />
    
  

  <summary>Random Fourier Feature Gaussian Process


  
    Random Fourier Feature Gaussian Process is a technique for approximating an infinite-dimensional function space based on kernel functions to a finite-dimensional function space based on real sinusoids.
  
  
    nonparametric function:

\[f(x)=\sum_{i=1}^{\infty}{\beta_{i}k(x,x_{i})}\]
  
  
    nonparametric function space:

\[\mathcal{F}
  =\ma...</summary>

  </entry>

  
  <entry>
    <title>Fourier Analysis</title>
    <link href="https://jayarnim.github.io/posts/fourier/" rel="alternate" type="text/html" title="Fourier Analysis" />
    <published>2025-08-05T00:00:00+09:00</published>
  
    <updated>2025-08-05T00:00:00+09:00</updated>
  
    <id>https://jayarnim.github.io/posts/fourier/</id>
    <content src="https://jayarnim.github.io/posts/fourier/" />
    <author>
      <name>jayarnim</name>
    </author>

  
    
    <category term="5.BAYES" />
    
    <category term="4.stochastic process" />
    
  

  <summary>Euler’s formula



  
    Euler’s formula is a formula that shows that the Taylor series of a complex exponential function can be expressed as a trigonometric function.

\[\begin{aligned}
  \exp{i\theta}
  &amp;amp;amp;=\sum_{n=0}^{\infty}{\frac{(i\theta)^{n}}{n!}}\\
  &amp;amp;amp;=\sum_{k=0}^{\infty}{\frac{(i\theta)^{2k}}{(2k)!}}+\sum_{k=0}^{\infty}{\frac{(i\theta)^{2k+1}}{(2k+1)!}}\\
  &amp;amp;amp;=\sum_{k=0}^{\in...</summary>

  </entry>

  
  <entry>
    <title>GP (2) Sparse Gaussian Process</title>
    <link href="https://jayarnim.github.io/posts/gp_sgp/" rel="alternate" type="text/html" title="GP (2) Sparse Gaussian Process" />
    <published>2025-08-04T00:00:00+09:00</published>
  
    <updated>2025-08-04T00:00:00+09:00</updated>
  
    <id>https://jayarnim.github.io/posts/gp_sgp/</id>
    <content src="https://jayarnim.github.io/posts/gp_sgp/" />
    <author>
      <name>jayarnim</name>
    </author>

  
    
    <category term="5.BAYES" />
    
    <category term="4.stochastic process" />
    
  

  <summary>sparse gaussian process



  sparse gaussian process is a technique that achieves the following two advantages by introducing $M$ inducing points that can represent all $N\to\infty$ observations:
    
      infinite-dimensional function space is projected onto a low-dimensional induction point space, thereby ensuring computational efficiency.
      uncertainty is restricted to the low-dimension...</summary>

  </entry>

  
  <entry>
    <title>GP (1) Gaussian Process</title>
    <link href="https://jayarnim.github.io/posts/gp_gp/" rel="alternate" type="text/html" title="GP (1) Gaussian Process" />
    <published>2025-08-03T00:00:00+09:00</published>
  
    <updated>2025-08-03T00:00:00+09:00</updated>
  
    <id>https://jayarnim.github.io/posts/gp_gp/</id>
    <content src="https://jayarnim.github.io/posts/gp_gp/" />
    <author>
      <name>jayarnim</name>
    </author>

  
    
    <category term="5.BAYES" />
    
    <category term="4.stochastic process" />
    
  

  <summary>gaussian process



  
    gaussian process is a nonparametric stochastic process that uses the mean and covariance structure of function values as prior information to infer the function distribution, assuming that the function values defined for an arbitrary input set jointly follow a multivariate normal distribution.
  
  
    function definition:

\[y_{i}=f(X_{i})+\epsilon_{i}, \quad \epsil...</summary>

  </entry>

</feed>


